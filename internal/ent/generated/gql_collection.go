// Code generated by ent, DO NOT EDIT.

package generated

import (
	"context"
	"database/sql/driver"
	"fmt"

	"entgo.io/contrib/entgql"
	"entgo.io/ent/dialect/sql"
	"github.com/99designs/gqlgen/graphql"
	"github.com/theopenlane/core/internal/ent/generated/actionplan"
	"github.com/theopenlane/core/internal/ent/generated/actionplanhistory"
	"github.com/theopenlane/core/internal/ent/generated/apitoken"
	"github.com/theopenlane/core/internal/ent/generated/asset"
	"github.com/theopenlane/core/internal/ent/generated/assethistory"
	"github.com/theopenlane/core/internal/ent/generated/contact"
	"github.com/theopenlane/core/internal/ent/generated/contacthistory"
	"github.com/theopenlane/core/internal/ent/generated/control"
	"github.com/theopenlane/core/internal/ent/generated/controlhistory"
	"github.com/theopenlane/core/internal/ent/generated/controlimplementation"
	"github.com/theopenlane/core/internal/ent/generated/controlimplementationhistory"
	"github.com/theopenlane/core/internal/ent/generated/controlobjective"
	"github.com/theopenlane/core/internal/ent/generated/controlobjectivehistory"
	"github.com/theopenlane/core/internal/ent/generated/controlscheduledjob"
	"github.com/theopenlane/core/internal/ent/generated/controlscheduledjobhistory"
	"github.com/theopenlane/core/internal/ent/generated/customdomain"
	"github.com/theopenlane/core/internal/ent/generated/customdomainhistory"
	"github.com/theopenlane/core/internal/ent/generated/dnsverification"
	"github.com/theopenlane/core/internal/ent/generated/dnsverificationhistory"
	"github.com/theopenlane/core/internal/ent/generated/documentdata"
	"github.com/theopenlane/core/internal/ent/generated/documentdatahistory"
	"github.com/theopenlane/core/internal/ent/generated/entity"
	"github.com/theopenlane/core/internal/ent/generated/entityhistory"
	"github.com/theopenlane/core/internal/ent/generated/entitytype"
	"github.com/theopenlane/core/internal/ent/generated/entitytypehistory"
	"github.com/theopenlane/core/internal/ent/generated/event"
	"github.com/theopenlane/core/internal/ent/generated/evidence"
	"github.com/theopenlane/core/internal/ent/generated/evidencehistory"
	"github.com/theopenlane/core/internal/ent/generated/export"
	"github.com/theopenlane/core/internal/ent/generated/file"
	"github.com/theopenlane/core/internal/ent/generated/filehistory"
	"github.com/theopenlane/core/internal/ent/generated/group"
	"github.com/theopenlane/core/internal/ent/generated/grouphistory"
	"github.com/theopenlane/core/internal/ent/generated/groupmembership"
	"github.com/theopenlane/core/internal/ent/generated/groupmembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/groupsetting"
	"github.com/theopenlane/core/internal/ent/generated/groupsettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/hush"
	"github.com/theopenlane/core/internal/ent/generated/hushhistory"
	"github.com/theopenlane/core/internal/ent/generated/integration"
	"github.com/theopenlane/core/internal/ent/generated/integrationhistory"
	"github.com/theopenlane/core/internal/ent/generated/internalpolicy"
	"github.com/theopenlane/core/internal/ent/generated/internalpolicyhistory"
	"github.com/theopenlane/core/internal/ent/generated/invite"
	"github.com/theopenlane/core/internal/ent/generated/jobresult"
	"github.com/theopenlane/core/internal/ent/generated/jobrunner"
	"github.com/theopenlane/core/internal/ent/generated/jobrunnerregistrationtoken"
	"github.com/theopenlane/core/internal/ent/generated/jobrunnertoken"
	"github.com/theopenlane/core/internal/ent/generated/mappabledomain"
	"github.com/theopenlane/core/internal/ent/generated/mappabledomainhistory"
	"github.com/theopenlane/core/internal/ent/generated/mappedcontrol"
	"github.com/theopenlane/core/internal/ent/generated/mappedcontrolhistory"
	"github.com/theopenlane/core/internal/ent/generated/narrative"
	"github.com/theopenlane/core/internal/ent/generated/narrativehistory"
	"github.com/theopenlane/core/internal/ent/generated/note"
	"github.com/theopenlane/core/internal/ent/generated/notehistory"
	"github.com/theopenlane/core/internal/ent/generated/onboarding"
	"github.com/theopenlane/core/internal/ent/generated/organization"
	"github.com/theopenlane/core/internal/ent/generated/organizationhistory"
	"github.com/theopenlane/core/internal/ent/generated/organizationsetting"
	"github.com/theopenlane/core/internal/ent/generated/organizationsettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/orgmembership"
	"github.com/theopenlane/core/internal/ent/generated/orgmembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/orgsubscription"
	"github.com/theopenlane/core/internal/ent/generated/orgsubscriptionhistory"
	"github.com/theopenlane/core/internal/ent/generated/personalaccesstoken"
	"github.com/theopenlane/core/internal/ent/generated/procedure"
	"github.com/theopenlane/core/internal/ent/generated/procedurehistory"
	"github.com/theopenlane/core/internal/ent/generated/program"
	"github.com/theopenlane/core/internal/ent/generated/programhistory"
	"github.com/theopenlane/core/internal/ent/generated/programmembership"
	"github.com/theopenlane/core/internal/ent/generated/programmembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/risk"
	"github.com/theopenlane/core/internal/ent/generated/riskhistory"
	"github.com/theopenlane/core/internal/ent/generated/scan"
	"github.com/theopenlane/core/internal/ent/generated/scanhistory"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjob"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjobhistory"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjobrun"
	"github.com/theopenlane/core/internal/ent/generated/standard"
	"github.com/theopenlane/core/internal/ent/generated/standardhistory"
	"github.com/theopenlane/core/internal/ent/generated/subcontrol"
	"github.com/theopenlane/core/internal/ent/generated/subcontrolhistory"
	"github.com/theopenlane/core/internal/ent/generated/subprocessor"
	"github.com/theopenlane/core/internal/ent/generated/subprocessorhistory"
	"github.com/theopenlane/core/internal/ent/generated/subscriber"
	"github.com/theopenlane/core/internal/ent/generated/task"
	"github.com/theopenlane/core/internal/ent/generated/taskhistory"
	"github.com/theopenlane/core/internal/ent/generated/template"
	"github.com/theopenlane/core/internal/ent/generated/templatehistory"
	"github.com/theopenlane/core/internal/ent/generated/tfasetting"
	"github.com/theopenlane/core/internal/ent/generated/trustcenter"
	"github.com/theopenlane/core/internal/ent/generated/trustcentercompliance"
	"github.com/theopenlane/core/internal/ent/generated/trustcentercompliancehistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterhistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersetting"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersubprocessor"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersubprocessorhistory"
	"github.com/theopenlane/core/internal/ent/generated/user"
	"github.com/theopenlane/core/internal/ent/generated/userhistory"
	"github.com/theopenlane/core/internal/ent/generated/usersetting"
	"github.com/theopenlane/core/internal/ent/generated/usersettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/webauthn"
)

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (at *APITokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*APITokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return at, nil
	}
	if err := at.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return at, nil
}

func (at *APITokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(apitoken.Columns))
		selectedFields = []string{apitoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: at.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			at.withOwner = query
			if _, ok := fieldSeen[apitoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldOwnerID)
				fieldSeen[apitoken.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[apitoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldCreatedAt)
				fieldSeen[apitoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[apitoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldUpdatedAt)
				fieldSeen[apitoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[apitoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldCreatedBy)
				fieldSeen[apitoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[apitoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldUpdatedBy)
				fieldSeen[apitoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[apitoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldTags)
				fieldSeen[apitoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[apitoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldOwnerID)
				fieldSeen[apitoken.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[apitoken.FieldName]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldName)
				fieldSeen[apitoken.FieldName] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[apitoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldToken)
				fieldSeen[apitoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[apitoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldExpiresAt)
				fieldSeen[apitoken.FieldExpiresAt] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[apitoken.FieldDescription]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldDescription)
				fieldSeen[apitoken.FieldDescription] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[apitoken.FieldScopes]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldScopes)
				fieldSeen[apitoken.FieldScopes] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[apitoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldLastUsedAt)
				fieldSeen[apitoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[apitoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldIsActive)
				fieldSeen[apitoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[apitoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedReason)
				fieldSeen[apitoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[apitoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedBy)
				fieldSeen[apitoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[apitoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedAt)
				fieldSeen[apitoken.FieldRevokedAt] = struct{}{}
			}
		case "ssoAuthorizations":
			if _, ok := fieldSeen[apitoken.FieldSSOAuthorizations]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldSSOAuthorizations)
				fieldSeen[apitoken.FieldSSOAuthorizations] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		at.Select(selectedFields...)
	}
	return nil
}

type apitokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []APITokenPaginateOption
}

func newAPITokenPaginateArgs(rv map[string]any) *apitokenPaginateArgs {
	args := &apitokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*APITokenOrder:
			args.opts = append(args.opts, WithAPITokenOrder(v))
		case []any:
			var orders []*APITokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &APITokenOrder{Field: &APITokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAPITokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*APITokenWhereInput); ok {
		args.opts = append(args.opts, WithAPITokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ap *ActionPlanQuery) CollectFields(ctx context.Context, satisfies ...string) (*ActionPlanQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ap, nil
	}
	if err := ap.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ap, nil
}

func (ap *ActionPlanQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(actionplan.Columns))
		selectedFields = []string{actionplan.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ap.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			ap.withApprover = query
			if _, ok := fieldSeen[actionplan.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApproverID)
				fieldSeen[actionplan.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ap.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			ap.withDelegate = query
			if _, ok := fieldSeen[actionplan.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDelegateID)
				fieldSeen[actionplan.FieldDelegateID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: ap.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			ap.withOwner = query
			if _, ok := fieldSeen[actionplan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldOwnerID)
				fieldSeen[actionplan.FieldOwnerID] = struct{}{}
			}

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: ap.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ap.loadTotal = append(ap.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(actionplan.RisksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.RisksPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.RisksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.RisksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					ap.loadTotal = append(ap.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.RisksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ap.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: ap.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ap.loadTotal = append(ap.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(actionplan.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					ap.loadTotal = append(ap.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ap.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: ap.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ap.loadTotal = append(ap.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(actionplan.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					ap.loadTotal = append(ap.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ap.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: ap.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ap.loadTotal = append(ap.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(actionplan.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					ap.loadTotal = append(ap.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ap.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[actionplan.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCreatedAt)
				fieldSeen[actionplan.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[actionplan.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldUpdatedAt)
				fieldSeen[actionplan.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[actionplan.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCreatedBy)
				fieldSeen[actionplan.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[actionplan.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldUpdatedBy)
				fieldSeen[actionplan.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[actionplan.FieldTags]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTags)
				fieldSeen[actionplan.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[actionplan.FieldRevision]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRevision)
				fieldSeen[actionplan.FieldRevision] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[actionplan.FieldName]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldName)
				fieldSeen[actionplan.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[actionplan.FieldStatus]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldStatus)
				fieldSeen[actionplan.FieldStatus] = struct{}{}
			}
		case "actionPlanType":
			if _, ok := fieldSeen[actionplan.FieldActionPlanType]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanType)
				fieldSeen[actionplan.FieldActionPlanType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[actionplan.FieldDetails]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDetails)
				fieldSeen[actionplan.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[actionplan.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApprovalRequired)
				fieldSeen[actionplan.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[actionplan.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldReviewDue)
				fieldSeen[actionplan.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[actionplan.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldReviewFrequency)
				fieldSeen[actionplan.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[actionplan.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApproverID)
				fieldSeen[actionplan.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[actionplan.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDelegateID)
				fieldSeen[actionplan.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[actionplan.FieldSummary]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSummary)
				fieldSeen[actionplan.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[actionplan.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTagSuggestions)
				fieldSeen[actionplan.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedTagSuggestions)
				fieldSeen[actionplan.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[actionplan.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldControlSuggestions)
				fieldSeen[actionplan.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedControlSuggestions)
				fieldSeen[actionplan.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[actionplan.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldImprovementSuggestions)
				fieldSeen[actionplan.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedImprovementSuggestions)
				fieldSeen[actionplan.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[actionplan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldOwnerID)
				fieldSeen[actionplan.FieldOwnerID] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[actionplan.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDueDate)
				fieldSeen[actionplan.FieldDueDate] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[actionplan.FieldPriority]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldPriority)
				fieldSeen[actionplan.FieldPriority] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[actionplan.FieldSource]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSource)
				fieldSeen[actionplan.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ap.Select(selectedFields...)
	}
	return nil
}

type actionplanPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ActionPlanPaginateOption
}

func newActionPlanPaginateArgs(rv map[string]any) *actionplanPaginateArgs {
	args := &actionplanPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ActionPlanOrder:
			args.opts = append(args.opts, WithActionPlanOrder(v))
		case []any:
			var orders []*ActionPlanOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ActionPlanOrder{Field: &ActionPlanOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithActionPlanOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ActionPlanWhereInput); ok {
		args.opts = append(args.opts, WithActionPlanFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (aph *ActionPlanHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ActionPlanHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return aph, nil
	}
	if err := aph.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return aph, nil
}

func (aph *ActionPlanHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(actionplanhistory.Columns))
		selectedFields = []string{actionplanhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[actionplanhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldHistoryTime)
				fieldSeen[actionplanhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[actionplanhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldRef)
				fieldSeen[actionplanhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[actionplanhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldOperation)
				fieldSeen[actionplanhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[actionplanhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldCreatedAt)
				fieldSeen[actionplanhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[actionplanhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldUpdatedAt)
				fieldSeen[actionplanhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[actionplanhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldCreatedBy)
				fieldSeen[actionplanhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[actionplanhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldUpdatedBy)
				fieldSeen[actionplanhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[actionplanhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldTags)
				fieldSeen[actionplanhistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[actionplanhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldRevision)
				fieldSeen[actionplanhistory.FieldRevision] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[actionplanhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldName)
				fieldSeen[actionplanhistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[actionplanhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldStatus)
				fieldSeen[actionplanhistory.FieldStatus] = struct{}{}
			}
		case "actionPlanType":
			if _, ok := fieldSeen[actionplanhistory.FieldActionPlanType]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldActionPlanType)
				fieldSeen[actionplanhistory.FieldActionPlanType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[actionplanhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDetails)
				fieldSeen[actionplanhistory.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[actionplanhistory.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldApprovalRequired)
				fieldSeen[actionplanhistory.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[actionplanhistory.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldReviewDue)
				fieldSeen[actionplanhistory.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[actionplanhistory.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldReviewFrequency)
				fieldSeen[actionplanhistory.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[actionplanhistory.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldApproverID)
				fieldSeen[actionplanhistory.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[actionplanhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDelegateID)
				fieldSeen[actionplanhistory.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[actionplanhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldSummary)
				fieldSeen[actionplanhistory.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldTagSuggestions)
				fieldSeen[actionplanhistory.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDismissedTagSuggestions)
				fieldSeen[actionplanhistory.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldControlSuggestions)
				fieldSeen[actionplanhistory.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDismissedControlSuggestions)
				fieldSeen[actionplanhistory.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldImprovementSuggestions)
				fieldSeen[actionplanhistory.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDismissedImprovementSuggestions)
				fieldSeen[actionplanhistory.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[actionplanhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldOwnerID)
				fieldSeen[actionplanhistory.FieldOwnerID] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[actionplanhistory.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDueDate)
				fieldSeen[actionplanhistory.FieldDueDate] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[actionplanhistory.FieldPriority]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldPriority)
				fieldSeen[actionplanhistory.FieldPriority] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[actionplanhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldSource)
				fieldSeen[actionplanhistory.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		aph.Select(selectedFields...)
	}
	return nil
}

type actionplanhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ActionPlanHistoryPaginateOption
}

func newActionPlanHistoryPaginateArgs(rv map[string]any) *actionplanhistoryPaginateArgs {
	args := &actionplanhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ActionPlanHistoryOrder{Field: &ActionPlanHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithActionPlanHistoryOrder(order))
			}
		case *ActionPlanHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithActionPlanHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ActionPlanHistoryWhereInput); ok {
		args.opts = append(args.opts, WithActionPlanHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (a *AssetQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssetQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return a, nil
	}
	if err := a.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return a, nil
}

func (a *AssetQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(asset.Columns))
		selectedFields = []string{asset.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: a.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			a.withOwner = query
			if _, ok := fieldSeen[asset.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, asset.FieldOwnerID)
				fieldSeen[asset.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: a.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					a.loadTotal = append(a.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(asset.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					a.loadTotal = append(a.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			a.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: a.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					a.loadTotal = append(a.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.EditorsColumn), ids...))
						})
						if err := query.GroupBy(asset.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					a.loadTotal = append(a.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			a.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: a.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					a.loadTotal = append(a.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.ViewersColumn), ids...))
						})
						if err := query.GroupBy(asset.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					a.loadTotal = append(a.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			a.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: a.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					a.loadTotal = append(a.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.ScansTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(asset.ScansPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.ScansPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.ScansPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.ScansPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					a.loadTotal = append(a.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ScansPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			a.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: a.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					a.loadTotal = append(a.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(asset.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					a.loadTotal = append(a.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			a.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: a.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					a.loadTotal = append(a.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(asset.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					a.loadTotal = append(a.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			a.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[asset.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, asset.FieldCreatedAt)
				fieldSeen[asset.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[asset.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, asset.FieldUpdatedAt)
				fieldSeen[asset.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[asset.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, asset.FieldCreatedBy)
				fieldSeen[asset.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[asset.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, asset.FieldUpdatedBy)
				fieldSeen[asset.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[asset.FieldTags]; !ok {
				selectedFields = append(selectedFields, asset.FieldTags)
				fieldSeen[asset.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[asset.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, asset.FieldOwnerID)
				fieldSeen[asset.FieldOwnerID] = struct{}{}
			}
		case "assetType":
			if _, ok := fieldSeen[asset.FieldAssetType]; !ok {
				selectedFields = append(selectedFields, asset.FieldAssetType)
				fieldSeen[asset.FieldAssetType] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[asset.FieldName]; !ok {
				selectedFields = append(selectedFields, asset.FieldName)
				fieldSeen[asset.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[asset.FieldDescription]; !ok {
				selectedFields = append(selectedFields, asset.FieldDescription)
				fieldSeen[asset.FieldDescription] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[asset.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, asset.FieldIdentifier)
				fieldSeen[asset.FieldIdentifier] = struct{}{}
			}
		case "website":
			if _, ok := fieldSeen[asset.FieldWebsite]; !ok {
				selectedFields = append(selectedFields, asset.FieldWebsite)
				fieldSeen[asset.FieldWebsite] = struct{}{}
			}
		case "cpe":
			if _, ok := fieldSeen[asset.FieldCpe]; !ok {
				selectedFields = append(selectedFields, asset.FieldCpe)
				fieldSeen[asset.FieldCpe] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[asset.FieldCategories]; !ok {
				selectedFields = append(selectedFields, asset.FieldCategories)
				fieldSeen[asset.FieldCategories] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		a.Select(selectedFields...)
	}
	return nil
}

type assetPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssetPaginateOption
}

func newAssetPaginateArgs(rv map[string]any) *assetPaginateArgs {
	args := &assetPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssetOrder:
			args.opts = append(args.opts, WithAssetOrder(v))
		case []any:
			var orders []*AssetOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssetOrder{Field: &AssetOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssetOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssetWhereInput); ok {
		args.opts = append(args.opts, WithAssetFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ah *AssetHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssetHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ah, nil
	}
	if err := ah.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ah, nil
}

func (ah *AssetHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assethistory.Columns))
		selectedFields = []string{assethistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[assethistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldHistoryTime)
				fieldSeen[assethistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[assethistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldRef)
				fieldSeen[assethistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[assethistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldOperation)
				fieldSeen[assethistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[assethistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCreatedAt)
				fieldSeen[assethistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assethistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldUpdatedAt)
				fieldSeen[assethistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assethistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCreatedBy)
				fieldSeen[assethistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assethistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldUpdatedBy)
				fieldSeen[assethistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[assethistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldTags)
				fieldSeen[assethistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assethistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldOwnerID)
				fieldSeen[assethistory.FieldOwnerID] = struct{}{}
			}
		case "assetType":
			if _, ok := fieldSeen[assethistory.FieldAssetType]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldAssetType)
				fieldSeen[assethistory.FieldAssetType] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[assethistory.FieldName]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldName)
				fieldSeen[assethistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[assethistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldDescription)
				fieldSeen[assethistory.FieldDescription] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[assethistory.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldIdentifier)
				fieldSeen[assethistory.FieldIdentifier] = struct{}{}
			}
		case "website":
			if _, ok := fieldSeen[assethistory.FieldWebsite]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldWebsite)
				fieldSeen[assethistory.FieldWebsite] = struct{}{}
			}
		case "cpe":
			if _, ok := fieldSeen[assethistory.FieldCpe]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCpe)
				fieldSeen[assethistory.FieldCpe] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[assethistory.FieldCategories]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCategories)
				fieldSeen[assethistory.FieldCategories] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ah.Select(selectedFields...)
	}
	return nil
}

type assethistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssetHistoryPaginateOption
}

func newAssetHistoryPaginateArgs(rv map[string]any) *assethistoryPaginateArgs {
	args := &assethistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &AssetHistoryOrder{Field: &AssetHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithAssetHistoryOrder(order))
			}
		case *AssetHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithAssetHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*AssetHistoryWhereInput); ok {
		args.opts = append(args.opts, WithAssetHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (c *ContactQuery) CollectFields(ctx context.Context, satisfies ...string) (*ContactQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return c, nil
	}
	if err := c.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return c, nil
}

func (c *ContactQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(contact.Columns))
		selectedFields = []string{contact.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: c.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			c.withOwner = query
			if _, ok := fieldSeen[contact.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contact.FieldOwnerID)
				fieldSeen[contact.FieldOwnerID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: c.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Contact) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"contact_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(contact.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(contact.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(contact.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(contact.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(contact.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Contact) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(contact.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: c.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Contact) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"contact_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(contact.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(contact.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(contact.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(contact.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(contact.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Contact) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(contact.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[contact.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, contact.FieldCreatedAt)
				fieldSeen[contact.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[contact.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, contact.FieldUpdatedAt)
				fieldSeen[contact.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[contact.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, contact.FieldCreatedBy)
				fieldSeen[contact.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[contact.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, contact.FieldUpdatedBy)
				fieldSeen[contact.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[contact.FieldTags]; !ok {
				selectedFields = append(selectedFields, contact.FieldTags)
				fieldSeen[contact.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[contact.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contact.FieldOwnerID)
				fieldSeen[contact.FieldOwnerID] = struct{}{}
			}
		case "fullName":
			if _, ok := fieldSeen[contact.FieldFullName]; !ok {
				selectedFields = append(selectedFields, contact.FieldFullName)
				fieldSeen[contact.FieldFullName] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[contact.FieldTitle]; !ok {
				selectedFields = append(selectedFields, contact.FieldTitle)
				fieldSeen[contact.FieldTitle] = struct{}{}
			}
		case "company":
			if _, ok := fieldSeen[contact.FieldCompany]; !ok {
				selectedFields = append(selectedFields, contact.FieldCompany)
				fieldSeen[contact.FieldCompany] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[contact.FieldEmail]; !ok {
				selectedFields = append(selectedFields, contact.FieldEmail)
				fieldSeen[contact.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[contact.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, contact.FieldPhoneNumber)
				fieldSeen[contact.FieldPhoneNumber] = struct{}{}
			}
		case "address":
			if _, ok := fieldSeen[contact.FieldAddress]; !ok {
				selectedFields = append(selectedFields, contact.FieldAddress)
				fieldSeen[contact.FieldAddress] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[contact.FieldStatus]; !ok {
				selectedFields = append(selectedFields, contact.FieldStatus)
				fieldSeen[contact.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		c.Select(selectedFields...)
	}
	return nil
}

type contactPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ContactPaginateOption
}

func newContactPaginateArgs(rv map[string]any) *contactPaginateArgs {
	args := &contactPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ContactOrder:
			args.opts = append(args.opts, WithContactOrder(v))
		case []any:
			var orders []*ContactOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ContactOrder{Field: &ContactOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithContactOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ContactWhereInput); ok {
		args.opts = append(args.opts, WithContactFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ch *ContactHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ContactHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ch, nil
	}
	if err := ch.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ch, nil
}

func (ch *ContactHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(contacthistory.Columns))
		selectedFields = []string{contacthistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[contacthistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldHistoryTime)
				fieldSeen[contacthistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[contacthistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldRef)
				fieldSeen[contacthistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[contacthistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldOperation)
				fieldSeen[contacthistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[contacthistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldCreatedAt)
				fieldSeen[contacthistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[contacthistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldUpdatedAt)
				fieldSeen[contacthistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[contacthistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldCreatedBy)
				fieldSeen[contacthistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[contacthistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldUpdatedBy)
				fieldSeen[contacthistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[contacthistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldTags)
				fieldSeen[contacthistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[contacthistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldOwnerID)
				fieldSeen[contacthistory.FieldOwnerID] = struct{}{}
			}
		case "fullName":
			if _, ok := fieldSeen[contacthistory.FieldFullName]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldFullName)
				fieldSeen[contacthistory.FieldFullName] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[contacthistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldTitle)
				fieldSeen[contacthistory.FieldTitle] = struct{}{}
			}
		case "company":
			if _, ok := fieldSeen[contacthistory.FieldCompany]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldCompany)
				fieldSeen[contacthistory.FieldCompany] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[contacthistory.FieldEmail]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldEmail)
				fieldSeen[contacthistory.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[contacthistory.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldPhoneNumber)
				fieldSeen[contacthistory.FieldPhoneNumber] = struct{}{}
			}
		case "address":
			if _, ok := fieldSeen[contacthistory.FieldAddress]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldAddress)
				fieldSeen[contacthistory.FieldAddress] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[contacthistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldStatus)
				fieldSeen[contacthistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ch.Select(selectedFields...)
	}
	return nil
}

type contacthistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ContactHistoryPaginateOption
}

func newContactHistoryPaginateArgs(rv map[string]any) *contacthistoryPaginateArgs {
	args := &contacthistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ContactHistoryOrder{Field: &ContactHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithContactHistoryOrder(order))
			}
		case *ContactHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithContactHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ContactHistoryWhereInput); ok {
		args.opts = append(args.opts, WithContactHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (c *ControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return c, nil
	}
	if err := c.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return c, nil
}

func (c *ControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(control.Columns))
		selectedFields = []string{control.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: c.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(control.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(control.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: c.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(control.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: c.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(control.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: c.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(control.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: c.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(control.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: c.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(control.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: c.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(control.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: c.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(control.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "controlOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: c.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			c.withControlOwner = query
			if _, ok := fieldSeen[control.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlOwnerID)
				fieldSeen[control.FieldControlOwnerID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: c.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			c.withDelegate = query
			if _, ok := fieldSeen[control.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, control.FieldDelegateID)
				fieldSeen[control.FieldDelegateID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: c.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			c.withOwner = query
			if _, ok := fieldSeen[control.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldOwnerID)
				fieldSeen[control.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: c.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(control.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: c.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(control.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: c.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			c.withStandard = query
			if _, ok := fieldSeen[control.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, control.FieldStandardID)
				fieldSeen[control.FieldStandardID] = struct{}{}
			}

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: c.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(control.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: c.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(control.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: c.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.ScansColumn), ids...))
						})
						if err := query.GroupBy(control.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: c.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(control.ControlImplementationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ControlImplementationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ControlImplementationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ControlImplementationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlImplementationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: c.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(control.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlScheduledJobClient{config: c.config}).Query()
			)
			args := newControlScheduledJobPaginateArgs(fieldArgs(ctx, new(ControlScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					c.loadTotal = append(c.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ScheduledJobsTable)
							s.Join(joinT).On(s.C(controlscheduledjob.FieldID), joinT.C(control.ScheduledJobsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.ScheduledJobsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.ScheduledJobsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ScheduledJobsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					c.loadTotal = append(c.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlscheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ScheduledJobsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			c.WithNamedScheduledJobs(alias, func(wq *ControlScheduledJobQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[control.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, control.FieldCreatedAt)
				fieldSeen[control.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[control.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, control.FieldUpdatedAt)
				fieldSeen[control.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[control.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, control.FieldCreatedBy)
				fieldSeen[control.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[control.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, control.FieldUpdatedBy)
				fieldSeen[control.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[control.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, control.FieldDisplayID)
				fieldSeen[control.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[control.FieldTags]; !ok {
				selectedFields = append(selectedFields, control.FieldTags)
				fieldSeen[control.FieldTags] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[control.FieldDescription]; !ok {
				selectedFields = append(selectedFields, control.FieldDescription)
				fieldSeen[control.FieldDescription] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[control.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceID)
				fieldSeen[control.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[control.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, control.FieldAuditorReferenceID)
				fieldSeen[control.FieldAuditorReferenceID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[control.FieldStatus]; !ok {
				selectedFields = append(selectedFields, control.FieldStatus)
				fieldSeen[control.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[control.FieldSource]; !ok {
				selectedFields = append(selectedFields, control.FieldSource)
				fieldSeen[control.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[control.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceFramework)
				fieldSeen[control.FieldReferenceFramework] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[control.FieldControlType]; !ok {
				selectedFields = append(selectedFields, control.FieldControlType)
				fieldSeen[control.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[control.FieldCategory]; !ok {
				selectedFields = append(selectedFields, control.FieldCategory)
				fieldSeen[control.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[control.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, control.FieldCategoryID)
				fieldSeen[control.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[control.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, control.FieldSubcategory)
				fieldSeen[control.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[control.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, control.FieldMappedCategories)
				fieldSeen[control.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[control.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, control.FieldAssessmentObjectives)
				fieldSeen[control.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[control.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, control.FieldAssessmentMethods)
				fieldSeen[control.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[control.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, control.FieldControlQuestions)
				fieldSeen[control.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[control.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, control.FieldImplementationGuidance)
				fieldSeen[control.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[control.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, control.FieldExampleEvidence)
				fieldSeen[control.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[control.FieldReferences]; !ok {
				selectedFields = append(selectedFields, control.FieldReferences)
				fieldSeen[control.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[control.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlOwnerID)
				fieldSeen[control.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[control.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, control.FieldDelegateID)
				fieldSeen[control.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[control.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldOwnerID)
				fieldSeen[control.FieldOwnerID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[control.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, control.FieldRefCode)
				fieldSeen[control.FieldRefCode] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[control.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, control.FieldStandardID)
				fieldSeen[control.FieldStandardID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		c.Select(selectedFields...)
	}
	return nil
}

type controlPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlPaginateOption
}

func newControlPaginateArgs(rv map[string]any) *controlPaginateArgs {
	args := &controlPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlOrder:
			args.opts = append(args.opts, WithControlOrder(v))
		case []any:
			var orders []*ControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlOrder{Field: &ControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlWhereInput); ok {
		args.opts = append(args.opts, WithControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ch *ControlHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ch, nil
	}
	if err := ch.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ch, nil
}

func (ch *ControlHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlhistory.Columns))
		selectedFields = []string{controlhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldHistoryTime)
				fieldSeen[controlhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldRef)
				fieldSeen[controlhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldOperation)
				fieldSeen[controlhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCreatedAt)
				fieldSeen[controlhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldUpdatedAt)
				fieldSeen[controlhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCreatedBy)
				fieldSeen[controlhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldUpdatedBy)
				fieldSeen[controlhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldDisplayID)
				fieldSeen[controlhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldTags)
				fieldSeen[controlhistory.FieldTags] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[controlhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldDescription)
				fieldSeen[controlhistory.FieldDescription] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[controlhistory.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferenceID)
				fieldSeen[controlhistory.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[controlhistory.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAuditorReferenceID)
				fieldSeen[controlhistory.FieldAuditorReferenceID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldStatus)
				fieldSeen[controlhistory.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldSource)
				fieldSeen[controlhistory.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[controlhistory.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferenceFramework)
				fieldSeen[controlhistory.FieldReferenceFramework] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[controlhistory.FieldControlType]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlType)
				fieldSeen[controlhistory.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCategory)
				fieldSeen[controlhistory.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[controlhistory.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCategoryID)
				fieldSeen[controlhistory.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlhistory.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldSubcategory)
				fieldSeen[controlhistory.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[controlhistory.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldMappedCategories)
				fieldSeen[controlhistory.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[controlhistory.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAssessmentObjectives)
				fieldSeen[controlhistory.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[controlhistory.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAssessmentMethods)
				fieldSeen[controlhistory.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[controlhistory.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlQuestions)
				fieldSeen[controlhistory.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[controlhistory.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldImplementationGuidance)
				fieldSeen[controlhistory.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[controlhistory.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldExampleEvidence)
				fieldSeen[controlhistory.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[controlhistory.FieldReferences]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferences)
				fieldSeen[controlhistory.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[controlhistory.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlOwnerID)
				fieldSeen[controlhistory.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[controlhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldDelegateID)
				fieldSeen[controlhistory.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldOwnerID)
				fieldSeen[controlhistory.FieldOwnerID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[controlhistory.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldRefCode)
				fieldSeen[controlhistory.FieldRefCode] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[controlhistory.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldStandardID)
				fieldSeen[controlhistory.FieldStandardID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ch.Select(selectedFields...)
	}
	return nil
}

type controlhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlHistoryPaginateOption
}

func newControlHistoryPaginateArgs(rv map[string]any) *controlhistoryPaginateArgs {
	args := &controlhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlHistoryOrder{Field: &ControlHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlHistoryOrder(order))
			}
		case *ControlHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ci *ControlImplementationQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlImplementationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ci, nil
	}
	if err := ci.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ci, nil
}

func (ci *ControlImplementationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlimplementation.Columns))
		selectedFields = []string{controlimplementation.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: ci.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			ci.withOwner = query
			if _, ok := fieldSeen[controlimplementation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldOwnerID)
				fieldSeen[controlimplementation.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ci.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ci.loadTotal = append(ci.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					ci.loadTotal = append(ci.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ci.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ci.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ci.loadTotal = append(ci.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					ci.loadTotal = append(ci.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ci.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ci.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ci.loadTotal = append(ci.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					ci.loadTotal = append(ci.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ci.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: ci.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ci.loadTotal = append(ci.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlimplementation.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlimplementation.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlimplementation.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					ci.loadTotal = append(ci.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ci.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: ci.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ci.loadTotal = append(ci.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlimplementation.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					ci.loadTotal = append(ci.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ci.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[controlimplementation.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldCreatedAt)
				fieldSeen[controlimplementation.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlimplementation.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldUpdatedAt)
				fieldSeen[controlimplementation.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlimplementation.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldCreatedBy)
				fieldSeen[controlimplementation.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlimplementation.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldUpdatedBy)
				fieldSeen[controlimplementation.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlimplementation.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldTags)
				fieldSeen[controlimplementation.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlimplementation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldOwnerID)
				fieldSeen[controlimplementation.FieldOwnerID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlimplementation.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldStatus)
				fieldSeen[controlimplementation.FieldStatus] = struct{}{}
			}
		case "implementationDate":
			if _, ok := fieldSeen[controlimplementation.FieldImplementationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldImplementationDate)
				fieldSeen[controlimplementation.FieldImplementationDate] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[controlimplementation.FieldVerified]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldVerified)
				fieldSeen[controlimplementation.FieldVerified] = struct{}{}
			}
		case "verificationDate":
			if _, ok := fieldSeen[controlimplementation.FieldVerificationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldVerificationDate)
				fieldSeen[controlimplementation.FieldVerificationDate] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[controlimplementation.FieldDetails]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldDetails)
				fieldSeen[controlimplementation.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ci.Select(selectedFields...)
	}
	return nil
}

type controlimplementationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlImplementationPaginateOption
}

func newControlImplementationPaginateArgs(rv map[string]any) *controlimplementationPaginateArgs {
	args := &controlimplementationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlImplementationOrder:
			args.opts = append(args.opts, WithControlImplementationOrder(v))
		case []any:
			var orders []*ControlImplementationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlImplementationOrder{Field: &ControlImplementationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlImplementationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlImplementationWhereInput); ok {
		args.opts = append(args.opts, WithControlImplementationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (cih *ControlImplementationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlImplementationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return cih, nil
	}
	if err := cih.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return cih, nil
}

func (cih *ControlImplementationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlimplementationhistory.Columns))
		selectedFields = []string{controlimplementationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlimplementationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldHistoryTime)
				fieldSeen[controlimplementationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlimplementationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldRef)
				fieldSeen[controlimplementationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlimplementationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldOperation)
				fieldSeen[controlimplementationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlimplementationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldCreatedAt)
				fieldSeen[controlimplementationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlimplementationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldUpdatedAt)
				fieldSeen[controlimplementationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlimplementationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldCreatedBy)
				fieldSeen[controlimplementationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlimplementationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldUpdatedBy)
				fieldSeen[controlimplementationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlimplementationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldTags)
				fieldSeen[controlimplementationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlimplementationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldOwnerID)
				fieldSeen[controlimplementationhistory.FieldOwnerID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlimplementationhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldStatus)
				fieldSeen[controlimplementationhistory.FieldStatus] = struct{}{}
			}
		case "implementationDate":
			if _, ok := fieldSeen[controlimplementationhistory.FieldImplementationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldImplementationDate)
				fieldSeen[controlimplementationhistory.FieldImplementationDate] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[controlimplementationhistory.FieldVerified]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldVerified)
				fieldSeen[controlimplementationhistory.FieldVerified] = struct{}{}
			}
		case "verificationDate":
			if _, ok := fieldSeen[controlimplementationhistory.FieldVerificationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldVerificationDate)
				fieldSeen[controlimplementationhistory.FieldVerificationDate] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[controlimplementationhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldDetails)
				fieldSeen[controlimplementationhistory.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		cih.Select(selectedFields...)
	}
	return nil
}

type controlimplementationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlImplementationHistoryPaginateOption
}

func newControlImplementationHistoryPaginateArgs(rv map[string]any) *controlimplementationhistoryPaginateArgs {
	args := &controlimplementationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlImplementationHistoryOrder{Field: &ControlImplementationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlImplementationHistoryOrder(order))
			}
		case *ControlImplementationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlImplementationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlImplementationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlImplementationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (co *ControlObjectiveQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlObjectiveQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return co, nil
	}
	if err := co.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return co, nil
}

func (co *ControlObjectiveQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlobjective.Columns))
		selectedFields = []string{controlobjective.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: co.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			co.withOwner = query
			if _, ok := fieldSeen[controlobjective.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldOwnerID)
				fieldSeen[controlobjective.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: co.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: co.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: co.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: co.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(controlobjective.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: co.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(controlobjective.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: co.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlobjective.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: co.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlobjective.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: co.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(controlobjective.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: co.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_procedures"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: co.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.RisksColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: co.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_narratives"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: co.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					co.loadTotal = append(co.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(controlobjective.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					co.loadTotal = append(co.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			co.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[controlobjective.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCreatedAt)
				fieldSeen[controlobjective.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlobjective.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldUpdatedAt)
				fieldSeen[controlobjective.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlobjective.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCreatedBy)
				fieldSeen[controlobjective.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlobjective.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldUpdatedBy)
				fieldSeen[controlobjective.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlobjective.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDisplayID)
				fieldSeen[controlobjective.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlobjective.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldTags)
				fieldSeen[controlobjective.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[controlobjective.FieldRevision]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldRevision)
				fieldSeen[controlobjective.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlobjective.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldOwnerID)
				fieldSeen[controlobjective.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[controlobjective.FieldName]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldName)
				fieldSeen[controlobjective.FieldName] = struct{}{}
			}
		case "desiredOutcome":
			if _, ok := fieldSeen[controlobjective.FieldDesiredOutcome]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDesiredOutcome)
				fieldSeen[controlobjective.FieldDesiredOutcome] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlobjective.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldStatus)
				fieldSeen[controlobjective.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlobjective.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSource)
				fieldSeen[controlobjective.FieldSource] = struct{}{}
			}
		case "controlObjectiveType":
			if _, ok := fieldSeen[controlobjective.FieldControlObjectiveType]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldControlObjectiveType)
				fieldSeen[controlobjective.FieldControlObjectiveType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlobjective.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCategory)
				fieldSeen[controlobjective.FieldCategory] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlobjective.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSubcategory)
				fieldSeen[controlobjective.FieldSubcategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		co.Select(selectedFields...)
	}
	return nil
}

type controlobjectivePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlObjectivePaginateOption
}

func newControlObjectivePaginateArgs(rv map[string]any) *controlobjectivePaginateArgs {
	args := &controlobjectivePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlObjectiveOrder:
			args.opts = append(args.opts, WithControlObjectiveOrder(v))
		case []any:
			var orders []*ControlObjectiveOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlObjectiveOrder{Field: &ControlObjectiveOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlObjectiveOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlObjectiveWhereInput); ok {
		args.opts = append(args.opts, WithControlObjectiveFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (coh *ControlObjectiveHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlObjectiveHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return coh, nil
	}
	if err := coh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return coh, nil
}

func (coh *ControlObjectiveHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlobjectivehistory.Columns))
		selectedFields = []string{controlobjectivehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlobjectivehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldHistoryTime)
				fieldSeen[controlobjectivehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlobjectivehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldRef)
				fieldSeen[controlobjectivehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlobjectivehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldOperation)
				fieldSeen[controlobjectivehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlobjectivehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldCreatedAt)
				fieldSeen[controlobjectivehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlobjectivehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldUpdatedAt)
				fieldSeen[controlobjectivehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlobjectivehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldCreatedBy)
				fieldSeen[controlobjectivehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlobjectivehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldUpdatedBy)
				fieldSeen[controlobjectivehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlobjectivehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldDisplayID)
				fieldSeen[controlobjectivehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlobjectivehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldTags)
				fieldSeen[controlobjectivehistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[controlobjectivehistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldRevision)
				fieldSeen[controlobjectivehistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlobjectivehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldOwnerID)
				fieldSeen[controlobjectivehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[controlobjectivehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldName)
				fieldSeen[controlobjectivehistory.FieldName] = struct{}{}
			}
		case "desiredOutcome":
			if _, ok := fieldSeen[controlobjectivehistory.FieldDesiredOutcome]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldDesiredOutcome)
				fieldSeen[controlobjectivehistory.FieldDesiredOutcome] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlobjectivehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldStatus)
				fieldSeen[controlobjectivehistory.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlobjectivehistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldSource)
				fieldSeen[controlobjectivehistory.FieldSource] = struct{}{}
			}
		case "controlObjectiveType":
			if _, ok := fieldSeen[controlobjectivehistory.FieldControlObjectiveType]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldControlObjectiveType)
				fieldSeen[controlobjectivehistory.FieldControlObjectiveType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlobjectivehistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldCategory)
				fieldSeen[controlobjectivehistory.FieldCategory] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlobjectivehistory.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldSubcategory)
				fieldSeen[controlobjectivehistory.FieldSubcategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		coh.Select(selectedFields...)
	}
	return nil
}

type controlobjectivehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlObjectiveHistoryPaginateOption
}

func newControlObjectiveHistoryPaginateArgs(rv map[string]any) *controlobjectivehistoryPaginateArgs {
	args := &controlobjectivehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlObjectiveHistoryOrder{Field: &ControlObjectiveHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlObjectiveHistoryOrder(order))
			}
		case *ControlObjectiveHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlObjectiveHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlObjectiveHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlObjectiveHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (csj *ControlScheduledJobQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlScheduledJobQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return csj, nil
	}
	if err := csj.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return csj, nil
}

func (csj *ControlScheduledJobQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlscheduledjob.Columns))
		selectedFields = []string{controlscheduledjob.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: csj.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			csj.withOwner = query
			if _, ok := fieldSeen[controlscheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldOwnerID)
				fieldSeen[controlscheduledjob.FieldOwnerID] = struct{}{}
			}

		case "job":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: csj.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
				return err
			}
			csj.withJob = query
			if _, ok := fieldSeen[controlscheduledjob.FieldJobID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldJobID)
				fieldSeen[controlscheduledjob.FieldJobID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: csj.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					csj.loadTotal = append(csj.loadTotal, func(ctx context.Context, nodes []*ControlScheduledJob) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_scheduled_job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlscheduledjob.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlscheduledjob.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlscheduledjob.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlscheduledjob.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlscheduledjob.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					csj.loadTotal = append(csj.loadTotal, func(_ context.Context, nodes []*ControlScheduledJob) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlscheduledjob.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			csj.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: csj.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					csj.loadTotal = append(csj.loadTotal, func(ctx context.Context, nodes []*ControlScheduledJob) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_scheduled_job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlscheduledjob.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlscheduledjob.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlscheduledjob.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlscheduledjob.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlscheduledjob.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					csj.loadTotal = append(csj.loadTotal, func(_ context.Context, nodes []*ControlScheduledJob) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlscheduledjob.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			csj.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: csj.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			csj.withJobRunner = query
			if _, ok := fieldSeen[controlscheduledjob.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldJobRunnerID)
				fieldSeen[controlscheduledjob.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlscheduledjob.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldCreatedAt)
				fieldSeen[controlscheduledjob.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlscheduledjob.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldUpdatedAt)
				fieldSeen[controlscheduledjob.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlscheduledjob.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldCreatedBy)
				fieldSeen[controlscheduledjob.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlscheduledjob.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldUpdatedBy)
				fieldSeen[controlscheduledjob.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlscheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldOwnerID)
				fieldSeen[controlscheduledjob.FieldOwnerID] = struct{}{}
			}
		case "jobID":
			if _, ok := fieldSeen[controlscheduledjob.FieldJobID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldJobID)
				fieldSeen[controlscheduledjob.FieldJobID] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[controlscheduledjob.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldConfiguration)
				fieldSeen[controlscheduledjob.FieldConfiguration] = struct{}{}
			}
		case "cadence":
			if _, ok := fieldSeen[controlscheduledjob.FieldCadence]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldCadence)
				fieldSeen[controlscheduledjob.FieldCadence] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[controlscheduledjob.FieldCron]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldCron)
				fieldSeen[controlscheduledjob.FieldCron] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[controlscheduledjob.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjob.FieldJobRunnerID)
				fieldSeen[controlscheduledjob.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		csj.Select(selectedFields...)
	}
	return nil
}

type controlscheduledjobPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlScheduledJobPaginateOption
}

func newControlScheduledJobPaginateArgs(rv map[string]any) *controlscheduledjobPaginateArgs {
	args := &controlscheduledjobPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlScheduledJobOrder:
			args.opts = append(args.opts, WithControlScheduledJobOrder(v))
		case []any:
			var orders []*ControlScheduledJobOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlScheduledJobOrder{Field: &ControlScheduledJobOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlScheduledJobOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlScheduledJobWhereInput); ok {
		args.opts = append(args.opts, WithControlScheduledJobFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (csjh *ControlScheduledJobHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlScheduledJobHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return csjh, nil
	}
	if err := csjh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return csjh, nil
}

func (csjh *ControlScheduledJobHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlscheduledjobhistory.Columns))
		selectedFields = []string{controlscheduledjobhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldHistoryTime)
				fieldSeen[controlscheduledjobhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldRef)
				fieldSeen[controlscheduledjobhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldOperation)
				fieldSeen[controlscheduledjobhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldCreatedAt)
				fieldSeen[controlscheduledjobhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldUpdatedAt)
				fieldSeen[controlscheduledjobhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldCreatedBy)
				fieldSeen[controlscheduledjobhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldUpdatedBy)
				fieldSeen[controlscheduledjobhistory.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldOwnerID)
				fieldSeen[controlscheduledjobhistory.FieldOwnerID] = struct{}{}
			}
		case "jobID":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldJobID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldJobID)
				fieldSeen[controlscheduledjobhistory.FieldJobID] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldConfiguration)
				fieldSeen[controlscheduledjobhistory.FieldConfiguration] = struct{}{}
			}
		case "cadence":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldCadence]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldCadence)
				fieldSeen[controlscheduledjobhistory.FieldCadence] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldCron]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldCron)
				fieldSeen[controlscheduledjobhistory.FieldCron] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[controlscheduledjobhistory.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, controlscheduledjobhistory.FieldJobRunnerID)
				fieldSeen[controlscheduledjobhistory.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		csjh.Select(selectedFields...)
	}
	return nil
}

type controlscheduledjobhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlScheduledJobHistoryPaginateOption
}

func newControlScheduledJobHistoryPaginateArgs(rv map[string]any) *controlscheduledjobhistoryPaginateArgs {
	args := &controlscheduledjobhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlScheduledJobHistoryOrder{Field: &ControlScheduledJobHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlScheduledJobHistoryOrder(order))
			}
		case *ControlScheduledJobHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlScheduledJobHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlScheduledJobHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlScheduledJobHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (cd *CustomDomainQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomDomainQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return cd, nil
	}
	if err := cd.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return cd, nil
}

func (cd *CustomDomainQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customdomain.Columns))
		selectedFields = []string{customdomain.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: cd.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			cd.withOwner = query
			if _, ok := fieldSeen[customdomain.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldOwnerID)
				fieldSeen[customdomain.FieldOwnerID] = struct{}{}
			}

		case "mappableDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappableDomainClient{config: cd.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, mappabledomainImplementors)...); err != nil {
				return err
			}
			cd.withMappableDomain = query
			if _, ok := fieldSeen[customdomain.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldMappableDomainID)
				fieldSeen[customdomain.FieldMappableDomainID] = struct{}{}
			}

		case "dnsVerification":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DNSVerificationClient{config: cd.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, dnsverificationImplementors)...); err != nil {
				return err
			}
			cd.withDNSVerification = query
			if _, ok := fieldSeen[customdomain.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldDNSVerificationID)
				fieldSeen[customdomain.FieldDNSVerificationID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[customdomain.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCreatedAt)
				fieldSeen[customdomain.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customdomain.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldUpdatedAt)
				fieldSeen[customdomain.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customdomain.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCreatedBy)
				fieldSeen[customdomain.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customdomain.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldUpdatedBy)
				fieldSeen[customdomain.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[customdomain.FieldTags]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldTags)
				fieldSeen[customdomain.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customdomain.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldOwnerID)
				fieldSeen[customdomain.FieldOwnerID] = struct{}{}
			}
		case "cnameRecord":
			if _, ok := fieldSeen[customdomain.FieldCnameRecord]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCnameRecord)
				fieldSeen[customdomain.FieldCnameRecord] = struct{}{}
			}
		case "mappableDomainID":
			if _, ok := fieldSeen[customdomain.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldMappableDomainID)
				fieldSeen[customdomain.FieldMappableDomainID] = struct{}{}
			}
		case "dnsVerificationID":
			if _, ok := fieldSeen[customdomain.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldDNSVerificationID)
				fieldSeen[customdomain.FieldDNSVerificationID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		cd.Select(selectedFields...)
	}
	return nil
}

type customdomainPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomDomainPaginateOption
}

func newCustomDomainPaginateArgs(rv map[string]any) *customdomainPaginateArgs {
	args := &customdomainPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*CustomDomainOrder:
			args.opts = append(args.opts, WithCustomDomainOrder(v))
		case []any:
			var orders []*CustomDomainOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &CustomDomainOrder{Field: &CustomDomainOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithCustomDomainOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*CustomDomainWhereInput); ok {
		args.opts = append(args.opts, WithCustomDomainFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (cdh *CustomDomainHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomDomainHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return cdh, nil
	}
	if err := cdh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return cdh, nil
}

func (cdh *CustomDomainHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customdomainhistory.Columns))
		selectedFields = []string{customdomainhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[customdomainhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldHistoryTime)
				fieldSeen[customdomainhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[customdomainhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldRef)
				fieldSeen[customdomainhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[customdomainhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldOperation)
				fieldSeen[customdomainhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[customdomainhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldCreatedAt)
				fieldSeen[customdomainhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customdomainhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldUpdatedAt)
				fieldSeen[customdomainhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customdomainhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldCreatedBy)
				fieldSeen[customdomainhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customdomainhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldUpdatedBy)
				fieldSeen[customdomainhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[customdomainhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldTags)
				fieldSeen[customdomainhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customdomainhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldOwnerID)
				fieldSeen[customdomainhistory.FieldOwnerID] = struct{}{}
			}
		case "cnameRecord":
			if _, ok := fieldSeen[customdomainhistory.FieldCnameRecord]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldCnameRecord)
				fieldSeen[customdomainhistory.FieldCnameRecord] = struct{}{}
			}
		case "mappableDomainID":
			if _, ok := fieldSeen[customdomainhistory.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldMappableDomainID)
				fieldSeen[customdomainhistory.FieldMappableDomainID] = struct{}{}
			}
		case "dnsVerificationID":
			if _, ok := fieldSeen[customdomainhistory.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldDNSVerificationID)
				fieldSeen[customdomainhistory.FieldDNSVerificationID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		cdh.Select(selectedFields...)
	}
	return nil
}

type customdomainhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomDomainHistoryPaginateOption
}

func newCustomDomainHistoryPaginateArgs(rv map[string]any) *customdomainhistoryPaginateArgs {
	args := &customdomainhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &CustomDomainHistoryOrder{Field: &CustomDomainHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithCustomDomainHistoryOrder(order))
			}
		case *CustomDomainHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithCustomDomainHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*CustomDomainHistoryWhereInput); ok {
		args.opts = append(args.opts, WithCustomDomainHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (dv *DNSVerificationQuery) CollectFields(ctx context.Context, satisfies ...string) (*DNSVerificationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return dv, nil
	}
	if err := dv.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return dv, nil
}

func (dv *DNSVerificationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(dnsverification.Columns))
		selectedFields = []string{dnsverification.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: dv.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			dv.withOwner = query
			if _, ok := fieldSeen[dnsverification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldOwnerID)
				fieldSeen[dnsverification.FieldOwnerID] = struct{}{}
			}

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: dv.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					dv.loadTotal = append(dv.loadTotal, func(ctx context.Context, nodes []*DNSVerification) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"dns_verification_custom_domains"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(dnsverification.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(dnsverification.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					dv.loadTotal = append(dv.loadTotal, func(_ context.Context, nodes []*DNSVerification) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(dnsverification.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			dv.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[dnsverification.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCreatedAt)
				fieldSeen[dnsverification.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[dnsverification.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldUpdatedAt)
				fieldSeen[dnsverification.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[dnsverification.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCreatedBy)
				fieldSeen[dnsverification.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[dnsverification.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldUpdatedBy)
				fieldSeen[dnsverification.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[dnsverification.FieldTags]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldTags)
				fieldSeen[dnsverification.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[dnsverification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldOwnerID)
				fieldSeen[dnsverification.FieldOwnerID] = struct{}{}
			}
		case "cloudflareHostnameID":
			if _, ok := fieldSeen[dnsverification.FieldCloudflareHostnameID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCloudflareHostnameID)
				fieldSeen[dnsverification.FieldCloudflareHostnameID] = struct{}{}
			}
		case "dnsTxtRecord":
			if _, ok := fieldSeen[dnsverification.FieldDNSTxtRecord]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSTxtRecord)
				fieldSeen[dnsverification.FieldDNSTxtRecord] = struct{}{}
			}
		case "dnsTxtValue":
			if _, ok := fieldSeen[dnsverification.FieldDNSTxtValue]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSTxtValue)
				fieldSeen[dnsverification.FieldDNSTxtValue] = struct{}{}
			}
		case "dnsVerificationStatus":
			if _, ok := fieldSeen[dnsverification.FieldDNSVerificationStatus]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSVerificationStatus)
				fieldSeen[dnsverification.FieldDNSVerificationStatus] = struct{}{}
			}
		case "dnsVerificationStatusReason":
			if _, ok := fieldSeen[dnsverification.FieldDNSVerificationStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSVerificationStatusReason)
				fieldSeen[dnsverification.FieldDNSVerificationStatusReason] = struct{}{}
			}
		case "acmeChallengePath":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengePath]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengePath)
				fieldSeen[dnsverification.FieldAcmeChallengePath] = struct{}{}
			}
		case "expectedAcmeChallengeValue":
			if _, ok := fieldSeen[dnsverification.FieldExpectedAcmeChallengeValue]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldExpectedAcmeChallengeValue)
				fieldSeen[dnsverification.FieldExpectedAcmeChallengeValue] = struct{}{}
			}
		case "acmeChallengeStatus":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengeStatus]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengeStatus)
				fieldSeen[dnsverification.FieldAcmeChallengeStatus] = struct{}{}
			}
		case "acmeChallengeStatusReason":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengeStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengeStatusReason)
				fieldSeen[dnsverification.FieldAcmeChallengeStatusReason] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		dv.Select(selectedFields...)
	}
	return nil
}

type dnsverificationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DNSVerificationPaginateOption
}

func newDNSVerificationPaginateArgs(rv map[string]any) *dnsverificationPaginateArgs {
	args := &dnsverificationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DNSVerificationOrder:
			args.opts = append(args.opts, WithDNSVerificationOrder(v))
		case []any:
			var orders []*DNSVerificationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DNSVerificationOrder{Field: &DNSVerificationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDNSVerificationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DNSVerificationWhereInput); ok {
		args.opts = append(args.opts, WithDNSVerificationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (dvh *DNSVerificationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DNSVerificationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return dvh, nil
	}
	if err := dvh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return dvh, nil
}

func (dvh *DNSVerificationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(dnsverificationhistory.Columns))
		selectedFields = []string{dnsverificationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[dnsverificationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldHistoryTime)
				fieldSeen[dnsverificationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[dnsverificationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldRef)
				fieldSeen[dnsverificationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[dnsverificationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldOperation)
				fieldSeen[dnsverificationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[dnsverificationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldCreatedAt)
				fieldSeen[dnsverificationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[dnsverificationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldUpdatedAt)
				fieldSeen[dnsverificationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[dnsverificationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldCreatedBy)
				fieldSeen[dnsverificationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[dnsverificationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldUpdatedBy)
				fieldSeen[dnsverificationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[dnsverificationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldTags)
				fieldSeen[dnsverificationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[dnsverificationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldOwnerID)
				fieldSeen[dnsverificationhistory.FieldOwnerID] = struct{}{}
			}
		case "cloudflareHostnameID":
			if _, ok := fieldSeen[dnsverificationhistory.FieldCloudflareHostnameID]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldCloudflareHostnameID)
				fieldSeen[dnsverificationhistory.FieldCloudflareHostnameID] = struct{}{}
			}
		case "dnsTxtRecord":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSTxtRecord]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSTxtRecord)
				fieldSeen[dnsverificationhistory.FieldDNSTxtRecord] = struct{}{}
			}
		case "dnsTxtValue":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSTxtValue]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSTxtValue)
				fieldSeen[dnsverificationhistory.FieldDNSTxtValue] = struct{}{}
			}
		case "dnsVerificationStatus":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSVerificationStatus]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSVerificationStatus)
				fieldSeen[dnsverificationhistory.FieldDNSVerificationStatus] = struct{}{}
			}
		case "dnsVerificationStatusReason":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSVerificationStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSVerificationStatusReason)
				fieldSeen[dnsverificationhistory.FieldDNSVerificationStatusReason] = struct{}{}
			}
		case "acmeChallengePath":
			if _, ok := fieldSeen[dnsverificationhistory.FieldAcmeChallengePath]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldAcmeChallengePath)
				fieldSeen[dnsverificationhistory.FieldAcmeChallengePath] = struct{}{}
			}
		case "expectedAcmeChallengeValue":
			if _, ok := fieldSeen[dnsverificationhistory.FieldExpectedAcmeChallengeValue]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldExpectedAcmeChallengeValue)
				fieldSeen[dnsverificationhistory.FieldExpectedAcmeChallengeValue] = struct{}{}
			}
		case "acmeChallengeStatus":
			if _, ok := fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatus]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldAcmeChallengeStatus)
				fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatus] = struct{}{}
			}
		case "acmeChallengeStatusReason":
			if _, ok := fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldAcmeChallengeStatusReason)
				fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatusReason] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		dvh.Select(selectedFields...)
	}
	return nil
}

type dnsverificationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DNSVerificationHistoryPaginateOption
}

func newDNSVerificationHistoryPaginateArgs(rv map[string]any) *dnsverificationhistoryPaginateArgs {
	args := &dnsverificationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DNSVerificationHistoryOrder{Field: &DNSVerificationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDNSVerificationHistoryOrder(order))
			}
		case *DNSVerificationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDNSVerificationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DNSVerificationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDNSVerificationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (dd *DocumentDataQuery) CollectFields(ctx context.Context, satisfies ...string) (*DocumentDataQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return dd, nil
	}
	if err := dd.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return dd, nil
}

func (dd *DocumentDataQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(documentdata.Columns))
		selectedFields = []string{documentdata.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: dd.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			dd.withOwner = query
			if _, ok := fieldSeen[documentdata.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldOwnerID)
				fieldSeen[documentdata.FieldOwnerID] = struct{}{}
			}

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: dd.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			dd.withTemplate = query
			if _, ok := fieldSeen[documentdata.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTemplateID)
				fieldSeen[documentdata.FieldTemplateID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: dd.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					dd.loadTotal = append(dd.loadTotal, func(ctx context.Context, nodes []*DocumentData) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"document_data_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(documentdata.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(documentdata.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(documentdata.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(documentdata.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(documentdata.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					dd.loadTotal = append(dd.loadTotal, func(_ context.Context, nodes []*DocumentData) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(documentdata.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			dd.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: dd.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					dd.loadTotal = append(dd.loadTotal, func(ctx context.Context, nodes []*DocumentData) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"document_data_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(documentdata.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(documentdata.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(documentdata.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(documentdata.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(documentdata.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					dd.loadTotal = append(dd.loadTotal, func(_ context.Context, nodes []*DocumentData) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(documentdata.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			dd.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[documentdata.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldCreatedAt)
				fieldSeen[documentdata.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[documentdata.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldUpdatedAt)
				fieldSeen[documentdata.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[documentdata.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldCreatedBy)
				fieldSeen[documentdata.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[documentdata.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldUpdatedBy)
				fieldSeen[documentdata.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[documentdata.FieldTags]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTags)
				fieldSeen[documentdata.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[documentdata.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldOwnerID)
				fieldSeen[documentdata.FieldOwnerID] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[documentdata.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTemplateID)
				fieldSeen[documentdata.FieldTemplateID] = struct{}{}
			}
		case "data":
			if _, ok := fieldSeen[documentdata.FieldData]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldData)
				fieldSeen[documentdata.FieldData] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		dd.Select(selectedFields...)
	}
	return nil
}

type documentdataPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DocumentDataPaginateOption
}

func newDocumentDataPaginateArgs(rv map[string]any) *documentdataPaginateArgs {
	args := &documentdataPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DocumentDataOrder:
			args.opts = append(args.opts, WithDocumentDataOrder(v))
		case []any:
			var orders []*DocumentDataOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DocumentDataOrder{Field: &DocumentDataOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDocumentDataOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DocumentDataWhereInput); ok {
		args.opts = append(args.opts, WithDocumentDataFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ddh *DocumentDataHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DocumentDataHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ddh, nil
	}
	if err := ddh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ddh, nil
}

func (ddh *DocumentDataHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(documentdatahistory.Columns))
		selectedFields = []string{documentdatahistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[documentdatahistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldHistoryTime)
				fieldSeen[documentdatahistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[documentdatahistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldRef)
				fieldSeen[documentdatahistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[documentdatahistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldOperation)
				fieldSeen[documentdatahistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[documentdatahistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldCreatedAt)
				fieldSeen[documentdatahistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[documentdatahistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldUpdatedAt)
				fieldSeen[documentdatahistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[documentdatahistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldCreatedBy)
				fieldSeen[documentdatahistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[documentdatahistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldUpdatedBy)
				fieldSeen[documentdatahistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[documentdatahistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldTags)
				fieldSeen[documentdatahistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[documentdatahistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldOwnerID)
				fieldSeen[documentdatahistory.FieldOwnerID] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[documentdatahistory.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldTemplateID)
				fieldSeen[documentdatahistory.FieldTemplateID] = struct{}{}
			}
		case "data":
			if _, ok := fieldSeen[documentdatahistory.FieldData]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldData)
				fieldSeen[documentdatahistory.FieldData] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ddh.Select(selectedFields...)
	}
	return nil
}

type documentdatahistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DocumentDataHistoryPaginateOption
}

func newDocumentDataHistoryPaginateArgs(rv map[string]any) *documentdatahistoryPaginateArgs {
	args := &documentdatahistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DocumentDataHistoryOrder{Field: &DocumentDataHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDocumentDataHistoryOrder(order))
			}
		case *DocumentDataHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDocumentDataHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DocumentDataHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDocumentDataHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (e *EntityQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return e, nil
	}
	if err := e.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return e, nil
}

func (e *EntityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entity.Columns))
		selectedFields = []string{entity.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: e.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			e.withOwner = query
			if _, ok := fieldSeen[entity.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entity.FieldOwnerID)
				fieldSeen[entity.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: e.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(entity.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: e.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.EditorsColumn), ids...))
						})
						if err := query.GroupBy(entity.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: e.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.ViewersColumn), ids...))
						})
						if err := query.GroupBy(entity.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "contacts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: e.config}).Query()
			)
			args := newContactPaginateArgs(fieldArgs(ctx, new(ContactWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newContactPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.ContactsTable)
							s.Join(joinT).On(s.C(contact.FieldID), joinT.C(entity.ContactsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.ContactsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.ContactsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.ContactsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Contacts)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ContactsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedContacts(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: e.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.DocumentsTable)
							s.Join(joinT).On(s.C(documentdata.FieldID), joinT.C(entity.DocumentsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.DocumentsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.DocumentsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.DocumentsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.DocumentsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: e.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_notes"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.NotesColumn), ids...))
						})
						if err := query.GroupBy(entity.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: e.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(entity.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: e.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(entity.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: e.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.ScansColumn), ids...))
						})
						if err := query.GroupBy(entity.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entityType":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: e.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
				return err
			}
			e.withEntityType = query
			if _, ok := fieldSeen[entity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entity.FieldEntityTypeID)
				fieldSeen[entity.FieldEntityTypeID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entity.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entity.FieldCreatedAt)
				fieldSeen[entity.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entity.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entity.FieldUpdatedAt)
				fieldSeen[entity.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entity.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entity.FieldCreatedBy)
				fieldSeen[entity.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entity.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entity.FieldUpdatedBy)
				fieldSeen[entity.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entity.FieldTags]; !ok {
				selectedFields = append(selectedFields, entity.FieldTags)
				fieldSeen[entity.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entity.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entity.FieldOwnerID)
				fieldSeen[entity.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entity.FieldName]; !ok {
				selectedFields = append(selectedFields, entity.FieldName)
				fieldSeen[entity.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[entity.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, entity.FieldDisplayName)
				fieldSeen[entity.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[entity.FieldDescription]; !ok {
				selectedFields = append(selectedFields, entity.FieldDescription)
				fieldSeen[entity.FieldDescription] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[entity.FieldDomains]; !ok {
				selectedFields = append(selectedFields, entity.FieldDomains)
				fieldSeen[entity.FieldDomains] = struct{}{}
			}
		case "entityTypeID":
			if _, ok := fieldSeen[entity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entity.FieldEntityTypeID)
				fieldSeen[entity.FieldEntityTypeID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[entity.FieldStatus]; !ok {
				selectedFields = append(selectedFields, entity.FieldStatus)
				fieldSeen[entity.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		e.Select(selectedFields...)
	}
	return nil
}

type entityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityPaginateOption
}

func newEntityPaginateArgs(rv map[string]any) *entityPaginateArgs {
	args := &entityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EntityOrder:
			args.opts = append(args.opts, WithEntityOrder(v))
		case []any:
			var orders []*EntityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EntityOrder{Field: &EntityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEntityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EntityWhereInput); ok {
		args.opts = append(args.opts, WithEntityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (eh *EntityHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return eh, nil
	}
	if err := eh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return eh, nil
}

func (eh *EntityHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entityhistory.Columns))
		selectedFields = []string{entityhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[entityhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldHistoryTime)
				fieldSeen[entityhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[entityhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldRef)
				fieldSeen[entityhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[entityhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldOperation)
				fieldSeen[entityhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entityhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldCreatedAt)
				fieldSeen[entityhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entityhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldUpdatedAt)
				fieldSeen[entityhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entityhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldCreatedBy)
				fieldSeen[entityhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entityhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldUpdatedBy)
				fieldSeen[entityhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entityhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldTags)
				fieldSeen[entityhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entityhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldOwnerID)
				fieldSeen[entityhistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entityhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldName)
				fieldSeen[entityhistory.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[entityhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldDisplayName)
				fieldSeen[entityhistory.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[entityhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldDescription)
				fieldSeen[entityhistory.FieldDescription] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[entityhistory.FieldDomains]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldDomains)
				fieldSeen[entityhistory.FieldDomains] = struct{}{}
			}
		case "entityTypeID":
			if _, ok := fieldSeen[entityhistory.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldEntityTypeID)
				fieldSeen[entityhistory.FieldEntityTypeID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[entityhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldStatus)
				fieldSeen[entityhistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		eh.Select(selectedFields...)
	}
	return nil
}

type entityhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityHistoryPaginateOption
}

func newEntityHistoryPaginateArgs(rv map[string]any) *entityhistoryPaginateArgs {
	args := &entityhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &EntityHistoryOrder{Field: &EntityHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithEntityHistoryOrder(order))
			}
		case *EntityHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithEntityHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*EntityHistoryWhereInput); ok {
		args.opts = append(args.opts, WithEntityHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (et *EntityTypeQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityTypeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return et, nil
	}
	if err := et.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return et, nil
}

func (et *EntityTypeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entitytype.Columns))
		selectedFields = []string{entitytype.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: et.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			et.withOwner = query
			if _, ok := fieldSeen[entitytype.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldOwnerID)
				fieldSeen[entitytype.FieldOwnerID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: et.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					et.loadTotal = append(et.loadTotal, func(ctx context.Context, nodes []*EntityType) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_type_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entitytype.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(entitytype.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					et.loadTotal = append(et.loadTotal, func(_ context.Context, nodes []*EntityType) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entitytype.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			et.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[entitytype.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldCreatedAt)
				fieldSeen[entitytype.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entitytype.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldUpdatedAt)
				fieldSeen[entitytype.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entitytype.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldCreatedBy)
				fieldSeen[entitytype.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entitytype.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldUpdatedBy)
				fieldSeen[entitytype.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entitytype.FieldTags]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldTags)
				fieldSeen[entitytype.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entitytype.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldOwnerID)
				fieldSeen[entitytype.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entitytype.FieldName]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldName)
				fieldSeen[entitytype.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		et.Select(selectedFields...)
	}
	return nil
}

type entitytypePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityTypePaginateOption
}

func newEntityTypePaginateArgs(rv map[string]any) *entitytypePaginateArgs {
	args := &entitytypePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EntityTypeOrder:
			args.opts = append(args.opts, WithEntityTypeOrder(v))
		case []any:
			var orders []*EntityTypeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EntityTypeOrder{Field: &EntityTypeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEntityTypeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EntityTypeWhereInput); ok {
		args.opts = append(args.opts, WithEntityTypeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (eth *EntityTypeHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityTypeHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return eth, nil
	}
	if err := eth.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return eth, nil
}

func (eth *EntityTypeHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entitytypehistory.Columns))
		selectedFields = []string{entitytypehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[entitytypehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldHistoryTime)
				fieldSeen[entitytypehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[entitytypehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldRef)
				fieldSeen[entitytypehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[entitytypehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldOperation)
				fieldSeen[entitytypehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entitytypehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldCreatedAt)
				fieldSeen[entitytypehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entitytypehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldUpdatedAt)
				fieldSeen[entitytypehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entitytypehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldCreatedBy)
				fieldSeen[entitytypehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entitytypehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldUpdatedBy)
				fieldSeen[entitytypehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entitytypehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldTags)
				fieldSeen[entitytypehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entitytypehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldOwnerID)
				fieldSeen[entitytypehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entitytypehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldName)
				fieldSeen[entitytypehistory.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		eth.Select(selectedFields...)
	}
	return nil
}

type entitytypehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityTypeHistoryPaginateOption
}

func newEntityTypeHistoryPaginateArgs(rv map[string]any) *entitytypehistoryPaginateArgs {
	args := &entitytypehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &EntityTypeHistoryOrder{Field: &EntityTypeHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithEntityTypeHistoryOrder(order))
			}
		case *EntityTypeHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithEntityTypeHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*EntityTypeHistoryWhereInput); ok {
		args.opts = append(args.opts, WithEntityTypeHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (e *EventQuery) CollectFields(ctx context.Context, satisfies ...string) (*EventQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return e, nil
	}
	if err := e.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return e, nil
}

func (e *EventQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(event.Columns))
		selectedFields = []string{event.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: e.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(event.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: e.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(event.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: e.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(event.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: e.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(event.OrganizationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrganizationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrganizationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrganizationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrganizationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "invites":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InviteClient{config: e.config}).Query()
			)
			args := newInvitePaginateArgs(fieldArgs(ctx, new(InviteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInvitePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.InvitesTable)
							s.Join(joinT).On(s.C(invite.FieldID), joinT.C(event.InvitesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.InvitesPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.InvitesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.InvitesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Invites)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, inviteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.InvitesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedInvites(alias, func(wq *InviteQuery) {
				*wq = *query
			})

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: e.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.PersonalAccessTokensTable)
							s.Join(joinT).On(s.C(personalaccesstoken.FieldID), joinT.C(event.PersonalAccessTokensPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.PersonalAccessTokensPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.PersonalAccessTokensPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.PersonalAccessTokensPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.PersonalAccessTokensPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: e.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(event.SecretsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.SecretsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.SecretsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.SecretsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.SecretsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "orgmemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: e.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrgmembershipsTable)
							s.Join(joinT).On(s.C(orgmembership.FieldID), joinT.C(event.OrgmembershipsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrgmembershipsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrgmembershipsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrgmembershipsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Orgmemberships)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrgmembershipsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedOrgmemberships(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})

		case "groupmemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: e.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.GroupmembershipsTable)
							s.Join(joinT).On(s.C(groupmembership.FieldID), joinT.C(event.GroupmembershipsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.GroupmembershipsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.GroupmembershipsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.GroupmembershipsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groupmemberships)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.GroupmembershipsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedGroupmemberships(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})

		case "subscribers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubscriberClient{config: e.config}).Query()
			)
			args := newSubscriberPaginateArgs(fieldArgs(ctx, new(SubscriberWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubscriberPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.SubscribersTable)
							s.Join(joinT).On(s.C(subscriber.FieldID), joinT.C(event.SubscribersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.SubscribersPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.SubscribersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.SubscribersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subscribers)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subscriberImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.SubscribersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedSubscribers(alias, func(wq *SubscriberQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: e.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(event.FilesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.FilesPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.FilesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.FilesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.FilesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "orgSubscriptions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgSubscriptionClient{config: e.config}).Query()
			)
			args := newOrgSubscriptionPaginateArgs(fieldArgs(ctx, new(OrgSubscriptionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgSubscriptionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrgSubscriptionsTable)
							s.Join(joinT).On(s.C(orgsubscription.FieldID), joinT.C(event.OrgSubscriptionsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrgSubscriptionsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrgSubscriptionsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrgSubscriptionsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgSubscriptions)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgsubscriptionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrgSubscriptionsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedOrgSubscriptions(alias, func(wq *OrgSubscriptionQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[event.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, event.FieldCreatedAt)
				fieldSeen[event.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[event.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, event.FieldUpdatedAt)
				fieldSeen[event.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[event.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, event.FieldCreatedBy)
				fieldSeen[event.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[event.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, event.FieldUpdatedBy)
				fieldSeen[event.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[event.FieldTags]; !ok {
				selectedFields = append(selectedFields, event.FieldTags)
				fieldSeen[event.FieldTags] = struct{}{}
			}
		case "eventID":
			if _, ok := fieldSeen[event.FieldEventID]; !ok {
				selectedFields = append(selectedFields, event.FieldEventID)
				fieldSeen[event.FieldEventID] = struct{}{}
			}
		case "correlationID":
			if _, ok := fieldSeen[event.FieldCorrelationID]; !ok {
				selectedFields = append(selectedFields, event.FieldCorrelationID)
				fieldSeen[event.FieldCorrelationID] = struct{}{}
			}
		case "eventType":
			if _, ok := fieldSeen[event.FieldEventType]; !ok {
				selectedFields = append(selectedFields, event.FieldEventType)
				fieldSeen[event.FieldEventType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[event.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, event.FieldMetadata)
				fieldSeen[event.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		e.Select(selectedFields...)
	}
	return nil
}

type eventPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EventPaginateOption
}

func newEventPaginateArgs(rv map[string]any) *eventPaginateArgs {
	args := &eventPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EventOrder:
			args.opts = append(args.opts, WithEventOrder(v))
		case []any:
			var orders []*EventOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EventOrder{Field: &EventOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEventOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EventWhereInput); ok {
		args.opts = append(args.opts, WithEventFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (e *EvidenceQuery) CollectFields(ctx context.Context, satisfies ...string) (*EvidenceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return e, nil
	}
	if err := e.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return e, nil
}

func (e *EvidenceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(evidence.Columns))
		selectedFields = []string{evidence.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: e.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			e.withOwner = query
			if _, ok := fieldSeen[evidence.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldOwnerID)
				fieldSeen[evidence.FieldOwnerID] = struct{}{}
			}

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: e.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(evidence.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: e.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(evidence.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: e.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(evidence.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: e.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(evidence.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: e.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(evidence.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(evidence.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(evidence.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: e.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(evidence.TasksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(evidence.TasksPrimaryKey[1]), ids...))
							s.Select(joinT.C(evidence.TasksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.TasksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.TasksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[evidence.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreatedAt)
				fieldSeen[evidence.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[evidence.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, evidence.FieldUpdatedAt)
				fieldSeen[evidence.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[evidence.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreatedBy)
				fieldSeen[evidence.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[evidence.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, evidence.FieldUpdatedBy)
				fieldSeen[evidence.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[evidence.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldDisplayID)
				fieldSeen[evidence.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[evidence.FieldTags]; !ok {
				selectedFields = append(selectedFields, evidence.FieldTags)
				fieldSeen[evidence.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[evidence.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldOwnerID)
				fieldSeen[evidence.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[evidence.FieldName]; !ok {
				selectedFields = append(selectedFields, evidence.FieldName)
				fieldSeen[evidence.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[evidence.FieldDescription]; !ok {
				selectedFields = append(selectedFields, evidence.FieldDescription)
				fieldSeen[evidence.FieldDescription] = struct{}{}
			}
		case "collectionProcedure":
			if _, ok := fieldSeen[evidence.FieldCollectionProcedure]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCollectionProcedure)
				fieldSeen[evidence.FieldCollectionProcedure] = struct{}{}
			}
		case "creationDate":
			if _, ok := fieldSeen[evidence.FieldCreationDate]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreationDate)
				fieldSeen[evidence.FieldCreationDate] = struct{}{}
			}
		case "renewalDate":
			if _, ok := fieldSeen[evidence.FieldRenewalDate]; !ok {
				selectedFields = append(selectedFields, evidence.FieldRenewalDate)
				fieldSeen[evidence.FieldRenewalDate] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[evidence.FieldSource]; !ok {
				selectedFields = append(selectedFields, evidence.FieldSource)
				fieldSeen[evidence.FieldSource] = struct{}{}
			}
		case "isAutomated":
			if _, ok := fieldSeen[evidence.FieldIsAutomated]; !ok {
				selectedFields = append(selectedFields, evidence.FieldIsAutomated)
				fieldSeen[evidence.FieldIsAutomated] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[evidence.FieldURL]; !ok {
				selectedFields = append(selectedFields, evidence.FieldURL)
				fieldSeen[evidence.FieldURL] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[evidence.FieldStatus]; !ok {
				selectedFields = append(selectedFields, evidence.FieldStatus)
				fieldSeen[evidence.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		e.Select(selectedFields...)
	}
	return nil
}

type evidencePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EvidencePaginateOption
}

func newEvidencePaginateArgs(rv map[string]any) *evidencePaginateArgs {
	args := &evidencePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EvidenceOrder:
			args.opts = append(args.opts, WithEvidenceOrder(v))
		case []any:
			var orders []*EvidenceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EvidenceOrder{Field: &EvidenceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEvidenceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EvidenceWhereInput); ok {
		args.opts = append(args.opts, WithEvidenceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (eh *EvidenceHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*EvidenceHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return eh, nil
	}
	if err := eh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return eh, nil
}

func (eh *EvidenceHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(evidencehistory.Columns))
		selectedFields = []string{evidencehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[evidencehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldHistoryTime)
				fieldSeen[evidencehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[evidencehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldRef)
				fieldSeen[evidencehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[evidencehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldOperation)
				fieldSeen[evidencehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[evidencehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCreatedAt)
				fieldSeen[evidencehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[evidencehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldUpdatedAt)
				fieldSeen[evidencehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[evidencehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCreatedBy)
				fieldSeen[evidencehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[evidencehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldUpdatedBy)
				fieldSeen[evidencehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[evidencehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldDisplayID)
				fieldSeen[evidencehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[evidencehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldTags)
				fieldSeen[evidencehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[evidencehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldOwnerID)
				fieldSeen[evidencehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[evidencehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldName)
				fieldSeen[evidencehistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[evidencehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldDescription)
				fieldSeen[evidencehistory.FieldDescription] = struct{}{}
			}
		case "collectionProcedure":
			if _, ok := fieldSeen[evidencehistory.FieldCollectionProcedure]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCollectionProcedure)
				fieldSeen[evidencehistory.FieldCollectionProcedure] = struct{}{}
			}
		case "creationDate":
			if _, ok := fieldSeen[evidencehistory.FieldCreationDate]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCreationDate)
				fieldSeen[evidencehistory.FieldCreationDate] = struct{}{}
			}
		case "renewalDate":
			if _, ok := fieldSeen[evidencehistory.FieldRenewalDate]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldRenewalDate)
				fieldSeen[evidencehistory.FieldRenewalDate] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[evidencehistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldSource)
				fieldSeen[evidencehistory.FieldSource] = struct{}{}
			}
		case "isAutomated":
			if _, ok := fieldSeen[evidencehistory.FieldIsAutomated]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldIsAutomated)
				fieldSeen[evidencehistory.FieldIsAutomated] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[evidencehistory.FieldURL]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldURL)
				fieldSeen[evidencehistory.FieldURL] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[evidencehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldStatus)
				fieldSeen[evidencehistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		eh.Select(selectedFields...)
	}
	return nil
}

type evidencehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EvidenceHistoryPaginateOption
}

func newEvidenceHistoryPaginateArgs(rv map[string]any) *evidencehistoryPaginateArgs {
	args := &evidencehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &EvidenceHistoryOrder{Field: &EvidenceHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithEvidenceHistoryOrder(order))
			}
		case *EvidenceHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithEvidenceHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*EvidenceHistoryWhereInput); ok {
		args.opts = append(args.opts, WithEvidenceHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (e *ExportQuery) CollectFields(ctx context.Context, satisfies ...string) (*ExportQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return e, nil
	}
	if err := e.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return e, nil
}

func (e *ExportQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(export.Columns))
		selectedFields = []string{export.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: e.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			e.withOwner = query
			if _, ok := fieldSeen[export.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, export.FieldOwnerID)
				fieldSeen[export.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: e.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Export) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"export_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(export.EventsColumn), ids...))
						})
						if err := query.GroupBy(export.EventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Export) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(export.EventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: e.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					e.loadTotal = append(e.loadTotal, func(ctx context.Context, nodes []*Export) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"export_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(export.FilesColumn), ids...))
						})
						if err := query.GroupBy(export.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					e.loadTotal = append(e.loadTotal, func(_ context.Context, nodes []*Export) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(export.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			e.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[export.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, export.FieldCreatedAt)
				fieldSeen[export.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[export.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, export.FieldUpdatedAt)
				fieldSeen[export.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[export.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, export.FieldCreatedBy)
				fieldSeen[export.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[export.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, export.FieldUpdatedBy)
				fieldSeen[export.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[export.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, export.FieldOwnerID)
				fieldSeen[export.FieldOwnerID] = struct{}{}
			}
		case "exportType":
			if _, ok := fieldSeen[export.FieldExportType]; !ok {
				selectedFields = append(selectedFields, export.FieldExportType)
				fieldSeen[export.FieldExportType] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[export.FieldFormat]; !ok {
				selectedFields = append(selectedFields, export.FieldFormat)
				fieldSeen[export.FieldFormat] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[export.FieldStatus]; !ok {
				selectedFields = append(selectedFields, export.FieldStatus)
				fieldSeen[export.FieldStatus] = struct{}{}
			}
		case "requestorID":
			if _, ok := fieldSeen[export.FieldRequestorID]; !ok {
				selectedFields = append(selectedFields, export.FieldRequestorID)
				fieldSeen[export.FieldRequestorID] = struct{}{}
			}
		case "fields":
			if _, ok := fieldSeen[export.FieldFields]; !ok {
				selectedFields = append(selectedFields, export.FieldFields)
				fieldSeen[export.FieldFields] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		e.Select(selectedFields...)
	}
	return nil
}

type exportPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ExportPaginateOption
}

func newExportPaginateArgs(rv map[string]any) *exportPaginateArgs {
	args := &exportPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ExportOrder:
			args.opts = append(args.opts, WithExportOrder(v))
		case []any:
			var orders []*ExportOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ExportOrder{Field: &ExportOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithExportOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ExportWhereInput); ok {
		args.opts = append(args.opts, WithExportFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (f *FileQuery) CollectFields(ctx context.Context, satisfies ...string) (*FileQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return f, nil
	}
	if err := f.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return f, nil
}

func (f *FileQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(file.Columns))
		selectedFields = []string{file.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			f.WithNamedUser(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			f.WithNamedOrganization(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: f.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					f.loadTotal = append(f.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(file.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(file.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(file.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(file.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					f.loadTotal = append(f.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			f.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "contact":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
				return err
			}
			f.WithNamedContact(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "entity":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			f.WithNamedEntity(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "userSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserSettingClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, usersettingImplementors)...); err != nil {
				return err
			}
			f.WithNamedUserSetting(alias, func(wq *UserSettingQuery) {
				*wq = *query
			})

		case "organizationSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationSettingClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, organizationsettingImplementors)...); err != nil {
				return err
			}
			f.WithNamedOrganizationSetting(alias, func(wq *OrganizationSettingQuery) {
				*wq = *query
			})

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			f.WithNamedTemplate(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "document":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
				return err
			}
			f.WithNamedDocument(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "program":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
				return err
			}
			f.WithNamedProgram(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
				return err
			}
			f.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: f.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					f.loadTotal = append(f.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(file.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(file.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(file.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(file.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					f.loadTotal = append(f.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			f.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "trustCenterSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			f.WithNamedTrustCenterSetting(alias, func(wq *TrustCenterSettingQuery) {
				*wq = *query
			})

		case "subprocessor":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: f.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
				return err
			}
			f.WithNamedSubprocessor(alias, func(wq *SubprocessorQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[file.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedAt)
				fieldSeen[file.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[file.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldUpdatedAt)
				fieldSeen[file.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[file.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedBy)
				fieldSeen[file.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[file.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, file.FieldUpdatedBy)
				fieldSeen[file.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[file.FieldTags]; !ok {
				selectedFields = append(selectedFields, file.FieldTags)
				fieldSeen[file.FieldTags] = struct{}{}
			}
		case "providedFileName":
			if _, ok := fieldSeen[file.FieldProvidedFileName]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileName)
				fieldSeen[file.FieldProvidedFileName] = struct{}{}
			}
		case "providedFileExtension":
			if _, ok := fieldSeen[file.FieldProvidedFileExtension]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileExtension)
				fieldSeen[file.FieldProvidedFileExtension] = struct{}{}
			}
		case "providedFileSize":
			if _, ok := fieldSeen[file.FieldProvidedFileSize]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileSize)
				fieldSeen[file.FieldProvidedFileSize] = struct{}{}
			}
		case "persistedFileSize":
			if _, ok := fieldSeen[file.FieldPersistedFileSize]; !ok {
				selectedFields = append(selectedFields, file.FieldPersistedFileSize)
				fieldSeen[file.FieldPersistedFileSize] = struct{}{}
			}
		case "detectedMimeType":
			if _, ok := fieldSeen[file.FieldDetectedMimeType]; !ok {
				selectedFields = append(selectedFields, file.FieldDetectedMimeType)
				fieldSeen[file.FieldDetectedMimeType] = struct{}{}
			}
		case "md5Hash":
			if _, ok := fieldSeen[file.FieldMd5Hash]; !ok {
				selectedFields = append(selectedFields, file.FieldMd5Hash)
				fieldSeen[file.FieldMd5Hash] = struct{}{}
			}
		case "detectedContentType":
			if _, ok := fieldSeen[file.FieldDetectedContentType]; !ok {
				selectedFields = append(selectedFields, file.FieldDetectedContentType)
				fieldSeen[file.FieldDetectedContentType] = struct{}{}
			}
		case "storeKey":
			if _, ok := fieldSeen[file.FieldStoreKey]; !ok {
				selectedFields = append(selectedFields, file.FieldStoreKey)
				fieldSeen[file.FieldStoreKey] = struct{}{}
			}
		case "categoryType":
			if _, ok := fieldSeen[file.FieldCategoryType]; !ok {
				selectedFields = append(selectedFields, file.FieldCategoryType)
				fieldSeen[file.FieldCategoryType] = struct{}{}
			}
		case "uri":
			if _, ok := fieldSeen[file.FieldURI]; !ok {
				selectedFields = append(selectedFields, file.FieldURI)
				fieldSeen[file.FieldURI] = struct{}{}
			}
		case "storageScheme":
			if _, ok := fieldSeen[file.FieldStorageScheme]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageScheme)
				fieldSeen[file.FieldStorageScheme] = struct{}{}
			}
		case "storageVolume":
			if _, ok := fieldSeen[file.FieldStorageVolume]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageVolume)
				fieldSeen[file.FieldStorageVolume] = struct{}{}
			}
		case "storagePath":
			if _, ok := fieldSeen[file.FieldStoragePath]; !ok {
				selectedFields = append(selectedFields, file.FieldStoragePath)
				fieldSeen[file.FieldStoragePath] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		f.Select(selectedFields...)
	}
	return nil
}

type filePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FilePaginateOption
}

func newFilePaginateArgs(rv map[string]any) *filePaginateArgs {
	args := &filePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FileOrder:
			args.opts = append(args.opts, WithFileOrder(v))
		case []any:
			var orders []*FileOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FileOrder{Field: &FileOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFileOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FileWhereInput); ok {
		args.opts = append(args.opts, WithFileFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (fh *FileHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*FileHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return fh, nil
	}
	if err := fh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return fh, nil
}

func (fh *FileHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(filehistory.Columns))
		selectedFields = []string{filehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[filehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldHistoryTime)
				fieldSeen[filehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[filehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldRef)
				fieldSeen[filehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[filehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldOperation)
				fieldSeen[filehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[filehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldCreatedAt)
				fieldSeen[filehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[filehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldUpdatedAt)
				fieldSeen[filehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[filehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldCreatedBy)
				fieldSeen[filehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[filehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldUpdatedBy)
				fieldSeen[filehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[filehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldTags)
				fieldSeen[filehistory.FieldTags] = struct{}{}
			}
		case "providedFileName":
			if _, ok := fieldSeen[filehistory.FieldProvidedFileName]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldProvidedFileName)
				fieldSeen[filehistory.FieldProvidedFileName] = struct{}{}
			}
		case "providedFileExtension":
			if _, ok := fieldSeen[filehistory.FieldProvidedFileExtension]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldProvidedFileExtension)
				fieldSeen[filehistory.FieldProvidedFileExtension] = struct{}{}
			}
		case "providedFileSize":
			if _, ok := fieldSeen[filehistory.FieldProvidedFileSize]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldProvidedFileSize)
				fieldSeen[filehistory.FieldProvidedFileSize] = struct{}{}
			}
		case "persistedFileSize":
			if _, ok := fieldSeen[filehistory.FieldPersistedFileSize]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldPersistedFileSize)
				fieldSeen[filehistory.FieldPersistedFileSize] = struct{}{}
			}
		case "detectedMimeType":
			if _, ok := fieldSeen[filehistory.FieldDetectedMimeType]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldDetectedMimeType)
				fieldSeen[filehistory.FieldDetectedMimeType] = struct{}{}
			}
		case "md5Hash":
			if _, ok := fieldSeen[filehistory.FieldMd5Hash]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldMd5Hash)
				fieldSeen[filehistory.FieldMd5Hash] = struct{}{}
			}
		case "detectedContentType":
			if _, ok := fieldSeen[filehistory.FieldDetectedContentType]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldDetectedContentType)
				fieldSeen[filehistory.FieldDetectedContentType] = struct{}{}
			}
		case "storeKey":
			if _, ok := fieldSeen[filehistory.FieldStoreKey]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStoreKey)
				fieldSeen[filehistory.FieldStoreKey] = struct{}{}
			}
		case "categoryType":
			if _, ok := fieldSeen[filehistory.FieldCategoryType]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldCategoryType)
				fieldSeen[filehistory.FieldCategoryType] = struct{}{}
			}
		case "uri":
			if _, ok := fieldSeen[filehistory.FieldURI]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldURI)
				fieldSeen[filehistory.FieldURI] = struct{}{}
			}
		case "storageScheme":
			if _, ok := fieldSeen[filehistory.FieldStorageScheme]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStorageScheme)
				fieldSeen[filehistory.FieldStorageScheme] = struct{}{}
			}
		case "storageVolume":
			if _, ok := fieldSeen[filehistory.FieldStorageVolume]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStorageVolume)
				fieldSeen[filehistory.FieldStorageVolume] = struct{}{}
			}
		case "storagePath":
			if _, ok := fieldSeen[filehistory.FieldStoragePath]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStoragePath)
				fieldSeen[filehistory.FieldStoragePath] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		fh.Select(selectedFields...)
	}
	return nil
}

type filehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FileHistoryPaginateOption
}

func newFileHistoryPaginateArgs(rv map[string]any) *filehistoryPaginateArgs {
	args := &filehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &FileHistoryOrder{Field: &FileHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithFileHistoryOrder(order))
			}
		case *FileHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithFileHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*FileHistoryWhereInput); ok {
		args.opts = append(args.opts, WithFileHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (gr *GroupQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return gr, nil
	}
	if err := gr.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return gr, nil
}

func (gr *GroupQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(group.Columns))
		selectedFields = []string{group.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: gr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			gr.withOwner = query
			if _, ok := fieldSeen[group.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, group.FieldOwnerID)
				fieldSeen[group.FieldOwnerID] = struct{}{}
			}

		case "programEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: gr.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramEditorsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramEditors)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedProgramEditors(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: gr.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramBlockedGroupsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramBlockedGroups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedProgramBlockedGroups(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: gr.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramViewersTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramViewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedProgramViewers(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "riskEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: gr.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskEditorsTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskEditors)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedRiskEditors(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: gr.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskBlockedGroupsTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskBlockedGroups)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedRiskBlockedGroups(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: gr.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskViewersTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskViewers)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedRiskViewers(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlObjectiveEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: gr.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveEditorsTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveEditors)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlObjectiveEditors(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlObjectiveBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: gr.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveBlockedGroupsTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveBlockedGroups)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlObjectiveBlockedGroups(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlObjectiveViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: gr.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveViewersTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveViewers)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlObjectiveViewers(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "narrativeEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: gr.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeEditorsTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeEditors)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedNarrativeEditors(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "narrativeBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: gr.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeBlockedGroupsTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeBlockedGroups)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedNarrativeBlockedGroups(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "narrativeViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: gr.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeViewersTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeViewers)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedNarrativeViewers(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "controlImplementationEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: gr.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationEditorsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationEditors)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlImplementationEditors(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controlImplementationBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: gr.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationBlockedGroupsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationBlockedGroups)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlImplementationBlockedGroups(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controlImplementationViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: gr.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationViewersTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationViewers)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlImplementationViewers(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "scanEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: gr.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanEditorsTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanEditors)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedScanEditors(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "scanBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: gr.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanBlockedGroupsTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanBlockedGroups)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedScanBlockedGroups(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "scanViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: gr.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanViewersTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanViewers)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedScanViewers(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "procedureEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: gr.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProcedureEditorsTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(group.ProcedureEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProcedureEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProcedureEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProcedureEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureEditors)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProcedureEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedProcedureEditors(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "procedureBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: gr.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProcedureBlockedGroupsTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(group.ProcedureBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureBlockedGroups)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProcedureBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedProcedureBlockedGroups(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicyEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: gr.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.InternalPolicyEditorsTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(group.InternalPolicyEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyEditors)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.InternalPolicyEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedInternalPolicyEditors(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "internalPolicyBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: gr.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.InternalPolicyBlockedGroupsTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyBlockedGroups)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.InternalPolicyBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedInternalPolicyBlockedGroups(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "controlEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: gr.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlEditorsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(group.ControlEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlEditors)
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlEditors(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "controlBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: gr.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlBlockedGroupsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(group.ControlBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlBlockedGroups)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedControlBlockedGroups(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "mappedControlEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: gr.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.MappedControlEditorsTable)
							s.Join(joinT).On(s.C(mappedcontrol.FieldID), joinT.C(group.MappedControlEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.MappedControlEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.MappedControlEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.MappedControlEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlEditors)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MappedControlEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedMappedControlEditors(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "mappedControlBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: gr.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.MappedControlBlockedGroupsTable)
							s.Join(joinT).On(s.C(mappedcontrol.FieldID), joinT.C(group.MappedControlBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlBlockedGroups)
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MappedControlBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedMappedControlBlockedGroups(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupSettingClient{config: gr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupsettingImplementors)...); err != nil {
				return err
			}
			gr.withSetting = query

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: gr.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(group.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: gr.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(group.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: gr.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_integrations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(group.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(group.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: gr.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(group.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: gr.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(group.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: gr.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gr.loadTotal = append(gr.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(group.MembersColumn), ids...))
						})
						if err := query.GroupBy(group.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				} else {
					gr.loadTotal = append(gr.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gr.WithNamedMembers(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[group.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, group.FieldCreatedAt)
				fieldSeen[group.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[group.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, group.FieldUpdatedAt)
				fieldSeen[group.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[group.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, group.FieldCreatedBy)
				fieldSeen[group.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[group.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, group.FieldUpdatedBy)
				fieldSeen[group.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[group.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, group.FieldDisplayID)
				fieldSeen[group.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[group.FieldTags]; !ok {
				selectedFields = append(selectedFields, group.FieldTags)
				fieldSeen[group.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[group.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, group.FieldOwnerID)
				fieldSeen[group.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[group.FieldName]; !ok {
				selectedFields = append(selectedFields, group.FieldName)
				fieldSeen[group.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[group.FieldDescription]; !ok {
				selectedFields = append(selectedFields, group.FieldDescription)
				fieldSeen[group.FieldDescription] = struct{}{}
			}
		case "isManaged":
			if _, ok := fieldSeen[group.FieldIsManaged]; !ok {
				selectedFields = append(selectedFields, group.FieldIsManaged)
				fieldSeen[group.FieldIsManaged] = struct{}{}
			}
		case "gravatarLogoURL":
			if _, ok := fieldSeen[group.FieldGravatarLogoURL]; !ok {
				selectedFields = append(selectedFields, group.FieldGravatarLogoURL)
				fieldSeen[group.FieldGravatarLogoURL] = struct{}{}
			}
		case "logoURL":
			if _, ok := fieldSeen[group.FieldLogoURL]; !ok {
				selectedFields = append(selectedFields, group.FieldLogoURL)
				fieldSeen[group.FieldLogoURL] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[group.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, group.FieldDisplayName)
				fieldSeen[group.FieldDisplayName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		gr.Select(selectedFields...)
	}
	return nil
}

type groupPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupPaginateOption
}

func newGroupPaginateArgs(rv map[string]any) *groupPaginateArgs {
	args := &groupPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupOrder:
			args.opts = append(args.opts, WithGroupOrder(v))
		case []any:
			var orders []*GroupOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupOrder{Field: &GroupOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupWhereInput); ok {
		args.opts = append(args.opts, WithGroupFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (gh *GroupHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return gh, nil
	}
	if err := gh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return gh, nil
}

func (gh *GroupHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(grouphistory.Columns))
		selectedFields = []string{grouphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[grouphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldHistoryTime)
				fieldSeen[grouphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[grouphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldRef)
				fieldSeen[grouphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[grouphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldOperation)
				fieldSeen[grouphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[grouphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldCreatedAt)
				fieldSeen[grouphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[grouphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldUpdatedAt)
				fieldSeen[grouphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[grouphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldCreatedBy)
				fieldSeen[grouphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[grouphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldUpdatedBy)
				fieldSeen[grouphistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[grouphistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldDisplayID)
				fieldSeen[grouphistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[grouphistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldTags)
				fieldSeen[grouphistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[grouphistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldOwnerID)
				fieldSeen[grouphistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[grouphistory.FieldName]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldName)
				fieldSeen[grouphistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[grouphistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldDescription)
				fieldSeen[grouphistory.FieldDescription] = struct{}{}
			}
		case "isManaged":
			if _, ok := fieldSeen[grouphistory.FieldIsManaged]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldIsManaged)
				fieldSeen[grouphistory.FieldIsManaged] = struct{}{}
			}
		case "gravatarLogoURL":
			if _, ok := fieldSeen[grouphistory.FieldGravatarLogoURL]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldGravatarLogoURL)
				fieldSeen[grouphistory.FieldGravatarLogoURL] = struct{}{}
			}
		case "logoURL":
			if _, ok := fieldSeen[grouphistory.FieldLogoURL]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldLogoURL)
				fieldSeen[grouphistory.FieldLogoURL] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[grouphistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldDisplayName)
				fieldSeen[grouphistory.FieldDisplayName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		gh.Select(selectedFields...)
	}
	return nil
}

type grouphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupHistoryPaginateOption
}

func newGroupHistoryPaginateArgs(rv map[string]any) *grouphistoryPaginateArgs {
	args := &grouphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &GroupHistoryOrder{Field: &GroupHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithGroupHistoryOrder(order))
			}
		case *GroupHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithGroupHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*GroupHistoryWhereInput); ok {
		args.opts = append(args.opts, WithGroupHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (gm *GroupMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return gm, nil
	}
	if err := gm.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return gm, nil
}

func (gm *GroupMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupmembership.Columns))
		selectedFields = []string{groupmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: gm.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			gm.withGroup = query
			if _, ok := fieldSeen[groupmembership.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldGroupID)
				fieldSeen[groupmembership.FieldGroupID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: gm.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			gm.withUser = query
			if _, ok := fieldSeen[groupmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUserID)
				fieldSeen[groupmembership.FieldUserID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: gm.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					gm.loadTotal = append(gm.loadTotal, func(ctx context.Context, nodes []*GroupMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(groupmembership.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(groupmembership.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(groupmembership.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(groupmembership.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(groupmembership.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					gm.loadTotal = append(gm.loadTotal, func(_ context.Context, nodes []*GroupMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(groupmembership.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			gm.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[groupmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldCreatedAt)
				fieldSeen[groupmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUpdatedAt)
				fieldSeen[groupmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldCreatedBy)
				fieldSeen[groupmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUpdatedBy)
				fieldSeen[groupmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[groupmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldRole)
				fieldSeen[groupmembership.FieldRole] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupmembership.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldGroupID)
				fieldSeen[groupmembership.FieldGroupID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[groupmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUserID)
				fieldSeen[groupmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		gm.Select(selectedFields...)
	}
	return nil
}

type groupmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupMembershipPaginateOption
}

func newGroupMembershipPaginateArgs(rv map[string]any) *groupmembershipPaginateArgs {
	args := &groupmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupMembershipOrder:
			args.opts = append(args.opts, WithGroupMembershipOrder(v))
		case []any:
			var orders []*GroupMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupMembershipOrder{Field: &GroupMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupMembershipWhereInput); ok {
		args.opts = append(args.opts, WithGroupMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (gmh *GroupMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return gmh, nil
	}
	if err := gmh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return gmh, nil
}

func (gmh *GroupMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupmembershiphistory.Columns))
		selectedFields = []string{groupmembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[groupmembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldHistoryTime)
				fieldSeen[groupmembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[groupmembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldRef)
				fieldSeen[groupmembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[groupmembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldOperation)
				fieldSeen[groupmembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupmembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldCreatedAt)
				fieldSeen[groupmembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupmembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldUpdatedAt)
				fieldSeen[groupmembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupmembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldCreatedBy)
				fieldSeen[groupmembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupmembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldUpdatedBy)
				fieldSeen[groupmembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[groupmembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldRole)
				fieldSeen[groupmembershiphistory.FieldRole] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupmembershiphistory.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldGroupID)
				fieldSeen[groupmembershiphistory.FieldGroupID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[groupmembershiphistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldUserID)
				fieldSeen[groupmembershiphistory.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		gmh.Select(selectedFields...)
	}
	return nil
}

type groupmembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupMembershipHistoryPaginateOption
}

func newGroupMembershipHistoryPaginateArgs(rv map[string]any) *groupmembershiphistoryPaginateArgs {
	args := &groupmembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &GroupMembershipHistoryOrder{Field: &GroupMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithGroupMembershipHistoryOrder(order))
			}
		case *GroupMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithGroupMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*GroupMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithGroupMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (gs *GroupSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return gs, nil
	}
	if err := gs.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return gs, nil
}

func (gs *GroupSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupsetting.Columns))
		selectedFields = []string{groupsetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: gs.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			gs.withGroup = query
			if _, ok := fieldSeen[groupsetting.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldGroupID)
				fieldSeen[groupsetting.FieldGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupsetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldCreatedAt)
				fieldSeen[groupsetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupsetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldUpdatedAt)
				fieldSeen[groupsetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupsetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldCreatedBy)
				fieldSeen[groupsetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupsetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldUpdatedBy)
				fieldSeen[groupsetting.FieldUpdatedBy] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[groupsetting.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldVisibility)
				fieldSeen[groupsetting.FieldVisibility] = struct{}{}
			}
		case "joinPolicy":
			if _, ok := fieldSeen[groupsetting.FieldJoinPolicy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldJoinPolicy)
				fieldSeen[groupsetting.FieldJoinPolicy] = struct{}{}
			}
		case "syncToSlack":
			if _, ok := fieldSeen[groupsetting.FieldSyncToSlack]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldSyncToSlack)
				fieldSeen[groupsetting.FieldSyncToSlack] = struct{}{}
			}
		case "syncToGithub":
			if _, ok := fieldSeen[groupsetting.FieldSyncToGithub]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldSyncToGithub)
				fieldSeen[groupsetting.FieldSyncToGithub] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupsetting.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldGroupID)
				fieldSeen[groupsetting.FieldGroupID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		gs.Select(selectedFields...)
	}
	return nil
}

type groupsettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupSettingPaginateOption
}

func newGroupSettingPaginateArgs(rv map[string]any) *groupsettingPaginateArgs {
	args := &groupsettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupSettingOrder:
			args.opts = append(args.opts, WithGroupSettingOrder(v))
		case []any:
			var orders []*GroupSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupSettingOrder{Field: &GroupSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupSettingWhereInput); ok {
		args.opts = append(args.opts, WithGroupSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (gsh *GroupSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return gsh, nil
	}
	if err := gsh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return gsh, nil
}

func (gsh *GroupSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupsettinghistory.Columns))
		selectedFields = []string{groupsettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[groupsettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldHistoryTime)
				fieldSeen[groupsettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[groupsettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldRef)
				fieldSeen[groupsettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[groupsettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldOperation)
				fieldSeen[groupsettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupsettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldCreatedAt)
				fieldSeen[groupsettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupsettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldUpdatedAt)
				fieldSeen[groupsettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupsettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldCreatedBy)
				fieldSeen[groupsettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupsettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldUpdatedBy)
				fieldSeen[groupsettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[groupsettinghistory.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldVisibility)
				fieldSeen[groupsettinghistory.FieldVisibility] = struct{}{}
			}
		case "joinPolicy":
			if _, ok := fieldSeen[groupsettinghistory.FieldJoinPolicy]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldJoinPolicy)
				fieldSeen[groupsettinghistory.FieldJoinPolicy] = struct{}{}
			}
		case "syncToSlack":
			if _, ok := fieldSeen[groupsettinghistory.FieldSyncToSlack]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldSyncToSlack)
				fieldSeen[groupsettinghistory.FieldSyncToSlack] = struct{}{}
			}
		case "syncToGithub":
			if _, ok := fieldSeen[groupsettinghistory.FieldSyncToGithub]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldSyncToGithub)
				fieldSeen[groupsettinghistory.FieldSyncToGithub] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupsettinghistory.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldGroupID)
				fieldSeen[groupsettinghistory.FieldGroupID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		gsh.Select(selectedFields...)
	}
	return nil
}

type groupsettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupSettingHistoryPaginateOption
}

func newGroupSettingHistoryPaginateArgs(rv map[string]any) *groupsettinghistoryPaginateArgs {
	args := &groupsettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &GroupSettingHistoryOrder{Field: &GroupSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithGroupSettingHistoryOrder(order))
			}
		case *GroupSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithGroupSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*GroupSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithGroupSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (h *HushQuery) CollectFields(ctx context.Context, satisfies ...string) (*HushQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return h, nil
	}
	if err := h.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return h, nil
}

func (h *HushQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hush.Columns))
		selectedFields = []string{hush.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: h.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			h.withOwner = query
			if _, ok := fieldSeen[hush.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hush.FieldOwnerID)
				fieldSeen[hush.FieldOwnerID] = struct{}{}
			}

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: h.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(hush.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(hush.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(hush.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: h.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(hush.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(hush.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(hush.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[hush.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldCreatedAt)
				fieldSeen[hush.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[hush.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldUpdatedAt)
				fieldSeen[hush.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[hush.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, hush.FieldCreatedBy)
				fieldSeen[hush.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[hush.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, hush.FieldUpdatedBy)
				fieldSeen[hush.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[hush.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hush.FieldOwnerID)
				fieldSeen[hush.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[hush.FieldName]; !ok {
				selectedFields = append(selectedFields, hush.FieldName)
				fieldSeen[hush.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[hush.FieldDescription]; !ok {
				selectedFields = append(selectedFields, hush.FieldDescription)
				fieldSeen[hush.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[hush.FieldKind]; !ok {
				selectedFields = append(selectedFields, hush.FieldKind)
				fieldSeen[hush.FieldKind] = struct{}{}
			}
		case "secretName":
			if _, ok := fieldSeen[hush.FieldSecretName]; !ok {
				selectedFields = append(selectedFields, hush.FieldSecretName)
				fieldSeen[hush.FieldSecretName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		h.Select(selectedFields...)
	}
	return nil
}

type hushPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HushPaginateOption
}

func newHushPaginateArgs(rv map[string]any) *hushPaginateArgs {
	args := &hushPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HushOrder:
			args.opts = append(args.opts, WithHushOrder(v))
		case []any:
			var orders []*HushOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HushOrder{Field: &HushOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHushOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HushWhereInput); ok {
		args.opts = append(args.opts, WithHushFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (hh *HushHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*HushHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return hh, nil
	}
	if err := hh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return hh, nil
}

func (hh *HushHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hushhistory.Columns))
		selectedFields = []string{hushhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[hushhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldHistoryTime)
				fieldSeen[hushhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[hushhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldRef)
				fieldSeen[hushhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[hushhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldOperation)
				fieldSeen[hushhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[hushhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldCreatedAt)
				fieldSeen[hushhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[hushhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldUpdatedAt)
				fieldSeen[hushhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[hushhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldCreatedBy)
				fieldSeen[hushhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[hushhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldUpdatedBy)
				fieldSeen[hushhistory.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[hushhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldOwnerID)
				fieldSeen[hushhistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[hushhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldName)
				fieldSeen[hushhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[hushhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldDescription)
				fieldSeen[hushhistory.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[hushhistory.FieldKind]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldKind)
				fieldSeen[hushhistory.FieldKind] = struct{}{}
			}
		case "secretName":
			if _, ok := fieldSeen[hushhistory.FieldSecretName]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldSecretName)
				fieldSeen[hushhistory.FieldSecretName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		hh.Select(selectedFields...)
	}
	return nil
}

type hushhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HushHistoryPaginateOption
}

func newHushHistoryPaginateArgs(rv map[string]any) *hushhistoryPaginateArgs {
	args := &hushhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &HushHistoryOrder{Field: &HushHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithHushHistoryOrder(order))
			}
		case *HushHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithHushHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*HushHistoryWhereInput); ok {
		args.opts = append(args.opts, WithHushHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (i *IntegrationQuery) CollectFields(ctx context.Context, satisfies ...string) (*IntegrationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return i, nil
	}
	if err := i.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return i, nil
}

func (i *IntegrationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(integration.Columns))
		selectedFields = []string{integration.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: i.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			i.withOwner = query
			if _, ok := fieldSeen[integration.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integration.FieldOwnerID)
				fieldSeen[integration.FieldOwnerID] = struct{}{}
			}

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: i.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					i.loadTotal = append(i.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(integration.SecretsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.SecretsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.SecretsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.SecretsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					i.loadTotal = append(i.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.SecretsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			i.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: i.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					i.loadTotal = append(i.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(integration.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					i.loadTotal = append(i.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			i.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[integration.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, integration.FieldCreatedAt)
				fieldSeen[integration.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[integration.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, integration.FieldUpdatedAt)
				fieldSeen[integration.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[integration.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, integration.FieldCreatedBy)
				fieldSeen[integration.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[integration.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, integration.FieldUpdatedBy)
				fieldSeen[integration.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[integration.FieldTags]; !ok {
				selectedFields = append(selectedFields, integration.FieldTags)
				fieldSeen[integration.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[integration.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integration.FieldOwnerID)
				fieldSeen[integration.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[integration.FieldName]; !ok {
				selectedFields = append(selectedFields, integration.FieldName)
				fieldSeen[integration.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[integration.FieldDescription]; !ok {
				selectedFields = append(selectedFields, integration.FieldDescription)
				fieldSeen[integration.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[integration.FieldKind]; !ok {
				selectedFields = append(selectedFields, integration.FieldKind)
				fieldSeen[integration.FieldKind] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		i.Select(selectedFields...)
	}
	return nil
}

type integrationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []IntegrationPaginateOption
}

func newIntegrationPaginateArgs(rv map[string]any) *integrationPaginateArgs {
	args := &integrationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*IntegrationOrder:
			args.opts = append(args.opts, WithIntegrationOrder(v))
		case []any:
			var orders []*IntegrationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &IntegrationOrder{Field: &IntegrationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithIntegrationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*IntegrationWhereInput); ok {
		args.opts = append(args.opts, WithIntegrationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ih *IntegrationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*IntegrationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ih, nil
	}
	if err := ih.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ih, nil
}

func (ih *IntegrationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(integrationhistory.Columns))
		selectedFields = []string{integrationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[integrationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldHistoryTime)
				fieldSeen[integrationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[integrationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldRef)
				fieldSeen[integrationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[integrationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldOperation)
				fieldSeen[integrationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[integrationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldCreatedAt)
				fieldSeen[integrationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[integrationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldUpdatedAt)
				fieldSeen[integrationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[integrationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldCreatedBy)
				fieldSeen[integrationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[integrationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldUpdatedBy)
				fieldSeen[integrationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[integrationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldTags)
				fieldSeen[integrationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[integrationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldOwnerID)
				fieldSeen[integrationhistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[integrationhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldName)
				fieldSeen[integrationhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[integrationhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldDescription)
				fieldSeen[integrationhistory.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[integrationhistory.FieldKind]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldKind)
				fieldSeen[integrationhistory.FieldKind] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ih.Select(selectedFields...)
	}
	return nil
}

type integrationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []IntegrationHistoryPaginateOption
}

func newIntegrationHistoryPaginateArgs(rv map[string]any) *integrationhistoryPaginateArgs {
	args := &integrationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &IntegrationHistoryOrder{Field: &IntegrationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithIntegrationHistoryOrder(order))
			}
		case *IntegrationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithIntegrationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*IntegrationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithIntegrationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ip *InternalPolicyQuery) CollectFields(ctx context.Context, satisfies ...string) (*InternalPolicyQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ip, nil
	}
	if err := ip.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ip, nil
}

func (ip *InternalPolicyQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(internalpolicy.Columns))
		selectedFields = []string{internalpolicy.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: ip.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			ip.withOwner = query
			if _, ok := fieldSeen[internalpolicy.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldOwnerID)
				fieldSeen[internalpolicy.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ip.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(internalpolicy.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ip.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(internalpolicy.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ip.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			ip.withApprover = query
			if _, ok := fieldSeen[internalpolicy.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApproverID)
				fieldSeen[internalpolicy.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: ip.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			ip.withDelegate = query
			if _, ok := fieldSeen[internalpolicy.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDelegateID)
				fieldSeen[internalpolicy.FieldDelegateID] = struct{}{}
			}

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: ip.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(internalpolicy.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: ip.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(internalpolicy.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: ip.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(internalpolicy.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: ip.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(internalpolicy.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: ip.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(internalpolicy.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: ip.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(internalpolicy.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: ip.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(internalpolicy.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: ip.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					ip.loadTotal = append(ip.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(internalpolicy.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(internalpolicy.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					ip.loadTotal = append(ip.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			ip.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[internalpolicy.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldCreatedAt)
				fieldSeen[internalpolicy.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[internalpolicy.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldUpdatedAt)
				fieldSeen[internalpolicy.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[internalpolicy.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldCreatedBy)
				fieldSeen[internalpolicy.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[internalpolicy.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldUpdatedBy)
				fieldSeen[internalpolicy.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[internalpolicy.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDisplayID)
				fieldSeen[internalpolicy.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[internalpolicy.FieldTags]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldTags)
				fieldSeen[internalpolicy.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[internalpolicy.FieldRevision]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldRevision)
				fieldSeen[internalpolicy.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[internalpolicy.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldOwnerID)
				fieldSeen[internalpolicy.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[internalpolicy.FieldName]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldName)
				fieldSeen[internalpolicy.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[internalpolicy.FieldStatus]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldStatus)
				fieldSeen[internalpolicy.FieldStatus] = struct{}{}
			}
		case "policyType":
			if _, ok := fieldSeen[internalpolicy.FieldPolicyType]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldPolicyType)
				fieldSeen[internalpolicy.FieldPolicyType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[internalpolicy.FieldDetails]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDetails)
				fieldSeen[internalpolicy.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[internalpolicy.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApprovalRequired)
				fieldSeen[internalpolicy.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[internalpolicy.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldReviewDue)
				fieldSeen[internalpolicy.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[internalpolicy.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldReviewFrequency)
				fieldSeen[internalpolicy.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[internalpolicy.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApproverID)
				fieldSeen[internalpolicy.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[internalpolicy.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDelegateID)
				fieldSeen[internalpolicy.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[internalpolicy.FieldSummary]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSummary)
				fieldSeen[internalpolicy.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldTagSuggestions)
				fieldSeen[internalpolicy.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedTagSuggestions)
				fieldSeen[internalpolicy.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldControlSuggestions)
				fieldSeen[internalpolicy.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedControlSuggestions)
				fieldSeen[internalpolicy.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldImprovementSuggestions)
				fieldSeen[internalpolicy.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedImprovementSuggestions)
				fieldSeen[internalpolicy.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ip.Select(selectedFields...)
	}
	return nil
}

type internalpolicyPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InternalPolicyPaginateOption
}

func newInternalPolicyPaginateArgs(rv map[string]any) *internalpolicyPaginateArgs {
	args := &internalpolicyPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*InternalPolicyOrder:
			args.opts = append(args.opts, WithInternalPolicyOrder(v))
		case []any:
			var orders []*InternalPolicyOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &InternalPolicyOrder{Field: &InternalPolicyOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithInternalPolicyOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*InternalPolicyWhereInput); ok {
		args.opts = append(args.opts, WithInternalPolicyFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (iph *InternalPolicyHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*InternalPolicyHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return iph, nil
	}
	if err := iph.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return iph, nil
}

func (iph *InternalPolicyHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(internalpolicyhistory.Columns))
		selectedFields = []string{internalpolicyhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[internalpolicyhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldHistoryTime)
				fieldSeen[internalpolicyhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[internalpolicyhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldRef)
				fieldSeen[internalpolicyhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[internalpolicyhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldOperation)
				fieldSeen[internalpolicyhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[internalpolicyhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldCreatedAt)
				fieldSeen[internalpolicyhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[internalpolicyhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldUpdatedAt)
				fieldSeen[internalpolicyhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[internalpolicyhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldCreatedBy)
				fieldSeen[internalpolicyhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[internalpolicyhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldUpdatedBy)
				fieldSeen[internalpolicyhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDisplayID)
				fieldSeen[internalpolicyhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[internalpolicyhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldTags)
				fieldSeen[internalpolicyhistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[internalpolicyhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldRevision)
				fieldSeen[internalpolicyhistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldOwnerID)
				fieldSeen[internalpolicyhistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[internalpolicyhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldName)
				fieldSeen[internalpolicyhistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[internalpolicyhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldStatus)
				fieldSeen[internalpolicyhistory.FieldStatus] = struct{}{}
			}
		case "policyType":
			if _, ok := fieldSeen[internalpolicyhistory.FieldPolicyType]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldPolicyType)
				fieldSeen[internalpolicyhistory.FieldPolicyType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDetails)
				fieldSeen[internalpolicyhistory.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[internalpolicyhistory.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldApprovalRequired)
				fieldSeen[internalpolicyhistory.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[internalpolicyhistory.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldReviewDue)
				fieldSeen[internalpolicyhistory.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[internalpolicyhistory.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldReviewFrequency)
				fieldSeen[internalpolicyhistory.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldApproverID)
				fieldSeen[internalpolicyhistory.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDelegateID)
				fieldSeen[internalpolicyhistory.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[internalpolicyhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldSummary)
				fieldSeen[internalpolicyhistory.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldTagSuggestions)
				fieldSeen[internalpolicyhistory.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDismissedTagSuggestions)
				fieldSeen[internalpolicyhistory.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldControlSuggestions)
				fieldSeen[internalpolicyhistory.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDismissedControlSuggestions)
				fieldSeen[internalpolicyhistory.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldImprovementSuggestions)
				fieldSeen[internalpolicyhistory.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDismissedImprovementSuggestions)
				fieldSeen[internalpolicyhistory.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		iph.Select(selectedFields...)
	}
	return nil
}

type internalpolicyhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InternalPolicyHistoryPaginateOption
}

func newInternalPolicyHistoryPaginateArgs(rv map[string]any) *internalpolicyhistoryPaginateArgs {
	args := &internalpolicyhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &InternalPolicyHistoryOrder{Field: &InternalPolicyHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithInternalPolicyHistoryOrder(order))
			}
		case *InternalPolicyHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithInternalPolicyHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*InternalPolicyHistoryWhereInput); ok {
		args.opts = append(args.opts, WithInternalPolicyHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (i *InviteQuery) CollectFields(ctx context.Context, satisfies ...string) (*InviteQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return i, nil
	}
	if err := i.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return i, nil
}

func (i *InviteQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(invite.Columns))
		selectedFields = []string{invite.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: i.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			i.withOwner = query
			if _, ok := fieldSeen[invite.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnerID)
				fieldSeen[invite.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: i.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					i.loadTotal = append(i.loadTotal, func(ctx context.Context, nodes []*Invite) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"invite_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(invite.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(invite.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(invite.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(invite.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(invite.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					i.loadTotal = append(i.loadTotal, func(_ context.Context, nodes []*Invite) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(invite.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			i.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[invite.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, invite.FieldCreatedAt)
				fieldSeen[invite.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[invite.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, invite.FieldUpdatedAt)
				fieldSeen[invite.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[invite.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, invite.FieldCreatedBy)
				fieldSeen[invite.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[invite.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, invite.FieldUpdatedBy)
				fieldSeen[invite.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[invite.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnerID)
				fieldSeen[invite.FieldOwnerID] = struct{}{}
			}
		case "expires":
			if _, ok := fieldSeen[invite.FieldExpires]; !ok {
				selectedFields = append(selectedFields, invite.FieldExpires)
				fieldSeen[invite.FieldExpires] = struct{}{}
			}
		case "recipient":
			if _, ok := fieldSeen[invite.FieldRecipient]; !ok {
				selectedFields = append(selectedFields, invite.FieldRecipient)
				fieldSeen[invite.FieldRecipient] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[invite.FieldStatus]; !ok {
				selectedFields = append(selectedFields, invite.FieldStatus)
				fieldSeen[invite.FieldStatus] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[invite.FieldRole]; !ok {
				selectedFields = append(selectedFields, invite.FieldRole)
				fieldSeen[invite.FieldRole] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[invite.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, invite.FieldSendAttempts)
				fieldSeen[invite.FieldSendAttempts] = struct{}{}
			}
		case "requestorID":
			if _, ok := fieldSeen[invite.FieldRequestorID]; !ok {
				selectedFields = append(selectedFields, invite.FieldRequestorID)
				fieldSeen[invite.FieldRequestorID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		i.Select(selectedFields...)
	}
	return nil
}

type invitePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InvitePaginateOption
}

func newInvitePaginateArgs(rv map[string]any) *invitePaginateArgs {
	args := &invitePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*InviteOrder:
			args.opts = append(args.opts, WithInviteOrder(v))
		case []any:
			var orders []*InviteOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &InviteOrder{Field: &InviteOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithInviteOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*InviteWhereInput); ok {
		args.opts = append(args.opts, WithInviteFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (jr *JobResultQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobResultQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return jr, nil
	}
	if err := jr.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return jr, nil
}

func (jr *JobResultQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobresult.Columns))
		selectedFields = []string{jobresult.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: jr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			jr.withOwner = query
			if _, ok := fieldSeen[jobresult.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldOwnerID)
				fieldSeen[jobresult.FieldOwnerID] = struct{}{}
			}

		case "scheduledJob":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlScheduledJobClient{config: jr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlscheduledjobImplementors)...); err != nil {
				return err
			}
			jr.withScheduledJob = query
			if _, ok := fieldSeen[jobresult.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldScheduledJobID)
				fieldSeen[jobresult.FieldScheduledJobID] = struct{}{}
			}

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: jr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			jr.withFile = query
			if _, ok := fieldSeen[jobresult.FieldFileID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFileID)
				fieldSeen[jobresult.FieldFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobresult.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldCreatedAt)
				fieldSeen[jobresult.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobresult.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldUpdatedAt)
				fieldSeen[jobresult.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobresult.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldCreatedBy)
				fieldSeen[jobresult.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobresult.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldUpdatedBy)
				fieldSeen[jobresult.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobresult.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldOwnerID)
				fieldSeen[jobresult.FieldOwnerID] = struct{}{}
			}
		case "scheduledJobID":
			if _, ok := fieldSeen[jobresult.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldScheduledJobID)
				fieldSeen[jobresult.FieldScheduledJobID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[jobresult.FieldStatus]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldStatus)
				fieldSeen[jobresult.FieldStatus] = struct{}{}
			}
		case "exitCode":
			if _, ok := fieldSeen[jobresult.FieldExitCode]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldExitCode)
				fieldSeen[jobresult.FieldExitCode] = struct{}{}
			}
		case "finishedAt":
			if _, ok := fieldSeen[jobresult.FieldFinishedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFinishedAt)
				fieldSeen[jobresult.FieldFinishedAt] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[jobresult.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldStartedAt)
				fieldSeen[jobresult.FieldStartedAt] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[jobresult.FieldFileID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFileID)
				fieldSeen[jobresult.FieldFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		jr.Select(selectedFields...)
	}
	return nil
}

type jobresultPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobResultPaginateOption
}

func newJobResultPaginateArgs(rv map[string]any) *jobresultPaginateArgs {
	args := &jobresultPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobResultOrder:
			args.opts = append(args.opts, WithJobResultOrder(v))
		case []any:
			var orders []*JobResultOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobResultOrder{Field: &JobResultOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobResultOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobResultWhereInput); ok {
		args.opts = append(args.opts, WithJobResultFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (jr *JobRunnerQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return jr, nil
	}
	if err := jr.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return jr, nil
}

func (jr *JobRunnerQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunner.Columns))
		selectedFields = []string{jobrunner.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: jr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			jr.withOwner = query
			if _, ok := fieldSeen[jobrunner.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOwnerID)
				fieldSeen[jobrunner.FieldOwnerID] = struct{}{}
			}

		case "jobRunnerTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerTokenClient{config: jr.config}).Query()
			)
			args := newJobRunnerTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					jr.loadTotal = append(jr.loadTotal, func(ctx context.Context, nodes []*JobRunner) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_runner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(jobrunner.JobRunnerTokensTable)
							s.Join(joinT).On(s.C(jobrunnertoken.FieldID), joinT.C(jobrunner.JobRunnerTokensPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]), ids...))
							s.Select(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					jr.loadTotal = append(jr.loadTotal, func(_ context.Context, nodes []*JobRunner) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerTokens)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnertokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobrunner.JobRunnerTokensPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			jr.WithNamedJobRunnerTokens(alias, func(wq *JobRunnerTokenQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobrunner.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldCreatedAt)
				fieldSeen[jobrunner.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunner.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldUpdatedAt)
				fieldSeen[jobrunner.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunner.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldCreatedBy)
				fieldSeen[jobrunner.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunner.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldUpdatedBy)
				fieldSeen[jobrunner.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[jobrunner.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldDisplayID)
				fieldSeen[jobrunner.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunner.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldTags)
				fieldSeen[jobrunner.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunner.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOwnerID)
				fieldSeen[jobrunner.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[jobrunner.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldSystemOwned)
				fieldSeen[jobrunner.FieldSystemOwned] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[jobrunner.FieldName]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldName)
				fieldSeen[jobrunner.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[jobrunner.FieldStatus]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldStatus)
				fieldSeen[jobrunner.FieldStatus] = struct{}{}
			}
		case "ipAddress":
			if _, ok := fieldSeen[jobrunner.FieldIPAddress]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldIPAddress)
				fieldSeen[jobrunner.FieldIPAddress] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		jr.Select(selectedFields...)
	}
	return nil
}

type jobrunnerPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerPaginateOption
}

func newJobRunnerPaginateArgs(rv map[string]any) *jobrunnerPaginateArgs {
	args := &jobrunnerPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerOrder:
			args.opts = append(args.opts, WithJobRunnerOrder(v))
		case []any:
			var orders []*JobRunnerOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerOrder{Field: &JobRunnerOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (jrrt *JobRunnerRegistrationTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerRegistrationTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return jrrt, nil
	}
	if err := jrrt.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return jrrt, nil
}

func (jrrt *JobRunnerRegistrationTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunnerregistrationtoken.Columns))
		selectedFields = []string{jobrunnerregistrationtoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: jrrt.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			jrrt.withOwner = query
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldOwnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldOwnerID] = struct{}{}
			}

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: jrrt.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			jrrt.withJobRunner = query
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldJobRunnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldCreatedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldUpdatedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldCreatedBy)
				fieldSeen[jobrunnerregistrationtoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldUpdatedBy)
				fieldSeen[jobrunnerregistrationtoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldTags)
				fieldSeen[jobrunnerregistrationtoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldOwnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldOwnerID] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldToken)
				fieldSeen[jobrunnerregistrationtoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldExpiresAt)
				fieldSeen[jobrunnerregistrationtoken.FieldExpiresAt] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldLastUsedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldLastUsedAt] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldJobRunnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		jrrt.Select(selectedFields...)
	}
	return nil
}

type jobrunnerregistrationtokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerRegistrationTokenPaginateOption
}

func newJobRunnerRegistrationTokenPaginateArgs(rv map[string]any) *jobrunnerregistrationtokenPaginateArgs {
	args := &jobrunnerregistrationtokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerRegistrationTokenOrder:
			args.opts = append(args.opts, WithJobRunnerRegistrationTokenOrder(v))
		case []any:
			var orders []*JobRunnerRegistrationTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerRegistrationTokenOrder{Field: &JobRunnerRegistrationTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerRegistrationTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerRegistrationTokenWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerRegistrationTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (jrt *JobRunnerTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return jrt, nil
	}
	if err := jrt.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return jrt, nil
}

func (jrt *JobRunnerTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunnertoken.Columns))
		selectedFields = []string{jobrunnertoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: jrt.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			jrt.withOwner = query
			if _, ok := fieldSeen[jobrunnertoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldOwnerID)
				fieldSeen[jobrunnertoken.FieldOwnerID] = struct{}{}
			}

		case "jobRunners":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: jrt.config}).Query()
			)
			args := newJobRunnerPaginateArgs(fieldArgs(ctx, new(JobRunnerWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					jrt.loadTotal = append(jrt.loadTotal, func(ctx context.Context, nodes []*JobRunnerToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_runner_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(jobrunnertoken.JobRunnersTable)
							s.Join(joinT).On(s.C(jobrunner.FieldID), joinT.C(jobrunnertoken.JobRunnersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]), ids...))
							s.Select(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					jrt.loadTotal = append(jrt.loadTotal, func(_ context.Context, nodes []*JobRunnerToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunners)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobrunnertoken.JobRunnersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			jrt.WithNamedJobRunners(alias, func(wq *JobRunnerQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldCreatedAt)
				fieldSeen[jobrunnertoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldUpdatedAt)
				fieldSeen[jobrunnertoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldCreatedBy)
				fieldSeen[jobrunnertoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldUpdatedBy)
				fieldSeen[jobrunnertoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunnertoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldTags)
				fieldSeen[jobrunnertoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunnertoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldOwnerID)
				fieldSeen[jobrunnertoken.FieldOwnerID] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[jobrunnertoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldToken)
				fieldSeen[jobrunnertoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldExpiresAt)
				fieldSeen[jobrunnertoken.FieldExpiresAt] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldLastUsedAt)
				fieldSeen[jobrunnertoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[jobrunnertoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldIsActive)
				fieldSeen[jobrunnertoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedReason)
				fieldSeen[jobrunnertoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedBy)
				fieldSeen[jobrunnertoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedAt)
				fieldSeen[jobrunnertoken.FieldRevokedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		jrt.Select(selectedFields...)
	}
	return nil
}

type jobrunnertokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerTokenPaginateOption
}

func newJobRunnerTokenPaginateArgs(rv map[string]any) *jobrunnertokenPaginateArgs {
	args := &jobrunnertokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerTokenOrder:
			args.opts = append(args.opts, WithJobRunnerTokenOrder(v))
		case []any:
			var orders []*JobRunnerTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerTokenOrder{Field: &JobRunnerTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerTokenWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (md *MappableDomainQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappableDomainQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return md, nil
	}
	if err := md.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return md, nil
}

func (md *MappableDomainQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappabledomain.Columns))
		selectedFields = []string{mappabledomain.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: md.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					md.loadTotal = append(md.loadTotal, func(ctx context.Context, nodes []*MappableDomain) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mappable_domain_custom_domains"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(mappabledomain.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(mappabledomain.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					md.loadTotal = append(md.loadTotal, func(_ context.Context, nodes []*MappableDomain) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappabledomain.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			md.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[mappabledomain.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldCreatedAt)
				fieldSeen[mappabledomain.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappabledomain.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldUpdatedAt)
				fieldSeen[mappabledomain.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappabledomain.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldCreatedBy)
				fieldSeen[mappabledomain.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappabledomain.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldUpdatedBy)
				fieldSeen[mappabledomain.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappabledomain.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldTags)
				fieldSeen[mappabledomain.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[mappabledomain.FieldName]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldName)
				fieldSeen[mappabledomain.FieldName] = struct{}{}
			}
		case "zoneID":
			if _, ok := fieldSeen[mappabledomain.FieldZoneID]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldZoneID)
				fieldSeen[mappabledomain.FieldZoneID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		md.Select(selectedFields...)
	}
	return nil
}

type mappabledomainPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappableDomainPaginateOption
}

func newMappableDomainPaginateArgs(rv map[string]any) *mappabledomainPaginateArgs {
	args := &mappabledomainPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*MappableDomainOrder:
			args.opts = append(args.opts, WithMappableDomainOrder(v))
		case []any:
			var orders []*MappableDomainOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &MappableDomainOrder{Field: &MappableDomainOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithMappableDomainOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*MappableDomainWhereInput); ok {
		args.opts = append(args.opts, WithMappableDomainFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (mdh *MappableDomainHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappableDomainHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return mdh, nil
	}
	if err := mdh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return mdh, nil
}

func (mdh *MappableDomainHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappabledomainhistory.Columns))
		selectedFields = []string{mappabledomainhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[mappabledomainhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldHistoryTime)
				fieldSeen[mappabledomainhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[mappabledomainhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldRef)
				fieldSeen[mappabledomainhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[mappabledomainhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldOperation)
				fieldSeen[mappabledomainhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[mappabledomainhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldCreatedAt)
				fieldSeen[mappabledomainhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappabledomainhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldUpdatedAt)
				fieldSeen[mappabledomainhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappabledomainhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldCreatedBy)
				fieldSeen[mappabledomainhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappabledomainhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldUpdatedBy)
				fieldSeen[mappabledomainhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappabledomainhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldTags)
				fieldSeen[mappabledomainhistory.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[mappabledomainhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldName)
				fieldSeen[mappabledomainhistory.FieldName] = struct{}{}
			}
		case "zoneID":
			if _, ok := fieldSeen[mappabledomainhistory.FieldZoneID]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldZoneID)
				fieldSeen[mappabledomainhistory.FieldZoneID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		mdh.Select(selectedFields...)
	}
	return nil
}

type mappabledomainhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappableDomainHistoryPaginateOption
}

func newMappableDomainHistoryPaginateArgs(rv map[string]any) *mappabledomainhistoryPaginateArgs {
	args := &mappabledomainhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &MappableDomainHistoryOrder{Field: &MappableDomainHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithMappableDomainHistoryOrder(order))
			}
		case *MappableDomainHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithMappableDomainHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*MappableDomainHistoryWhereInput); ok {
		args.opts = append(args.opts, WithMappableDomainHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (mc *MappedControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappedControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return mc, nil
	}
	if err := mc.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return mc, nil
}

func (mc *MappedControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappedcontrol.Columns))
		selectedFields = []string{mappedcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: mc.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			mc.withOwner = query
			if _, ok := fieldSeen[mappedcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldOwnerID)
				fieldSeen[mappedcontrol.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: mc.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					mc.loadTotal = append(mc.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					mc.loadTotal = append(mc.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			mc.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: mc.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					mc.loadTotal = append(mc.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(mappedcontrol.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					mc.loadTotal = append(mc.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			mc.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "fromControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: mc.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					mc.loadTotal = append(mc.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.FromControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(mappedcontrol.FromControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					mc.loadTotal = append(mc.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FromControls)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.FromControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			mc.WithNamedFromControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "toControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: mc.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					mc.loadTotal = append(mc.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.ToControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(mappedcontrol.ToControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					mc.loadTotal = append(mc.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ToControls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.ToControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			mc.WithNamedToControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "fromSubcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: mc.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					mc.loadTotal = append(mc.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.FromSubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					mc.loadTotal = append(mc.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FromSubcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.FromSubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			mc.WithNamedFromSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "toSubcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: mc.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					mc.loadTotal = append(mc.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.ToSubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					mc.loadTotal = append(mc.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ToSubcontrols)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.ToSubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			mc.WithNamedToSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[mappedcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldCreatedAt)
				fieldSeen[mappedcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappedcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldUpdatedAt)
				fieldSeen[mappedcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappedcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldCreatedBy)
				fieldSeen[mappedcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappedcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldUpdatedBy)
				fieldSeen[mappedcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappedcontrol.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldTags)
				fieldSeen[mappedcontrol.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[mappedcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldOwnerID)
				fieldSeen[mappedcontrol.FieldOwnerID] = struct{}{}
			}
		case "mappingType":
			if _, ok := fieldSeen[mappedcontrol.FieldMappingType]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldMappingType)
				fieldSeen[mappedcontrol.FieldMappingType] = struct{}{}
			}
		case "relation":
			if _, ok := fieldSeen[mappedcontrol.FieldRelation]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldRelation)
				fieldSeen[mappedcontrol.FieldRelation] = struct{}{}
			}
		case "confidence":
			if _, ok := fieldSeen[mappedcontrol.FieldConfidence]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldConfidence)
				fieldSeen[mappedcontrol.FieldConfidence] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[mappedcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSource)
				fieldSeen[mappedcontrol.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		mc.Select(selectedFields...)
	}
	return nil
}

type mappedcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappedControlPaginateOption
}

func newMappedControlPaginateArgs(rv map[string]any) *mappedcontrolPaginateArgs {
	args := &mappedcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*MappedControlOrder:
			args.opts = append(args.opts, WithMappedControlOrder(v))
		case []any:
			var orders []*MappedControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &MappedControlOrder{Field: &MappedControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithMappedControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*MappedControlWhereInput); ok {
		args.opts = append(args.opts, WithMappedControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (mch *MappedControlHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappedControlHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return mch, nil
	}
	if err := mch.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return mch, nil
}

func (mch *MappedControlHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappedcontrolhistory.Columns))
		selectedFields = []string{mappedcontrolhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldHistoryTime)
				fieldSeen[mappedcontrolhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldRef)
				fieldSeen[mappedcontrolhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldOperation)
				fieldSeen[mappedcontrolhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldCreatedAt)
				fieldSeen[mappedcontrolhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldUpdatedAt)
				fieldSeen[mappedcontrolhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldCreatedBy)
				fieldSeen[mappedcontrolhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldUpdatedBy)
				fieldSeen[mappedcontrolhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldTags)
				fieldSeen[mappedcontrolhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldOwnerID)
				fieldSeen[mappedcontrolhistory.FieldOwnerID] = struct{}{}
			}
		case "mappingType":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldMappingType]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldMappingType)
				fieldSeen[mappedcontrolhistory.FieldMappingType] = struct{}{}
			}
		case "relation":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldRelation]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldRelation)
				fieldSeen[mappedcontrolhistory.FieldRelation] = struct{}{}
			}
		case "confidence":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldConfidence]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldConfidence)
				fieldSeen[mappedcontrolhistory.FieldConfidence] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldSource)
				fieldSeen[mappedcontrolhistory.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		mch.Select(selectedFields...)
	}
	return nil
}

type mappedcontrolhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappedControlHistoryPaginateOption
}

func newMappedControlHistoryPaginateArgs(rv map[string]any) *mappedcontrolhistoryPaginateArgs {
	args := &mappedcontrolhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &MappedControlHistoryOrder{Field: &MappedControlHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithMappedControlHistoryOrder(order))
			}
		case *MappedControlHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithMappedControlHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*MappedControlHistoryWhereInput); ok {
		args.opts = append(args.opts, WithMappedControlHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (n *NarrativeQuery) CollectFields(ctx context.Context, satisfies ...string) (*NarrativeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return n, nil
	}
	if err := n.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return n, nil
}

func (n *NarrativeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(narrative.Columns))
		selectedFields = []string{narrative.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: n.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			n.withOwner = query
			if _, ok := fieldSeen[narrative.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldOwnerID)
				fieldSeen[narrative.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: n.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: n.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: n.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "satisfies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: n.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.SatisfiesTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(narrative.SatisfiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.SatisfiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.SatisfiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.SatisfiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Satisfies)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.SatisfiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedSatisfies(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: n.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(narrative.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: n.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(narrative.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: n.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(narrative.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[narrative.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, narrative.FieldCreatedAt)
				fieldSeen[narrative.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[narrative.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, narrative.FieldUpdatedAt)
				fieldSeen[narrative.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[narrative.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, narrative.FieldCreatedBy)
				fieldSeen[narrative.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[narrative.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, narrative.FieldUpdatedBy)
				fieldSeen[narrative.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[narrative.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDisplayID)
				fieldSeen[narrative.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[narrative.FieldTags]; !ok {
				selectedFields = append(selectedFields, narrative.FieldTags)
				fieldSeen[narrative.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[narrative.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldOwnerID)
				fieldSeen[narrative.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[narrative.FieldName]; !ok {
				selectedFields = append(selectedFields, narrative.FieldName)
				fieldSeen[narrative.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[narrative.FieldDescription]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDescription)
				fieldSeen[narrative.FieldDescription] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[narrative.FieldDetails]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDetails)
				fieldSeen[narrative.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		n.Select(selectedFields...)
	}
	return nil
}

type narrativePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NarrativePaginateOption
}

func newNarrativePaginateArgs(rv map[string]any) *narrativePaginateArgs {
	args := &narrativePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*NarrativeOrder:
			args.opts = append(args.opts, WithNarrativeOrder(v))
		case []any:
			var orders []*NarrativeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &NarrativeOrder{Field: &NarrativeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithNarrativeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*NarrativeWhereInput); ok {
		args.opts = append(args.opts, WithNarrativeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (nh *NarrativeHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*NarrativeHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return nh, nil
	}
	if err := nh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return nh, nil
}

func (nh *NarrativeHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(narrativehistory.Columns))
		selectedFields = []string{narrativehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[narrativehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldHistoryTime)
				fieldSeen[narrativehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[narrativehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldRef)
				fieldSeen[narrativehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[narrativehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldOperation)
				fieldSeen[narrativehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[narrativehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldCreatedAt)
				fieldSeen[narrativehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[narrativehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldUpdatedAt)
				fieldSeen[narrativehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[narrativehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldCreatedBy)
				fieldSeen[narrativehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[narrativehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldUpdatedBy)
				fieldSeen[narrativehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[narrativehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldDisplayID)
				fieldSeen[narrativehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[narrativehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldTags)
				fieldSeen[narrativehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[narrativehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldOwnerID)
				fieldSeen[narrativehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[narrativehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldName)
				fieldSeen[narrativehistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[narrativehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldDescription)
				fieldSeen[narrativehistory.FieldDescription] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[narrativehistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldDetails)
				fieldSeen[narrativehistory.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		nh.Select(selectedFields...)
	}
	return nil
}

type narrativehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NarrativeHistoryPaginateOption
}

func newNarrativeHistoryPaginateArgs(rv map[string]any) *narrativehistoryPaginateArgs {
	args := &narrativehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &NarrativeHistoryOrder{Field: &NarrativeHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithNarrativeHistoryOrder(order))
			}
		case *NarrativeHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithNarrativeHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*NarrativeHistoryWhereInput); ok {
		args.opts = append(args.opts, WithNarrativeHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (n *NoteQuery) CollectFields(ctx context.Context, satisfies ...string) (*NoteQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return n, nil
	}
	if err := n.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return n, nil
}

func (n *NoteQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(note.Columns))
		selectedFields = []string{note.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: n.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			n.withOwner = query
			if _, ok := fieldSeen[note.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, note.FieldOwnerID)
				fieldSeen[note.FieldOwnerID] = struct{}{}
			}

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: n.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			n.withTask = query

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: n.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					n.loadTotal = append(n.loadTotal, func(ctx context.Context, nodes []*Note) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"note_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(note.FilesColumn), ids...))
						})
						if err := query.GroupBy(note.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					n.loadTotal = append(n.loadTotal, func(_ context.Context, nodes []*Note) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(note.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			n.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[note.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, note.FieldCreatedAt)
				fieldSeen[note.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[note.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, note.FieldUpdatedAt)
				fieldSeen[note.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[note.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, note.FieldCreatedBy)
				fieldSeen[note.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[note.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, note.FieldUpdatedBy)
				fieldSeen[note.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[note.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, note.FieldDisplayID)
				fieldSeen[note.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[note.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, note.FieldOwnerID)
				fieldSeen[note.FieldOwnerID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[note.FieldText]; !ok {
				selectedFields = append(selectedFields, note.FieldText)
				fieldSeen[note.FieldText] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		n.Select(selectedFields...)
	}
	return nil
}

type notePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NotePaginateOption
}

func newNotePaginateArgs(rv map[string]any) *notePaginateArgs {
	args := &notePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*NoteOrder:
			args.opts = append(args.opts, WithNoteOrder(v))
		case []any:
			var orders []*NoteOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &NoteOrder{Field: &NoteOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithNoteOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*NoteWhereInput); ok {
		args.opts = append(args.opts, WithNoteFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (nh *NoteHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*NoteHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return nh, nil
	}
	if err := nh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return nh, nil
}

func (nh *NoteHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(notehistory.Columns))
		selectedFields = []string{notehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[notehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldHistoryTime)
				fieldSeen[notehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[notehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldRef)
				fieldSeen[notehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[notehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldOperation)
				fieldSeen[notehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[notehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldCreatedAt)
				fieldSeen[notehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[notehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldUpdatedAt)
				fieldSeen[notehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[notehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldCreatedBy)
				fieldSeen[notehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[notehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldUpdatedBy)
				fieldSeen[notehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[notehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldDisplayID)
				fieldSeen[notehistory.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[notehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldOwnerID)
				fieldSeen[notehistory.FieldOwnerID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[notehistory.FieldText]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldText)
				fieldSeen[notehistory.FieldText] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		nh.Select(selectedFields...)
	}
	return nil
}

type notehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NoteHistoryPaginateOption
}

func newNoteHistoryPaginateArgs(rv map[string]any) *notehistoryPaginateArgs {
	args := &notehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &NoteHistoryOrder{Field: &NoteHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithNoteHistoryOrder(order))
			}
		case *NoteHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithNoteHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*NoteHistoryWhereInput); ok {
		args.opts = append(args.opts, WithNoteHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (o *OnboardingQuery) CollectFields(ctx context.Context, satisfies ...string) (*OnboardingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return o, nil
	}
	if err := o.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return o, nil
}

func (o *OnboardingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(onboarding.Columns))
		selectedFields = []string{onboarding.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: o.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			o.withOrganization = query
			if _, ok := fieldSeen[onboarding.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldOrganizationID)
				fieldSeen[onboarding.FieldOrganizationID] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[onboarding.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldOrganizationID)
				fieldSeen[onboarding.FieldOrganizationID] = struct{}{}
			}
		case "companyName":
			if _, ok := fieldSeen[onboarding.FieldCompanyName]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompanyName)
				fieldSeen[onboarding.FieldCompanyName] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[onboarding.FieldDomains]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldDomains)
				fieldSeen[onboarding.FieldDomains] = struct{}{}
			}
		case "companyDetails":
			if _, ok := fieldSeen[onboarding.FieldCompanyDetails]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompanyDetails)
				fieldSeen[onboarding.FieldCompanyDetails] = struct{}{}
			}
		case "userDetails":
			if _, ok := fieldSeen[onboarding.FieldUserDetails]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldUserDetails)
				fieldSeen[onboarding.FieldUserDetails] = struct{}{}
			}
		case "compliance":
			if _, ok := fieldSeen[onboarding.FieldCompliance]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompliance)
				fieldSeen[onboarding.FieldCompliance] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		o.Select(selectedFields...)
	}
	return nil
}

type onboardingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OnboardingPaginateOption
}

func newOnboardingPaginateArgs(rv map[string]any) *onboardingPaginateArgs {
	args := &onboardingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[whereField].(*OnboardingWhereInput); ok {
		args.opts = append(args.opts, WithOnboardingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (om *OrgMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return om, nil
	}
	if err := om.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return om, nil
}

func (om *OrgMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgmembership.Columns))
		selectedFields = []string{orgmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: om.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			om.withOrganization = query
			if _, ok := fieldSeen[orgmembership.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldOrganizationID)
				fieldSeen[orgmembership.FieldOrganizationID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: om.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			om.withUser = query
			if _, ok := fieldSeen[orgmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUserID)
				fieldSeen[orgmembership.FieldUserID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: om.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					om.loadTotal = append(om.loadTotal, func(ctx context.Context, nodes []*OrgMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"org_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(orgmembership.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(orgmembership.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(orgmembership.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(orgmembership.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(orgmembership.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					om.loadTotal = append(om.loadTotal, func(_ context.Context, nodes []*OrgMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(orgmembership.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			om.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[orgmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldCreatedAt)
				fieldSeen[orgmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUpdatedAt)
				fieldSeen[orgmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldCreatedBy)
				fieldSeen[orgmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUpdatedBy)
				fieldSeen[orgmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[orgmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldRole)
				fieldSeen[orgmembership.FieldRole] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[orgmembership.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldOrganizationID)
				fieldSeen[orgmembership.FieldOrganizationID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[orgmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUserID)
				fieldSeen[orgmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		om.Select(selectedFields...)
	}
	return nil
}

type orgmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgMembershipPaginateOption
}

func newOrgMembershipPaginateArgs(rv map[string]any) *orgmembershipPaginateArgs {
	args := &orgmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrgMembershipOrder:
			args.opts = append(args.opts, WithOrgMembershipOrder(v))
		case []any:
			var orders []*OrgMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrgMembershipOrder{Field: &OrgMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrgMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrgMembershipWhereInput); ok {
		args.opts = append(args.opts, WithOrgMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (omh *OrgMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return omh, nil
	}
	if err := omh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return omh, nil
}

func (omh *OrgMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgmembershiphistory.Columns))
		selectedFields = []string{orgmembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[orgmembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldHistoryTime)
				fieldSeen[orgmembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[orgmembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldRef)
				fieldSeen[orgmembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[orgmembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldOperation)
				fieldSeen[orgmembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[orgmembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldCreatedAt)
				fieldSeen[orgmembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgmembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldUpdatedAt)
				fieldSeen[orgmembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgmembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldCreatedBy)
				fieldSeen[orgmembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgmembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldUpdatedBy)
				fieldSeen[orgmembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[orgmembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldRole)
				fieldSeen[orgmembershiphistory.FieldRole] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[orgmembershiphistory.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldOrganizationID)
				fieldSeen[orgmembershiphistory.FieldOrganizationID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[orgmembershiphistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldUserID)
				fieldSeen[orgmembershiphistory.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		omh.Select(selectedFields...)
	}
	return nil
}

type orgmembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgMembershipHistoryPaginateOption
}

func newOrgMembershipHistoryPaginateArgs(rv map[string]any) *orgmembershiphistoryPaginateArgs {
	args := &orgmembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgMembershipHistoryOrder{Field: &OrgMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgMembershipHistoryOrder(order))
			}
		case *OrgMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrgMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (os *OrgSubscriptionQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgSubscriptionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return os, nil
	}
	if err := os.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return os, nil
}

func (os *OrgSubscriptionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgsubscription.Columns))
		selectedFields = []string{orgsubscription.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: os.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			os.withOwner = query
			if _, ok := fieldSeen[orgsubscription.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldOwnerID)
				fieldSeen[orgsubscription.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: os.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					os.loadTotal = append(os.loadTotal, func(ctx context.Context, nodes []*OrgSubscription) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"org_subscription_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(orgsubscription.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(orgsubscription.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(orgsubscription.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(orgsubscription.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(orgsubscription.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					os.loadTotal = append(os.loadTotal, func(_ context.Context, nodes []*OrgSubscription) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(orgsubscription.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			os.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[orgsubscription.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldCreatedAt)
				fieldSeen[orgsubscription.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgsubscription.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldUpdatedAt)
				fieldSeen[orgsubscription.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgsubscription.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldCreatedBy)
				fieldSeen[orgsubscription.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgsubscription.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldUpdatedBy)
				fieldSeen[orgsubscription.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[orgsubscription.FieldTags]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldTags)
				fieldSeen[orgsubscription.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[orgsubscription.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldOwnerID)
				fieldSeen[orgsubscription.FieldOwnerID] = struct{}{}
			}
		case "stripeSubscriptionID":
			if _, ok := fieldSeen[orgsubscription.FieldStripeSubscriptionID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeSubscriptionID)
				fieldSeen[orgsubscription.FieldStripeSubscriptionID] = struct{}{}
			}
		case "productTier":
			if _, ok := fieldSeen[orgsubscription.FieldProductTier]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldProductTier)
				fieldSeen[orgsubscription.FieldProductTier] = struct{}{}
			}
		case "productPrice":
			if _, ok := fieldSeen[orgsubscription.FieldProductPrice]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldProductPrice)
				fieldSeen[orgsubscription.FieldProductPrice] = struct{}{}
			}
		case "stripeProductTierID":
			if _, ok := fieldSeen[orgsubscription.FieldStripeProductTierID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeProductTierID)
				fieldSeen[orgsubscription.FieldStripeProductTierID] = struct{}{}
			}
		case "stripeSubscriptionStatus":
			if _, ok := fieldSeen[orgsubscription.FieldStripeSubscriptionStatus]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeSubscriptionStatus)
				fieldSeen[orgsubscription.FieldStripeSubscriptionStatus] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[orgsubscription.FieldActive]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldActive)
				fieldSeen[orgsubscription.FieldActive] = struct{}{}
			}
		case "stripeCustomerID":
			if _, ok := fieldSeen[orgsubscription.FieldStripeCustomerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeCustomerID)
				fieldSeen[orgsubscription.FieldStripeCustomerID] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[orgsubscription.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldExpiresAt)
				fieldSeen[orgsubscription.FieldExpiresAt] = struct{}{}
			}
		case "trialExpiresAt":
			if _, ok := fieldSeen[orgsubscription.FieldTrialExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldTrialExpiresAt)
				fieldSeen[orgsubscription.FieldTrialExpiresAt] = struct{}{}
			}
		case "daysUntilDue":
			if _, ok := fieldSeen[orgsubscription.FieldDaysUntilDue]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldDaysUntilDue)
				fieldSeen[orgsubscription.FieldDaysUntilDue] = struct{}{}
			}
		case "paymentMethodAdded":
			if _, ok := fieldSeen[orgsubscription.FieldPaymentMethodAdded]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldPaymentMethodAdded)
				fieldSeen[orgsubscription.FieldPaymentMethodAdded] = struct{}{}
			}
		case "features":
			if _, ok := fieldSeen[orgsubscription.FieldFeatures]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldFeatures)
				fieldSeen[orgsubscription.FieldFeatures] = struct{}{}
			}
		case "featureLookupKeys":
			if _, ok := fieldSeen[orgsubscription.FieldFeatureLookupKeys]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldFeatureLookupKeys)
				fieldSeen[orgsubscription.FieldFeatureLookupKeys] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		os.Select(selectedFields...)
	}
	return nil
}

type orgsubscriptionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgSubscriptionPaginateOption
}

func newOrgSubscriptionPaginateArgs(rv map[string]any) *orgsubscriptionPaginateArgs {
	args := &orgsubscriptionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgSubscriptionOrder{Field: &OrgSubscriptionOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgSubscriptionOrder(order))
			}
		case *OrgSubscriptionOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgSubscriptionOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgSubscriptionWhereInput); ok {
		args.opts = append(args.opts, WithOrgSubscriptionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (osh *OrgSubscriptionHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgSubscriptionHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return osh, nil
	}
	if err := osh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return osh, nil
}

func (osh *OrgSubscriptionHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgsubscriptionhistory.Columns))
		selectedFields = []string{orgsubscriptionhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldHistoryTime)
				fieldSeen[orgsubscriptionhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldRef)
				fieldSeen[orgsubscriptionhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldOperation)
				fieldSeen[orgsubscriptionhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldCreatedAt)
				fieldSeen[orgsubscriptionhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldUpdatedAt)
				fieldSeen[orgsubscriptionhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldCreatedBy)
				fieldSeen[orgsubscriptionhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldUpdatedBy)
				fieldSeen[orgsubscriptionhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldTags)
				fieldSeen[orgsubscriptionhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldOwnerID)
				fieldSeen[orgsubscriptionhistory.FieldOwnerID] = struct{}{}
			}
		case "stripeSubscriptionID":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionID]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldStripeSubscriptionID)
				fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionID] = struct{}{}
			}
		case "productTier":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldProductTier]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldProductTier)
				fieldSeen[orgsubscriptionhistory.FieldProductTier] = struct{}{}
			}
		case "productPrice":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldProductPrice]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldProductPrice)
				fieldSeen[orgsubscriptionhistory.FieldProductPrice] = struct{}{}
			}
		case "stripeProductTierID":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldStripeProductTierID]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldStripeProductTierID)
				fieldSeen[orgsubscriptionhistory.FieldStripeProductTierID] = struct{}{}
			}
		case "stripeSubscriptionStatus":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionStatus]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldStripeSubscriptionStatus)
				fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionStatus] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldActive]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldActive)
				fieldSeen[orgsubscriptionhistory.FieldActive] = struct{}{}
			}
		case "stripeCustomerID":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldStripeCustomerID]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldStripeCustomerID)
				fieldSeen[orgsubscriptionhistory.FieldStripeCustomerID] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldExpiresAt)
				fieldSeen[orgsubscriptionhistory.FieldExpiresAt] = struct{}{}
			}
		case "trialExpiresAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldTrialExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldTrialExpiresAt)
				fieldSeen[orgsubscriptionhistory.FieldTrialExpiresAt] = struct{}{}
			}
		case "daysUntilDue":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldDaysUntilDue]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldDaysUntilDue)
				fieldSeen[orgsubscriptionhistory.FieldDaysUntilDue] = struct{}{}
			}
		case "paymentMethodAdded":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldPaymentMethodAdded]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldPaymentMethodAdded)
				fieldSeen[orgsubscriptionhistory.FieldPaymentMethodAdded] = struct{}{}
			}
		case "features":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldFeatures]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldFeatures)
				fieldSeen[orgsubscriptionhistory.FieldFeatures] = struct{}{}
			}
		case "featureLookupKeys":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldFeatureLookupKeys]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldFeatureLookupKeys)
				fieldSeen[orgsubscriptionhistory.FieldFeatureLookupKeys] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		osh.Select(selectedFields...)
	}
	return nil
}

type orgsubscriptionhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgSubscriptionHistoryPaginateOption
}

func newOrgSubscriptionHistoryPaginateArgs(rv map[string]any) *orgsubscriptionhistoryPaginateArgs {
	args := &orgsubscriptionhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgSubscriptionHistoryOrder{Field: &OrgSubscriptionHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgSubscriptionHistoryOrder(order))
			}
		case *OrgSubscriptionHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgSubscriptionHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgSubscriptionHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrgSubscriptionHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (o *OrganizationQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return o, nil
	}
	if err := o.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return o, nil
}

func (o *OrganizationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organization.Columns))
		selectedFields = []string{organization.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "controlCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlCreators)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedControlCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlImplementationCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_implementation_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlImplementationCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlImplementationCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationCreators)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlImplementationCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedControlImplementationCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlObjectiveCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_objective_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlObjectiveCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlObjectiveCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveCreators)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlObjectiveCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedControlObjectiveCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "evidenceCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_evidence_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EvidenceCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.EvidenceCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EvidenceCreators)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EvidenceCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedEvidenceCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "groupCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_group_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.GroupCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.GroupCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupCreators)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.GroupCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedGroupCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "internalPolicyCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_internal_policy_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InternalPolicyCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.InternalPolicyCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyCreators)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InternalPolicyCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedInternalPolicyCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "mappedControlCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_mapped_control_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MappedControlCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.MappedControlCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlCreators)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MappedControlCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedMappedControlCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "narrativeCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_narrative_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NarrativeCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.NarrativeCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeCreators)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NarrativeCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedNarrativeCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "procedureCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_procedure_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProcedureCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProcedureCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureCreators)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProcedureCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedProcedureCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_program_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProgramCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProgramCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramCreators)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProgramCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedProgramCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "riskCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_risk_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RiskCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.RiskCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskCreators)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RiskCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedRiskCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "scheduledJobCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_scheduled_job_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobCreators)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedScheduledJobCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "standardCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_standard_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.StandardCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.StandardCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.StandardCreators)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.StandardCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedStandardCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "templateCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_template_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TemplateCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TemplateCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TemplateCreators)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TemplateCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedTemplateCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "parent":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: o.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			o.withParent = query
			if _, ok := fieldSeen[organization.FieldParentOrganizationID]; !ok {
				selectedFields = append(selectedFields, organization.FieldParentOrganizationID)
				fieldSeen[organization.FieldParentOrganizationID] = struct{}{}
			}

		case "children":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: o.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"parent_organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ChildrenColumn), ids...))
						})
						if err := query.GroupBy(organization.ChildrenColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Children)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ChildrenColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedChildren(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationSettingClient{config: o.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationsettingImplementors)...); err != nil {
				return err
			}
			o.withSetting = query

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: o.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.PersonalAccessTokensTable)
							s.Join(joinT).On(s.C(personalaccesstoken.FieldID), joinT.C(organization.PersonalAccessTokensPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.PersonalAccessTokensPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "apiTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APITokenClient{config: o.config}).Query()
			)
			args := newAPITokenPaginateArgs(fieldArgs(ctx, new(APITokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAPITokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.APITokensColumn), ids...))
						})
						if err := query.GroupBy(organization.APITokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.APITokens)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, apitokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.APITokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedAPITokens(alias, func(wq *APITokenQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: o.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(organization.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(organization.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(organization.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: o.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(organization.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: o.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(organization.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: o.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SecretsColumn), ids...))
						})
						if err := query.GroupBy(organization.SecretsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SecretsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "avatarFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: o.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			o.withAvatarFile = query
			if _, ok := fieldSeen[organization.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarLocalFileID)
				fieldSeen[organization.FieldAvatarLocalFileID] = struct{}{}
			}

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: o.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.GroupsColumn), ids...))
						})
						if err := query.GroupBy(organization.GroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.GroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "templates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: o.config}).Query()
			)
			args := newTemplatePaginateArgs(fieldArgs(ctx, new(TemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TemplatesColumn), ids...))
						})
						if err := query.GroupBy(organization.TemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Templates)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedTemplates(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: o.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(organization.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: o.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DocumentsColumn), ids...))
						})
						if err := query.GroupBy(organization.DocumentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DocumentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "orgSubscriptions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgSubscriptionClient{config: o.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, orgsubscriptionImplementors)...); err != nil {
				return err
			}
			o.WithNamedOrgSubscriptions(alias, func(wq *OrgSubscriptionQuery) {
				*wq = *query
			})

		case "invites":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InviteClient{config: o.config}).Query()
			)
			args := newInvitePaginateArgs(fieldArgs(ctx, new(InviteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInvitePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InvitesColumn), ids...))
						})
						if err := query.GroupBy(organization.InvitesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Invites)
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, inviteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InvitesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedInvites(alias, func(wq *InviteQuery) {
				*wq = *query
			})

		case "subscribers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubscriberClient{config: o.config}).Query()
			)
			args := newSubscriberPaginateArgs(fieldArgs(ctx, new(SubscriberWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubscriberPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubscribersColumn), ids...))
						})
						if err := query.GroupBy(organization.SubscribersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subscribers)
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subscriberImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubscribersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedSubscribers(alias, func(wq *SubscriberQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: o.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(organization.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityTypes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: o.config}).Query()
			)
			args := newEntityTypePaginateArgs(fieldArgs(ctx, new(EntityTypeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityTypePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EntityTypesColumn), ids...))
						})
						if err := query.GroupBy(organization.EntityTypesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityTypes)
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EntityTypesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedEntityTypes(alias, func(wq *EntityTypeQuery) {
				*wq = *query
			})

		case "contacts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: o.config}).Query()
			)
			args := newContactPaginateArgs(fieldArgs(ctx, new(ContactWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newContactPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ContactsColumn), ids...))
						})
						if err := query.GroupBy(organization.ContactsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Contacts)
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ContactsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedContacts(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: o.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NotesColumn), ids...))
						})
						if err := query.GroupBy(organization.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: o.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TasksColumn), ids...))
						})
						if err := query.GroupBy(organization.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: o.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: o.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(organization.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: o.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InternalPoliciesColumn), ids...))
						})
						if err := query.GroupBy(organization.InternalPoliciesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InternalPoliciesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: o.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RisksColumn), ids...))
						})
						if err := query.GroupBy(organization.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: o.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlObjectivesColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlObjectivesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[40] == nil {
								nodes[i].Edges.totalCount[40] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[40][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[40] == nil {
								nodes[i].Edges.totalCount[40] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[40][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlObjectivesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: o.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(organization.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[41] == nil {
								nodes[i].Edges.totalCount[41] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[41][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[41] == nil {
								nodes[i].Edges.totalCount[41] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[41][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: o.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[42] == nil {
								nodes[i].Edges.totalCount[42] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[42][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[42] == nil {
								nodes[i].Edges.totalCount[42] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[42][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: o.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[43] == nil {
								nodes[i].Edges.totalCount[43] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[43][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[43] == nil {
								nodes[i].Edges.totalCount[43] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[43][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: o.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[44] == nil {
								nodes[i].Edges.totalCount[44] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[44][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[44] == nil {
								nodes[i].Edges.totalCount[44] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[44][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "mappedControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: o.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MappedControlsColumn), ids...))
						})
						if err := query.GroupBy(organization.MappedControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[45] == nil {
								nodes[i].Edges.totalCount[45] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[45][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControls)
							if nodes[i].Edges.totalCount[45] == nil {
								nodes[i].Edges.totalCount[45] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[45][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MappedControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedMappedControls(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: o.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EvidenceColumn), ids...))
						})
						if err := query.GroupBy(organization.EvidenceColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[46] == nil {
								nodes[i].Edges.totalCount[46] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[46][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[46] == nil {
								nodes[i].Edges.totalCount[46] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[46][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EvidenceColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "standards":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: o.config}).Query()
			)
			args := newStandardPaginateArgs(fieldArgs(ctx, new(StandardWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newStandardPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.StandardsColumn), ids...))
						})
						if err := query.GroupBy(organization.StandardsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[47] == nil {
								nodes[i].Edges.totalCount[47] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[47][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Standards)
							if nodes[i].Edges.totalCount[47] == nil {
								nodes[i].Edges.totalCount[47] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[47][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.StandardsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedStandards(alias, func(wq *StandardQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: o.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(organization.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[48] == nil {
								nodes[i].Edges.totalCount[48] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[48][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[48] == nil {
								nodes[i].Edges.totalCount[48] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[48][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: o.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(organization.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[49] == nil {
								nodes[i].Edges.totalCount[49] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[49][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[49] == nil {
								nodes[i].Edges.totalCount[49] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[49][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})

		case "jobRunners":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: o.config}).Query()
			)
			args := newJobRunnerPaginateArgs(fieldArgs(ctx, new(JobRunnerWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnersColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[50] == nil {
								nodes[i].Edges.totalCount[50] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[50][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunners)
							if nodes[i].Edges.totalCount[50] == nil {
								nodes[i].Edges.totalCount[50] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[50][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedJobRunners(alias, func(wq *JobRunnerQuery) {
				*wq = *query
			})

		case "jobRunnerTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerTokenClient{config: o.config}).Query()
			)
			args := newJobRunnerTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnerTokensColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnerTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[51] == nil {
								nodes[i].Edges.totalCount[51] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[51][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerTokens)
							if nodes[i].Edges.totalCount[51] == nil {
								nodes[i].Edges.totalCount[51] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[51][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnertokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnerTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedJobRunnerTokens(alias, func(wq *JobRunnerTokenQuery) {
				*wq = *query
			})

		case "jobRunnerRegistrationTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerRegistrationTokenClient{config: o.config}).Query()
			)
			args := newJobRunnerRegistrationTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerRegistrationTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerRegistrationTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnerRegistrationTokensColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnerRegistrationTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[52] == nil {
								nodes[i].Edges.totalCount[52] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[52][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerRegistrationTokens)
							if nodes[i].Edges.totalCount[52] == nil {
								nodes[i].Edges.totalCount[52] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[52][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerregistrationtokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnerRegistrationTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedJobRunnerRegistrationTokens(alias, func(wq *JobRunnerRegistrationTokenQuery) {
				*wq = *query
			})

		case "dnsVerifications":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DNSVerificationClient{config: o.config}).Query()
			)
			args := newDNSVerificationPaginateArgs(fieldArgs(ctx, new(DNSVerificationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDNSVerificationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DNSVerificationsColumn), ids...))
						})
						if err := query.GroupBy(organization.DNSVerificationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[53] == nil {
								nodes[i].Edges.totalCount[53] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[53][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DNSVerifications)
							if nodes[i].Edges.totalCount[53] == nil {
								nodes[i].Edges.totalCount[53] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[53][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, dnsverificationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DNSVerificationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedDNSVerifications(alias, func(wq *DNSVerificationQuery) {
				*wq = *query
			})

		case "jobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: o.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobsColumn), ids...))
						})
						if err := query.GroupBy(organization.JobsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[54] == nil {
								nodes[i].Edges.totalCount[54] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[54][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Jobs)
							if nodes[i].Edges.totalCount[54] == nil {
								nodes[i].Edges.totalCount[54] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[54][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlScheduledJobClient{config: o.config}).Query()
			)
			args := newControlScheduledJobPaginateArgs(fieldArgs(ctx, new(ControlScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[55] == nil {
								nodes[i].Edges.totalCount[55] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[55][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[55] == nil {
								nodes[i].Edges.totalCount[55] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[55][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlscheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedScheduledJobs(alias, func(wq *ControlScheduledJobQuery) {
				*wq = *query
			})

		case "jobResults":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobResultClient{config: o.config}).Query()
			)
			args := newJobResultPaginateArgs(fieldArgs(ctx, new(JobResultWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobResultPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobResultsColumn), ids...))
						})
						if err := query.GroupBy(organization.JobResultsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[56] == nil {
								nodes[i].Edges.totalCount[56] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[56][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobResults)
							if nodes[i].Edges.totalCount[56] == nil {
								nodes[i].Edges.totalCount[56] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[56][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobresultImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobResultsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedJobResults(alias, func(wq *JobResultQuery) {
				*wq = *query
			})

		case "scheduledJobRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobRunClient{config: o.config}).Query()
			)
			args := newScheduledJobRunPaginateArgs(fieldArgs(ctx, new(ScheduledJobRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobRunsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[57] == nil {
								nodes[i].Edges.totalCount[57] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[57][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobRuns)
							if nodes[i].Edges.totalCount[57] == nil {
								nodes[i].Edges.totalCount[57] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[57][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedScheduledJobRuns(alias, func(wq *ScheduledJobRunQuery) {
				*wq = *query
			})

		case "trustCenters":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: o.config}).Query()
			)
			args := newTrustCenterPaginateArgs(fieldArgs(ctx, new(TrustCenterWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCentersColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCentersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[58] == nil {
								nodes[i].Edges.totalCount[58] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[58][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenters)
							if nodes[i].Edges.totalCount[58] == nil {
								nodes[i].Edges.totalCount[58] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[58][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCentersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedTrustCenters(alias, func(wq *TrustCenterQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: o.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssetsColumn), ids...))
						})
						if err := query.GroupBy(organization.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[59] == nil {
								nodes[i].Edges.totalCount[59] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[59][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[59] == nil {
								nodes[i].Edges.totalCount[59] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[59][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: o.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScansColumn), ids...))
						})
						if err := query.GroupBy(organization.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[60] == nil {
								nodes[i].Edges.totalCount[60] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[60][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[60] == nil {
								nodes[i].Edges.totalCount[60] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[60][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "subprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: o.config}).Query()
			)
			args := newSubprocessorPaginateArgs(fieldArgs(ctx, new(SubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[61] == nil {
								nodes[i].Edges.totalCount[61] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[61][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subprocessors)
							if nodes[i].Edges.totalCount[61] == nil {
								nodes[i].Edges.totalCount[61] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[61][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedSubprocessors(alias, func(wq *SubprocessorQuery) {
				*wq = *query
			})

		case "exports":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ExportClient{config: o.config}).Query()
			)
			args := newExportPaginateArgs(fieldArgs(ctx, new(ExportWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newExportPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ExportsColumn), ids...))
						})
						if err := query.GroupBy(organization.ExportsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[62] == nil {
								nodes[i].Edges.totalCount[62] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[62][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Exports)
							if nodes[i].Edges.totalCount[62] == nil {
								nodes[i].Edges.totalCount[62] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[62][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, exportImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ExportsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedExports(alias, func(wq *ExportQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: o.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					o.loadTotal = append(o.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MembersColumn), ids...))
						})
						if err := query.GroupBy(organization.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[63] == nil {
								nodes[i].Edges.totalCount[63] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[63][alias] = n
						}
						return nil
					})
				} else {
					o.loadTotal = append(o.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[63] == nil {
								nodes[i].Edges.totalCount[63] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[63][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			o.WithNamedMembers(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[organization.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldCreatedAt)
				fieldSeen[organization.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organization.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldUpdatedAt)
				fieldSeen[organization.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organization.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organization.FieldCreatedBy)
				fieldSeen[organization.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organization.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organization.FieldUpdatedBy)
				fieldSeen[organization.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organization.FieldTags]; !ok {
				selectedFields = append(selectedFields, organization.FieldTags)
				fieldSeen[organization.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[organization.FieldName]; !ok {
				selectedFields = append(selectedFields, organization.FieldName)
				fieldSeen[organization.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[organization.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, organization.FieldDisplayName)
				fieldSeen[organization.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[organization.FieldDescription]; !ok {
				selectedFields = append(selectedFields, organization.FieldDescription)
				fieldSeen[organization.FieldDescription] = struct{}{}
			}
		case "personalOrg":
			if _, ok := fieldSeen[organization.FieldPersonalOrg]; !ok {
				selectedFields = append(selectedFields, organization.FieldPersonalOrg)
				fieldSeen[organization.FieldPersonalOrg] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[organization.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarRemoteURL)
				fieldSeen[organization.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[organization.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarLocalFileID)
				fieldSeen[organization.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[organization.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarUpdatedAt)
				fieldSeen[organization.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "dedicatedDb":
			if _, ok := fieldSeen[organization.FieldDedicatedDb]; !ok {
				selectedFields = append(selectedFields, organization.FieldDedicatedDb)
				fieldSeen[organization.FieldDedicatedDb] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		o.Select(selectedFields...)
	}
	return nil
}

type organizationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationPaginateOption
}

func newOrganizationPaginateArgs(rv map[string]any) *organizationPaginateArgs {
	args := &organizationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrganizationOrder:
			args.opts = append(args.opts, WithOrganizationOrder(v))
		case []any:
			var orders []*OrganizationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrganizationOrder{Field: &OrganizationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrganizationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrganizationWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (oh *OrganizationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return oh, nil
	}
	if err := oh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return oh, nil
}

func (oh *OrganizationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationhistory.Columns))
		selectedFields = []string{organizationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[organizationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldHistoryTime)
				fieldSeen[organizationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[organizationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldRef)
				fieldSeen[organizationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[organizationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldOperation)
				fieldSeen[organizationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[organizationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldCreatedAt)
				fieldSeen[organizationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldUpdatedAt)
				fieldSeen[organizationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldCreatedBy)
				fieldSeen[organizationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldUpdatedBy)
				fieldSeen[organizationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldTags)
				fieldSeen[organizationhistory.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[organizationhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldName)
				fieldSeen[organizationhistory.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[organizationhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldDisplayName)
				fieldSeen[organizationhistory.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[organizationhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldDescription)
				fieldSeen[organizationhistory.FieldDescription] = struct{}{}
			}
		case "personalOrg":
			if _, ok := fieldSeen[organizationhistory.FieldPersonalOrg]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldPersonalOrg)
				fieldSeen[organizationhistory.FieldPersonalOrg] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[organizationhistory.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldAvatarRemoteURL)
				fieldSeen[organizationhistory.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[organizationhistory.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldAvatarLocalFileID)
				fieldSeen[organizationhistory.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[organizationhistory.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldAvatarUpdatedAt)
				fieldSeen[organizationhistory.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "dedicatedDb":
			if _, ok := fieldSeen[organizationhistory.FieldDedicatedDb]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldDedicatedDb)
				fieldSeen[organizationhistory.FieldDedicatedDb] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		oh.Select(selectedFields...)
	}
	return nil
}

type organizationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationHistoryPaginateOption
}

func newOrganizationHistoryPaginateArgs(rv map[string]any) *organizationhistoryPaginateArgs {
	args := &organizationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrganizationHistoryOrder{Field: &OrganizationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrganizationHistoryOrder(order))
			}
		case *OrganizationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrganizationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrganizationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (os *OrganizationSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return os, nil
	}
	if err := os.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return os, nil
}

func (os *OrganizationSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationsetting.Columns))
		selectedFields = []string{organizationsetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: os.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			os.withOrganization = query
			if _, ok := fieldSeen[organizationsetting.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOrganizationID)
				fieldSeen[organizationsetting.FieldOrganizationID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: os.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					os.loadTotal = append(os.loadTotal, func(ctx context.Context, nodes []*OrganizationSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organizationsetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(organizationsetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organizationsetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(organizationsetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organizationsetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					os.loadTotal = append(os.loadTotal, func(_ context.Context, nodes []*OrganizationSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organizationsetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			os.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[organizationsetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldCreatedAt)
				fieldSeen[organizationsetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationsetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldUpdatedAt)
				fieldSeen[organizationsetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationsetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldCreatedBy)
				fieldSeen[organizationsetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationsetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldUpdatedBy)
				fieldSeen[organizationsetting.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationsetting.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldTags)
				fieldSeen[organizationsetting.FieldTags] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[organizationsetting.FieldDomains]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldDomains)
				fieldSeen[organizationsetting.FieldDomains] = struct{}{}
			}
		case "billingContact":
			if _, ok := fieldSeen[organizationsetting.FieldBillingContact]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingContact)
				fieldSeen[organizationsetting.FieldBillingContact] = struct{}{}
			}
		case "billingEmail":
			if _, ok := fieldSeen[organizationsetting.FieldBillingEmail]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingEmail)
				fieldSeen[organizationsetting.FieldBillingEmail] = struct{}{}
			}
		case "billingPhone":
			if _, ok := fieldSeen[organizationsetting.FieldBillingPhone]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingPhone)
				fieldSeen[organizationsetting.FieldBillingPhone] = struct{}{}
			}
		case "billingAddress":
			if _, ok := fieldSeen[organizationsetting.FieldBillingAddress]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingAddress)
				fieldSeen[organizationsetting.FieldBillingAddress] = struct{}{}
			}
		case "taxIdentifier":
			if _, ok := fieldSeen[organizationsetting.FieldTaxIdentifier]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldTaxIdentifier)
				fieldSeen[organizationsetting.FieldTaxIdentifier] = struct{}{}
			}
		case "geoLocation":
			if _, ok := fieldSeen[organizationsetting.FieldGeoLocation]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldGeoLocation)
				fieldSeen[organizationsetting.FieldGeoLocation] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[organizationsetting.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOrganizationID)
				fieldSeen[organizationsetting.FieldOrganizationID] = struct{}{}
			}
		case "billingNotificationsEnabled":
			if _, ok := fieldSeen[organizationsetting.FieldBillingNotificationsEnabled]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingNotificationsEnabled)
				fieldSeen[organizationsetting.FieldBillingNotificationsEnabled] = struct{}{}
			}
		case "allowedEmailDomains":
			if _, ok := fieldSeen[organizationsetting.FieldAllowedEmailDomains]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldAllowedEmailDomains)
				fieldSeen[organizationsetting.FieldAllowedEmailDomains] = struct{}{}
			}
		case "identityProvider":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProvider]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProvider)
				fieldSeen[organizationsetting.FieldIdentityProvider] = struct{}{}
			}
		case "identityProviderClientID":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderClientID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderClientID)
				fieldSeen[organizationsetting.FieldIdentityProviderClientID] = struct{}{}
			}
		case "identityProviderClientSecret":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderClientSecret]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderClientSecret)
				fieldSeen[organizationsetting.FieldIdentityProviderClientSecret] = struct{}{}
			}
		case "identityProviderMetadataEndpoint":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderMetadataEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderMetadataEndpoint)
				fieldSeen[organizationsetting.FieldIdentityProviderMetadataEndpoint] = struct{}{}
			}
		case "identityProviderEntityID":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderEntityID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderEntityID)
				fieldSeen[organizationsetting.FieldIdentityProviderEntityID] = struct{}{}
			}
		case "oidcDiscoveryEndpoint":
			if _, ok := fieldSeen[organizationsetting.FieldOidcDiscoveryEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOidcDiscoveryEndpoint)
				fieldSeen[organizationsetting.FieldOidcDiscoveryEndpoint] = struct{}{}
			}
		case "identityProviderLoginEnforced":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderLoginEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderLoginEnforced)
				fieldSeen[organizationsetting.FieldIdentityProviderLoginEnforced] = struct{}{}
			}
		case "complianceWebhookToken":
			if _, ok := fieldSeen[organizationsetting.FieldComplianceWebhookToken]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldComplianceWebhookToken)
				fieldSeen[organizationsetting.FieldComplianceWebhookToken] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		os.Select(selectedFields...)
	}
	return nil
}

type organizationsettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationSettingPaginateOption
}

func newOrganizationSettingPaginateArgs(rv map[string]any) *organizationsettingPaginateArgs {
	args := &organizationsettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrganizationSettingOrder:
			args.opts = append(args.opts, WithOrganizationSettingOrder(v))
		case []any:
			var orders []*OrganizationSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrganizationSettingOrder{Field: &OrganizationSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrganizationSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrganizationSettingWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (osh *OrganizationSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return osh, nil
	}
	if err := osh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return osh, nil
}

func (osh *OrganizationSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationsettinghistory.Columns))
		selectedFields = []string{organizationsettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[organizationsettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldHistoryTime)
				fieldSeen[organizationsettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[organizationsettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldRef)
				fieldSeen[organizationsettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[organizationsettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldOperation)
				fieldSeen[organizationsettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[organizationsettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldCreatedAt)
				fieldSeen[organizationsettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationsettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldUpdatedAt)
				fieldSeen[organizationsettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationsettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldCreatedBy)
				fieldSeen[organizationsettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationsettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldUpdatedBy)
				fieldSeen[organizationsettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationsettinghistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldTags)
				fieldSeen[organizationsettinghistory.FieldTags] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[organizationsettinghistory.FieldDomains]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldDomains)
				fieldSeen[organizationsettinghistory.FieldDomains] = struct{}{}
			}
		case "billingContact":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingContact]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingContact)
				fieldSeen[organizationsettinghistory.FieldBillingContact] = struct{}{}
			}
		case "billingEmail":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingEmail]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingEmail)
				fieldSeen[organizationsettinghistory.FieldBillingEmail] = struct{}{}
			}
		case "billingPhone":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingPhone]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingPhone)
				fieldSeen[organizationsettinghistory.FieldBillingPhone] = struct{}{}
			}
		case "billingAddress":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingAddress]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingAddress)
				fieldSeen[organizationsettinghistory.FieldBillingAddress] = struct{}{}
			}
		case "taxIdentifier":
			if _, ok := fieldSeen[organizationsettinghistory.FieldTaxIdentifier]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldTaxIdentifier)
				fieldSeen[organizationsettinghistory.FieldTaxIdentifier] = struct{}{}
			}
		case "geoLocation":
			if _, ok := fieldSeen[organizationsettinghistory.FieldGeoLocation]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldGeoLocation)
				fieldSeen[organizationsettinghistory.FieldGeoLocation] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[organizationsettinghistory.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldOrganizationID)
				fieldSeen[organizationsettinghistory.FieldOrganizationID] = struct{}{}
			}
		case "billingNotificationsEnabled":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingNotificationsEnabled]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingNotificationsEnabled)
				fieldSeen[organizationsettinghistory.FieldBillingNotificationsEnabled] = struct{}{}
			}
		case "allowedEmailDomains":
			if _, ok := fieldSeen[organizationsettinghistory.FieldAllowedEmailDomains]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldAllowedEmailDomains)
				fieldSeen[organizationsettinghistory.FieldAllowedEmailDomains] = struct{}{}
			}
		case "identityProvider":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProvider]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProvider)
				fieldSeen[organizationsettinghistory.FieldIdentityProvider] = struct{}{}
			}
		case "identityProviderClientID":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderClientID]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderClientID)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderClientID] = struct{}{}
			}
		case "identityProviderClientSecret":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderClientSecret]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderClientSecret)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderClientSecret] = struct{}{}
			}
		case "identityProviderMetadataEndpoint":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderMetadataEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderMetadataEndpoint)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderMetadataEndpoint] = struct{}{}
			}
		case "identityProviderEntityID":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderEntityID]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderEntityID)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderEntityID] = struct{}{}
			}
		case "oidcDiscoveryEndpoint":
			if _, ok := fieldSeen[organizationsettinghistory.FieldOidcDiscoveryEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldOidcDiscoveryEndpoint)
				fieldSeen[organizationsettinghistory.FieldOidcDiscoveryEndpoint] = struct{}{}
			}
		case "identityProviderLoginEnforced":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderLoginEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderLoginEnforced)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderLoginEnforced] = struct{}{}
			}
		case "complianceWebhookToken":
			if _, ok := fieldSeen[organizationsettinghistory.FieldComplianceWebhookToken]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldComplianceWebhookToken)
				fieldSeen[organizationsettinghistory.FieldComplianceWebhookToken] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		osh.Select(selectedFields...)
	}
	return nil
}

type organizationsettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationSettingHistoryPaginateOption
}

func newOrganizationSettingHistoryPaginateArgs(rv map[string]any) *organizationsettinghistoryPaginateArgs {
	args := &organizationsettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrganizationSettingHistoryOrder{Field: &OrganizationSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrganizationSettingHistoryOrder(order))
			}
		case *OrganizationSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrganizationSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrganizationSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (pat *PersonalAccessTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*PersonalAccessTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return pat, nil
	}
	if err := pat.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return pat, nil
}

func (pat *PersonalAccessTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(personalaccesstoken.Columns))
		selectedFields = []string{personalaccesstoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: pat.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			pat.withOwner = query
			if _, ok := fieldSeen[personalaccesstoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldOwnerID)
				fieldSeen[personalaccesstoken.FieldOwnerID] = struct{}{}
			}

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: pat.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pat.loadTotal = append(pat.loadTotal, func(ctx context.Context, nodes []*PersonalAccessToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"personal_access_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(personalaccesstoken.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(personalaccesstoken.OrganizationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					pat.loadTotal = append(pat.loadTotal, func(_ context.Context, nodes []*PersonalAccessToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(personalaccesstoken.OrganizationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pat.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: pat.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pat.loadTotal = append(pat.loadTotal, func(ctx context.Context, nodes []*PersonalAccessToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"personal_access_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(personalaccesstoken.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(personalaccesstoken.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(personalaccesstoken.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(personalaccesstoken.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(personalaccesstoken.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					pat.loadTotal = append(pat.loadTotal, func(_ context.Context, nodes []*PersonalAccessToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(personalaccesstoken.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pat.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldCreatedAt)
				fieldSeen[personalaccesstoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldUpdatedAt)
				fieldSeen[personalaccesstoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldCreatedBy)
				fieldSeen[personalaccesstoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldUpdatedBy)
				fieldSeen[personalaccesstoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[personalaccesstoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldTags)
				fieldSeen[personalaccesstoken.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[personalaccesstoken.FieldName]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldName)
				fieldSeen[personalaccesstoken.FieldName] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[personalaccesstoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldToken)
				fieldSeen[personalaccesstoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldExpiresAt)
				fieldSeen[personalaccesstoken.FieldExpiresAt] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[personalaccesstoken.FieldDescription]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldDescription)
				fieldSeen[personalaccesstoken.FieldDescription] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[personalaccesstoken.FieldScopes]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldScopes)
				fieldSeen[personalaccesstoken.FieldScopes] = struct{}{}
			}
		case "ssoAuthorizations":
			if _, ok := fieldSeen[personalaccesstoken.FieldSSOAuthorizations]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldSSOAuthorizations)
				fieldSeen[personalaccesstoken.FieldSSOAuthorizations] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldLastUsedAt)
				fieldSeen[personalaccesstoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[personalaccesstoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldIsActive)
				fieldSeen[personalaccesstoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedReason)
				fieldSeen[personalaccesstoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedBy)
				fieldSeen[personalaccesstoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedAt)
				fieldSeen[personalaccesstoken.FieldRevokedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		pat.Select(selectedFields...)
	}
	return nil
}

type personalaccesstokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []PersonalAccessTokenPaginateOption
}

func newPersonalAccessTokenPaginateArgs(rv map[string]any) *personalaccesstokenPaginateArgs {
	args := &personalaccesstokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*PersonalAccessTokenOrder:
			args.opts = append(args.opts, WithPersonalAccessTokenOrder(v))
		case []any:
			var orders []*PersonalAccessTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &PersonalAccessTokenOrder{Field: &PersonalAccessTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithPersonalAccessTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*PersonalAccessTokenWhereInput); ok {
		args.opts = append(args.opts, WithPersonalAccessTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (pr *ProcedureQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProcedureQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return pr, nil
	}
	if err := pr.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return pr, nil
}

func (pr *ProcedureQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(procedure.Columns))
		selectedFields = []string{procedure.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: pr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			pr.withOwner = query
			if _, ok := fieldSeen[procedure.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldOwnerID)
				fieldSeen[procedure.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(procedure.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(procedure.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			pr.withApprover = query
			if _, ok := fieldSeen[procedure.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApproverID)
				fieldSeen[procedure.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			pr.withDelegate = query
			if _, ok := fieldSeen[procedure.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDelegateID)
				fieldSeen[procedure.FieldDelegateID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: pr.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(procedure.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: pr.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(procedure.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: pr.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(procedure.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: pr.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(procedure.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: pr.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(procedure.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: pr.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(procedure.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: pr.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(procedure.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[procedure.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, procedure.FieldCreatedAt)
				fieldSeen[procedure.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[procedure.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, procedure.FieldUpdatedAt)
				fieldSeen[procedure.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[procedure.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, procedure.FieldCreatedBy)
				fieldSeen[procedure.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[procedure.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, procedure.FieldUpdatedBy)
				fieldSeen[procedure.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[procedure.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDisplayID)
				fieldSeen[procedure.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[procedure.FieldTags]; !ok {
				selectedFields = append(selectedFields, procedure.FieldTags)
				fieldSeen[procedure.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[procedure.FieldRevision]; !ok {
				selectedFields = append(selectedFields, procedure.FieldRevision)
				fieldSeen[procedure.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[procedure.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldOwnerID)
				fieldSeen[procedure.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[procedure.FieldName]; !ok {
				selectedFields = append(selectedFields, procedure.FieldName)
				fieldSeen[procedure.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[procedure.FieldStatus]; !ok {
				selectedFields = append(selectedFields, procedure.FieldStatus)
				fieldSeen[procedure.FieldStatus] = struct{}{}
			}
		case "procedureType":
			if _, ok := fieldSeen[procedure.FieldProcedureType]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureType)
				fieldSeen[procedure.FieldProcedureType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[procedure.FieldDetails]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDetails)
				fieldSeen[procedure.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[procedure.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApprovalRequired)
				fieldSeen[procedure.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[procedure.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, procedure.FieldReviewDue)
				fieldSeen[procedure.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[procedure.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, procedure.FieldReviewFrequency)
				fieldSeen[procedure.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[procedure.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApproverID)
				fieldSeen[procedure.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[procedure.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDelegateID)
				fieldSeen[procedure.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[procedure.FieldSummary]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSummary)
				fieldSeen[procedure.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[procedure.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldTagSuggestions)
				fieldSeen[procedure.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedTagSuggestions)
				fieldSeen[procedure.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[procedure.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldControlSuggestions)
				fieldSeen[procedure.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedControlSuggestions)
				fieldSeen[procedure.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[procedure.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldImprovementSuggestions)
				fieldSeen[procedure.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedImprovementSuggestions)
				fieldSeen[procedure.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		pr.Select(selectedFields...)
	}
	return nil
}

type procedurePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProcedurePaginateOption
}

func newProcedurePaginateArgs(rv map[string]any) *procedurePaginateArgs {
	args := &procedurePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProcedureOrder:
			args.opts = append(args.opts, WithProcedureOrder(v))
		case []any:
			var orders []*ProcedureOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProcedureOrder{Field: &ProcedureOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProcedureOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProcedureWhereInput); ok {
		args.opts = append(args.opts, WithProcedureFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ph *ProcedureHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProcedureHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ph, nil
	}
	if err := ph.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ph, nil
}

func (ph *ProcedureHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(procedurehistory.Columns))
		selectedFields = []string{procedurehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[procedurehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldHistoryTime)
				fieldSeen[procedurehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[procedurehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldRef)
				fieldSeen[procedurehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[procedurehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldOperation)
				fieldSeen[procedurehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[procedurehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldCreatedAt)
				fieldSeen[procedurehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[procedurehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldUpdatedAt)
				fieldSeen[procedurehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[procedurehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldCreatedBy)
				fieldSeen[procedurehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[procedurehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldUpdatedBy)
				fieldSeen[procedurehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[procedurehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDisplayID)
				fieldSeen[procedurehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[procedurehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldTags)
				fieldSeen[procedurehistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[procedurehistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldRevision)
				fieldSeen[procedurehistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[procedurehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldOwnerID)
				fieldSeen[procedurehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[procedurehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldName)
				fieldSeen[procedurehistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[procedurehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldStatus)
				fieldSeen[procedurehistory.FieldStatus] = struct{}{}
			}
		case "procedureType":
			if _, ok := fieldSeen[procedurehistory.FieldProcedureType]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldProcedureType)
				fieldSeen[procedurehistory.FieldProcedureType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[procedurehistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDetails)
				fieldSeen[procedurehistory.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[procedurehistory.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldApprovalRequired)
				fieldSeen[procedurehistory.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[procedurehistory.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldReviewDue)
				fieldSeen[procedurehistory.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[procedurehistory.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldReviewFrequency)
				fieldSeen[procedurehistory.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[procedurehistory.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldApproverID)
				fieldSeen[procedurehistory.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[procedurehistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDelegateID)
				fieldSeen[procedurehistory.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[procedurehistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldSummary)
				fieldSeen[procedurehistory.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldTagSuggestions)
				fieldSeen[procedurehistory.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDismissedTagSuggestions)
				fieldSeen[procedurehistory.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldControlSuggestions)
				fieldSeen[procedurehistory.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDismissedControlSuggestions)
				fieldSeen[procedurehistory.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldImprovementSuggestions)
				fieldSeen[procedurehistory.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDismissedImprovementSuggestions)
				fieldSeen[procedurehistory.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ph.Select(selectedFields...)
	}
	return nil
}

type procedurehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProcedureHistoryPaginateOption
}

func newProcedureHistoryPaginateArgs(rv map[string]any) *procedurehistoryPaginateArgs {
	args := &procedurehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProcedureHistoryOrder{Field: &ProcedureHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProcedureHistoryOrder(order))
			}
		case *ProcedureHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithProcedureHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProcedureHistoryWhereInput); ok {
		args.opts = append(args.opts, WithProcedureHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (pr *ProgramQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return pr, nil
	}
	if err := pr.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return pr, nil
}

func (pr *ProgramQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(program.Columns))
		selectedFields = []string{program.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: pr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			pr.withOwner = query
			if _, ok := fieldSeen[program.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldOwnerID)
				fieldSeen[program.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: pr.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: pr.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(program.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: pr.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(program.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: pr.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(program.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: pr.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(program.InternalPoliciesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.InternalPoliciesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.InternalPoliciesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.InternalPoliciesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.InternalPoliciesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: pr.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(program.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: pr.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(program.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: pr.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(program.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: pr.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_notes"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.NotesColumn), ids...))
						})
						if err := query.GroupBy(program.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: pr.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(program.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: pr.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(program.EvidencePrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.EvidencePrimaryKey[0]), ids...))
							s.Select(joinT.C(program.EvidencePrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.EvidencePrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.EvidencePrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: pr.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(program.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: pr.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(program.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: pr.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(program.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(program.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(program.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(program.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramMembershipClient{config: pr.config}).Query()
			)
			args := newProgramMembershipPaginateArgs(fieldArgs(ctx, new(ProgramMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					pr.loadTotal = append(pr.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.MembersColumn), ids...))
						})
						if err := query.GroupBy(program.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					pr.loadTotal = append(pr.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			pr.WithNamedMembers(alias, func(wq *ProgramMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[program.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, program.FieldCreatedAt)
				fieldSeen[program.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[program.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, program.FieldUpdatedAt)
				fieldSeen[program.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[program.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, program.FieldCreatedBy)
				fieldSeen[program.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[program.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, program.FieldUpdatedBy)
				fieldSeen[program.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[program.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, program.FieldDisplayID)
				fieldSeen[program.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[program.FieldTags]; !ok {
				selectedFields = append(selectedFields, program.FieldTags)
				fieldSeen[program.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[program.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldOwnerID)
				fieldSeen[program.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[program.FieldName]; !ok {
				selectedFields = append(selectedFields, program.FieldName)
				fieldSeen[program.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[program.FieldDescription]; !ok {
				selectedFields = append(selectedFields, program.FieldDescription)
				fieldSeen[program.FieldDescription] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[program.FieldStatus]; !ok {
				selectedFields = append(selectedFields, program.FieldStatus)
				fieldSeen[program.FieldStatus] = struct{}{}
			}
		case "programType":
			if _, ok := fieldSeen[program.FieldProgramType]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramType)
				fieldSeen[program.FieldProgramType] = struct{}{}
			}
		case "frameworkName":
			if _, ok := fieldSeen[program.FieldFrameworkName]; !ok {
				selectedFields = append(selectedFields, program.FieldFrameworkName)
				fieldSeen[program.FieldFrameworkName] = struct{}{}
			}
		case "startDate":
			if _, ok := fieldSeen[program.FieldStartDate]; !ok {
				selectedFields = append(selectedFields, program.FieldStartDate)
				fieldSeen[program.FieldStartDate] = struct{}{}
			}
		case "endDate":
			if _, ok := fieldSeen[program.FieldEndDate]; !ok {
				selectedFields = append(selectedFields, program.FieldEndDate)
				fieldSeen[program.FieldEndDate] = struct{}{}
			}
		case "auditorReady":
			if _, ok := fieldSeen[program.FieldAuditorReady]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorReady)
				fieldSeen[program.FieldAuditorReady] = struct{}{}
			}
		case "auditorWriteComments":
			if _, ok := fieldSeen[program.FieldAuditorWriteComments]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorWriteComments)
				fieldSeen[program.FieldAuditorWriteComments] = struct{}{}
			}
		case "auditorReadComments":
			if _, ok := fieldSeen[program.FieldAuditorReadComments]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorReadComments)
				fieldSeen[program.FieldAuditorReadComments] = struct{}{}
			}
		case "auditFirm":
			if _, ok := fieldSeen[program.FieldAuditFirm]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditFirm)
				fieldSeen[program.FieldAuditFirm] = struct{}{}
			}
		case "auditor":
			if _, ok := fieldSeen[program.FieldAuditor]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditor)
				fieldSeen[program.FieldAuditor] = struct{}{}
			}
		case "auditorEmail":
			if _, ok := fieldSeen[program.FieldAuditorEmail]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorEmail)
				fieldSeen[program.FieldAuditorEmail] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		pr.Select(selectedFields...)
	}
	return nil
}

type programPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramPaginateOption
}

func newProgramPaginateArgs(rv map[string]any) *programPaginateArgs {
	args := &programPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProgramOrder:
			args.opts = append(args.opts, WithProgramOrder(v))
		case []any:
			var orders []*ProgramOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProgramOrder{Field: &ProgramOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProgramOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProgramWhereInput); ok {
		args.opts = append(args.opts, WithProgramFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ph *ProgramHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ph, nil
	}
	if err := ph.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ph, nil
}

func (ph *ProgramHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programhistory.Columns))
		selectedFields = []string{programhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[programhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldHistoryTime)
				fieldSeen[programhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[programhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldRef)
				fieldSeen[programhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[programhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldOperation)
				fieldSeen[programhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldCreatedAt)
				fieldSeen[programhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldUpdatedAt)
				fieldSeen[programhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldCreatedBy)
				fieldSeen[programhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldUpdatedBy)
				fieldSeen[programhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[programhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldDisplayID)
				fieldSeen[programhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[programhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldTags)
				fieldSeen[programhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[programhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldOwnerID)
				fieldSeen[programhistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[programhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldName)
				fieldSeen[programhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[programhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldDescription)
				fieldSeen[programhistory.FieldDescription] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[programhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldStatus)
				fieldSeen[programhistory.FieldStatus] = struct{}{}
			}
		case "programType":
			if _, ok := fieldSeen[programhistory.FieldProgramType]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldProgramType)
				fieldSeen[programhistory.FieldProgramType] = struct{}{}
			}
		case "frameworkName":
			if _, ok := fieldSeen[programhistory.FieldFrameworkName]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldFrameworkName)
				fieldSeen[programhistory.FieldFrameworkName] = struct{}{}
			}
		case "startDate":
			if _, ok := fieldSeen[programhistory.FieldStartDate]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldStartDate)
				fieldSeen[programhistory.FieldStartDate] = struct{}{}
			}
		case "endDate":
			if _, ok := fieldSeen[programhistory.FieldEndDate]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldEndDate)
				fieldSeen[programhistory.FieldEndDate] = struct{}{}
			}
		case "auditorReady":
			if _, ok := fieldSeen[programhistory.FieldAuditorReady]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorReady)
				fieldSeen[programhistory.FieldAuditorReady] = struct{}{}
			}
		case "auditorWriteComments":
			if _, ok := fieldSeen[programhistory.FieldAuditorWriteComments]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorWriteComments)
				fieldSeen[programhistory.FieldAuditorWriteComments] = struct{}{}
			}
		case "auditorReadComments":
			if _, ok := fieldSeen[programhistory.FieldAuditorReadComments]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorReadComments)
				fieldSeen[programhistory.FieldAuditorReadComments] = struct{}{}
			}
		case "auditFirm":
			if _, ok := fieldSeen[programhistory.FieldAuditFirm]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditFirm)
				fieldSeen[programhistory.FieldAuditFirm] = struct{}{}
			}
		case "auditor":
			if _, ok := fieldSeen[programhistory.FieldAuditor]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditor)
				fieldSeen[programhistory.FieldAuditor] = struct{}{}
			}
		case "auditorEmail":
			if _, ok := fieldSeen[programhistory.FieldAuditorEmail]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorEmail)
				fieldSeen[programhistory.FieldAuditorEmail] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ph.Select(selectedFields...)
	}
	return nil
}

type programhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramHistoryPaginateOption
}

func newProgramHistoryPaginateArgs(rv map[string]any) *programhistoryPaginateArgs {
	args := &programhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProgramHistoryOrder{Field: &ProgramHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProgramHistoryOrder(order))
			}
		case *ProgramHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithProgramHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProgramHistoryWhereInput); ok {
		args.opts = append(args.opts, WithProgramHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (pm *ProgramMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return pm, nil
	}
	if err := pm.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return pm, nil
}

func (pm *ProgramMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programmembership.Columns))
		selectedFields = []string{programmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "program":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: pm.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
				return err
			}
			pm.withProgram = query
			if _, ok := fieldSeen[programmembership.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldProgramID)
				fieldSeen[programmembership.FieldProgramID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: pm.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			pm.withUser = query
			if _, ok := fieldSeen[programmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUserID)
				fieldSeen[programmembership.FieldUserID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldCreatedAt)
				fieldSeen[programmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUpdatedAt)
				fieldSeen[programmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldCreatedBy)
				fieldSeen[programmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUpdatedBy)
				fieldSeen[programmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[programmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldRole)
				fieldSeen[programmembership.FieldRole] = struct{}{}
			}
		case "programID":
			if _, ok := fieldSeen[programmembership.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldProgramID)
				fieldSeen[programmembership.FieldProgramID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[programmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUserID)
				fieldSeen[programmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		pm.Select(selectedFields...)
	}
	return nil
}

type programmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramMembershipPaginateOption
}

func newProgramMembershipPaginateArgs(rv map[string]any) *programmembershipPaginateArgs {
	args := &programmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProgramMembershipOrder:
			args.opts = append(args.opts, WithProgramMembershipOrder(v))
		case []any:
			var orders []*ProgramMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProgramMembershipOrder{Field: &ProgramMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProgramMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProgramMembershipWhereInput); ok {
		args.opts = append(args.opts, WithProgramMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (pmh *ProgramMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return pmh, nil
	}
	if err := pmh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return pmh, nil
}

func (pmh *ProgramMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programmembershiphistory.Columns))
		selectedFields = []string{programmembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[programmembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldHistoryTime)
				fieldSeen[programmembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[programmembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldRef)
				fieldSeen[programmembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[programmembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldOperation)
				fieldSeen[programmembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programmembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldCreatedAt)
				fieldSeen[programmembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programmembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldUpdatedAt)
				fieldSeen[programmembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programmembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldCreatedBy)
				fieldSeen[programmembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programmembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldUpdatedBy)
				fieldSeen[programmembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[programmembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldRole)
				fieldSeen[programmembershiphistory.FieldRole] = struct{}{}
			}
		case "programID":
			if _, ok := fieldSeen[programmembershiphistory.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldProgramID)
				fieldSeen[programmembershiphistory.FieldProgramID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[programmembershiphistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldUserID)
				fieldSeen[programmembershiphistory.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		pmh.Select(selectedFields...)
	}
	return nil
}

type programmembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramMembershipHistoryPaginateOption
}

func newProgramMembershipHistoryPaginateArgs(rv map[string]any) *programmembershiphistoryPaginateArgs {
	args := &programmembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProgramMembershipHistoryOrder{Field: &ProgramMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProgramMembershipHistoryOrder(order))
			}
		case *ProgramMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithProgramMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProgramMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithProgramMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (r *RiskQuery) CollectFields(ctx context.Context, satisfies ...string) (*RiskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return r, nil
	}
	if err := r.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return r, nil
}

func (r *RiskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(risk.Columns))
		selectedFields = []string{risk.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: r.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			r.withOwner = query
			if _, ok := fieldSeen[risk.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, risk.FieldOwnerID)
				fieldSeen[risk.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: r.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: r.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: r.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: r.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(risk.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: r.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(risk.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: r.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(risk.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: r.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(risk.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: r.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(risk.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: r.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(risk.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: r.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(risk.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: r.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.AssetsColumn), ids...))
						})
						if err := query.GroupBy(risk.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: r.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(risk.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: r.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.ScansColumn), ids...))
						})
						if err := query.GroupBy(risk.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "stakeholder":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: r.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			r.withStakeholder = query
			if _, ok := fieldSeen[risk.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, risk.FieldStakeholderID)
				fieldSeen[risk.FieldStakeholderID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: r.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			r.withDelegate = query
			if _, ok := fieldSeen[risk.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDelegateID)
				fieldSeen[risk.FieldDelegateID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[risk.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, risk.FieldCreatedAt)
				fieldSeen[risk.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[risk.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, risk.FieldUpdatedAt)
				fieldSeen[risk.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[risk.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, risk.FieldCreatedBy)
				fieldSeen[risk.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[risk.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, risk.FieldUpdatedBy)
				fieldSeen[risk.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[risk.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDisplayID)
				fieldSeen[risk.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[risk.FieldTags]; !ok {
				selectedFields = append(selectedFields, risk.FieldTags)
				fieldSeen[risk.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[risk.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, risk.FieldOwnerID)
				fieldSeen[risk.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[risk.FieldName]; !ok {
				selectedFields = append(selectedFields, risk.FieldName)
				fieldSeen[risk.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[risk.FieldStatus]; !ok {
				selectedFields = append(selectedFields, risk.FieldStatus)
				fieldSeen[risk.FieldStatus] = struct{}{}
			}
		case "riskType":
			if _, ok := fieldSeen[risk.FieldRiskType]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskType)
				fieldSeen[risk.FieldRiskType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[risk.FieldCategory]; !ok {
				selectedFields = append(selectedFields, risk.FieldCategory)
				fieldSeen[risk.FieldCategory] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[risk.FieldImpact]; !ok {
				selectedFields = append(selectedFields, risk.FieldImpact)
				fieldSeen[risk.FieldImpact] = struct{}{}
			}
		case "likelihood":
			if _, ok := fieldSeen[risk.FieldLikelihood]; !ok {
				selectedFields = append(selectedFields, risk.FieldLikelihood)
				fieldSeen[risk.FieldLikelihood] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[risk.FieldScore]; !ok {
				selectedFields = append(selectedFields, risk.FieldScore)
				fieldSeen[risk.FieldScore] = struct{}{}
			}
		case "mitigation":
			if _, ok := fieldSeen[risk.FieldMitigation]; !ok {
				selectedFields = append(selectedFields, risk.FieldMitigation)
				fieldSeen[risk.FieldMitigation] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[risk.FieldDetails]; !ok {
				selectedFields = append(selectedFields, risk.FieldDetails)
				fieldSeen[risk.FieldDetails] = struct{}{}
			}
		case "businessCosts":
			if _, ok := fieldSeen[risk.FieldBusinessCosts]; !ok {
				selectedFields = append(selectedFields, risk.FieldBusinessCosts)
				fieldSeen[risk.FieldBusinessCosts] = struct{}{}
			}
		case "stakeholderID":
			if _, ok := fieldSeen[risk.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, risk.FieldStakeholderID)
				fieldSeen[risk.FieldStakeholderID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[risk.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDelegateID)
				fieldSeen[risk.FieldDelegateID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		r.Select(selectedFields...)
	}
	return nil
}

type riskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RiskPaginateOption
}

func newRiskPaginateArgs(rv map[string]any) *riskPaginateArgs {
	args := &riskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*RiskOrder:
			args.opts = append(args.opts, WithRiskOrder(v))
		case []any:
			var orders []*RiskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &RiskOrder{Field: &RiskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithRiskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*RiskWhereInput); ok {
		args.opts = append(args.opts, WithRiskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (rh *RiskHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*RiskHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return rh, nil
	}
	if err := rh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return rh, nil
}

func (rh *RiskHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(riskhistory.Columns))
		selectedFields = []string{riskhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[riskhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldHistoryTime)
				fieldSeen[riskhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[riskhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRef)
				fieldSeen[riskhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[riskhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldOperation)
				fieldSeen[riskhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[riskhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldCreatedAt)
				fieldSeen[riskhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[riskhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldUpdatedAt)
				fieldSeen[riskhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[riskhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldCreatedBy)
				fieldSeen[riskhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[riskhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldUpdatedBy)
				fieldSeen[riskhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[riskhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldDisplayID)
				fieldSeen[riskhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[riskhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldTags)
				fieldSeen[riskhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[riskhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldOwnerID)
				fieldSeen[riskhistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[riskhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldName)
				fieldSeen[riskhistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[riskhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldStatus)
				fieldSeen[riskhistory.FieldStatus] = struct{}{}
			}
		case "riskType":
			if _, ok := fieldSeen[riskhistory.FieldRiskType]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRiskType)
				fieldSeen[riskhistory.FieldRiskType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[riskhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldCategory)
				fieldSeen[riskhistory.FieldCategory] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[riskhistory.FieldImpact]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldImpact)
				fieldSeen[riskhistory.FieldImpact] = struct{}{}
			}
		case "likelihood":
			if _, ok := fieldSeen[riskhistory.FieldLikelihood]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldLikelihood)
				fieldSeen[riskhistory.FieldLikelihood] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[riskhistory.FieldScore]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldScore)
				fieldSeen[riskhistory.FieldScore] = struct{}{}
			}
		case "mitigation":
			if _, ok := fieldSeen[riskhistory.FieldMitigation]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldMitigation)
				fieldSeen[riskhistory.FieldMitigation] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[riskhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldDetails)
				fieldSeen[riskhistory.FieldDetails] = struct{}{}
			}
		case "businessCosts":
			if _, ok := fieldSeen[riskhistory.FieldBusinessCosts]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldBusinessCosts)
				fieldSeen[riskhistory.FieldBusinessCosts] = struct{}{}
			}
		case "stakeholderID":
			if _, ok := fieldSeen[riskhistory.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldStakeholderID)
				fieldSeen[riskhistory.FieldStakeholderID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[riskhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldDelegateID)
				fieldSeen[riskhistory.FieldDelegateID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		rh.Select(selectedFields...)
	}
	return nil
}

type riskhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RiskHistoryPaginateOption
}

func newRiskHistoryPaginateArgs(rv map[string]any) *riskhistoryPaginateArgs {
	args := &riskhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RiskHistoryOrder{Field: &RiskHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRiskHistoryOrder(order))
			}
		case *RiskHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithRiskHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RiskHistoryWhereInput); ok {
		args.opts = append(args.opts, WithRiskHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (s *ScanQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScanQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return s, nil
	}
	if err := s.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return s, nil
}

func (s *ScanQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scan.Columns))
		selectedFields = []string{scan.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			s.withOwner = query
			if _, ok := fieldSeen[scan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scan.FieldOwnerID)
				fieldSeen[scan.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: s.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: s.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: s.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: s.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(scan.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: s.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(scan.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(scan.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[scan.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scan.FieldCreatedAt)
				fieldSeen[scan.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scan.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scan.FieldUpdatedAt)
				fieldSeen[scan.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scan.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scan.FieldCreatedBy)
				fieldSeen[scan.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scan.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scan.FieldUpdatedBy)
				fieldSeen[scan.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scan.FieldTags]; !ok {
				selectedFields = append(selectedFields, scan.FieldTags)
				fieldSeen[scan.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scan.FieldOwnerID)
				fieldSeen[scan.FieldOwnerID] = struct{}{}
			}
		case "target":
			if _, ok := fieldSeen[scan.FieldTarget]; !ok {
				selectedFields = append(selectedFields, scan.FieldTarget)
				fieldSeen[scan.FieldTarget] = struct{}{}
			}
		case "scanType":
			if _, ok := fieldSeen[scan.FieldScanType]; !ok {
				selectedFields = append(selectedFields, scan.FieldScanType)
				fieldSeen[scan.FieldScanType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[scan.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, scan.FieldMetadata)
				fieldSeen[scan.FieldMetadata] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scan.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scan.FieldStatus)
				fieldSeen[scan.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		s.Select(selectedFields...)
	}
	return nil
}

type scanPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScanPaginateOption
}

func newScanPaginateArgs(rv map[string]any) *scanPaginateArgs {
	args := &scanPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScanOrder:
			args.opts = append(args.opts, WithScanOrder(v))
		case []any:
			var orders []*ScanOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScanOrder{Field: &ScanOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScanOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScanWhereInput); ok {
		args.opts = append(args.opts, WithScanFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sh *ScanHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScanHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sh, nil
	}
	if err := sh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sh, nil
}

func (sh *ScanHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scanhistory.Columns))
		selectedFields = []string{scanhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[scanhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldHistoryTime)
				fieldSeen[scanhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[scanhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldRef)
				fieldSeen[scanhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[scanhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldOperation)
				fieldSeen[scanhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scanhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldCreatedAt)
				fieldSeen[scanhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scanhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldUpdatedAt)
				fieldSeen[scanhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scanhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldCreatedBy)
				fieldSeen[scanhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scanhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldUpdatedBy)
				fieldSeen[scanhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scanhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldTags)
				fieldSeen[scanhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scanhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldOwnerID)
				fieldSeen[scanhistory.FieldOwnerID] = struct{}{}
			}
		case "target":
			if _, ok := fieldSeen[scanhistory.FieldTarget]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldTarget)
				fieldSeen[scanhistory.FieldTarget] = struct{}{}
			}
		case "scanType":
			if _, ok := fieldSeen[scanhistory.FieldScanType]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldScanType)
				fieldSeen[scanhistory.FieldScanType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[scanhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldMetadata)
				fieldSeen[scanhistory.FieldMetadata] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scanhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldStatus)
				fieldSeen[scanhistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sh.Select(selectedFields...)
	}
	return nil
}

type scanhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScanHistoryPaginateOption
}

func newScanHistoryPaginateArgs(rv map[string]any) *scanhistoryPaginateArgs {
	args := &scanhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ScanHistoryOrder{Field: &ScanHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithScanHistoryOrder(order))
			}
		case *ScanHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithScanHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ScanHistoryWhereInput); ok {
		args.opts = append(args.opts, WithScanHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sj *ScheduledJobQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sj, nil
	}
	if err := sj.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sj, nil
}

func (sj *ScheduledJobQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjob.Columns))
		selectedFields = []string{scheduledjob.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: sj.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			sj.withOwner = query
			if _, ok := fieldSeen[scheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldOwnerID)
				fieldSeen[scheduledjob.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjob.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCreatedAt)
				fieldSeen[scheduledjob.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjob.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldUpdatedAt)
				fieldSeen[scheduledjob.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjob.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCreatedBy)
				fieldSeen[scheduledjob.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjob.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldUpdatedBy)
				fieldSeen[scheduledjob.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[scheduledjob.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldDisplayID)
				fieldSeen[scheduledjob.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scheduledjob.FieldTags]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldTags)
				fieldSeen[scheduledjob.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldOwnerID)
				fieldSeen[scheduledjob.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[scheduledjob.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldSystemOwned)
				fieldSeen[scheduledjob.FieldSystemOwned] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[scheduledjob.FieldTitle]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldTitle)
				fieldSeen[scheduledjob.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[scheduledjob.FieldDescription]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldDescription)
				fieldSeen[scheduledjob.FieldDescription] = struct{}{}
			}
		case "jobType":
			if _, ok := fieldSeen[scheduledjob.FieldJobType]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobType)
				fieldSeen[scheduledjob.FieldJobType] = struct{}{}
			}
		case "script":
			if _, ok := fieldSeen[scheduledjob.FieldScript]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldScript)
				fieldSeen[scheduledjob.FieldScript] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[scheduledjob.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldConfiguration)
				fieldSeen[scheduledjob.FieldConfiguration] = struct{}{}
			}
		case "cadence":
			if _, ok := fieldSeen[scheduledjob.FieldCadence]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCadence)
				fieldSeen[scheduledjob.FieldCadence] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[scheduledjob.FieldCron]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCron)
				fieldSeen[scheduledjob.FieldCron] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sj.Select(selectedFields...)
	}
	return nil
}

type scheduledjobPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobPaginateOption
}

func newScheduledJobPaginateArgs(rv map[string]any) *scheduledjobPaginateArgs {
	args := &scheduledjobPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScheduledJobOrder:
			args.opts = append(args.opts, WithScheduledJobOrder(v))
		case []any:
			var orders []*ScheduledJobOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScheduledJobOrder{Field: &ScheduledJobOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScheduledJobOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sjh *ScheduledJobHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sjh, nil
	}
	if err := sjh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sjh, nil
}

func (sjh *ScheduledJobHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjobhistory.Columns))
		selectedFields = []string{scheduledjobhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[scheduledjobhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldHistoryTime)
				fieldSeen[scheduledjobhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[scheduledjobhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldRef)
				fieldSeen[scheduledjobhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[scheduledjobhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldOperation)
				fieldSeen[scheduledjobhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCreatedAt)
				fieldSeen[scheduledjobhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjobhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldUpdatedAt)
				fieldSeen[scheduledjobhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCreatedBy)
				fieldSeen[scheduledjobhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjobhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldUpdatedBy)
				fieldSeen[scheduledjobhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[scheduledjobhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldDisplayID)
				fieldSeen[scheduledjobhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scheduledjobhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldTags)
				fieldSeen[scheduledjobhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjobhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldOwnerID)
				fieldSeen[scheduledjobhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[scheduledjobhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldSystemOwned)
				fieldSeen[scheduledjobhistory.FieldSystemOwned] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[scheduledjobhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldTitle)
				fieldSeen[scheduledjobhistory.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[scheduledjobhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldDescription)
				fieldSeen[scheduledjobhistory.FieldDescription] = struct{}{}
			}
		case "jobType":
			if _, ok := fieldSeen[scheduledjobhistory.FieldJobType]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldJobType)
				fieldSeen[scheduledjobhistory.FieldJobType] = struct{}{}
			}
		case "script":
			if _, ok := fieldSeen[scheduledjobhistory.FieldScript]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldScript)
				fieldSeen[scheduledjobhistory.FieldScript] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[scheduledjobhistory.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldConfiguration)
				fieldSeen[scheduledjobhistory.FieldConfiguration] = struct{}{}
			}
		case "cadence":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCadence]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCadence)
				fieldSeen[scheduledjobhistory.FieldCadence] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCron]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCron)
				fieldSeen[scheduledjobhistory.FieldCron] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sjh.Select(selectedFields...)
	}
	return nil
}

type scheduledjobhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobHistoryPaginateOption
}

func newScheduledJobHistoryPaginateArgs(rv map[string]any) *scheduledjobhistoryPaginateArgs {
	args := &scheduledjobhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ScheduledJobHistoryOrder{Field: &ScheduledJobHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithScheduledJobHistoryOrder(order))
			}
		case *ScheduledJobHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithScheduledJobHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobHistoryWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sjr *ScheduledJobRunQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobRunQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sjr, nil
	}
	if err := sjr.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sjr, nil
}

func (sjr *ScheduledJobRunQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjobrun.Columns))
		selectedFields = []string{scheduledjobrun.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: sjr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			sjr.withOwner = query
			if _, ok := fieldSeen[scheduledjobrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldOwnerID)
				fieldSeen[scheduledjobrun.FieldOwnerID] = struct{}{}
			}

		case "scheduledJob":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlScheduledJobClient{config: sjr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlscheduledjobImplementors)...); err != nil {
				return err
			}
			sjr.withScheduledJob = query
			if _, ok := fieldSeen[scheduledjobrun.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScheduledJobID)
				fieldSeen[scheduledjobrun.FieldScheduledJobID] = struct{}{}
			}

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: sjr.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			sjr.withJobRunner = query
			if _, ok := fieldSeen[scheduledjobrun.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldJobRunnerID)
				fieldSeen[scheduledjobrun.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjobrun.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldCreatedAt)
				fieldSeen[scheduledjobrun.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjobrun.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldUpdatedAt)
				fieldSeen[scheduledjobrun.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjobrun.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldCreatedBy)
				fieldSeen[scheduledjobrun.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjobrun.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldUpdatedBy)
				fieldSeen[scheduledjobrun.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjobrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldOwnerID)
				fieldSeen[scheduledjobrun.FieldOwnerID] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[scheduledjobrun.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldJobRunnerID)
				fieldSeen[scheduledjobrun.FieldJobRunnerID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scheduledjobrun.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldStatus)
				fieldSeen[scheduledjobrun.FieldStatus] = struct{}{}
			}
		case "scheduledJobID":
			if _, ok := fieldSeen[scheduledjobrun.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScheduledJobID)
				fieldSeen[scheduledjobrun.FieldScheduledJobID] = struct{}{}
			}
		case "expectedExecutionTime":
			if _, ok := fieldSeen[scheduledjobrun.FieldExpectedExecutionTime]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldExpectedExecutionTime)
				fieldSeen[scheduledjobrun.FieldExpectedExecutionTime] = struct{}{}
			}
		case "script":
			if _, ok := fieldSeen[scheduledjobrun.FieldScript]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScript)
				fieldSeen[scheduledjobrun.FieldScript] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sjr.Select(selectedFields...)
	}
	return nil
}

type scheduledjobrunPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobRunPaginateOption
}

func newScheduledJobRunPaginateArgs(rv map[string]any) *scheduledjobrunPaginateArgs {
	args := &scheduledjobrunPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScheduledJobRunOrder:
			args.opts = append(args.opts, WithScheduledJobRunOrder(v))
		case []any:
			var orders []*ScheduledJobRunOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScheduledJobRunOrder{Field: &ScheduledJobRunOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScheduledJobRunOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobRunWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobRunFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (s *StandardQuery) CollectFields(ctx context.Context, satisfies ...string) (*StandardQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return s, nil
	}
	if err := s.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return s, nil
}

func (s *StandardQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(standard.Columns))
		selectedFields = []string{standard.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			s.withOwner = query
			if _, ok := fieldSeen[standard.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standard.FieldOwnerID)
				fieldSeen[standard.FieldOwnerID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: s.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Standard) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"standard_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(standard.ControlsColumn), ids...))
						})
						if err := query.GroupBy(standard.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Standard) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(standard.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[standard.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, standard.FieldCreatedAt)
				fieldSeen[standard.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[standard.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, standard.FieldUpdatedAt)
				fieldSeen[standard.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[standard.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, standard.FieldCreatedBy)
				fieldSeen[standard.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[standard.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, standard.FieldUpdatedBy)
				fieldSeen[standard.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[standard.FieldTags]; !ok {
				selectedFields = append(selectedFields, standard.FieldTags)
				fieldSeen[standard.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[standard.FieldRevision]; !ok {
				selectedFields = append(selectedFields, standard.FieldRevision)
				fieldSeen[standard.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[standard.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standard.FieldOwnerID)
				fieldSeen[standard.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[standard.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, standard.FieldSystemOwned)
				fieldSeen[standard.FieldSystemOwned] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[standard.FieldName]; !ok {
				selectedFields = append(selectedFields, standard.FieldName)
				fieldSeen[standard.FieldName] = struct{}{}
			}
		case "shortName":
			if _, ok := fieldSeen[standard.FieldShortName]; !ok {
				selectedFields = append(selectedFields, standard.FieldShortName)
				fieldSeen[standard.FieldShortName] = struct{}{}
			}
		case "framework":
			if _, ok := fieldSeen[standard.FieldFramework]; !ok {
				selectedFields = append(selectedFields, standard.FieldFramework)
				fieldSeen[standard.FieldFramework] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[standard.FieldDescription]; !ok {
				selectedFields = append(selectedFields, standard.FieldDescription)
				fieldSeen[standard.FieldDescription] = struct{}{}
			}
		case "governingBodyLogoURL":
			if _, ok := fieldSeen[standard.FieldGoverningBodyLogoURL]; !ok {
				selectedFields = append(selectedFields, standard.FieldGoverningBodyLogoURL)
				fieldSeen[standard.FieldGoverningBodyLogoURL] = struct{}{}
			}
		case "governingBody":
			if _, ok := fieldSeen[standard.FieldGoverningBody]; !ok {
				selectedFields = append(selectedFields, standard.FieldGoverningBody)
				fieldSeen[standard.FieldGoverningBody] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[standard.FieldDomains]; !ok {
				selectedFields = append(selectedFields, standard.FieldDomains)
				fieldSeen[standard.FieldDomains] = struct{}{}
			}
		case "link":
			if _, ok := fieldSeen[standard.FieldLink]; !ok {
				selectedFields = append(selectedFields, standard.FieldLink)
				fieldSeen[standard.FieldLink] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[standard.FieldStatus]; !ok {
				selectedFields = append(selectedFields, standard.FieldStatus)
				fieldSeen[standard.FieldStatus] = struct{}{}
			}
		case "isPublic":
			if _, ok := fieldSeen[standard.FieldIsPublic]; !ok {
				selectedFields = append(selectedFields, standard.FieldIsPublic)
				fieldSeen[standard.FieldIsPublic] = struct{}{}
			}
		case "freeToUse":
			if _, ok := fieldSeen[standard.FieldFreeToUse]; !ok {
				selectedFields = append(selectedFields, standard.FieldFreeToUse)
				fieldSeen[standard.FieldFreeToUse] = struct{}{}
			}
		case "standardType":
			if _, ok := fieldSeen[standard.FieldStandardType]; !ok {
				selectedFields = append(selectedFields, standard.FieldStandardType)
				fieldSeen[standard.FieldStandardType] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[standard.FieldVersion]; !ok {
				selectedFields = append(selectedFields, standard.FieldVersion)
				fieldSeen[standard.FieldVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		s.Select(selectedFields...)
	}
	return nil
}

type standardPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []StandardPaginateOption
}

func newStandardPaginateArgs(rv map[string]any) *standardPaginateArgs {
	args := &standardPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*StandardOrder:
			args.opts = append(args.opts, WithStandardOrder(v))
		case []any:
			var orders []*StandardOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &StandardOrder{Field: &StandardOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithStandardOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*StandardWhereInput); ok {
		args.opts = append(args.opts, WithStandardFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sh *StandardHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*StandardHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sh, nil
	}
	if err := sh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sh, nil
}

func (sh *StandardHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(standardhistory.Columns))
		selectedFields = []string{standardhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[standardhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldHistoryTime)
				fieldSeen[standardhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[standardhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldRef)
				fieldSeen[standardhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[standardhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldOperation)
				fieldSeen[standardhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[standardhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldCreatedAt)
				fieldSeen[standardhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[standardhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldUpdatedAt)
				fieldSeen[standardhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[standardhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldCreatedBy)
				fieldSeen[standardhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[standardhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldUpdatedBy)
				fieldSeen[standardhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[standardhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldTags)
				fieldSeen[standardhistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[standardhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldRevision)
				fieldSeen[standardhistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[standardhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldOwnerID)
				fieldSeen[standardhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[standardhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldSystemOwned)
				fieldSeen[standardhistory.FieldSystemOwned] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[standardhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldName)
				fieldSeen[standardhistory.FieldName] = struct{}{}
			}
		case "shortName":
			if _, ok := fieldSeen[standardhistory.FieldShortName]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldShortName)
				fieldSeen[standardhistory.FieldShortName] = struct{}{}
			}
		case "framework":
			if _, ok := fieldSeen[standardhistory.FieldFramework]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldFramework)
				fieldSeen[standardhistory.FieldFramework] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[standardhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldDescription)
				fieldSeen[standardhistory.FieldDescription] = struct{}{}
			}
		case "governingBodyLogoURL":
			if _, ok := fieldSeen[standardhistory.FieldGoverningBodyLogoURL]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldGoverningBodyLogoURL)
				fieldSeen[standardhistory.FieldGoverningBodyLogoURL] = struct{}{}
			}
		case "governingBody":
			if _, ok := fieldSeen[standardhistory.FieldGoverningBody]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldGoverningBody)
				fieldSeen[standardhistory.FieldGoverningBody] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[standardhistory.FieldDomains]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldDomains)
				fieldSeen[standardhistory.FieldDomains] = struct{}{}
			}
		case "link":
			if _, ok := fieldSeen[standardhistory.FieldLink]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldLink)
				fieldSeen[standardhistory.FieldLink] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[standardhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldStatus)
				fieldSeen[standardhistory.FieldStatus] = struct{}{}
			}
		case "isPublic":
			if _, ok := fieldSeen[standardhistory.FieldIsPublic]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldIsPublic)
				fieldSeen[standardhistory.FieldIsPublic] = struct{}{}
			}
		case "freeToUse":
			if _, ok := fieldSeen[standardhistory.FieldFreeToUse]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldFreeToUse)
				fieldSeen[standardhistory.FieldFreeToUse] = struct{}{}
			}
		case "standardType":
			if _, ok := fieldSeen[standardhistory.FieldStandardType]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldStandardType)
				fieldSeen[standardhistory.FieldStandardType] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[standardhistory.FieldVersion]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldVersion)
				fieldSeen[standardhistory.FieldVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sh.Select(selectedFields...)
	}
	return nil
}

type standardhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []StandardHistoryPaginateOption
}

func newStandardHistoryPaginateArgs(rv map[string]any) *standardhistoryPaginateArgs {
	args := &standardhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &StandardHistoryOrder{Field: &StandardHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithStandardHistoryOrder(order))
			}
		case *StandardHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithStandardHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*StandardHistoryWhereInput); ok {
		args.opts = append(args.opts, WithStandardHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (s *SubcontrolQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubcontrolQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return s, nil
	}
	if err := s.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return s, nil
}

func (s *SubcontrolQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subcontrol.Columns))
		selectedFields = []string{subcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: s.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(subcontrol.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: s.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(subcontrol.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: s.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(subcontrol.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: s.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_narratives"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: s.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(subcontrol.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: s.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: s.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(subcontrol.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: s.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(subcontrol.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "controlOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			s.withControlOwner = query
			if _, ok := fieldSeen[subcontrol.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlOwnerID)
				fieldSeen[subcontrol.FieldControlOwnerID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			s.withDelegate = query
			if _, ok := fieldSeen[subcontrol.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDelegateID)
				fieldSeen[subcontrol.FieldDelegateID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			s.withOwner = query
			if _, ok := fieldSeen[subcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldOwnerID)
				fieldSeen[subcontrol.FieldOwnerID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			s.withControl = query
			if _, ok := fieldSeen[subcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlID)
				fieldSeen[subcontrol.FieldControlID] = struct{}{}
			}

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: s.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(subcontrol.ControlImplementationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ControlImplementationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlScheduledJobClient{config: s.config}).Query()
			)
			args := newControlScheduledJobPaginateArgs(fieldArgs(ctx, new(ControlScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ScheduledJobsTable)
							s.Join(joinT).On(s.C(controlscheduledjob.FieldID), joinT.C(subcontrol.ScheduledJobsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlscheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ScheduledJobsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedScheduledJobs(alias, func(wq *ControlScheduledJobQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCreatedAt)
				fieldSeen[subcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldUpdatedAt)
				fieldSeen[subcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCreatedBy)
				fieldSeen[subcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldUpdatedBy)
				fieldSeen[subcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[subcontrol.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDisplayID)
				fieldSeen[subcontrol.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subcontrol.FieldTags]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldTags)
				fieldSeen[subcontrol.FieldTags] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subcontrol.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDescription)
				fieldSeen[subcontrol.FieldDescription] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[subcontrol.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceID)
				fieldSeen[subcontrol.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[subcontrol.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAuditorReferenceID)
				fieldSeen[subcontrol.FieldAuditorReferenceID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[subcontrol.FieldStatus]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldStatus)
				fieldSeen[subcontrol.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[subcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSource)
				fieldSeen[subcontrol.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[subcontrol.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceFramework)
				fieldSeen[subcontrol.FieldReferenceFramework] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[subcontrol.FieldControlType]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlType)
				fieldSeen[subcontrol.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[subcontrol.FieldCategory]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCategory)
				fieldSeen[subcontrol.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[subcontrol.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCategoryID)
				fieldSeen[subcontrol.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[subcontrol.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcategory)
				fieldSeen[subcontrol.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[subcontrol.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldMappedCategories)
				fieldSeen[subcontrol.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[subcontrol.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAssessmentObjectives)
				fieldSeen[subcontrol.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[subcontrol.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAssessmentMethods)
				fieldSeen[subcontrol.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[subcontrol.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlQuestions)
				fieldSeen[subcontrol.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[subcontrol.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldImplementationGuidance)
				fieldSeen[subcontrol.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[subcontrol.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldExampleEvidence)
				fieldSeen[subcontrol.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[subcontrol.FieldReferences]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferences)
				fieldSeen[subcontrol.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[subcontrol.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlOwnerID)
				fieldSeen[subcontrol.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[subcontrol.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDelegateID)
				fieldSeen[subcontrol.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldOwnerID)
				fieldSeen[subcontrol.FieldOwnerID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[subcontrol.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldRefCode)
				fieldSeen[subcontrol.FieldRefCode] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[subcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlID)
				fieldSeen[subcontrol.FieldControlID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		s.Select(selectedFields...)
	}
	return nil
}

type subcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubcontrolPaginateOption
}

func newSubcontrolPaginateArgs(rv map[string]any) *subcontrolPaginateArgs {
	args := &subcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubcontrolOrder:
			args.opts = append(args.opts, WithSubcontrolOrder(v))
		case []any:
			var orders []*SubcontrolOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubcontrolOrder{Field: &SubcontrolOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubcontrolOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubcontrolWhereInput); ok {
		args.opts = append(args.opts, WithSubcontrolFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sh *SubcontrolHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubcontrolHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sh, nil
	}
	if err := sh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sh, nil
}

func (sh *SubcontrolHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subcontrolhistory.Columns))
		selectedFields = []string{subcontrolhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[subcontrolhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldHistoryTime)
				fieldSeen[subcontrolhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[subcontrolhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldRef)
				fieldSeen[subcontrolhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[subcontrolhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldOperation)
				fieldSeen[subcontrolhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[subcontrolhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCreatedAt)
				fieldSeen[subcontrolhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subcontrolhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldUpdatedAt)
				fieldSeen[subcontrolhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subcontrolhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCreatedBy)
				fieldSeen[subcontrolhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subcontrolhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldUpdatedBy)
				fieldSeen[subcontrolhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[subcontrolhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldDisplayID)
				fieldSeen[subcontrolhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subcontrolhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldTags)
				fieldSeen[subcontrolhistory.FieldTags] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subcontrolhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldDescription)
				fieldSeen[subcontrolhistory.FieldDescription] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferenceID)
				fieldSeen[subcontrolhistory.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[subcontrolhistory.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAuditorReferenceID)
				fieldSeen[subcontrolhistory.FieldAuditorReferenceID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[subcontrolhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldStatus)
				fieldSeen[subcontrolhistory.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[subcontrolhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSource)
				fieldSeen[subcontrolhistory.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferenceFramework)
				fieldSeen[subcontrolhistory.FieldReferenceFramework] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlType]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlType)
				fieldSeen[subcontrolhistory.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[subcontrolhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCategory)
				fieldSeen[subcontrolhistory.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[subcontrolhistory.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCategoryID)
				fieldSeen[subcontrolhistory.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[subcontrolhistory.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSubcategory)
				fieldSeen[subcontrolhistory.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[subcontrolhistory.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldMappedCategories)
				fieldSeen[subcontrolhistory.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[subcontrolhistory.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAssessmentObjectives)
				fieldSeen[subcontrolhistory.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[subcontrolhistory.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAssessmentMethods)
				fieldSeen[subcontrolhistory.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlQuestions)
				fieldSeen[subcontrolhistory.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[subcontrolhistory.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldImplementationGuidance)
				fieldSeen[subcontrolhistory.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[subcontrolhistory.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldExampleEvidence)
				fieldSeen[subcontrolhistory.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferences]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferences)
				fieldSeen[subcontrolhistory.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlOwnerID)
				fieldSeen[subcontrolhistory.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[subcontrolhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldDelegateID)
				fieldSeen[subcontrolhistory.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subcontrolhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldOwnerID)
				fieldSeen[subcontrolhistory.FieldOwnerID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[subcontrolhistory.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldRefCode)
				fieldSeen[subcontrolhistory.FieldRefCode] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlID)
				fieldSeen[subcontrolhistory.FieldControlID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sh.Select(selectedFields...)
	}
	return nil
}

type subcontrolhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubcontrolHistoryPaginateOption
}

func newSubcontrolHistoryPaginateArgs(rv map[string]any) *subcontrolhistoryPaginateArgs {
	args := &subcontrolhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &SubcontrolHistoryOrder{Field: &SubcontrolHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithSubcontrolHistoryOrder(order))
			}
		case *SubcontrolHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithSubcontrolHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*SubcontrolHistoryWhereInput); ok {
		args.opts = append(args.opts, WithSubcontrolHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (s *SubprocessorQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubprocessorQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return s, nil
	}
	if err := s.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return s, nil
}

func (s *SubprocessorQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subprocessor.Columns))
		selectedFields = []string{subprocessor.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			s.withOwner = query
			if _, ok := fieldSeen[subprocessor.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldOwnerID)
				fieldSeen[subprocessor.FieldOwnerID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: s.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subprocessor) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subprocessor_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subprocessor.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(subprocessor.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subprocessor.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(subprocessor.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subprocessor.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subprocessor) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subprocessor.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			s.withLogoFile = query
			if _, ok := fieldSeen[subprocessor.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoLocalFileID)
				fieldSeen[subprocessor.FieldLogoLocalFileID] = struct{}{}
			}

		case "trustCenterSubprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSubprocessorClient{config: s.config}).Query()
			)
			args := newTrustCenterSubprocessorPaginateArgs(fieldArgs(ctx, new(TrustCenterSubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subprocessor) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subprocessor_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subprocessor.TrustCenterSubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(subprocessor.TrustCenterSubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subprocessor) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessors)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentersubprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subprocessor.TrustCenterSubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedTrustCenterSubprocessors(alias, func(wq *TrustCenterSubprocessorQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subprocessor.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldCreatedAt)
				fieldSeen[subprocessor.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subprocessor.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldUpdatedAt)
				fieldSeen[subprocessor.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subprocessor.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldCreatedBy)
				fieldSeen[subprocessor.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subprocessor.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldUpdatedBy)
				fieldSeen[subprocessor.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subprocessor.FieldTags]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldTags)
				fieldSeen[subprocessor.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subprocessor.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldOwnerID)
				fieldSeen[subprocessor.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subprocessor.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldSystemOwned)
				fieldSeen[subprocessor.FieldSystemOwned] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[subprocessor.FieldName]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldName)
				fieldSeen[subprocessor.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subprocessor.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldDescription)
				fieldSeen[subprocessor.FieldDescription] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[subprocessor.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoRemoteURL)
				fieldSeen[subprocessor.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[subprocessor.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoLocalFileID)
				fieldSeen[subprocessor.FieldLogoLocalFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		s.Select(selectedFields...)
	}
	return nil
}

type subprocessorPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubprocessorPaginateOption
}

func newSubprocessorPaginateArgs(rv map[string]any) *subprocessorPaginateArgs {
	args := &subprocessorPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubprocessorOrder:
			args.opts = append(args.opts, WithSubprocessorOrder(v))
		case []any:
			var orders []*SubprocessorOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubprocessorOrder{Field: &SubprocessorOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubprocessorOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubprocessorWhereInput); ok {
		args.opts = append(args.opts, WithSubprocessorFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sh *SubprocessorHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubprocessorHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sh, nil
	}
	if err := sh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sh, nil
}

func (sh *SubprocessorHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subprocessorhistory.Columns))
		selectedFields = []string{subprocessorhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[subprocessorhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldHistoryTime)
				fieldSeen[subprocessorhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[subprocessorhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldRef)
				fieldSeen[subprocessorhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[subprocessorhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldOperation)
				fieldSeen[subprocessorhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[subprocessorhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldCreatedAt)
				fieldSeen[subprocessorhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subprocessorhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldUpdatedAt)
				fieldSeen[subprocessorhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subprocessorhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldCreatedBy)
				fieldSeen[subprocessorhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subprocessorhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldUpdatedBy)
				fieldSeen[subprocessorhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subprocessorhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldTags)
				fieldSeen[subprocessorhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subprocessorhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldOwnerID)
				fieldSeen[subprocessorhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subprocessorhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldSystemOwned)
				fieldSeen[subprocessorhistory.FieldSystemOwned] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[subprocessorhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldName)
				fieldSeen[subprocessorhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subprocessorhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldDescription)
				fieldSeen[subprocessorhistory.FieldDescription] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[subprocessorhistory.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldLogoRemoteURL)
				fieldSeen[subprocessorhistory.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[subprocessorhistory.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldLogoLocalFileID)
				fieldSeen[subprocessorhistory.FieldLogoLocalFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sh.Select(selectedFields...)
	}
	return nil
}

type subprocessorhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubprocessorHistoryPaginateOption
}

func newSubprocessorHistoryPaginateArgs(rv map[string]any) *subprocessorhistoryPaginateArgs {
	args := &subprocessorhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &SubprocessorHistoryOrder{Field: &SubprocessorHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithSubprocessorHistoryOrder(order))
			}
		case *SubprocessorHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithSubprocessorHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*SubprocessorHistoryWhereInput); ok {
		args.opts = append(args.opts, WithSubprocessorHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (s *SubscriberQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubscriberQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return s, nil
	}
	if err := s.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return s, nil
}

func (s *SubscriberQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subscriber.Columns))
		selectedFields = []string{subscriber.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			s.withOwner = query
			if _, ok := fieldSeen[subscriber.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldOwnerID)
				fieldSeen[subscriber.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: s.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Subscriber) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subscriber_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subscriber.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(subscriber.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subscriber.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(subscriber.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subscriber.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Subscriber) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subscriber.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subscriber.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldCreatedAt)
				fieldSeen[subscriber.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subscriber.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUpdatedAt)
				fieldSeen[subscriber.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subscriber.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldCreatedBy)
				fieldSeen[subscriber.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subscriber.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUpdatedBy)
				fieldSeen[subscriber.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subscriber.FieldTags]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldTags)
				fieldSeen[subscriber.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subscriber.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldOwnerID)
				fieldSeen[subscriber.FieldOwnerID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[subscriber.FieldEmail]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldEmail)
				fieldSeen[subscriber.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[subscriber.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldPhoneNumber)
				fieldSeen[subscriber.FieldPhoneNumber] = struct{}{}
			}
		case "verifiedEmail":
			if _, ok := fieldSeen[subscriber.FieldVerifiedEmail]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldVerifiedEmail)
				fieldSeen[subscriber.FieldVerifiedEmail] = struct{}{}
			}
		case "verifiedPhone":
			if _, ok := fieldSeen[subscriber.FieldVerifiedPhone]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldVerifiedPhone)
				fieldSeen[subscriber.FieldVerifiedPhone] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[subscriber.FieldActive]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldActive)
				fieldSeen[subscriber.FieldActive] = struct{}{}
			}
		case "unsubscribed":
			if _, ok := fieldSeen[subscriber.FieldUnsubscribed]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUnsubscribed)
				fieldSeen[subscriber.FieldUnsubscribed] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[subscriber.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldSendAttempts)
				fieldSeen[subscriber.FieldSendAttempts] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		s.Select(selectedFields...)
	}
	return nil
}

type subscriberPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubscriberPaginateOption
}

func newSubscriberPaginateArgs(rv map[string]any) *subscriberPaginateArgs {
	args := &subscriberPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubscriberOrder:
			args.opts = append(args.opts, WithSubscriberOrder(v))
		case []any:
			var orders []*SubscriberOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubscriberOrder{Field: &SubscriberOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubscriberOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubscriberWhereInput); ok {
		args.opts = append(args.opts, WithSubscriberFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ts *TFASettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*TFASettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ts, nil
	}
	if err := ts.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ts, nil
}

func (ts *TFASettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tfasetting.Columns))
		selectedFields = []string{tfasetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: ts.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			ts.withOwner = query
			if _, ok := fieldSeen[tfasetting.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldOwnerID)
				fieldSeen[tfasetting.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[tfasetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldCreatedAt)
				fieldSeen[tfasetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[tfasetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldUpdatedAt)
				fieldSeen[tfasetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[tfasetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldCreatedBy)
				fieldSeen[tfasetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[tfasetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldUpdatedBy)
				fieldSeen[tfasetting.FieldUpdatedBy] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[tfasetting.FieldVerified]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldVerified)
				fieldSeen[tfasetting.FieldVerified] = struct{}{}
			}
		case "totpAllowed":
			if _, ok := fieldSeen[tfasetting.FieldTotpAllowed]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldTotpAllowed)
				fieldSeen[tfasetting.FieldTotpAllowed] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ts.Select(selectedFields...)
	}
	return nil
}

type tfasettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TFASettingPaginateOption
}

func newTFASettingPaginateArgs(rv map[string]any) *tfasettingPaginateArgs {
	args := &tfasettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TFASettingOrder:
			args.opts = append(args.opts, WithTFASettingOrder(v))
		case []any:
			var orders []*TFASettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TFASettingOrder{Field: &TFASettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTFASettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TFASettingWhereInput); ok {
		args.opts = append(args.opts, WithTFASettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (t *TaskQuery) CollectFields(ctx context.Context, satisfies ...string) (*TaskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return t, nil
	}
	if err := t.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return t, nil
}

func (t *TaskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(task.Columns))
		selectedFields = []string{task.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			t.withOwner = query
			if _, ok := fieldSeen[task.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, task.FieldOwnerID)
				fieldSeen[task.FieldOwnerID] = struct{}{}
			}

		case "assigner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			t.withAssigner = query
			if _, ok := fieldSeen[task.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssignerID)
				fieldSeen[task.FieldAssignerID] = struct{}{}
			}

		case "assignee":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			t.withAssignee = query
			if _, ok := fieldSeen[task.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssigneeID)
				fieldSeen[task.FieldAssigneeID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: t.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.CommentsColumn), ids...))
						})
						if err := query.GroupBy(task.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: t.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(task.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: t.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(task.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: t.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(task.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: t.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(task.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: t.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(task.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: t.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(task.ControlObjectivesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlObjectivesPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlObjectivesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlObjectivesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlObjectivesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: t.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(task.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: t.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(task.RisksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.RisksPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.RisksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.RisksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.RisksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: t.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(task.EvidencePrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(task.EvidencePrimaryKey[0]), ids...))
							s.Select(joinT.C(task.EvidencePrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(task.EvidencePrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.EvidencePrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[task.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedAt)
				fieldSeen[task.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[task.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldUpdatedAt)
				fieldSeen[task.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[task.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedBy)
				fieldSeen[task.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[task.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, task.FieldUpdatedBy)
				fieldSeen[task.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[task.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, task.FieldDisplayID)
				fieldSeen[task.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[task.FieldTags]; !ok {
				selectedFields = append(selectedFields, task.FieldTags)
				fieldSeen[task.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[task.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, task.FieldOwnerID)
				fieldSeen[task.FieldOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[task.FieldTitle]; !ok {
				selectedFields = append(selectedFields, task.FieldTitle)
				fieldSeen[task.FieldTitle] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[task.FieldDetails]; !ok {
				selectedFields = append(selectedFields, task.FieldDetails)
				fieldSeen[task.FieldDetails] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[task.FieldStatus]; !ok {
				selectedFields = append(selectedFields, task.FieldStatus)
				fieldSeen[task.FieldStatus] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[task.FieldCategory]; !ok {
				selectedFields = append(selectedFields, task.FieldCategory)
				fieldSeen[task.FieldCategory] = struct{}{}
			}
		case "due":
			if _, ok := fieldSeen[task.FieldDue]; !ok {
				selectedFields = append(selectedFields, task.FieldDue)
				fieldSeen[task.FieldDue] = struct{}{}
			}
		case "completed":
			if _, ok := fieldSeen[task.FieldCompleted]; !ok {
				selectedFields = append(selectedFields, task.FieldCompleted)
				fieldSeen[task.FieldCompleted] = struct{}{}
			}
		case "assigneeID":
			if _, ok := fieldSeen[task.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssigneeID)
				fieldSeen[task.FieldAssigneeID] = struct{}{}
			}
		case "assignerID":
			if _, ok := fieldSeen[task.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssignerID)
				fieldSeen[task.FieldAssignerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		t.Select(selectedFields...)
	}
	return nil
}

type taskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TaskPaginateOption
}

func newTaskPaginateArgs(rv map[string]any) *taskPaginateArgs {
	args := &taskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TaskOrder:
			args.opts = append(args.opts, WithTaskOrder(v))
		case []any:
			var orders []*TaskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TaskOrder{Field: &TaskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTaskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TaskWhereInput); ok {
		args.opts = append(args.opts, WithTaskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (th *TaskHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TaskHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return th, nil
	}
	if err := th.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return th, nil
}

func (th *TaskHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(taskhistory.Columns))
		selectedFields = []string{taskhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[taskhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldHistoryTime)
				fieldSeen[taskhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[taskhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldRef)
				fieldSeen[taskhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[taskhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldOperation)
				fieldSeen[taskhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[taskhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCreatedAt)
				fieldSeen[taskhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[taskhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldUpdatedAt)
				fieldSeen[taskhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[taskhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCreatedBy)
				fieldSeen[taskhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[taskhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldUpdatedBy)
				fieldSeen[taskhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[taskhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldDisplayID)
				fieldSeen[taskhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[taskhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldTags)
				fieldSeen[taskhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[taskhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldOwnerID)
				fieldSeen[taskhistory.FieldOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[taskhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldTitle)
				fieldSeen[taskhistory.FieldTitle] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[taskhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldDetails)
				fieldSeen[taskhistory.FieldDetails] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[taskhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldStatus)
				fieldSeen[taskhistory.FieldStatus] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[taskhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCategory)
				fieldSeen[taskhistory.FieldCategory] = struct{}{}
			}
		case "due":
			if _, ok := fieldSeen[taskhistory.FieldDue]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldDue)
				fieldSeen[taskhistory.FieldDue] = struct{}{}
			}
		case "completed":
			if _, ok := fieldSeen[taskhistory.FieldCompleted]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCompleted)
				fieldSeen[taskhistory.FieldCompleted] = struct{}{}
			}
		case "assigneeID":
			if _, ok := fieldSeen[taskhistory.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldAssigneeID)
				fieldSeen[taskhistory.FieldAssigneeID] = struct{}{}
			}
		case "assignerID":
			if _, ok := fieldSeen[taskhistory.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldAssignerID)
				fieldSeen[taskhistory.FieldAssignerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		th.Select(selectedFields...)
	}
	return nil
}

type taskhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TaskHistoryPaginateOption
}

func newTaskHistoryPaginateArgs(rv map[string]any) *taskhistoryPaginateArgs {
	args := &taskhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TaskHistoryOrder{Field: &TaskHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTaskHistoryOrder(order))
			}
		case *TaskHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTaskHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TaskHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTaskHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (t *TemplateQuery) CollectFields(ctx context.Context, satisfies ...string) (*TemplateQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return t, nil
	}
	if err := t.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return t, nil
}

func (t *TemplateQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(template.Columns))
		selectedFields = []string{template.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			t.withOwner = query
			if _, ok := fieldSeen[template.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, template.FieldOwnerID)
				fieldSeen[template.FieldOwnerID] = struct{}{}
			}

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: t.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(template.DocumentsColumn), ids...))
						})
						if err := query.GroupBy(template.DocumentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.DocumentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: t.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(template.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(template.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(template.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(template.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(template.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[template.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, template.FieldCreatedAt)
				fieldSeen[template.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[template.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, template.FieldUpdatedAt)
				fieldSeen[template.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[template.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, template.FieldCreatedBy)
				fieldSeen[template.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[template.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, template.FieldUpdatedBy)
				fieldSeen[template.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[template.FieldTags]; !ok {
				selectedFields = append(selectedFields, template.FieldTags)
				fieldSeen[template.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[template.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, template.FieldOwnerID)
				fieldSeen[template.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[template.FieldName]; !ok {
				selectedFields = append(selectedFields, template.FieldName)
				fieldSeen[template.FieldName] = struct{}{}
			}
		case "templateType":
			if _, ok := fieldSeen[template.FieldTemplateType]; !ok {
				selectedFields = append(selectedFields, template.FieldTemplateType)
				fieldSeen[template.FieldTemplateType] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[template.FieldDescription]; !ok {
				selectedFields = append(selectedFields, template.FieldDescription)
				fieldSeen[template.FieldDescription] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[template.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, template.FieldJsonconfig)
				fieldSeen[template.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[template.FieldUischema]; !ok {
				selectedFields = append(selectedFields, template.FieldUischema)
				fieldSeen[template.FieldUischema] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		t.Select(selectedFields...)
	}
	return nil
}

type templatePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TemplatePaginateOption
}

func newTemplatePaginateArgs(rv map[string]any) *templatePaginateArgs {
	args := &templatePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TemplateOrder:
			args.opts = append(args.opts, WithTemplateOrder(v))
		case []any:
			var orders []*TemplateOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TemplateOrder{Field: &TemplateOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTemplateOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TemplateWhereInput); ok {
		args.opts = append(args.opts, WithTemplateFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (th *TemplateHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TemplateHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return th, nil
	}
	if err := th.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return th, nil
}

func (th *TemplateHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(templatehistory.Columns))
		selectedFields = []string{templatehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[templatehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldHistoryTime)
				fieldSeen[templatehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[templatehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldRef)
				fieldSeen[templatehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[templatehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldOperation)
				fieldSeen[templatehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[templatehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldCreatedAt)
				fieldSeen[templatehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[templatehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldUpdatedAt)
				fieldSeen[templatehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[templatehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldCreatedBy)
				fieldSeen[templatehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[templatehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldUpdatedBy)
				fieldSeen[templatehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[templatehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldTags)
				fieldSeen[templatehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[templatehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldOwnerID)
				fieldSeen[templatehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[templatehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldName)
				fieldSeen[templatehistory.FieldName] = struct{}{}
			}
		case "templateType":
			if _, ok := fieldSeen[templatehistory.FieldTemplateType]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldTemplateType)
				fieldSeen[templatehistory.FieldTemplateType] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[templatehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldDescription)
				fieldSeen[templatehistory.FieldDescription] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[templatehistory.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldJsonconfig)
				fieldSeen[templatehistory.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[templatehistory.FieldUischema]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldUischema)
				fieldSeen[templatehistory.FieldUischema] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		th.Select(selectedFields...)
	}
	return nil
}

type templatehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TemplateHistoryPaginateOption
}

func newTemplateHistoryPaginateArgs(rv map[string]any) *templatehistoryPaginateArgs {
	args := &templatehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TemplateHistoryOrder{Field: &TemplateHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTemplateHistoryOrder(order))
			}
		case *TemplateHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTemplateHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TemplateHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTemplateHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tc *TrustCenterQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tc, nil
	}
	if err := tc.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tc, nil
}

func (tc *TrustCenterQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenter.Columns))
		selectedFields = []string{trustcenter.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: tc.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			tc.withOwner = query
			if _, ok := fieldSeen[trustcenter.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldOwnerID)
				fieldSeen[trustcenter.FieldOwnerID] = struct{}{}
			}

		case "customDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: tc.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
				return err
			}
			tc.withCustomDomain = query
			if _, ok := fieldSeen[trustcenter.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCustomDomainID)
				fieldSeen[trustcenter.FieldCustomDomainID] = struct{}{}
			}

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: tc.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			tc.withSetting = query

		case "trustCenterSubprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSubprocessorClient{config: tc.config}).Query()
			)
			args := newTrustCenterSubprocessorPaginateArgs(fieldArgs(ctx, new(TrustCenterSubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					tc.loadTotal = append(tc.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterSubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterSubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					tc.loadTotal = append(tc.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessors)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentersubprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterSubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			tc.WithNamedTrustCenterSubprocessors(alias, func(wq *TrustCenterSubprocessorQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[trustcenter.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCreatedAt)
				fieldSeen[trustcenter.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenter.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldUpdatedAt)
				fieldSeen[trustcenter.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenter.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCreatedBy)
				fieldSeen[trustcenter.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenter.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldUpdatedBy)
				fieldSeen[trustcenter.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenter.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldTags)
				fieldSeen[trustcenter.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenter.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldOwnerID)
				fieldSeen[trustcenter.FieldOwnerID] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[trustcenter.FieldSlug]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldSlug)
				fieldSeen[trustcenter.FieldSlug] = struct{}{}
			}
		case "customDomainID":
			if _, ok := fieldSeen[trustcenter.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCustomDomainID)
				fieldSeen[trustcenter.FieldCustomDomainID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tc.Select(selectedFields...)
	}
	return nil
}

type trustcenterPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterPaginateOption
}

func newTrustCenterPaginateArgs(rv map[string]any) *trustcenterPaginateArgs {
	args := &trustcenterPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterOrder:
			args.opts = append(args.opts, WithTrustCenterOrder(v))
		case []any:
			var orders []*TrustCenterOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterOrder{Field: &TrustCenterOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tcc *TrustCenterComplianceQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterComplianceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tcc, nil
	}
	if err := tcc.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tcc, nil
}

func (tcc *TrustCenterComplianceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentercompliance.Columns))
		selectedFields = []string{trustcentercompliance.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "createdAt":
			if _, ok := fieldSeen[trustcentercompliance.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldCreatedAt)
				fieldSeen[trustcentercompliance.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentercompliance.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldUpdatedAt)
				fieldSeen[trustcentercompliance.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentercompliance.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldCreatedBy)
				fieldSeen[trustcentercompliance.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentercompliance.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldUpdatedBy)
				fieldSeen[trustcentercompliance.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcentercompliance.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTags)
				fieldSeen[trustcentercompliance.FieldTags] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tcc.Select(selectedFields...)
	}
	return nil
}

type trustcentercompliancePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterCompliancePaginateOption
}

func newTrustCenterCompliancePaginateArgs(rv map[string]any) *trustcentercompliancePaginateArgs {
	args := &trustcentercompliancePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterComplianceOrder:
			args.opts = append(args.opts, WithTrustCenterComplianceOrder(v))
		case []any:
			var orders []*TrustCenterComplianceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterComplianceOrder{Field: &TrustCenterComplianceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterComplianceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterComplianceWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterComplianceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tcch *TrustCenterComplianceHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterComplianceHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tcch, nil
	}
	if err := tcch.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tcch, nil
}

func (tcch *TrustCenterComplianceHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentercompliancehistory.Columns))
		selectedFields = []string{trustcentercompliancehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldHistoryTime)
				fieldSeen[trustcentercompliancehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldRef)
				fieldSeen[trustcentercompliancehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldOperation)
				fieldSeen[trustcentercompliancehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldCreatedAt)
				fieldSeen[trustcentercompliancehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldUpdatedAt)
				fieldSeen[trustcentercompliancehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldCreatedBy)
				fieldSeen[trustcentercompliancehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldUpdatedBy)
				fieldSeen[trustcentercompliancehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldTags)
				fieldSeen[trustcentercompliancehistory.FieldTags] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tcch.Select(selectedFields...)
	}
	return nil
}

type trustcentercompliancehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterComplianceHistoryPaginateOption
}

func newTrustCenterComplianceHistoryPaginateArgs(rv map[string]any) *trustcentercompliancehistoryPaginateArgs {
	args := &trustcentercompliancehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterComplianceHistoryOrder{Field: &TrustCenterComplianceHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterComplianceHistoryOrder(order))
			}
		case *TrustCenterComplianceHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterComplianceHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterComplianceHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterComplianceHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tch *TrustCenterHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tch, nil
	}
	if err := tch.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tch, nil
}

func (tch *TrustCenterHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterhistory.Columns))
		selectedFields = []string{trustcenterhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcenterhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldHistoryTime)
				fieldSeen[trustcenterhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcenterhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldRef)
				fieldSeen[trustcenterhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcenterhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldOperation)
				fieldSeen[trustcenterhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldCreatedAt)
				fieldSeen[trustcenterhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldUpdatedAt)
				fieldSeen[trustcenterhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldCreatedBy)
				fieldSeen[trustcenterhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldUpdatedBy)
				fieldSeen[trustcenterhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenterhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldTags)
				fieldSeen[trustcenterhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenterhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldOwnerID)
				fieldSeen[trustcenterhistory.FieldOwnerID] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[trustcenterhistory.FieldSlug]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldSlug)
				fieldSeen[trustcenterhistory.FieldSlug] = struct{}{}
			}
		case "customDomainID":
			if _, ok := fieldSeen[trustcenterhistory.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldCustomDomainID)
				fieldSeen[trustcenterhistory.FieldCustomDomainID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tch.Select(selectedFields...)
	}
	return nil
}

type trustcenterhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterHistoryPaginateOption
}

func newTrustCenterHistoryPaginateArgs(rv map[string]any) *trustcenterhistoryPaginateArgs {
	args := &trustcenterhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterHistoryOrder{Field: &TrustCenterHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterHistoryOrder(order))
			}
		case *TrustCenterHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tcs *TrustCenterSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tcs, nil
	}
	if err := tcs.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tcs, nil
}

func (tcs *TrustCenterSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersetting.Columns))
		selectedFields = []string{trustcentersetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: tcs.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			tcs.withTrustCenter = query
			if _, ok := fieldSeen[trustcentersetting.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTrustCenterID)
				fieldSeen[trustcentersetting.FieldTrustCenterID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: tcs.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					tcs.loadTotal = append(tcs.loadTotal, func(ctx context.Context, nodes []*TrustCenterSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(trustcentersetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(trustcentersetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(trustcentersetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(trustcentersetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(trustcentersetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					tcs.loadTotal = append(tcs.loadTotal, func(_ context.Context, nodes []*TrustCenterSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcentersetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			tcs.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: tcs.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			tcs.withLogoFile = query
			if _, ok := fieldSeen[trustcentersetting.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoLocalFileID)
				fieldSeen[trustcentersetting.FieldLogoLocalFileID] = struct{}{}
			}

		case "faviconFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: tcs.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			tcs.withFaviconFile = query
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconLocalFileID)
				fieldSeen[trustcentersetting.FieldFaviconLocalFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldCreatedAt)
				fieldSeen[trustcentersetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldUpdatedAt)
				fieldSeen[trustcentersetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldCreatedBy)
				fieldSeen[trustcentersetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldUpdatedBy)
				fieldSeen[trustcentersetting.FieldUpdatedBy] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersetting.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTrustCenterID)
				fieldSeen[trustcentersetting.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcentersetting.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTitle)
				fieldSeen[trustcentersetting.FieldTitle] = struct{}{}
			}
		case "overview":
			if _, ok := fieldSeen[trustcentersetting.FieldOverview]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldOverview)
				fieldSeen[trustcentersetting.FieldOverview] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[trustcentersetting.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoRemoteURL)
				fieldSeen[trustcentersetting.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[trustcentersetting.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoLocalFileID)
				fieldSeen[trustcentersetting.FieldLogoLocalFileID] = struct{}{}
			}
		case "faviconRemoteURL":
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconRemoteURL)
				fieldSeen[trustcentersetting.FieldFaviconRemoteURL] = struct{}{}
			}
		case "faviconLocalFileID":
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconLocalFileID)
				fieldSeen[trustcentersetting.FieldFaviconLocalFileID] = struct{}{}
			}
		case "themeMode":
			if _, ok := fieldSeen[trustcentersetting.FieldThemeMode]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldThemeMode)
				fieldSeen[trustcentersetting.FieldThemeMode] = struct{}{}
			}
		case "primaryColor":
			if _, ok := fieldSeen[trustcentersetting.FieldPrimaryColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldPrimaryColor)
				fieldSeen[trustcentersetting.FieldPrimaryColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcentersetting.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFont)
				fieldSeen[trustcentersetting.FieldFont] = struct{}{}
			}
		case "foregroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldForegroundColor)
				fieldSeen[trustcentersetting.FieldForegroundColor] = struct{}{}
			}
		case "backgroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldBackgroundColor)
				fieldSeen[trustcentersetting.FieldBackgroundColor] = struct{}{}
			}
		case "accentColor":
			if _, ok := fieldSeen[trustcentersetting.FieldAccentColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldAccentColor)
				fieldSeen[trustcentersetting.FieldAccentColor] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tcs.Select(selectedFields...)
	}
	return nil
}

type trustcentersettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSettingPaginateOption
}

func newTrustCenterSettingPaginateArgs(rv map[string]any) *trustcentersettingPaginateArgs {
	args := &trustcentersettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterSettingOrder:
			args.opts = append(args.opts, WithTrustCenterSettingOrder(v))
		case []any:
			var orders []*TrustCenterSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterSettingOrder{Field: &TrustCenterSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSettingWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tcsh *TrustCenterSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tcsh, nil
	}
	if err := tcsh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tcsh, nil
}

func (tcsh *TrustCenterSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersettinghistory.Columns))
		selectedFields = []string{trustcentersettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldHistoryTime)
				fieldSeen[trustcentersettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldRef)
				fieldSeen[trustcentersettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldOperation)
				fieldSeen[trustcentersettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldCreatedAt)
				fieldSeen[trustcentersettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldUpdatedAt)
				fieldSeen[trustcentersettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldCreatedBy)
				fieldSeen[trustcentersettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldUpdatedBy)
				fieldSeen[trustcentersettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldTrustCenterID)
				fieldSeen[trustcentersettinghistory.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldTitle)
				fieldSeen[trustcentersettinghistory.FieldTitle] = struct{}{}
			}
		case "overview":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldOverview]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldOverview)
				fieldSeen[trustcentersettinghistory.FieldOverview] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldLogoRemoteURL)
				fieldSeen[trustcentersettinghistory.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldLogoLocalFileID)
				fieldSeen[trustcentersettinghistory.FieldLogoLocalFileID] = struct{}{}
			}
		case "faviconRemoteURL":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldFaviconRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldFaviconRemoteURL)
				fieldSeen[trustcentersettinghistory.FieldFaviconRemoteURL] = struct{}{}
			}
		case "faviconLocalFileID":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldFaviconLocalFileID)
				fieldSeen[trustcentersettinghistory.FieldFaviconLocalFileID] = struct{}{}
			}
		case "themeMode":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldThemeMode]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldThemeMode)
				fieldSeen[trustcentersettinghistory.FieldThemeMode] = struct{}{}
			}
		case "primaryColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldPrimaryColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldPrimaryColor)
				fieldSeen[trustcentersettinghistory.FieldPrimaryColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldFont)
				fieldSeen[trustcentersettinghistory.FieldFont] = struct{}{}
			}
		case "foregroundColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldForegroundColor)
				fieldSeen[trustcentersettinghistory.FieldForegroundColor] = struct{}{}
			}
		case "backgroundColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldBackgroundColor)
				fieldSeen[trustcentersettinghistory.FieldBackgroundColor] = struct{}{}
			}
		case "accentColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldAccentColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldAccentColor)
				fieldSeen[trustcentersettinghistory.FieldAccentColor] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tcsh.Select(selectedFields...)
	}
	return nil
}

type trustcentersettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSettingHistoryPaginateOption
}

func newTrustCenterSettingHistoryPaginateArgs(rv map[string]any) *trustcentersettinghistoryPaginateArgs {
	args := &trustcentersettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterSettingHistoryOrder{Field: &TrustCenterSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterSettingHistoryOrder(order))
			}
		case *TrustCenterSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tcs *TrustCenterSubprocessorQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSubprocessorQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tcs, nil
	}
	if err := tcs.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tcs, nil
}

func (tcs *TrustCenterSubprocessorQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersubprocessor.Columns))
		selectedFields = []string{trustcentersubprocessor.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: tcs.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			tcs.withTrustCenter = query
			if _, ok := fieldSeen[trustcentersubprocessor.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessor.FieldTrustCenterID] = struct{}{}
			}

		case "subprocessor":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: tcs.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
				return err
			}
			tcs.withSubprocessor = query
			if _, ok := fieldSeen[trustcentersubprocessor.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessor.FieldSubprocessorID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCreatedAt)
				fieldSeen[trustcentersubprocessor.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldUpdatedAt)
				fieldSeen[trustcentersubprocessor.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCreatedBy)
				fieldSeen[trustcentersubprocessor.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldUpdatedBy)
				fieldSeen[trustcentersubprocessor.FieldUpdatedBy] = struct{}{}
			}
		case "subprocessorID":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessor.FieldSubprocessorID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessor.FieldTrustCenterID] = struct{}{}
			}
		case "countries":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCountries]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCountries)
				fieldSeen[trustcentersubprocessor.FieldCountries] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCategory)
				fieldSeen[trustcentersubprocessor.FieldCategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tcs.Select(selectedFields...)
	}
	return nil
}

type trustcentersubprocessorPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSubprocessorPaginateOption
}

func newTrustCenterSubprocessorPaginateArgs(rv map[string]any) *trustcentersubprocessorPaginateArgs {
	args := &trustcentersubprocessorPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterSubprocessorOrder:
			args.opts = append(args.opts, WithTrustCenterSubprocessorOrder(v))
		case []any:
			var orders []*TrustCenterSubprocessorOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterSubprocessorOrder{Field: &TrustCenterSubprocessorOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterSubprocessorOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSubprocessorWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSubprocessorFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (tcsh *TrustCenterSubprocessorHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSubprocessorHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return tcsh, nil
	}
	if err := tcsh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return tcsh, nil
}

func (tcsh *TrustCenterSubprocessorHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersubprocessorhistory.Columns))
		selectedFields = []string{trustcentersubprocessorhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldHistoryTime)
				fieldSeen[trustcentersubprocessorhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldRef)
				fieldSeen[trustcentersubprocessorhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldOperation)
				fieldSeen[trustcentersubprocessorhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCreatedAt)
				fieldSeen[trustcentersubprocessorhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldUpdatedAt)
				fieldSeen[trustcentersubprocessorhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCreatedBy)
				fieldSeen[trustcentersubprocessorhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldUpdatedBy)
				fieldSeen[trustcentersubprocessorhistory.FieldUpdatedBy] = struct{}{}
			}
		case "subprocessorID":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessorhistory.FieldSubprocessorID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessorhistory.FieldTrustCenterID] = struct{}{}
			}
		case "countries":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCountries]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCountries)
				fieldSeen[trustcentersubprocessorhistory.FieldCountries] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCategory)
				fieldSeen[trustcentersubprocessorhistory.FieldCategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		tcsh.Select(selectedFields...)
	}
	return nil
}

type trustcentersubprocessorhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSubprocessorHistoryPaginateOption
}

func newTrustCenterSubprocessorHistoryPaginateArgs(rv map[string]any) *trustcentersubprocessorhistoryPaginateArgs {
	args := &trustcentersubprocessorhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterSubprocessorHistoryOrder{Field: &TrustCenterSubprocessorHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterSubprocessorHistoryOrder(order))
			}
		case *TrustCenterSubprocessorHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterSubprocessorHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSubprocessorHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSubprocessorHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (u *UserQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return u, nil
	}
	if err := u.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return u, nil
}

func (u *UserQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(user.Columns))
		selectedFields = []string{user.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: u.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.PersonalAccessTokensColumn), ids...))
						})
						if err := query.GroupBy(user.PersonalAccessTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.PersonalAccessTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "tfaSettings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TFASettingClient{config: u.config}).Query()
			)
			args := newTFASettingPaginateArgs(fieldArgs(ctx, new(TFASettingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTFASettingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.TfaSettingsColumn), ids...))
						})
						if err := query.GroupBy(user.TfaSettingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TfaSettings)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tfasettingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.TfaSettingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedTfaSettings(alias, func(wq *TFASettingQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserSettingClient{config: u.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, usersettingImplementors)...); err != nil {
				return err
			}
			u.withSetting = query

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: u.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(user.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: u.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(user.OrganizationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.OrganizationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.OrganizationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.OrganizationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.OrganizationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "webauthns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WebauthnClient{config: u.config}).Query()
			)
			args := newWebauthnPaginateArgs(fieldArgs(ctx, new(WebauthnWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWebauthnPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.WebauthnsColumn), ids...))
						})
						if err := query.GroupBy(user.WebauthnsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Webauthns)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, webauthnImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.WebauthnsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedWebauthns(alias, func(wq *WebauthnQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: u.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(user.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "avatarFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: u.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			u.withAvatarFile = query
			if _, ok := fieldSeen[user.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarLocalFileID)
				fieldSeen[user.FieldAvatarLocalFileID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: u.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(user.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: u.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(user.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: u.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(user.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "assignerTasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: u.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assigner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.AssignerTasksColumn), ids...))
						})
						if err := query.GroupBy(user.AssignerTasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssignerTasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.AssignerTasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedAssignerTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "assigneeTasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: u.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assignee_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.AssigneeTasksColumn), ids...))
						})
						if err := query.GroupBy(user.AssigneeTasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssigneeTasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.AssigneeTasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedAssigneeTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: u.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(user.ProgramsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.ProgramsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.ProgramsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.ProgramsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "groupMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: u.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.GroupMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.GroupMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupMemberships)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.GroupMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedGroupMemberships(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})

		case "orgMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: u.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.OrgMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.OrgMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgMemberships)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.OrgMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedOrgMemberships(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})

		case "programMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramMembershipClient{config: u.config}).Query()
			)
			args := newProgramMembershipPaginateArgs(fieldArgs(ctx, new(ProgramMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ProgramMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.ProgramMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramMemberships)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedProgramMemberships(alias, func(wq *ProgramMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[user.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedAt)
				fieldSeen[user.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[user.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedAt)
				fieldSeen[user.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[user.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedBy)
				fieldSeen[user.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[user.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedBy)
				fieldSeen[user.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[user.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, user.FieldDisplayID)
				fieldSeen[user.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[user.FieldTags]; !ok {
				selectedFields = append(selectedFields, user.FieldTags)
				fieldSeen[user.FieldTags] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[user.FieldEmail]; !ok {
				selectedFields = append(selectedFields, user.FieldEmail)
				fieldSeen[user.FieldEmail] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[user.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, user.FieldFirstName)
				fieldSeen[user.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[user.FieldLastName]; !ok {
				selectedFields = append(selectedFields, user.FieldLastName)
				fieldSeen[user.FieldLastName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[user.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, user.FieldDisplayName)
				fieldSeen[user.FieldDisplayName] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[user.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarRemoteURL)
				fieldSeen[user.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[user.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarLocalFileID)
				fieldSeen[user.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[user.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarUpdatedAt)
				fieldSeen[user.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[user.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, user.FieldLastSeen)
				fieldSeen[user.FieldLastSeen] = struct{}{}
			}
		case "lastLoginProvider":
			if _, ok := fieldSeen[user.FieldLastLoginProvider]; !ok {
				selectedFields = append(selectedFields, user.FieldLastLoginProvider)
				fieldSeen[user.FieldLastLoginProvider] = struct{}{}
			}
		case "sub":
			if _, ok := fieldSeen[user.FieldSub]; !ok {
				selectedFields = append(selectedFields, user.FieldSub)
				fieldSeen[user.FieldSub] = struct{}{}
			}
		case "authProvider":
			if _, ok := fieldSeen[user.FieldAuthProvider]; !ok {
				selectedFields = append(selectedFields, user.FieldAuthProvider)
				fieldSeen[user.FieldAuthProvider] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[user.FieldRole]; !ok {
				selectedFields = append(selectedFields, user.FieldRole)
				fieldSeen[user.FieldRole] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		u.Select(selectedFields...)
	}
	return nil
}

type userPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserPaginateOption
}

func newUserPaginateArgs(rv map[string]any) *userPaginateArgs {
	args := &userPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserOrder:
			args.opts = append(args.opts, WithUserOrder(v))
		case []any:
			var orders []*UserOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserOrder{Field: &UserOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserWhereInput); ok {
		args.opts = append(args.opts, WithUserFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (uh *UserHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return uh, nil
	}
	if err := uh.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return uh, nil
}

func (uh *UserHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(userhistory.Columns))
		selectedFields = []string{userhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[userhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldHistoryTime)
				fieldSeen[userhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[userhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldRef)
				fieldSeen[userhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[userhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldOperation)
				fieldSeen[userhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[userhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldCreatedAt)
				fieldSeen[userhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[userhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldUpdatedAt)
				fieldSeen[userhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[userhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldCreatedBy)
				fieldSeen[userhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[userhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldUpdatedBy)
				fieldSeen[userhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[userhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldDisplayID)
				fieldSeen[userhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[userhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldTags)
				fieldSeen[userhistory.FieldTags] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[userhistory.FieldEmail]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldEmail)
				fieldSeen[userhistory.FieldEmail] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[userhistory.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldFirstName)
				fieldSeen[userhistory.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[userhistory.FieldLastName]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldLastName)
				fieldSeen[userhistory.FieldLastName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[userhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldDisplayName)
				fieldSeen[userhistory.FieldDisplayName] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[userhistory.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAvatarRemoteURL)
				fieldSeen[userhistory.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[userhistory.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAvatarLocalFileID)
				fieldSeen[userhistory.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[userhistory.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAvatarUpdatedAt)
				fieldSeen[userhistory.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[userhistory.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldLastSeen)
				fieldSeen[userhistory.FieldLastSeen] = struct{}{}
			}
		case "lastLoginProvider":
			if _, ok := fieldSeen[userhistory.FieldLastLoginProvider]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldLastLoginProvider)
				fieldSeen[userhistory.FieldLastLoginProvider] = struct{}{}
			}
		case "sub":
			if _, ok := fieldSeen[userhistory.FieldSub]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldSub)
				fieldSeen[userhistory.FieldSub] = struct{}{}
			}
		case "authProvider":
			if _, ok := fieldSeen[userhistory.FieldAuthProvider]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAuthProvider)
				fieldSeen[userhistory.FieldAuthProvider] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[userhistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldRole)
				fieldSeen[userhistory.FieldRole] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		uh.Select(selectedFields...)
	}
	return nil
}

type userhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserHistoryPaginateOption
}

func newUserHistoryPaginateArgs(rv map[string]any) *userhistoryPaginateArgs {
	args := &userhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserHistoryOrder{Field: &UserHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserHistoryOrder(order))
			}
		case *UserHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserHistoryWhereInput); ok {
		args.opts = append(args.opts, WithUserHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (us *UserSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return us, nil
	}
	if err := us.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return us, nil
}

func (us *UserSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usersetting.Columns))
		selectedFields = []string{usersetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: us.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			us.withUser = query
			if _, ok := fieldSeen[usersetting.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUserID)
				fieldSeen[usersetting.FieldUserID] = struct{}{}
			}

		case "defaultOrg":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: us.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			us.withDefaultOrg = query

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: us.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					us.loadTotal = append(us.loadTotal, func(ctx context.Context, nodes []*UserSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(usersetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(usersetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(usersetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(usersetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(usersetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					us.loadTotal = append(us.loadTotal, func(_ context.Context, nodes []*UserSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(usersetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			us.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[usersetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldCreatedAt)
				fieldSeen[usersetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usersetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUpdatedAt)
				fieldSeen[usersetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[usersetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldCreatedBy)
				fieldSeen[usersetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[usersetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUpdatedBy)
				fieldSeen[usersetting.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[usersetting.FieldTags]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldTags)
				fieldSeen[usersetting.FieldTags] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[usersetting.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUserID)
				fieldSeen[usersetting.FieldUserID] = struct{}{}
			}
		case "locked":
			if _, ok := fieldSeen[usersetting.FieldLocked]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldLocked)
				fieldSeen[usersetting.FieldLocked] = struct{}{}
			}
		case "silencedAt":
			if _, ok := fieldSeen[usersetting.FieldSilencedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldSilencedAt)
				fieldSeen[usersetting.FieldSilencedAt] = struct{}{}
			}
		case "suspendedAt":
			if _, ok := fieldSeen[usersetting.FieldSuspendedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldSuspendedAt)
				fieldSeen[usersetting.FieldSuspendedAt] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[usersetting.FieldStatus]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldStatus)
				fieldSeen[usersetting.FieldStatus] = struct{}{}
			}
		case "emailConfirmed":
			if _, ok := fieldSeen[usersetting.FieldEmailConfirmed]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldEmailConfirmed)
				fieldSeen[usersetting.FieldEmailConfirmed] = struct{}{}
			}
		case "isWebauthnAllowed":
			if _, ok := fieldSeen[usersetting.FieldIsWebauthnAllowed]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldIsWebauthnAllowed)
				fieldSeen[usersetting.FieldIsWebauthnAllowed] = struct{}{}
			}
		case "isTfaEnabled":
			if _, ok := fieldSeen[usersetting.FieldIsTfaEnabled]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldIsTfaEnabled)
				fieldSeen[usersetting.FieldIsTfaEnabled] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		us.Select(selectedFields...)
	}
	return nil
}

type usersettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserSettingPaginateOption
}

func newUserSettingPaginateArgs(rv map[string]any) *usersettingPaginateArgs {
	args := &usersettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserSettingOrder:
			args.opts = append(args.opts, WithUserSettingOrder(v))
		case []any:
			var orders []*UserSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserSettingOrder{Field: &UserSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserSettingWhereInput); ok {
		args.opts = append(args.opts, WithUserSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ush *UserSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ush, nil
	}
	if err := ush.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ush, nil
}

func (ush *UserSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usersettinghistory.Columns))
		selectedFields = []string{usersettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[usersettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldHistoryTime)
				fieldSeen[usersettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[usersettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldRef)
				fieldSeen[usersettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[usersettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldOperation)
				fieldSeen[usersettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[usersettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldCreatedAt)
				fieldSeen[usersettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usersettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldUpdatedAt)
				fieldSeen[usersettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[usersettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldCreatedBy)
				fieldSeen[usersettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[usersettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldUpdatedBy)
				fieldSeen[usersettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[usersettinghistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldTags)
				fieldSeen[usersettinghistory.FieldTags] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[usersettinghistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldUserID)
				fieldSeen[usersettinghistory.FieldUserID] = struct{}{}
			}
		case "locked":
			if _, ok := fieldSeen[usersettinghistory.FieldLocked]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldLocked)
				fieldSeen[usersettinghistory.FieldLocked] = struct{}{}
			}
		case "silencedAt":
			if _, ok := fieldSeen[usersettinghistory.FieldSilencedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldSilencedAt)
				fieldSeen[usersettinghistory.FieldSilencedAt] = struct{}{}
			}
		case "suspendedAt":
			if _, ok := fieldSeen[usersettinghistory.FieldSuspendedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldSuspendedAt)
				fieldSeen[usersettinghistory.FieldSuspendedAt] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[usersettinghistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldStatus)
				fieldSeen[usersettinghistory.FieldStatus] = struct{}{}
			}
		case "emailConfirmed":
			if _, ok := fieldSeen[usersettinghistory.FieldEmailConfirmed]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldEmailConfirmed)
				fieldSeen[usersettinghistory.FieldEmailConfirmed] = struct{}{}
			}
		case "isWebauthnAllowed":
			if _, ok := fieldSeen[usersettinghistory.FieldIsWebauthnAllowed]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldIsWebauthnAllowed)
				fieldSeen[usersettinghistory.FieldIsWebauthnAllowed] = struct{}{}
			}
		case "isTfaEnabled":
			if _, ok := fieldSeen[usersettinghistory.FieldIsTfaEnabled]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldIsTfaEnabled)
				fieldSeen[usersettinghistory.FieldIsTfaEnabled] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ush.Select(selectedFields...)
	}
	return nil
}

type usersettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserSettingHistoryPaginateOption
}

func newUserSettingHistoryPaginateArgs(rv map[string]any) *usersettinghistoryPaginateArgs {
	args := &usersettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserSettingHistoryOrder{Field: &UserSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserSettingHistoryOrder(order))
			}
		case *UserSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithUserSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (w *WebauthnQuery) CollectFields(ctx context.Context, satisfies ...string) (*WebauthnQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return w, nil
	}
	if err := w.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return w, nil
}

func (w *WebauthnQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(webauthn.Columns))
		selectedFields = []string{webauthn.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: w.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			w.withOwner = query
			if _, ok := fieldSeen[webauthn.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldOwnerID)
				fieldSeen[webauthn.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[webauthn.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldCreatedAt)
				fieldSeen[webauthn.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[webauthn.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldUpdatedAt)
				fieldSeen[webauthn.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[webauthn.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldCreatedBy)
				fieldSeen[webauthn.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[webauthn.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldUpdatedBy)
				fieldSeen[webauthn.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[webauthn.FieldTags]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldTags)
				fieldSeen[webauthn.FieldTags] = struct{}{}
			}
		case "aaguid":
			if _, ok := fieldSeen[webauthn.FieldAaguid]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldAaguid)
				fieldSeen[webauthn.FieldAaguid] = struct{}{}
			}
		case "backupEligible":
			if _, ok := fieldSeen[webauthn.FieldBackupEligible]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldBackupEligible)
				fieldSeen[webauthn.FieldBackupEligible] = struct{}{}
			}
		case "backupState":
			if _, ok := fieldSeen[webauthn.FieldBackupState]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldBackupState)
				fieldSeen[webauthn.FieldBackupState] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		w.Select(selectedFields...)
	}
	return nil
}

type webauthnPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WebauthnPaginateOption
}

func newWebauthnPaginateArgs(rv map[string]any) *webauthnPaginateArgs {
	args := &webauthnPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WebauthnOrder{Field: &WebauthnOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWebauthnOrder(order))
			}
		case *WebauthnOrder:
			if v != nil {
				args.opts = append(args.opts, WithWebauthnOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WebauthnWhereInput); ok {
		args.opts = append(args.opts, WithWebauthnFilter(v.Filter))
	}
	return args
}

const (
	afterField     = "after"
	firstField     = "first"
	beforeField    = "before"
	lastField      = "last"
	orderByField   = "orderBy"
	directionField = "direction"
	fieldField     = "field"
	whereField     = "where"
)

func fieldArgs(ctx context.Context, whereInput any, path ...string) map[string]any {
	field := collectedField(ctx, path...)
	if field == nil || field.Arguments == nil {
		return nil
	}
	oc := graphql.GetOperationContext(ctx)
	args := field.ArgumentMap(oc.Variables)
	return unmarshalArgs(ctx, whereInput, args)
}

// unmarshalArgs allows extracting the field arguments from their raw representation.
func unmarshalArgs(ctx context.Context, whereInput any, args map[string]any) map[string]any {
	for _, k := range []string{firstField, lastField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		i, err := graphql.UnmarshalInt(v)
		if err == nil {
			args[k] = &i
		}
	}
	for _, k := range []string{beforeField, afterField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		c := &Cursor{}
		if c.UnmarshalGQL(v) == nil {
			args[k] = c
		}
	}
	if v, ok := args[whereField]; ok && whereInput != nil {
		if err := graphql.UnmarshalInputFromContext(ctx, v, whereInput); err == nil {
			args[whereField] = whereInput
		}
	}

	return args
}

// mayAddCondition appends another type condition to the satisfies list
// if it does not exist in the list.
func mayAddCondition(satisfies []string, typeCond []string) []string {
Cond:
	for _, c := range typeCond {
		for _, s := range satisfies {
			if c == s {
				continue Cond
			}
		}
		satisfies = append(satisfies, c)
	}
	return satisfies
}
