// Code generated by ent, DO NOT EDIT.

package generated

import (
	"context"
	"database/sql/driver"
	"fmt"

	"entgo.io/contrib/entgql"
	"entgo.io/ent/dialect/sql"
	"github.com/99designs/gqlgen/graphql"
	"github.com/theopenlane/core/internal/ent/generated/actionplan"
	"github.com/theopenlane/core/internal/ent/generated/actionplanhistory"
	"github.com/theopenlane/core/internal/ent/generated/apitoken"
	"github.com/theopenlane/core/internal/ent/generated/assessment"
	"github.com/theopenlane/core/internal/ent/generated/assessmenthistory"
	"github.com/theopenlane/core/internal/ent/generated/assessmentresponse"
	"github.com/theopenlane/core/internal/ent/generated/assessmentresponsehistory"
	"github.com/theopenlane/core/internal/ent/generated/asset"
	"github.com/theopenlane/core/internal/ent/generated/assethistory"
	"github.com/theopenlane/core/internal/ent/generated/contact"
	"github.com/theopenlane/core/internal/ent/generated/contacthistory"
	"github.com/theopenlane/core/internal/ent/generated/control"
	"github.com/theopenlane/core/internal/ent/generated/controlhistory"
	"github.com/theopenlane/core/internal/ent/generated/controlimplementation"
	"github.com/theopenlane/core/internal/ent/generated/controlimplementationhistory"
	"github.com/theopenlane/core/internal/ent/generated/controlobjective"
	"github.com/theopenlane/core/internal/ent/generated/controlobjectivehistory"
	"github.com/theopenlane/core/internal/ent/generated/customdomain"
	"github.com/theopenlane/core/internal/ent/generated/customdomainhistory"
	"github.com/theopenlane/core/internal/ent/generated/customtypeenum"
	"github.com/theopenlane/core/internal/ent/generated/directoryaccount"
	"github.com/theopenlane/core/internal/ent/generated/directoryaccounthistory"
	"github.com/theopenlane/core/internal/ent/generated/directorygroup"
	"github.com/theopenlane/core/internal/ent/generated/directorygrouphistory"
	"github.com/theopenlane/core/internal/ent/generated/directorymembership"
	"github.com/theopenlane/core/internal/ent/generated/directorymembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/directorysyncrun"
	"github.com/theopenlane/core/internal/ent/generated/dnsverification"
	"github.com/theopenlane/core/internal/ent/generated/dnsverificationhistory"
	"github.com/theopenlane/core/internal/ent/generated/documentdata"
	"github.com/theopenlane/core/internal/ent/generated/documentdatahistory"
	"github.com/theopenlane/core/internal/ent/generated/entity"
	"github.com/theopenlane/core/internal/ent/generated/entityhistory"
	"github.com/theopenlane/core/internal/ent/generated/entitytype"
	"github.com/theopenlane/core/internal/ent/generated/entitytypehistory"
	"github.com/theopenlane/core/internal/ent/generated/event"
	"github.com/theopenlane/core/internal/ent/generated/evidence"
	"github.com/theopenlane/core/internal/ent/generated/evidencehistory"
	"github.com/theopenlane/core/internal/ent/generated/export"
	"github.com/theopenlane/core/internal/ent/generated/file"
	"github.com/theopenlane/core/internal/ent/generated/filehistory"
	"github.com/theopenlane/core/internal/ent/generated/finding"
	"github.com/theopenlane/core/internal/ent/generated/findingcontrol"
	"github.com/theopenlane/core/internal/ent/generated/findingcontrolhistory"
	"github.com/theopenlane/core/internal/ent/generated/findinghistory"
	"github.com/theopenlane/core/internal/ent/generated/group"
	"github.com/theopenlane/core/internal/ent/generated/grouphistory"
	"github.com/theopenlane/core/internal/ent/generated/groupmembership"
	"github.com/theopenlane/core/internal/ent/generated/groupmembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/groupsetting"
	"github.com/theopenlane/core/internal/ent/generated/groupsettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/hush"
	"github.com/theopenlane/core/internal/ent/generated/hushhistory"
	"github.com/theopenlane/core/internal/ent/generated/integration"
	"github.com/theopenlane/core/internal/ent/generated/integrationhistory"
	"github.com/theopenlane/core/internal/ent/generated/internalpolicy"
	"github.com/theopenlane/core/internal/ent/generated/internalpolicyhistory"
	"github.com/theopenlane/core/internal/ent/generated/invite"
	"github.com/theopenlane/core/internal/ent/generated/jobresult"
	"github.com/theopenlane/core/internal/ent/generated/jobrunner"
	"github.com/theopenlane/core/internal/ent/generated/jobrunnerregistrationtoken"
	"github.com/theopenlane/core/internal/ent/generated/jobrunnertoken"
	"github.com/theopenlane/core/internal/ent/generated/jobtemplate"
	"github.com/theopenlane/core/internal/ent/generated/jobtemplatehistory"
	"github.com/theopenlane/core/internal/ent/generated/mappabledomain"
	"github.com/theopenlane/core/internal/ent/generated/mappabledomainhistory"
	"github.com/theopenlane/core/internal/ent/generated/mappedcontrol"
	"github.com/theopenlane/core/internal/ent/generated/mappedcontrolhistory"
	"github.com/theopenlane/core/internal/ent/generated/narrative"
	"github.com/theopenlane/core/internal/ent/generated/narrativehistory"
	"github.com/theopenlane/core/internal/ent/generated/note"
	"github.com/theopenlane/core/internal/ent/generated/notehistory"
	"github.com/theopenlane/core/internal/ent/generated/onboarding"
	"github.com/theopenlane/core/internal/ent/generated/organization"
	"github.com/theopenlane/core/internal/ent/generated/organizationhistory"
	"github.com/theopenlane/core/internal/ent/generated/organizationsetting"
	"github.com/theopenlane/core/internal/ent/generated/organizationsettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/orgmembership"
	"github.com/theopenlane/core/internal/ent/generated/orgmembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/orgsubscription"
	"github.com/theopenlane/core/internal/ent/generated/orgsubscriptionhistory"
	"github.com/theopenlane/core/internal/ent/generated/personalaccesstoken"
	"github.com/theopenlane/core/internal/ent/generated/procedure"
	"github.com/theopenlane/core/internal/ent/generated/procedurehistory"
	"github.com/theopenlane/core/internal/ent/generated/program"
	"github.com/theopenlane/core/internal/ent/generated/programhistory"
	"github.com/theopenlane/core/internal/ent/generated/programmembership"
	"github.com/theopenlane/core/internal/ent/generated/programmembershiphistory"
	"github.com/theopenlane/core/internal/ent/generated/remediation"
	"github.com/theopenlane/core/internal/ent/generated/remediationhistory"
	"github.com/theopenlane/core/internal/ent/generated/review"
	"github.com/theopenlane/core/internal/ent/generated/reviewhistory"
	"github.com/theopenlane/core/internal/ent/generated/risk"
	"github.com/theopenlane/core/internal/ent/generated/riskhistory"
	"github.com/theopenlane/core/internal/ent/generated/scan"
	"github.com/theopenlane/core/internal/ent/generated/scanhistory"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjob"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjobhistory"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjobrun"
	"github.com/theopenlane/core/internal/ent/generated/standard"
	"github.com/theopenlane/core/internal/ent/generated/standardhistory"
	"github.com/theopenlane/core/internal/ent/generated/subcontrol"
	"github.com/theopenlane/core/internal/ent/generated/subcontrolhistory"
	"github.com/theopenlane/core/internal/ent/generated/subprocessor"
	"github.com/theopenlane/core/internal/ent/generated/subprocessorhistory"
	"github.com/theopenlane/core/internal/ent/generated/subscriber"
	"github.com/theopenlane/core/internal/ent/generated/tagdefinition"
	"github.com/theopenlane/core/internal/ent/generated/task"
	"github.com/theopenlane/core/internal/ent/generated/taskhistory"
	"github.com/theopenlane/core/internal/ent/generated/template"
	"github.com/theopenlane/core/internal/ent/generated/templatehistory"
	"github.com/theopenlane/core/internal/ent/generated/tfasetting"
	"github.com/theopenlane/core/internal/ent/generated/trustcenter"
	"github.com/theopenlane/core/internal/ent/generated/trustcentercompliance"
	"github.com/theopenlane/core/internal/ent/generated/trustcentercompliancehistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterdoc"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterdochistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterentity"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterentityhistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterhistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersetting"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersubprocessor"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersubprocessorhistory"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterwatermarkconfig"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterwatermarkconfighistory"
	"github.com/theopenlane/core/internal/ent/generated/user"
	"github.com/theopenlane/core/internal/ent/generated/userhistory"
	"github.com/theopenlane/core/internal/ent/generated/usersetting"
	"github.com/theopenlane/core/internal/ent/generated/usersettinghistory"
	"github.com/theopenlane/core/internal/ent/generated/vulnerability"
	"github.com/theopenlane/core/internal/ent/generated/vulnerabilityhistory"
	"github.com/theopenlane/core/internal/ent/generated/webauthn"
	"github.com/theopenlane/core/internal/ent/generated/workflowassignment"
	"github.com/theopenlane/core/internal/ent/generated/workflowassignmenthistory"
	"github.com/theopenlane/core/internal/ent/generated/workflowassignmenttarget"
	"github.com/theopenlane/core/internal/ent/generated/workflowassignmenttargethistory"
	"github.com/theopenlane/core/internal/ent/generated/workflowdefinition"
	"github.com/theopenlane/core/internal/ent/generated/workflowdefinitionhistory"
	"github.com/theopenlane/core/internal/ent/generated/workflowevent"
	"github.com/theopenlane/core/internal/ent/generated/workfloweventhistory"
	"github.com/theopenlane/core/internal/ent/generated/workflowinstance"
	"github.com/theopenlane/core/internal/ent/generated/workflowinstancehistory"
	"github.com/theopenlane/core/internal/ent/generated/workflowobjectref"
	"github.com/theopenlane/core/internal/ent/generated/workflowobjectrefhistory"
)

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *APITokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*APITokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *APITokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(apitoken.Columns))
		selectedFields = []string{apitoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[apitoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldOwnerID)
				fieldSeen[apitoken.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[apitoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldCreatedAt)
				fieldSeen[apitoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[apitoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldUpdatedAt)
				fieldSeen[apitoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[apitoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldCreatedBy)
				fieldSeen[apitoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[apitoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldUpdatedBy)
				fieldSeen[apitoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[apitoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldTags)
				fieldSeen[apitoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[apitoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldOwnerID)
				fieldSeen[apitoken.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[apitoken.FieldName]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldName)
				fieldSeen[apitoken.FieldName] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[apitoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldToken)
				fieldSeen[apitoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[apitoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldExpiresAt)
				fieldSeen[apitoken.FieldExpiresAt] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[apitoken.FieldDescription]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldDescription)
				fieldSeen[apitoken.FieldDescription] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[apitoken.FieldScopes]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldScopes)
				fieldSeen[apitoken.FieldScopes] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[apitoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldLastUsedAt)
				fieldSeen[apitoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[apitoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldIsActive)
				fieldSeen[apitoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[apitoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedReason)
				fieldSeen[apitoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[apitoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedBy)
				fieldSeen[apitoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[apitoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedAt)
				fieldSeen[apitoken.FieldRevokedAt] = struct{}{}
			}
		case "ssoAuthorizations":
			if _, ok := fieldSeen[apitoken.FieldSSOAuthorizations]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldSSOAuthorizations)
				fieldSeen[apitoken.FieldSSOAuthorizations] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type apitokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []APITokenPaginateOption
}

func newAPITokenPaginateArgs(rv map[string]any) *apitokenPaginateArgs {
	args := &apitokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*APITokenOrder:
			args.opts = append(args.opts, WithAPITokenOrder(v))
		case []any:
			var orders []*APITokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &APITokenOrder{Field: &APITokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAPITokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*APITokenWhereInput); ok {
		args.opts = append(args.opts, WithAPITokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ActionPlanQuery) CollectFields(ctx context.Context, satisfies ...string) (*ActionPlanQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ActionPlanQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(actionplan.Columns))
		selectedFields = []string{actionplan.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withApprover = query
			if _, ok := fieldSeen[actionplan.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApproverID)
				fieldSeen[actionplan.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[actionplan.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDelegateID)
				fieldSeen[actionplan.FieldDelegateID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[actionplan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldOwnerID)
				fieldSeen[actionplan.FieldOwnerID] = struct{}{}
			}

		case "actionPlanKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withActionPlanKind = query
			if _, ok := fieldSeen[actionplan.FieldActionPlanKindID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanKindID)
				fieldSeen[actionplan.FieldActionPlanKindID] = struct{}{}
			}

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(actionplan.RisksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.RisksPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.RisksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.RisksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.RisksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(actionplan.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(actionplan.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.FindingsTable)
							s.Join(joinT).On(s.C(finding.FieldID), joinT.C(actionplan.FindingsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.FindingsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.FindingsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.FindingsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.FindingsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.VulnerabilitiesTable)
							s.Join(joinT).On(s.C(vulnerability.FieldID), joinT.C(actionplan.VulnerabilitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.VulnerabilitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.VulnerabilitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.VulnerabilitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.VulnerabilitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ReviewsTable)
							s.Join(joinT).On(s.C(review.FieldID), joinT.C(actionplan.ReviewsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ReviewsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ReviewsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ReviewsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ReviewsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.RemediationsTable)
							s.Join(joinT).On(s.C(remediation.FieldID), joinT.C(actionplan.RemediationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.RemediationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.RemediationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.RemediationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.RemediationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(actionplan.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(actionplan.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(actionplan.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(actionplan.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[actionplan.FieldFileID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldFileID)
				fieldSeen[actionplan.FieldFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[actionplan.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCreatedAt)
				fieldSeen[actionplan.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[actionplan.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldUpdatedAt)
				fieldSeen[actionplan.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[actionplan.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCreatedBy)
				fieldSeen[actionplan.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[actionplan.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldUpdatedBy)
				fieldSeen[actionplan.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[actionplan.FieldTags]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTags)
				fieldSeen[actionplan.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[actionplan.FieldRevision]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRevision)
				fieldSeen[actionplan.FieldRevision] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[actionplan.FieldName]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldName)
				fieldSeen[actionplan.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[actionplan.FieldStatus]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldStatus)
				fieldSeen[actionplan.FieldStatus] = struct{}{}
			}
		case "actionPlanType":
			if _, ok := fieldSeen[actionplan.FieldActionPlanType]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanType)
				fieldSeen[actionplan.FieldActionPlanType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[actionplan.FieldDetails]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDetails)
				fieldSeen[actionplan.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[actionplan.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApprovalRequired)
				fieldSeen[actionplan.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[actionplan.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldReviewDue)
				fieldSeen[actionplan.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[actionplan.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldReviewFrequency)
				fieldSeen[actionplan.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[actionplan.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApproverID)
				fieldSeen[actionplan.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[actionplan.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDelegateID)
				fieldSeen[actionplan.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[actionplan.FieldSummary]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSummary)
				fieldSeen[actionplan.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[actionplan.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTagSuggestions)
				fieldSeen[actionplan.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedTagSuggestions)
				fieldSeen[actionplan.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[actionplan.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldControlSuggestions)
				fieldSeen[actionplan.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedControlSuggestions)
				fieldSeen[actionplan.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[actionplan.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldImprovementSuggestions)
				fieldSeen[actionplan.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedImprovementSuggestions)
				fieldSeen[actionplan.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[actionplan.FieldURL]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldURL)
				fieldSeen[actionplan.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[actionplan.FieldFileID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldFileID)
				fieldSeen[actionplan.FieldFileID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[actionplan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldOwnerID)
				fieldSeen[actionplan.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[actionplan.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSystemOwned)
				fieldSeen[actionplan.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[actionplan.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldInternalNotes)
				fieldSeen[actionplan.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[actionplan.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSystemInternalID)
				fieldSeen[actionplan.FieldSystemInternalID] = struct{}{}
			}
		case "actionPlanKindName":
			if _, ok := fieldSeen[actionplan.FieldActionPlanKindName]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanKindName)
				fieldSeen[actionplan.FieldActionPlanKindName] = struct{}{}
			}
		case "actionPlanKindID":
			if _, ok := fieldSeen[actionplan.FieldActionPlanKindID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanKindID)
				fieldSeen[actionplan.FieldActionPlanKindID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[actionplan.FieldTitle]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTitle)
				fieldSeen[actionplan.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[actionplan.FieldDescription]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDescription)
				fieldSeen[actionplan.FieldDescription] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[actionplan.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDueDate)
				fieldSeen[actionplan.FieldDueDate] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[actionplan.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCompletedAt)
				fieldSeen[actionplan.FieldCompletedAt] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[actionplan.FieldPriority]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldPriority)
				fieldSeen[actionplan.FieldPriority] = struct{}{}
			}
		case "requiresApproval":
			if _, ok := fieldSeen[actionplan.FieldRequiresApproval]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRequiresApproval)
				fieldSeen[actionplan.FieldRequiresApproval] = struct{}{}
			}
		case "blocked":
			if _, ok := fieldSeen[actionplan.FieldBlocked]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldBlocked)
				fieldSeen[actionplan.FieldBlocked] = struct{}{}
			}
		case "blockerReason":
			if _, ok := fieldSeen[actionplan.FieldBlockerReason]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldBlockerReason)
				fieldSeen[actionplan.FieldBlockerReason] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[actionplan.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldMetadata)
				fieldSeen[actionplan.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[actionplan.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRawPayload)
				fieldSeen[actionplan.FieldRawPayload] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[actionplan.FieldSource]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSource)
				fieldSeen[actionplan.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type actionplanPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ActionPlanPaginateOption
}

func newActionPlanPaginateArgs(rv map[string]any) *actionplanPaginateArgs {
	args := &actionplanPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ActionPlanOrder:
			args.opts = append(args.opts, WithActionPlanOrder(v))
		case []any:
			var orders []*ActionPlanOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ActionPlanOrder{Field: &ActionPlanOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithActionPlanOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ActionPlanWhereInput); ok {
		args.opts = append(args.opts, WithActionPlanFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ActionPlanHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ActionPlanHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ActionPlanHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(actionplanhistory.Columns))
		selectedFields = []string{actionplanhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[actionplanhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldHistoryTime)
				fieldSeen[actionplanhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[actionplanhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldRef)
				fieldSeen[actionplanhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[actionplanhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldOperation)
				fieldSeen[actionplanhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[actionplanhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldCreatedAt)
				fieldSeen[actionplanhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[actionplanhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldUpdatedAt)
				fieldSeen[actionplanhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[actionplanhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldCreatedBy)
				fieldSeen[actionplanhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[actionplanhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldUpdatedBy)
				fieldSeen[actionplanhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[actionplanhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldTags)
				fieldSeen[actionplanhistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[actionplanhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldRevision)
				fieldSeen[actionplanhistory.FieldRevision] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[actionplanhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldName)
				fieldSeen[actionplanhistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[actionplanhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldStatus)
				fieldSeen[actionplanhistory.FieldStatus] = struct{}{}
			}
		case "actionPlanType":
			if _, ok := fieldSeen[actionplanhistory.FieldActionPlanType]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldActionPlanType)
				fieldSeen[actionplanhistory.FieldActionPlanType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[actionplanhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDetails)
				fieldSeen[actionplanhistory.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[actionplanhistory.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldApprovalRequired)
				fieldSeen[actionplanhistory.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[actionplanhistory.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldReviewDue)
				fieldSeen[actionplanhistory.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[actionplanhistory.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldReviewFrequency)
				fieldSeen[actionplanhistory.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[actionplanhistory.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldApproverID)
				fieldSeen[actionplanhistory.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[actionplanhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDelegateID)
				fieldSeen[actionplanhistory.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[actionplanhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldSummary)
				fieldSeen[actionplanhistory.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldTagSuggestions)
				fieldSeen[actionplanhistory.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDismissedTagSuggestions)
				fieldSeen[actionplanhistory.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldControlSuggestions)
				fieldSeen[actionplanhistory.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDismissedControlSuggestions)
				fieldSeen[actionplanhistory.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldImprovementSuggestions)
				fieldSeen[actionplanhistory.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[actionplanhistory.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDismissedImprovementSuggestions)
				fieldSeen[actionplanhistory.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[actionplanhistory.FieldURL]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldURL)
				fieldSeen[actionplanhistory.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[actionplanhistory.FieldFileID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldFileID)
				fieldSeen[actionplanhistory.FieldFileID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[actionplanhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldOwnerID)
				fieldSeen[actionplanhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[actionplanhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldSystemOwned)
				fieldSeen[actionplanhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[actionplanhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldInternalNotes)
				fieldSeen[actionplanhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[actionplanhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldSystemInternalID)
				fieldSeen[actionplanhistory.FieldSystemInternalID] = struct{}{}
			}
		case "actionPlanKindName":
			if _, ok := fieldSeen[actionplanhistory.FieldActionPlanKindName]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldActionPlanKindName)
				fieldSeen[actionplanhistory.FieldActionPlanKindName] = struct{}{}
			}
		case "actionPlanKindID":
			if _, ok := fieldSeen[actionplanhistory.FieldActionPlanKindID]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldActionPlanKindID)
				fieldSeen[actionplanhistory.FieldActionPlanKindID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[actionplanhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldTitle)
				fieldSeen[actionplanhistory.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[actionplanhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDescription)
				fieldSeen[actionplanhistory.FieldDescription] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[actionplanhistory.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldDueDate)
				fieldSeen[actionplanhistory.FieldDueDate] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[actionplanhistory.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldCompletedAt)
				fieldSeen[actionplanhistory.FieldCompletedAt] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[actionplanhistory.FieldPriority]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldPriority)
				fieldSeen[actionplanhistory.FieldPriority] = struct{}{}
			}
		case "requiresApproval":
			if _, ok := fieldSeen[actionplanhistory.FieldRequiresApproval]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldRequiresApproval)
				fieldSeen[actionplanhistory.FieldRequiresApproval] = struct{}{}
			}
		case "blocked":
			if _, ok := fieldSeen[actionplanhistory.FieldBlocked]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldBlocked)
				fieldSeen[actionplanhistory.FieldBlocked] = struct{}{}
			}
		case "blockerReason":
			if _, ok := fieldSeen[actionplanhistory.FieldBlockerReason]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldBlockerReason)
				fieldSeen[actionplanhistory.FieldBlockerReason] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[actionplanhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldMetadata)
				fieldSeen[actionplanhistory.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[actionplanhistory.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldRawPayload)
				fieldSeen[actionplanhistory.FieldRawPayload] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[actionplanhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, actionplanhistory.FieldSource)
				fieldSeen[actionplanhistory.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type actionplanhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ActionPlanHistoryPaginateOption
}

func newActionPlanHistoryPaginateArgs(rv map[string]any) *actionplanhistoryPaginateArgs {
	args := &actionplanhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ActionPlanHistoryOrder{Field: &ActionPlanHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithActionPlanHistoryOrder(order))
			}
		case *ActionPlanHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithActionPlanHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ActionPlanHistoryWhereInput); ok {
		args.opts = append(args.opts, WithActionPlanHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssessmentQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssessmentQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssessmentQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assessment.Columns))
		selectedFields = []string{assessment.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[assessment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldOwnerID)
				fieldSeen[assessment.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(assessment.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.EditorsColumn), ids...))
						})
						if err := query.GroupBy(assessment.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.ViewersColumn), ids...))
						})
						if err := query.GroupBy(assessment.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			_q.withTemplate = query
			if _, ok := fieldSeen[assessment.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldTemplateID)
				fieldSeen[assessment.FieldTemplateID] = struct{}{}
			}

		case "assessmentResponses":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentResponseClient{config: _q.config}).Query()
			)
			args := newAssessmentResponsePaginateArgs(fieldArgs(ctx, new(AssessmentResponseWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentResponsePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.AssessmentResponsesColumn), ids...))
						})
						if err := query.GroupBy(assessment.AssessmentResponsesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssessmentResponses)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentresponseImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.AssessmentResponsesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessmentResponses(alias, func(wq *AssessmentResponseQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[assessment.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assessment.FieldCreatedAt)
				fieldSeen[assessment.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assessment.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assessment.FieldUpdatedAt)
				fieldSeen[assessment.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assessment.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assessment.FieldCreatedBy)
				fieldSeen[assessment.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assessment.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assessment.FieldUpdatedBy)
				fieldSeen[assessment.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[assessment.FieldTags]; !ok {
				selectedFields = append(selectedFields, assessment.FieldTags)
				fieldSeen[assessment.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assessment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldOwnerID)
				fieldSeen[assessment.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[assessment.FieldName]; !ok {
				selectedFields = append(selectedFields, assessment.FieldName)
				fieldSeen[assessment.FieldName] = struct{}{}
			}
		case "assessmentType":
			if _, ok := fieldSeen[assessment.FieldAssessmentType]; !ok {
				selectedFields = append(selectedFields, assessment.FieldAssessmentType)
				fieldSeen[assessment.FieldAssessmentType] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[assessment.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldTemplateID)
				fieldSeen[assessment.FieldTemplateID] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[assessment.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, assessment.FieldJsonconfig)
				fieldSeen[assessment.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[assessment.FieldUischema]; !ok {
				selectedFields = append(selectedFields, assessment.FieldUischema)
				fieldSeen[assessment.FieldUischema] = struct{}{}
			}
		case "responseDueDuration":
			if _, ok := fieldSeen[assessment.FieldResponseDueDuration]; !ok {
				selectedFields = append(selectedFields, assessment.FieldResponseDueDuration)
				fieldSeen[assessment.FieldResponseDueDuration] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assessmentPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssessmentPaginateOption
}

func newAssessmentPaginateArgs(rv map[string]any) *assessmentPaginateArgs {
	args := &assessmentPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssessmentOrder:
			args.opts = append(args.opts, WithAssessmentOrder(v))
		case []any:
			var orders []*AssessmentOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssessmentOrder{Field: &AssessmentOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssessmentOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssessmentWhereInput); ok {
		args.opts = append(args.opts, WithAssessmentFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssessmentHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssessmentHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssessmentHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assessmenthistory.Columns))
		selectedFields = []string{assessmenthistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[assessmenthistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldHistoryTime)
				fieldSeen[assessmenthistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[assessmenthistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldRef)
				fieldSeen[assessmenthistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[assessmenthistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldOperation)
				fieldSeen[assessmenthistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[assessmenthistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldCreatedAt)
				fieldSeen[assessmenthistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assessmenthistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldUpdatedAt)
				fieldSeen[assessmenthistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assessmenthistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldCreatedBy)
				fieldSeen[assessmenthistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assessmenthistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldUpdatedBy)
				fieldSeen[assessmenthistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[assessmenthistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldTags)
				fieldSeen[assessmenthistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assessmenthistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldOwnerID)
				fieldSeen[assessmenthistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[assessmenthistory.FieldName]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldName)
				fieldSeen[assessmenthistory.FieldName] = struct{}{}
			}
		case "assessmentType":
			if _, ok := fieldSeen[assessmenthistory.FieldAssessmentType]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldAssessmentType)
				fieldSeen[assessmenthistory.FieldAssessmentType] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[assessmenthistory.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldTemplateID)
				fieldSeen[assessmenthistory.FieldTemplateID] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[assessmenthistory.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldJsonconfig)
				fieldSeen[assessmenthistory.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[assessmenthistory.FieldUischema]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldUischema)
				fieldSeen[assessmenthistory.FieldUischema] = struct{}{}
			}
		case "responseDueDuration":
			if _, ok := fieldSeen[assessmenthistory.FieldResponseDueDuration]; !ok {
				selectedFields = append(selectedFields, assessmenthistory.FieldResponseDueDuration)
				fieldSeen[assessmenthistory.FieldResponseDueDuration] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assessmenthistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssessmentHistoryPaginateOption
}

func newAssessmentHistoryPaginateArgs(rv map[string]any) *assessmenthistoryPaginateArgs {
	args := &assessmenthistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &AssessmentHistoryOrder{Field: &AssessmentHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithAssessmentHistoryOrder(order))
			}
		case *AssessmentHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithAssessmentHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*AssessmentHistoryWhereInput); ok {
		args.opts = append(args.opts, WithAssessmentHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssessmentResponseQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssessmentResponseQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssessmentResponseQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assessmentresponse.Columns))
		selectedFields = []string{assessmentresponse.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[assessmentresponse.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldOwnerID)
				fieldSeen[assessmentresponse.FieldOwnerID] = struct{}{}
			}

		case "assessment":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, assessmentImplementors)...); err != nil {
				return err
			}
			_q.withAssessment = query
			if _, ok := fieldSeen[assessmentresponse.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldAssessmentID)
				fieldSeen[assessmentresponse.FieldAssessmentID] = struct{}{}
			}

		case "document":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
				return err
			}
			_q.withDocument = query
			if _, ok := fieldSeen[assessmentresponse.FieldDocumentDataID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldDocumentDataID)
				fieldSeen[assessmentresponse.FieldDocumentDataID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[assessmentresponse.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldCreatedAt)
				fieldSeen[assessmentresponse.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldUpdatedAt)
				fieldSeen[assessmentresponse.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assessmentresponse.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldCreatedBy)
				fieldSeen[assessmentresponse.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assessmentresponse.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldUpdatedBy)
				fieldSeen[assessmentresponse.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assessmentresponse.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldOwnerID)
				fieldSeen[assessmentresponse.FieldOwnerID] = struct{}{}
			}
		case "assessmentID":
			if _, ok := fieldSeen[assessmentresponse.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldAssessmentID)
				fieldSeen[assessmentresponse.FieldAssessmentID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[assessmentresponse.FieldEmail]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldEmail)
				fieldSeen[assessmentresponse.FieldEmail] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[assessmentresponse.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldSendAttempts)
				fieldSeen[assessmentresponse.FieldSendAttempts] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[assessmentresponse.FieldStatus]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldStatus)
				fieldSeen[assessmentresponse.FieldStatus] = struct{}{}
			}
		case "assignedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldAssignedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldAssignedAt)
				fieldSeen[assessmentresponse.FieldAssignedAt] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldStartedAt)
				fieldSeen[assessmentresponse.FieldStartedAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldCompletedAt)
				fieldSeen[assessmentresponse.FieldCompletedAt] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[assessmentresponse.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldDueDate)
				fieldSeen[assessmentresponse.FieldDueDate] = struct{}{}
			}
		case "documentDataID":
			if _, ok := fieldSeen[assessmentresponse.FieldDocumentDataID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldDocumentDataID)
				fieldSeen[assessmentresponse.FieldDocumentDataID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assessmentresponsePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssessmentResponsePaginateOption
}

func newAssessmentResponsePaginateArgs(rv map[string]any) *assessmentresponsePaginateArgs {
	args := &assessmentresponsePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssessmentResponseOrder:
			args.opts = append(args.opts, WithAssessmentResponseOrder(v))
		case []any:
			var orders []*AssessmentResponseOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssessmentResponseOrder{Field: &AssessmentResponseOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssessmentResponseOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssessmentResponseWhereInput); ok {
		args.opts = append(args.opts, WithAssessmentResponseFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssessmentResponseHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssessmentResponseHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssessmentResponseHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assessmentresponsehistory.Columns))
		selectedFields = []string{assessmentresponsehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldHistoryTime)
				fieldSeen[assessmentresponsehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldRef)
				fieldSeen[assessmentresponsehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldOperation)
				fieldSeen[assessmentresponsehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldCreatedAt)
				fieldSeen[assessmentresponsehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldUpdatedAt)
				fieldSeen[assessmentresponsehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldCreatedBy)
				fieldSeen[assessmentresponsehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldUpdatedBy)
				fieldSeen[assessmentresponsehistory.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldOwnerID)
				fieldSeen[assessmentresponsehistory.FieldOwnerID] = struct{}{}
			}
		case "assessmentID":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldAssessmentID)
				fieldSeen[assessmentresponsehistory.FieldAssessmentID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldEmail]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldEmail)
				fieldSeen[assessmentresponsehistory.FieldEmail] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldSendAttempts)
				fieldSeen[assessmentresponsehistory.FieldSendAttempts] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldStatus)
				fieldSeen[assessmentresponsehistory.FieldStatus] = struct{}{}
			}
		case "assignedAt":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldAssignedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldAssignedAt)
				fieldSeen[assessmentresponsehistory.FieldAssignedAt] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldStartedAt)
				fieldSeen[assessmentresponsehistory.FieldStartedAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldCompletedAt)
				fieldSeen[assessmentresponsehistory.FieldCompletedAt] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldDueDate)
				fieldSeen[assessmentresponsehistory.FieldDueDate] = struct{}{}
			}
		case "documentDataID":
			if _, ok := fieldSeen[assessmentresponsehistory.FieldDocumentDataID]; !ok {
				selectedFields = append(selectedFields, assessmentresponsehistory.FieldDocumentDataID)
				fieldSeen[assessmentresponsehistory.FieldDocumentDataID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assessmentresponsehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssessmentResponseHistoryPaginateOption
}

func newAssessmentResponseHistoryPaginateArgs(rv map[string]any) *assessmentresponsehistoryPaginateArgs {
	args := &assessmentresponsehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &AssessmentResponseHistoryOrder{Field: &AssessmentResponseHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithAssessmentResponseHistoryOrder(order))
			}
		case *AssessmentResponseHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithAssessmentResponseHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*AssessmentResponseHistoryWhereInput); ok {
		args.opts = append(args.opts, WithAssessmentResponseHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssetQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssetQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssetQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(asset.Columns))
		selectedFields = []string{asset.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[asset.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, asset.FieldOwnerID)
				fieldSeen[asset.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(asset.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.EditorsColumn), ids...))
						})
						if err := query.GroupBy(asset.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.ViewersColumn), ids...))
						})
						if err := query.GroupBy(asset.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.ScansTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(asset.ScansPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.ScansPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.ScansPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.ScansPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ScansPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(asset.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(asset.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[asset.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, asset.FieldCreatedAt)
				fieldSeen[asset.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[asset.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, asset.FieldUpdatedAt)
				fieldSeen[asset.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[asset.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, asset.FieldCreatedBy)
				fieldSeen[asset.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[asset.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, asset.FieldUpdatedBy)
				fieldSeen[asset.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[asset.FieldTags]; !ok {
				selectedFields = append(selectedFields, asset.FieldTags)
				fieldSeen[asset.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[asset.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, asset.FieldOwnerID)
				fieldSeen[asset.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[asset.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, asset.FieldSystemOwned)
				fieldSeen[asset.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[asset.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, asset.FieldInternalNotes)
				fieldSeen[asset.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[asset.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, asset.FieldSystemInternalID)
				fieldSeen[asset.FieldSystemInternalID] = struct{}{}
			}
		case "assetType":
			if _, ok := fieldSeen[asset.FieldAssetType]; !ok {
				selectedFields = append(selectedFields, asset.FieldAssetType)
				fieldSeen[asset.FieldAssetType] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[asset.FieldName]; !ok {
				selectedFields = append(selectedFields, asset.FieldName)
				fieldSeen[asset.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[asset.FieldDescription]; !ok {
				selectedFields = append(selectedFields, asset.FieldDescription)
				fieldSeen[asset.FieldDescription] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[asset.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, asset.FieldIdentifier)
				fieldSeen[asset.FieldIdentifier] = struct{}{}
			}
		case "website":
			if _, ok := fieldSeen[asset.FieldWebsite]; !ok {
				selectedFields = append(selectedFields, asset.FieldWebsite)
				fieldSeen[asset.FieldWebsite] = struct{}{}
			}
		case "cpe":
			if _, ok := fieldSeen[asset.FieldCpe]; !ok {
				selectedFields = append(selectedFields, asset.FieldCpe)
				fieldSeen[asset.FieldCpe] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[asset.FieldCategories]; !ok {
				selectedFields = append(selectedFields, asset.FieldCategories)
				fieldSeen[asset.FieldCategories] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assetPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssetPaginateOption
}

func newAssetPaginateArgs(rv map[string]any) *assetPaginateArgs {
	args := &assetPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssetOrder:
			args.opts = append(args.opts, WithAssetOrder(v))
		case []any:
			var orders []*AssetOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssetOrder{Field: &AssetOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssetOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssetWhereInput); ok {
		args.opts = append(args.opts, WithAssetFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssetHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssetHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssetHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assethistory.Columns))
		selectedFields = []string{assethistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[assethistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldHistoryTime)
				fieldSeen[assethistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[assethistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldRef)
				fieldSeen[assethistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[assethistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldOperation)
				fieldSeen[assethistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[assethistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCreatedAt)
				fieldSeen[assethistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assethistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldUpdatedAt)
				fieldSeen[assethistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assethistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCreatedBy)
				fieldSeen[assethistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assethistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldUpdatedBy)
				fieldSeen[assethistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[assethistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldTags)
				fieldSeen[assethistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assethistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldOwnerID)
				fieldSeen[assethistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[assethistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldSystemOwned)
				fieldSeen[assethistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[assethistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldInternalNotes)
				fieldSeen[assethistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[assethistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldSystemInternalID)
				fieldSeen[assethistory.FieldSystemInternalID] = struct{}{}
			}
		case "assetType":
			if _, ok := fieldSeen[assethistory.FieldAssetType]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldAssetType)
				fieldSeen[assethistory.FieldAssetType] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[assethistory.FieldName]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldName)
				fieldSeen[assethistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[assethistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldDescription)
				fieldSeen[assethistory.FieldDescription] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[assethistory.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldIdentifier)
				fieldSeen[assethistory.FieldIdentifier] = struct{}{}
			}
		case "website":
			if _, ok := fieldSeen[assethistory.FieldWebsite]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldWebsite)
				fieldSeen[assethistory.FieldWebsite] = struct{}{}
			}
		case "cpe":
			if _, ok := fieldSeen[assethistory.FieldCpe]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCpe)
				fieldSeen[assethistory.FieldCpe] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[assethistory.FieldCategories]; !ok {
				selectedFields = append(selectedFields, assethistory.FieldCategories)
				fieldSeen[assethistory.FieldCategories] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assethistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssetHistoryPaginateOption
}

func newAssetHistoryPaginateArgs(rv map[string]any) *assethistoryPaginateArgs {
	args := &assethistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &AssetHistoryOrder{Field: &AssetHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithAssetHistoryOrder(order))
			}
		case *AssetHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithAssetHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*AssetHistoryWhereInput); ok {
		args.opts = append(args.opts, WithAssetHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ContactQuery) CollectFields(ctx context.Context, satisfies ...string) (*ContactQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ContactQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(contact.Columns))
		selectedFields = []string{contact.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[contact.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contact.FieldOwnerID)
				fieldSeen[contact.FieldOwnerID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Contact) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"contact_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(contact.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(contact.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(contact.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(contact.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(contact.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Contact) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(contact.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Contact) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"contact_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(contact.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(contact.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(contact.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(contact.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(contact.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Contact) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(contact.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[contact.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, contact.FieldCreatedAt)
				fieldSeen[contact.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[contact.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, contact.FieldUpdatedAt)
				fieldSeen[contact.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[contact.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, contact.FieldCreatedBy)
				fieldSeen[contact.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[contact.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, contact.FieldUpdatedBy)
				fieldSeen[contact.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[contact.FieldTags]; !ok {
				selectedFields = append(selectedFields, contact.FieldTags)
				fieldSeen[contact.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[contact.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contact.FieldOwnerID)
				fieldSeen[contact.FieldOwnerID] = struct{}{}
			}
		case "fullName":
			if _, ok := fieldSeen[contact.FieldFullName]; !ok {
				selectedFields = append(selectedFields, contact.FieldFullName)
				fieldSeen[contact.FieldFullName] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[contact.FieldTitle]; !ok {
				selectedFields = append(selectedFields, contact.FieldTitle)
				fieldSeen[contact.FieldTitle] = struct{}{}
			}
		case "company":
			if _, ok := fieldSeen[contact.FieldCompany]; !ok {
				selectedFields = append(selectedFields, contact.FieldCompany)
				fieldSeen[contact.FieldCompany] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[contact.FieldEmail]; !ok {
				selectedFields = append(selectedFields, contact.FieldEmail)
				fieldSeen[contact.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[contact.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, contact.FieldPhoneNumber)
				fieldSeen[contact.FieldPhoneNumber] = struct{}{}
			}
		case "address":
			if _, ok := fieldSeen[contact.FieldAddress]; !ok {
				selectedFields = append(selectedFields, contact.FieldAddress)
				fieldSeen[contact.FieldAddress] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[contact.FieldStatus]; !ok {
				selectedFields = append(selectedFields, contact.FieldStatus)
				fieldSeen[contact.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type contactPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ContactPaginateOption
}

func newContactPaginateArgs(rv map[string]any) *contactPaginateArgs {
	args := &contactPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ContactOrder:
			args.opts = append(args.opts, WithContactOrder(v))
		case []any:
			var orders []*ContactOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ContactOrder{Field: &ContactOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithContactOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ContactWhereInput); ok {
		args.opts = append(args.opts, WithContactFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ContactHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ContactHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ContactHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(contacthistory.Columns))
		selectedFields = []string{contacthistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[contacthistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldHistoryTime)
				fieldSeen[contacthistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[contacthistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldRef)
				fieldSeen[contacthistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[contacthistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldOperation)
				fieldSeen[contacthistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[contacthistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldCreatedAt)
				fieldSeen[contacthistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[contacthistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldUpdatedAt)
				fieldSeen[contacthistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[contacthistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldCreatedBy)
				fieldSeen[contacthistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[contacthistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldUpdatedBy)
				fieldSeen[contacthistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[contacthistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldTags)
				fieldSeen[contacthistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[contacthistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldOwnerID)
				fieldSeen[contacthistory.FieldOwnerID] = struct{}{}
			}
		case "fullName":
			if _, ok := fieldSeen[contacthistory.FieldFullName]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldFullName)
				fieldSeen[contacthistory.FieldFullName] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[contacthistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldTitle)
				fieldSeen[contacthistory.FieldTitle] = struct{}{}
			}
		case "company":
			if _, ok := fieldSeen[contacthistory.FieldCompany]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldCompany)
				fieldSeen[contacthistory.FieldCompany] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[contacthistory.FieldEmail]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldEmail)
				fieldSeen[contacthistory.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[contacthistory.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldPhoneNumber)
				fieldSeen[contacthistory.FieldPhoneNumber] = struct{}{}
			}
		case "address":
			if _, ok := fieldSeen[contacthistory.FieldAddress]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldAddress)
				fieldSeen[contacthistory.FieldAddress] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[contacthistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, contacthistory.FieldStatus)
				fieldSeen[contacthistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type contacthistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ContactHistoryPaginateOption
}

func newContactHistoryPaginateArgs(rv map[string]any) *contacthistoryPaginateArgs {
	args := &contacthistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ContactHistoryOrder{Field: &ContactHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithContactHistoryOrder(order))
			}
		case *ContactHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithContactHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ContactHistoryWhereInput); ok {
		args.opts = append(args.opts, WithContactHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(control.Columns))
		selectedFields = []string{control.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(control.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(control.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(control.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(control.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(control.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(control.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(control.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(control.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(control.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.CommentsColumn), ids...))
						})
						if err := query.GroupBy(control.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "controlOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withControlOwner = query
			if _, ok := fieldSeen[control.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlOwnerID)
				fieldSeen[control.FieldControlOwnerID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[control.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, control.FieldDelegateID)
				fieldSeen[control.FieldDelegateID] = struct{}{}
			}

		case "responsibleParty":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			_q.withResponsibleParty = query
			if _, ok := fieldSeen[control.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, control.FieldResponsiblePartyID)
				fieldSeen[control.FieldResponsiblePartyID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[control.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldOwnerID)
				fieldSeen[control.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(control.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(control.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withControlKind = query
			if _, ok := fieldSeen[control.FieldControlKindID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlKindID)
				fieldSeen[control.FieldControlKindID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[control.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, control.FieldStandardID)
				fieldSeen[control.FieldStandardID] = struct{}{}
			}

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(control.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(control.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.ScansColumn), ids...))
						})
						if err := query.GroupBy(control.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.FindingsTable)
							s.Join(joinT).On(s.C(finding.FieldID), joinT.C(control.FindingsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.FindingsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.FindingsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.FindingsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.FindingsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(control.ControlImplementationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ControlImplementationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ControlImplementationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ControlImplementationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlImplementationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(control.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ScheduledJobsTable)
							s.Join(joinT).On(s.C(scheduledjob.FieldID), joinT.C(control.ScheduledJobsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.ScheduledJobsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.ScheduledJobsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ScheduledJobsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ScheduledJobsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(control.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "controlMappings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingControlClient{config: _q.config}).Query()
			)
			args := newFindingControlPaginateArgs(fieldArgs(ctx, new(FindingControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.ControlMappingsColumn), ids...))
						})
						if err := query.GroupBy(control.ControlMappingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlMappings)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlMappingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlMappings(alias, func(wq *FindingControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[control.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, control.FieldCreatedAt)
				fieldSeen[control.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[control.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, control.FieldUpdatedAt)
				fieldSeen[control.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[control.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, control.FieldCreatedBy)
				fieldSeen[control.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[control.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, control.FieldUpdatedBy)
				fieldSeen[control.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[control.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, control.FieldDisplayID)
				fieldSeen[control.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[control.FieldTags]; !ok {
				selectedFields = append(selectedFields, control.FieldTags)
				fieldSeen[control.FieldTags] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[control.FieldTitle]; !ok {
				selectedFields = append(selectedFields, control.FieldTitle)
				fieldSeen[control.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[control.FieldDescription]; !ok {
				selectedFields = append(selectedFields, control.FieldDescription)
				fieldSeen[control.FieldDescription] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[control.FieldAliases]; !ok {
				selectedFields = append(selectedFields, control.FieldAliases)
				fieldSeen[control.FieldAliases] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[control.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceID)
				fieldSeen[control.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[control.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, control.FieldAuditorReferenceID)
				fieldSeen[control.FieldAuditorReferenceID] = struct{}{}
			}
		case "responsiblePartyID":
			if _, ok := fieldSeen[control.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, control.FieldResponsiblePartyID)
				fieldSeen[control.FieldResponsiblePartyID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[control.FieldStatus]; !ok {
				selectedFields = append(selectedFields, control.FieldStatus)
				fieldSeen[control.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[control.FieldSource]; !ok {
				selectedFields = append(selectedFields, control.FieldSource)
				fieldSeen[control.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[control.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceFramework)
				fieldSeen[control.FieldReferenceFramework] = struct{}{}
			}
		case "referenceFrameworkRevision":
			if _, ok := fieldSeen[control.FieldReferenceFrameworkRevision]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceFrameworkRevision)
				fieldSeen[control.FieldReferenceFrameworkRevision] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[control.FieldControlType]; !ok {
				selectedFields = append(selectedFields, control.FieldControlType)
				fieldSeen[control.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[control.FieldCategory]; !ok {
				selectedFields = append(selectedFields, control.FieldCategory)
				fieldSeen[control.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[control.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, control.FieldCategoryID)
				fieldSeen[control.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[control.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, control.FieldSubcategory)
				fieldSeen[control.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[control.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, control.FieldMappedCategories)
				fieldSeen[control.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[control.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, control.FieldAssessmentObjectives)
				fieldSeen[control.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[control.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, control.FieldAssessmentMethods)
				fieldSeen[control.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[control.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, control.FieldControlQuestions)
				fieldSeen[control.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[control.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, control.FieldImplementationGuidance)
				fieldSeen[control.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[control.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, control.FieldExampleEvidence)
				fieldSeen[control.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[control.FieldReferences]; !ok {
				selectedFields = append(selectedFields, control.FieldReferences)
				fieldSeen[control.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[control.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlOwnerID)
				fieldSeen[control.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[control.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, control.FieldDelegateID)
				fieldSeen[control.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[control.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldOwnerID)
				fieldSeen[control.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[control.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, control.FieldSystemOwned)
				fieldSeen[control.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[control.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, control.FieldInternalNotes)
				fieldSeen[control.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[control.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, control.FieldSystemInternalID)
				fieldSeen[control.FieldSystemInternalID] = struct{}{}
			}
		case "controlKindName":
			if _, ok := fieldSeen[control.FieldControlKindName]; !ok {
				selectedFields = append(selectedFields, control.FieldControlKindName)
				fieldSeen[control.FieldControlKindName] = struct{}{}
			}
		case "controlKindID":
			if _, ok := fieldSeen[control.FieldControlKindID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlKindID)
				fieldSeen[control.FieldControlKindID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[control.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, control.FieldRefCode)
				fieldSeen[control.FieldRefCode] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[control.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, control.FieldStandardID)
				fieldSeen[control.FieldStandardID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlPaginateOption
}

func newControlPaginateArgs(rv map[string]any) *controlPaginateArgs {
	args := &controlPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlOrder:
			args.opts = append(args.opts, WithControlOrder(v))
		case []any:
			var orders []*ControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlOrder{Field: &ControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlWhereInput); ok {
		args.opts = append(args.opts, WithControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlhistory.Columns))
		selectedFields = []string{controlhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldHistoryTime)
				fieldSeen[controlhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldRef)
				fieldSeen[controlhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldOperation)
				fieldSeen[controlhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCreatedAt)
				fieldSeen[controlhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldUpdatedAt)
				fieldSeen[controlhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCreatedBy)
				fieldSeen[controlhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldUpdatedBy)
				fieldSeen[controlhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldDisplayID)
				fieldSeen[controlhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldTags)
				fieldSeen[controlhistory.FieldTags] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[controlhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldTitle)
				fieldSeen[controlhistory.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[controlhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldDescription)
				fieldSeen[controlhistory.FieldDescription] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[controlhistory.FieldAliases]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAliases)
				fieldSeen[controlhistory.FieldAliases] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[controlhistory.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferenceID)
				fieldSeen[controlhistory.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[controlhistory.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAuditorReferenceID)
				fieldSeen[controlhistory.FieldAuditorReferenceID] = struct{}{}
			}
		case "responsiblePartyID":
			if _, ok := fieldSeen[controlhistory.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldResponsiblePartyID)
				fieldSeen[controlhistory.FieldResponsiblePartyID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldStatus)
				fieldSeen[controlhistory.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldSource)
				fieldSeen[controlhistory.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[controlhistory.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferenceFramework)
				fieldSeen[controlhistory.FieldReferenceFramework] = struct{}{}
			}
		case "referenceFrameworkRevision":
			if _, ok := fieldSeen[controlhistory.FieldReferenceFrameworkRevision]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferenceFrameworkRevision)
				fieldSeen[controlhistory.FieldReferenceFrameworkRevision] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[controlhistory.FieldControlType]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlType)
				fieldSeen[controlhistory.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCategory)
				fieldSeen[controlhistory.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[controlhistory.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldCategoryID)
				fieldSeen[controlhistory.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlhistory.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldSubcategory)
				fieldSeen[controlhistory.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[controlhistory.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldMappedCategories)
				fieldSeen[controlhistory.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[controlhistory.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAssessmentObjectives)
				fieldSeen[controlhistory.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[controlhistory.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldAssessmentMethods)
				fieldSeen[controlhistory.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[controlhistory.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlQuestions)
				fieldSeen[controlhistory.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[controlhistory.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldImplementationGuidance)
				fieldSeen[controlhistory.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[controlhistory.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldExampleEvidence)
				fieldSeen[controlhistory.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[controlhistory.FieldReferences]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldReferences)
				fieldSeen[controlhistory.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[controlhistory.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlOwnerID)
				fieldSeen[controlhistory.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[controlhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldDelegateID)
				fieldSeen[controlhistory.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldOwnerID)
				fieldSeen[controlhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldSystemOwned)
				fieldSeen[controlhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldInternalNotes)
				fieldSeen[controlhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldSystemInternalID)
				fieldSeen[controlhistory.FieldSystemInternalID] = struct{}{}
			}
		case "controlKindName":
			if _, ok := fieldSeen[controlhistory.FieldControlKindName]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlKindName)
				fieldSeen[controlhistory.FieldControlKindName] = struct{}{}
			}
		case "controlKindID":
			if _, ok := fieldSeen[controlhistory.FieldControlKindID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldControlKindID)
				fieldSeen[controlhistory.FieldControlKindID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[controlhistory.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldRefCode)
				fieldSeen[controlhistory.FieldRefCode] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[controlhistory.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, controlhistory.FieldStandardID)
				fieldSeen[controlhistory.FieldStandardID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlHistoryPaginateOption
}

func newControlHistoryPaginateArgs(rv map[string]any) *controlhistoryPaginateArgs {
	args := &controlhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlHistoryOrder{Field: &ControlHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlHistoryOrder(order))
			}
		case *ControlHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlImplementationQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlImplementationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlImplementationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlimplementation.Columns))
		selectedFields = []string{controlimplementation.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[controlimplementation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldOwnerID)
				fieldSeen[controlimplementation.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlimplementation.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlimplementation.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlimplementation.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlimplementation.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(controlimplementation.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[controlimplementation.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldCreatedAt)
				fieldSeen[controlimplementation.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlimplementation.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldUpdatedAt)
				fieldSeen[controlimplementation.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlimplementation.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldCreatedBy)
				fieldSeen[controlimplementation.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlimplementation.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldUpdatedBy)
				fieldSeen[controlimplementation.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlimplementation.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldTags)
				fieldSeen[controlimplementation.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlimplementation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldOwnerID)
				fieldSeen[controlimplementation.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlimplementation.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldSystemOwned)
				fieldSeen[controlimplementation.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlimplementation.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldInternalNotes)
				fieldSeen[controlimplementation.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlimplementation.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldSystemInternalID)
				fieldSeen[controlimplementation.FieldSystemInternalID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlimplementation.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldStatus)
				fieldSeen[controlimplementation.FieldStatus] = struct{}{}
			}
		case "implementationDate":
			if _, ok := fieldSeen[controlimplementation.FieldImplementationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldImplementationDate)
				fieldSeen[controlimplementation.FieldImplementationDate] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[controlimplementation.FieldVerified]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldVerified)
				fieldSeen[controlimplementation.FieldVerified] = struct{}{}
			}
		case "verificationDate":
			if _, ok := fieldSeen[controlimplementation.FieldVerificationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldVerificationDate)
				fieldSeen[controlimplementation.FieldVerificationDate] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[controlimplementation.FieldDetails]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldDetails)
				fieldSeen[controlimplementation.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlimplementationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlImplementationPaginateOption
}

func newControlImplementationPaginateArgs(rv map[string]any) *controlimplementationPaginateArgs {
	args := &controlimplementationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlImplementationOrder:
			args.opts = append(args.opts, WithControlImplementationOrder(v))
		case []any:
			var orders []*ControlImplementationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlImplementationOrder{Field: &ControlImplementationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlImplementationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlImplementationWhereInput); ok {
		args.opts = append(args.opts, WithControlImplementationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlImplementationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlImplementationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlImplementationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlimplementationhistory.Columns))
		selectedFields = []string{controlimplementationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlimplementationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldHistoryTime)
				fieldSeen[controlimplementationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlimplementationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldRef)
				fieldSeen[controlimplementationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlimplementationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldOperation)
				fieldSeen[controlimplementationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlimplementationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldCreatedAt)
				fieldSeen[controlimplementationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlimplementationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldUpdatedAt)
				fieldSeen[controlimplementationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlimplementationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldCreatedBy)
				fieldSeen[controlimplementationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlimplementationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldUpdatedBy)
				fieldSeen[controlimplementationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlimplementationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldTags)
				fieldSeen[controlimplementationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlimplementationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldOwnerID)
				fieldSeen[controlimplementationhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlimplementationhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldSystemOwned)
				fieldSeen[controlimplementationhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlimplementationhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldInternalNotes)
				fieldSeen[controlimplementationhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlimplementationhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldSystemInternalID)
				fieldSeen[controlimplementationhistory.FieldSystemInternalID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlimplementationhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldStatus)
				fieldSeen[controlimplementationhistory.FieldStatus] = struct{}{}
			}
		case "implementationDate":
			if _, ok := fieldSeen[controlimplementationhistory.FieldImplementationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldImplementationDate)
				fieldSeen[controlimplementationhistory.FieldImplementationDate] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[controlimplementationhistory.FieldVerified]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldVerified)
				fieldSeen[controlimplementationhistory.FieldVerified] = struct{}{}
			}
		case "verificationDate":
			if _, ok := fieldSeen[controlimplementationhistory.FieldVerificationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldVerificationDate)
				fieldSeen[controlimplementationhistory.FieldVerificationDate] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[controlimplementationhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, controlimplementationhistory.FieldDetails)
				fieldSeen[controlimplementationhistory.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlimplementationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlImplementationHistoryPaginateOption
}

func newControlImplementationHistoryPaginateArgs(rv map[string]any) *controlimplementationhistoryPaginateArgs {
	args := &controlimplementationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlImplementationHistoryOrder{Field: &ControlImplementationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlImplementationHistoryOrder(order))
			}
		case *ControlImplementationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlImplementationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlImplementationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlImplementationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlObjectiveQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlObjectiveQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlObjectiveQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlobjective.Columns))
		selectedFields = []string{controlobjective.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[controlobjective.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldOwnerID)
				fieldSeen[controlobjective.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(controlobjective.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(controlobjective.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlobjective.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlobjective.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(controlobjective.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_procedures"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.RisksColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_narratives"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(controlobjective.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[controlobjective.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCreatedAt)
				fieldSeen[controlobjective.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlobjective.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldUpdatedAt)
				fieldSeen[controlobjective.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlobjective.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCreatedBy)
				fieldSeen[controlobjective.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlobjective.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldUpdatedBy)
				fieldSeen[controlobjective.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlobjective.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDisplayID)
				fieldSeen[controlobjective.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlobjective.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldTags)
				fieldSeen[controlobjective.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[controlobjective.FieldRevision]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldRevision)
				fieldSeen[controlobjective.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlobjective.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldOwnerID)
				fieldSeen[controlobjective.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlobjective.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSystemOwned)
				fieldSeen[controlobjective.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlobjective.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldInternalNotes)
				fieldSeen[controlobjective.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlobjective.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSystemInternalID)
				fieldSeen[controlobjective.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[controlobjective.FieldName]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldName)
				fieldSeen[controlobjective.FieldName] = struct{}{}
			}
		case "desiredOutcome":
			if _, ok := fieldSeen[controlobjective.FieldDesiredOutcome]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDesiredOutcome)
				fieldSeen[controlobjective.FieldDesiredOutcome] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlobjective.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldStatus)
				fieldSeen[controlobjective.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlobjective.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSource)
				fieldSeen[controlobjective.FieldSource] = struct{}{}
			}
		case "controlObjectiveType":
			if _, ok := fieldSeen[controlobjective.FieldControlObjectiveType]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldControlObjectiveType)
				fieldSeen[controlobjective.FieldControlObjectiveType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlobjective.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCategory)
				fieldSeen[controlobjective.FieldCategory] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlobjective.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSubcategory)
				fieldSeen[controlobjective.FieldSubcategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlobjectivePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlObjectivePaginateOption
}

func newControlObjectivePaginateArgs(rv map[string]any) *controlobjectivePaginateArgs {
	args := &controlobjectivePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlObjectiveOrder:
			args.opts = append(args.opts, WithControlObjectiveOrder(v))
		case []any:
			var orders []*ControlObjectiveOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlObjectiveOrder{Field: &ControlObjectiveOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlObjectiveOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlObjectiveWhereInput); ok {
		args.opts = append(args.opts, WithControlObjectiveFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlObjectiveHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlObjectiveHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlObjectiveHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlobjectivehistory.Columns))
		selectedFields = []string{controlobjectivehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[controlobjectivehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldHistoryTime)
				fieldSeen[controlobjectivehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[controlobjectivehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldRef)
				fieldSeen[controlobjectivehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[controlobjectivehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldOperation)
				fieldSeen[controlobjectivehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[controlobjectivehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldCreatedAt)
				fieldSeen[controlobjectivehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlobjectivehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldUpdatedAt)
				fieldSeen[controlobjectivehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlobjectivehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldCreatedBy)
				fieldSeen[controlobjectivehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlobjectivehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldUpdatedBy)
				fieldSeen[controlobjectivehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlobjectivehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldDisplayID)
				fieldSeen[controlobjectivehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlobjectivehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldTags)
				fieldSeen[controlobjectivehistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[controlobjectivehistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldRevision)
				fieldSeen[controlobjectivehistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlobjectivehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldOwnerID)
				fieldSeen[controlobjectivehistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlobjectivehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldSystemOwned)
				fieldSeen[controlobjectivehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlobjectivehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldInternalNotes)
				fieldSeen[controlobjectivehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlobjectivehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldSystemInternalID)
				fieldSeen[controlobjectivehistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[controlobjectivehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldName)
				fieldSeen[controlobjectivehistory.FieldName] = struct{}{}
			}
		case "desiredOutcome":
			if _, ok := fieldSeen[controlobjectivehistory.FieldDesiredOutcome]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldDesiredOutcome)
				fieldSeen[controlobjectivehistory.FieldDesiredOutcome] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlobjectivehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldStatus)
				fieldSeen[controlobjectivehistory.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlobjectivehistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldSource)
				fieldSeen[controlobjectivehistory.FieldSource] = struct{}{}
			}
		case "controlObjectiveType":
			if _, ok := fieldSeen[controlobjectivehistory.FieldControlObjectiveType]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldControlObjectiveType)
				fieldSeen[controlobjectivehistory.FieldControlObjectiveType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlobjectivehistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldCategory)
				fieldSeen[controlobjectivehistory.FieldCategory] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlobjectivehistory.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlobjectivehistory.FieldSubcategory)
				fieldSeen[controlobjectivehistory.FieldSubcategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlobjectivehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlObjectiveHistoryPaginateOption
}

func newControlObjectiveHistoryPaginateArgs(rv map[string]any) *controlobjectivehistoryPaginateArgs {
	args := &controlobjectivehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ControlObjectiveHistoryOrder{Field: &ControlObjectiveHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithControlObjectiveHistoryOrder(order))
			}
		case *ControlObjectiveHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithControlObjectiveHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ControlObjectiveHistoryWhereInput); ok {
		args.opts = append(args.opts, WithControlObjectiveHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *CustomDomainQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomDomainQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *CustomDomainQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customdomain.Columns))
		selectedFields = []string{customdomain.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[customdomain.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldOwnerID)
				fieldSeen[customdomain.FieldOwnerID] = struct{}{}
			}

		case "mappableDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappableDomainClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, mappabledomainImplementors)...); err != nil {
				return err
			}
			_q.withMappableDomain = query
			if _, ok := fieldSeen[customdomain.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldMappableDomainID)
				fieldSeen[customdomain.FieldMappableDomainID] = struct{}{}
			}

		case "dnsVerification":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DNSVerificationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, dnsverificationImplementors)...); err != nil {
				return err
			}
			_q.withDNSVerification = query
			if _, ok := fieldSeen[customdomain.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldDNSVerificationID)
				fieldSeen[customdomain.FieldDNSVerificationID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[customdomain.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCreatedAt)
				fieldSeen[customdomain.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customdomain.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldUpdatedAt)
				fieldSeen[customdomain.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customdomain.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCreatedBy)
				fieldSeen[customdomain.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customdomain.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldUpdatedBy)
				fieldSeen[customdomain.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[customdomain.FieldTags]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldTags)
				fieldSeen[customdomain.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customdomain.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldOwnerID)
				fieldSeen[customdomain.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[customdomain.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldSystemOwned)
				fieldSeen[customdomain.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[customdomain.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldInternalNotes)
				fieldSeen[customdomain.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[customdomain.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldSystemInternalID)
				fieldSeen[customdomain.FieldSystemInternalID] = struct{}{}
			}
		case "cnameRecord":
			if _, ok := fieldSeen[customdomain.FieldCnameRecord]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCnameRecord)
				fieldSeen[customdomain.FieldCnameRecord] = struct{}{}
			}
		case "mappableDomainID":
			if _, ok := fieldSeen[customdomain.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldMappableDomainID)
				fieldSeen[customdomain.FieldMappableDomainID] = struct{}{}
			}
		case "dnsVerificationID":
			if _, ok := fieldSeen[customdomain.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldDNSVerificationID)
				fieldSeen[customdomain.FieldDNSVerificationID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type customdomainPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomDomainPaginateOption
}

func newCustomDomainPaginateArgs(rv map[string]any) *customdomainPaginateArgs {
	args := &customdomainPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*CustomDomainOrder:
			args.opts = append(args.opts, WithCustomDomainOrder(v))
		case []any:
			var orders []*CustomDomainOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &CustomDomainOrder{Field: &CustomDomainOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithCustomDomainOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*CustomDomainWhereInput); ok {
		args.opts = append(args.opts, WithCustomDomainFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *CustomDomainHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomDomainHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *CustomDomainHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customdomainhistory.Columns))
		selectedFields = []string{customdomainhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[customdomainhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldHistoryTime)
				fieldSeen[customdomainhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[customdomainhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldRef)
				fieldSeen[customdomainhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[customdomainhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldOperation)
				fieldSeen[customdomainhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[customdomainhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldCreatedAt)
				fieldSeen[customdomainhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customdomainhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldUpdatedAt)
				fieldSeen[customdomainhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customdomainhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldCreatedBy)
				fieldSeen[customdomainhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customdomainhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldUpdatedBy)
				fieldSeen[customdomainhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[customdomainhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldTags)
				fieldSeen[customdomainhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customdomainhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldOwnerID)
				fieldSeen[customdomainhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[customdomainhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldSystemOwned)
				fieldSeen[customdomainhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[customdomainhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldInternalNotes)
				fieldSeen[customdomainhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[customdomainhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldSystemInternalID)
				fieldSeen[customdomainhistory.FieldSystemInternalID] = struct{}{}
			}
		case "cnameRecord":
			if _, ok := fieldSeen[customdomainhistory.FieldCnameRecord]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldCnameRecord)
				fieldSeen[customdomainhistory.FieldCnameRecord] = struct{}{}
			}
		case "mappableDomainID":
			if _, ok := fieldSeen[customdomainhistory.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldMappableDomainID)
				fieldSeen[customdomainhistory.FieldMappableDomainID] = struct{}{}
			}
		case "dnsVerificationID":
			if _, ok := fieldSeen[customdomainhistory.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomainhistory.FieldDNSVerificationID)
				fieldSeen[customdomainhistory.FieldDNSVerificationID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type customdomainhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomDomainHistoryPaginateOption
}

func newCustomDomainHistoryPaginateArgs(rv map[string]any) *customdomainhistoryPaginateArgs {
	args := &customdomainhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &CustomDomainHistoryOrder{Field: &CustomDomainHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithCustomDomainHistoryOrder(order))
			}
		case *CustomDomainHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithCustomDomainHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*CustomDomainHistoryWhereInput); ok {
		args.opts = append(args.opts, WithCustomDomainHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *CustomTypeEnumQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomTypeEnumQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *CustomTypeEnumQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customtypeenum.Columns))
		selectedFields = []string{customtypeenum.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[customtypeenum.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldOwnerID)
				fieldSeen[customtypeenum.FieldOwnerID] = struct{}{}
			}

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.TasksColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ControlsColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.RisksColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskCategories":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_risk_categories"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.RiskCategoriesColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.RiskCategoriesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskCategories)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.RiskCategoriesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskCategories(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_internal_policies"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.InternalPoliciesColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.InternalPoliciesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.InternalPoliciesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_procedures"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[customtypeenum.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldCreatedAt)
				fieldSeen[customtypeenum.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customtypeenum.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldUpdatedAt)
				fieldSeen[customtypeenum.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customtypeenum.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldCreatedBy)
				fieldSeen[customtypeenum.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customtypeenum.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldUpdatedBy)
				fieldSeen[customtypeenum.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customtypeenum.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldOwnerID)
				fieldSeen[customtypeenum.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[customtypeenum.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldSystemOwned)
				fieldSeen[customtypeenum.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[customtypeenum.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldInternalNotes)
				fieldSeen[customtypeenum.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[customtypeenum.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldSystemInternalID)
				fieldSeen[customtypeenum.FieldSystemInternalID] = struct{}{}
			}
		case "objectType":
			if _, ok := fieldSeen[customtypeenum.FieldObjectType]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldObjectType)
				fieldSeen[customtypeenum.FieldObjectType] = struct{}{}
			}
		case "field":
			if _, ok := fieldSeen[customtypeenum.FieldField]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldField)
				fieldSeen[customtypeenum.FieldField] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[customtypeenum.FieldName]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldName)
				fieldSeen[customtypeenum.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[customtypeenum.FieldDescription]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldDescription)
				fieldSeen[customtypeenum.FieldDescription] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[customtypeenum.FieldColor]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldColor)
				fieldSeen[customtypeenum.FieldColor] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type customtypeenumPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomTypeEnumPaginateOption
}

func newCustomTypeEnumPaginateArgs(rv map[string]any) *customtypeenumPaginateArgs {
	args := &customtypeenumPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*CustomTypeEnumOrder:
			args.opts = append(args.opts, WithCustomTypeEnumOrder(v))
		case []any:
			var orders []*CustomTypeEnumOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &CustomTypeEnumOrder{Field: &CustomTypeEnumOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithCustomTypeEnumOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*CustomTypeEnumWhereInput); ok {
		args.opts = append(args.opts, WithCustomTypeEnumFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DNSVerificationQuery) CollectFields(ctx context.Context, satisfies ...string) (*DNSVerificationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DNSVerificationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(dnsverification.Columns))
		selectedFields = []string{dnsverification.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[dnsverification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldOwnerID)
				fieldSeen[dnsverification.FieldOwnerID] = struct{}{}
			}

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DNSVerification) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"dns_verification_custom_domains"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(dnsverification.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(dnsverification.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DNSVerification) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(dnsverification.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[dnsverification.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCreatedAt)
				fieldSeen[dnsverification.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[dnsverification.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldUpdatedAt)
				fieldSeen[dnsverification.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[dnsverification.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCreatedBy)
				fieldSeen[dnsverification.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[dnsverification.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldUpdatedBy)
				fieldSeen[dnsverification.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[dnsverification.FieldTags]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldTags)
				fieldSeen[dnsverification.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[dnsverification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldOwnerID)
				fieldSeen[dnsverification.FieldOwnerID] = struct{}{}
			}
		case "cloudflareHostnameID":
			if _, ok := fieldSeen[dnsverification.FieldCloudflareHostnameID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCloudflareHostnameID)
				fieldSeen[dnsverification.FieldCloudflareHostnameID] = struct{}{}
			}
		case "dnsTxtRecord":
			if _, ok := fieldSeen[dnsverification.FieldDNSTxtRecord]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSTxtRecord)
				fieldSeen[dnsverification.FieldDNSTxtRecord] = struct{}{}
			}
		case "dnsTxtValue":
			if _, ok := fieldSeen[dnsverification.FieldDNSTxtValue]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSTxtValue)
				fieldSeen[dnsverification.FieldDNSTxtValue] = struct{}{}
			}
		case "dnsVerificationStatus":
			if _, ok := fieldSeen[dnsverification.FieldDNSVerificationStatus]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSVerificationStatus)
				fieldSeen[dnsverification.FieldDNSVerificationStatus] = struct{}{}
			}
		case "dnsVerificationStatusReason":
			if _, ok := fieldSeen[dnsverification.FieldDNSVerificationStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSVerificationStatusReason)
				fieldSeen[dnsverification.FieldDNSVerificationStatusReason] = struct{}{}
			}
		case "acmeChallengePath":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengePath]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengePath)
				fieldSeen[dnsverification.FieldAcmeChallengePath] = struct{}{}
			}
		case "expectedAcmeChallengeValue":
			if _, ok := fieldSeen[dnsverification.FieldExpectedAcmeChallengeValue]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldExpectedAcmeChallengeValue)
				fieldSeen[dnsverification.FieldExpectedAcmeChallengeValue] = struct{}{}
			}
		case "acmeChallengeStatus":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengeStatus]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengeStatus)
				fieldSeen[dnsverification.FieldAcmeChallengeStatus] = struct{}{}
			}
		case "acmeChallengeStatusReason":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengeStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengeStatusReason)
				fieldSeen[dnsverification.FieldAcmeChallengeStatusReason] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type dnsverificationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DNSVerificationPaginateOption
}

func newDNSVerificationPaginateArgs(rv map[string]any) *dnsverificationPaginateArgs {
	args := &dnsverificationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DNSVerificationOrder:
			args.opts = append(args.opts, WithDNSVerificationOrder(v))
		case []any:
			var orders []*DNSVerificationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DNSVerificationOrder{Field: &DNSVerificationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDNSVerificationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DNSVerificationWhereInput); ok {
		args.opts = append(args.opts, WithDNSVerificationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DNSVerificationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DNSVerificationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DNSVerificationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(dnsverificationhistory.Columns))
		selectedFields = []string{dnsverificationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[dnsverificationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldHistoryTime)
				fieldSeen[dnsverificationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[dnsverificationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldRef)
				fieldSeen[dnsverificationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[dnsverificationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldOperation)
				fieldSeen[dnsverificationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[dnsverificationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldCreatedAt)
				fieldSeen[dnsverificationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[dnsverificationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldUpdatedAt)
				fieldSeen[dnsverificationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[dnsverificationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldCreatedBy)
				fieldSeen[dnsverificationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[dnsverificationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldUpdatedBy)
				fieldSeen[dnsverificationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[dnsverificationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldTags)
				fieldSeen[dnsverificationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[dnsverificationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldOwnerID)
				fieldSeen[dnsverificationhistory.FieldOwnerID] = struct{}{}
			}
		case "cloudflareHostnameID":
			if _, ok := fieldSeen[dnsverificationhistory.FieldCloudflareHostnameID]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldCloudflareHostnameID)
				fieldSeen[dnsverificationhistory.FieldCloudflareHostnameID] = struct{}{}
			}
		case "dnsTxtRecord":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSTxtRecord]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSTxtRecord)
				fieldSeen[dnsverificationhistory.FieldDNSTxtRecord] = struct{}{}
			}
		case "dnsTxtValue":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSTxtValue]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSTxtValue)
				fieldSeen[dnsverificationhistory.FieldDNSTxtValue] = struct{}{}
			}
		case "dnsVerificationStatus":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSVerificationStatus]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSVerificationStatus)
				fieldSeen[dnsverificationhistory.FieldDNSVerificationStatus] = struct{}{}
			}
		case "dnsVerificationStatusReason":
			if _, ok := fieldSeen[dnsverificationhistory.FieldDNSVerificationStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldDNSVerificationStatusReason)
				fieldSeen[dnsverificationhistory.FieldDNSVerificationStatusReason] = struct{}{}
			}
		case "acmeChallengePath":
			if _, ok := fieldSeen[dnsverificationhistory.FieldAcmeChallengePath]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldAcmeChallengePath)
				fieldSeen[dnsverificationhistory.FieldAcmeChallengePath] = struct{}{}
			}
		case "expectedAcmeChallengeValue":
			if _, ok := fieldSeen[dnsverificationhistory.FieldExpectedAcmeChallengeValue]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldExpectedAcmeChallengeValue)
				fieldSeen[dnsverificationhistory.FieldExpectedAcmeChallengeValue] = struct{}{}
			}
		case "acmeChallengeStatus":
			if _, ok := fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatus]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldAcmeChallengeStatus)
				fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatus] = struct{}{}
			}
		case "acmeChallengeStatusReason":
			if _, ok := fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverificationhistory.FieldAcmeChallengeStatusReason)
				fieldSeen[dnsverificationhistory.FieldAcmeChallengeStatusReason] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type dnsverificationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DNSVerificationHistoryPaginateOption
}

func newDNSVerificationHistoryPaginateArgs(rv map[string]any) *dnsverificationhistoryPaginateArgs {
	args := &dnsverificationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DNSVerificationHistoryOrder{Field: &DNSVerificationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDNSVerificationHistoryOrder(order))
			}
		case *DNSVerificationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDNSVerificationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DNSVerificationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDNSVerificationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryAccountQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryAccountQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryAccountQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directoryaccount.Columns))
		selectedFields = []string{directoryaccount.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directoryaccount.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldOwnerID)
				fieldSeen[directoryaccount.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directoryaccount.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldIntegrationID)
				fieldSeen[directoryaccount.FieldIntegrationID] = struct{}{}
			}

		case "directorySyncRun":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
				return err
			}
			_q.withDirectorySyncRun = query
			if _, ok := fieldSeen[directoryaccount.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDirectorySyncRunID)
				fieldSeen[directoryaccount.FieldDirectorySyncRunID] = struct{}{}
			}

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryAccount) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_account_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(directoryaccount.GroupsTable)
							s.Join(joinT).On(s.C(directorygroup.FieldID), joinT.C(directoryaccount.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(directoryaccount.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(directoryaccount.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(directoryaccount.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryAccount) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directoryaccount.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryAccount) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_account_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directoryaccount.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(directoryaccount.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryAccount) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directoryaccount.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "memberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryAccount) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_account_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directoryaccount.MembershipsColumn), ids...))
						})
						if err := query.GroupBy(directoryaccount.MembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryAccount) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Memberships)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directoryaccount.MembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directoryaccount.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldCreatedAt)
				fieldSeen[directoryaccount.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directoryaccount.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldUpdatedAt)
				fieldSeen[directoryaccount.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directoryaccount.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldCreatedBy)
				fieldSeen[directoryaccount.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directoryaccount.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldUpdatedBy)
				fieldSeen[directoryaccount.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directoryaccount.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDisplayID)
				fieldSeen[directoryaccount.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[directoryaccount.FieldTags]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldTags)
				fieldSeen[directoryaccount.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directoryaccount.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldOwnerID)
				fieldSeen[directoryaccount.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directoryaccount.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldIntegrationID)
				fieldSeen[directoryaccount.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directoryaccount.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDirectorySyncRunID)
				fieldSeen[directoryaccount.FieldDirectorySyncRunID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[directoryaccount.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldExternalID)
				fieldSeen[directoryaccount.FieldExternalID] = struct{}{}
			}
		case "secondaryKey":
			if _, ok := fieldSeen[directoryaccount.FieldSecondaryKey]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldSecondaryKey)
				fieldSeen[directoryaccount.FieldSecondaryKey] = struct{}{}
			}
		case "canonicalEmail":
			if _, ok := fieldSeen[directoryaccount.FieldCanonicalEmail]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldCanonicalEmail)
				fieldSeen[directoryaccount.FieldCanonicalEmail] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[directoryaccount.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDisplayName)
				fieldSeen[directoryaccount.FieldDisplayName] = struct{}{}
			}
		case "givenName":
			if _, ok := fieldSeen[directoryaccount.FieldGivenName]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldGivenName)
				fieldSeen[directoryaccount.FieldGivenName] = struct{}{}
			}
		case "familyName":
			if _, ok := fieldSeen[directoryaccount.FieldFamilyName]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldFamilyName)
				fieldSeen[directoryaccount.FieldFamilyName] = struct{}{}
			}
		case "jobTitle":
			if _, ok := fieldSeen[directoryaccount.FieldJobTitle]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldJobTitle)
				fieldSeen[directoryaccount.FieldJobTitle] = struct{}{}
			}
		case "department":
			if _, ok := fieldSeen[directoryaccount.FieldDepartment]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDepartment)
				fieldSeen[directoryaccount.FieldDepartment] = struct{}{}
			}
		case "organizationUnit":
			if _, ok := fieldSeen[directoryaccount.FieldOrganizationUnit]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldOrganizationUnit)
				fieldSeen[directoryaccount.FieldOrganizationUnit] = struct{}{}
			}
		case "accountType":
			if _, ok := fieldSeen[directoryaccount.FieldAccountType]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldAccountType)
				fieldSeen[directoryaccount.FieldAccountType] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directoryaccount.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldStatus)
				fieldSeen[directoryaccount.FieldStatus] = struct{}{}
			}
		case "mfaState":
			if _, ok := fieldSeen[directoryaccount.FieldMfaState]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldMfaState)
				fieldSeen[directoryaccount.FieldMfaState] = struct{}{}
			}
		case "lastSeenIP":
			if _, ok := fieldSeen[directoryaccount.FieldLastSeenIP]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldLastSeenIP)
				fieldSeen[directoryaccount.FieldLastSeenIP] = struct{}{}
			}
		case "lastLoginAt":
			if _, ok := fieldSeen[directoryaccount.FieldLastLoginAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldLastLoginAt)
				fieldSeen[directoryaccount.FieldLastLoginAt] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directoryaccount.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldObservedAt)
				fieldSeen[directoryaccount.FieldObservedAt] = struct{}{}
			}
		case "profileHash":
			if _, ok := fieldSeen[directoryaccount.FieldProfileHash]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldProfileHash)
				fieldSeen[directoryaccount.FieldProfileHash] = struct{}{}
			}
		case "profile":
			if _, ok := fieldSeen[directoryaccount.FieldProfile]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldProfile)
				fieldSeen[directoryaccount.FieldProfile] = struct{}{}
			}
		case "rawProfileFileID":
			if _, ok := fieldSeen[directoryaccount.FieldRawProfileFileID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldRawProfileFileID)
				fieldSeen[directoryaccount.FieldRawProfileFileID] = struct{}{}
			}
		case "sourceVersion":
			if _, ok := fieldSeen[directoryaccount.FieldSourceVersion]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldSourceVersion)
				fieldSeen[directoryaccount.FieldSourceVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directoryaccountPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryAccountPaginateOption
}

func newDirectoryAccountPaginateArgs(rv map[string]any) *directoryaccountPaginateArgs {
	args := &directoryaccountPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectoryAccountOrder:
			args.opts = append(args.opts, WithDirectoryAccountOrder(v))
		case []any:
			var orders []*DirectoryAccountOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectoryAccountOrder{Field: &DirectoryAccountOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectoryAccountOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectoryAccountWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryAccountFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryAccountHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryAccountHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryAccountHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directoryaccounthistory.Columns))
		selectedFields = []string{directoryaccounthistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[directoryaccounthistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldHistoryTime)
				fieldSeen[directoryaccounthistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[directoryaccounthistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldRef)
				fieldSeen[directoryaccounthistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[directoryaccounthistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldOperation)
				fieldSeen[directoryaccounthistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[directoryaccounthistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldCreatedAt)
				fieldSeen[directoryaccounthistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directoryaccounthistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldUpdatedAt)
				fieldSeen[directoryaccounthistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directoryaccounthistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldCreatedBy)
				fieldSeen[directoryaccounthistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directoryaccounthistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldUpdatedBy)
				fieldSeen[directoryaccounthistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directoryaccounthistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldDisplayID)
				fieldSeen[directoryaccounthistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[directoryaccounthistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldTags)
				fieldSeen[directoryaccounthistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directoryaccounthistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldOwnerID)
				fieldSeen[directoryaccounthistory.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directoryaccounthistory.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldIntegrationID)
				fieldSeen[directoryaccounthistory.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directoryaccounthistory.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldDirectorySyncRunID)
				fieldSeen[directoryaccounthistory.FieldDirectorySyncRunID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[directoryaccounthistory.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldExternalID)
				fieldSeen[directoryaccounthistory.FieldExternalID] = struct{}{}
			}
		case "secondaryKey":
			if _, ok := fieldSeen[directoryaccounthistory.FieldSecondaryKey]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldSecondaryKey)
				fieldSeen[directoryaccounthistory.FieldSecondaryKey] = struct{}{}
			}
		case "canonicalEmail":
			if _, ok := fieldSeen[directoryaccounthistory.FieldCanonicalEmail]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldCanonicalEmail)
				fieldSeen[directoryaccounthistory.FieldCanonicalEmail] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[directoryaccounthistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldDisplayName)
				fieldSeen[directoryaccounthistory.FieldDisplayName] = struct{}{}
			}
		case "givenName":
			if _, ok := fieldSeen[directoryaccounthistory.FieldGivenName]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldGivenName)
				fieldSeen[directoryaccounthistory.FieldGivenName] = struct{}{}
			}
		case "familyName":
			if _, ok := fieldSeen[directoryaccounthistory.FieldFamilyName]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldFamilyName)
				fieldSeen[directoryaccounthistory.FieldFamilyName] = struct{}{}
			}
		case "jobTitle":
			if _, ok := fieldSeen[directoryaccounthistory.FieldJobTitle]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldJobTitle)
				fieldSeen[directoryaccounthistory.FieldJobTitle] = struct{}{}
			}
		case "department":
			if _, ok := fieldSeen[directoryaccounthistory.FieldDepartment]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldDepartment)
				fieldSeen[directoryaccounthistory.FieldDepartment] = struct{}{}
			}
		case "organizationUnit":
			if _, ok := fieldSeen[directoryaccounthistory.FieldOrganizationUnit]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldOrganizationUnit)
				fieldSeen[directoryaccounthistory.FieldOrganizationUnit] = struct{}{}
			}
		case "accountType":
			if _, ok := fieldSeen[directoryaccounthistory.FieldAccountType]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldAccountType)
				fieldSeen[directoryaccounthistory.FieldAccountType] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directoryaccounthistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldStatus)
				fieldSeen[directoryaccounthistory.FieldStatus] = struct{}{}
			}
		case "mfaState":
			if _, ok := fieldSeen[directoryaccounthistory.FieldMfaState]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldMfaState)
				fieldSeen[directoryaccounthistory.FieldMfaState] = struct{}{}
			}
		case "lastSeenIP":
			if _, ok := fieldSeen[directoryaccounthistory.FieldLastSeenIP]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldLastSeenIP)
				fieldSeen[directoryaccounthistory.FieldLastSeenIP] = struct{}{}
			}
		case "lastLoginAt":
			if _, ok := fieldSeen[directoryaccounthistory.FieldLastLoginAt]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldLastLoginAt)
				fieldSeen[directoryaccounthistory.FieldLastLoginAt] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directoryaccounthistory.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldObservedAt)
				fieldSeen[directoryaccounthistory.FieldObservedAt] = struct{}{}
			}
		case "profileHash":
			if _, ok := fieldSeen[directoryaccounthistory.FieldProfileHash]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldProfileHash)
				fieldSeen[directoryaccounthistory.FieldProfileHash] = struct{}{}
			}
		case "profile":
			if _, ok := fieldSeen[directoryaccounthistory.FieldProfile]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldProfile)
				fieldSeen[directoryaccounthistory.FieldProfile] = struct{}{}
			}
		case "rawProfileFileID":
			if _, ok := fieldSeen[directoryaccounthistory.FieldRawProfileFileID]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldRawProfileFileID)
				fieldSeen[directoryaccounthistory.FieldRawProfileFileID] = struct{}{}
			}
		case "sourceVersion":
			if _, ok := fieldSeen[directoryaccounthistory.FieldSourceVersion]; !ok {
				selectedFields = append(selectedFields, directoryaccounthistory.FieldSourceVersion)
				fieldSeen[directoryaccounthistory.FieldSourceVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directoryaccounthistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryAccountHistoryPaginateOption
}

func newDirectoryAccountHistoryPaginateArgs(rv map[string]any) *directoryaccounthistoryPaginateArgs {
	args := &directoryaccounthistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DirectoryAccountHistoryOrder{Field: &DirectoryAccountHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDirectoryAccountHistoryOrder(order))
			}
		case *DirectoryAccountHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDirectoryAccountHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DirectoryAccountHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryAccountHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryGroupQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryGroupQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryGroupQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorygroup.Columns))
		selectedFields = []string{directorygroup.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directorygroup.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldOwnerID)
				fieldSeen[directorygroup.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directorygroup.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldIntegrationID)
				fieldSeen[directorygroup.FieldIntegrationID] = struct{}{}
			}

		case "directorySyncRun":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
				return err
			}
			_q.withDirectorySyncRun = query
			if _, ok := fieldSeen[directorygroup.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDirectorySyncRunID)
				fieldSeen[directorygroup.FieldDirectorySyncRunID] = struct{}{}
			}

		case "accounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryGroup) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(directorygroup.AccountsTable)
							s.Join(joinT).On(s.C(directoryaccount.FieldID), joinT.C(directorygroup.AccountsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(directorygroup.AccountsPrimaryKey[1]), ids...))
							s.Select(joinT.C(directorygroup.AccountsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(directorygroup.AccountsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryGroup) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Accounts)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorygroup.AccountsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryGroup) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorygroup.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(directorygroup.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryGroup) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorygroup.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryGroup) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorygroup.MembersColumn), ids...))
						})
						if err := query.GroupBy(directorygroup.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryGroup) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorygroup.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directorygroup.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldCreatedAt)
				fieldSeen[directorygroup.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorygroup.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldUpdatedAt)
				fieldSeen[directorygroup.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorygroup.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldCreatedBy)
				fieldSeen[directorygroup.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorygroup.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldUpdatedBy)
				fieldSeen[directorygroup.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorygroup.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDisplayID)
				fieldSeen[directorygroup.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[directorygroup.FieldTags]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldTags)
				fieldSeen[directorygroup.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorygroup.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldOwnerID)
				fieldSeen[directorygroup.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorygroup.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldIntegrationID)
				fieldSeen[directorygroup.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directorygroup.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDirectorySyncRunID)
				fieldSeen[directorygroup.FieldDirectorySyncRunID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[directorygroup.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldExternalID)
				fieldSeen[directorygroup.FieldExternalID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[directorygroup.FieldEmail]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldEmail)
				fieldSeen[directorygroup.FieldEmail] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[directorygroup.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDisplayName)
				fieldSeen[directorygroup.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[directorygroup.FieldDescription]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDescription)
				fieldSeen[directorygroup.FieldDescription] = struct{}{}
			}
		case "classification":
			if _, ok := fieldSeen[directorygroup.FieldClassification]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldClassification)
				fieldSeen[directorygroup.FieldClassification] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directorygroup.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldStatus)
				fieldSeen[directorygroup.FieldStatus] = struct{}{}
			}
		case "externalSharingAllowed":
			if _, ok := fieldSeen[directorygroup.FieldExternalSharingAllowed]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldExternalSharingAllowed)
				fieldSeen[directorygroup.FieldExternalSharingAllowed] = struct{}{}
			}
		case "memberCount":
			if _, ok := fieldSeen[directorygroup.FieldMemberCount]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldMemberCount)
				fieldSeen[directorygroup.FieldMemberCount] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directorygroup.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldObservedAt)
				fieldSeen[directorygroup.FieldObservedAt] = struct{}{}
			}
		case "profileHash":
			if _, ok := fieldSeen[directorygroup.FieldProfileHash]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldProfileHash)
				fieldSeen[directorygroup.FieldProfileHash] = struct{}{}
			}
		case "profile":
			if _, ok := fieldSeen[directorygroup.FieldProfile]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldProfile)
				fieldSeen[directorygroup.FieldProfile] = struct{}{}
			}
		case "rawProfileFileID":
			if _, ok := fieldSeen[directorygroup.FieldRawProfileFileID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldRawProfileFileID)
				fieldSeen[directorygroup.FieldRawProfileFileID] = struct{}{}
			}
		case "sourceVersion":
			if _, ok := fieldSeen[directorygroup.FieldSourceVersion]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldSourceVersion)
				fieldSeen[directorygroup.FieldSourceVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorygroupPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryGroupPaginateOption
}

func newDirectoryGroupPaginateArgs(rv map[string]any) *directorygroupPaginateArgs {
	args := &directorygroupPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectoryGroupOrder:
			args.opts = append(args.opts, WithDirectoryGroupOrder(v))
		case []any:
			var orders []*DirectoryGroupOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectoryGroupOrder{Field: &DirectoryGroupOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectoryGroupOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectoryGroupWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryGroupFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryGroupHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryGroupHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryGroupHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorygrouphistory.Columns))
		selectedFields = []string{directorygrouphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[directorygrouphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldHistoryTime)
				fieldSeen[directorygrouphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[directorygrouphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldRef)
				fieldSeen[directorygrouphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[directorygrouphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldOperation)
				fieldSeen[directorygrouphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[directorygrouphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldCreatedAt)
				fieldSeen[directorygrouphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorygrouphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldUpdatedAt)
				fieldSeen[directorygrouphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorygrouphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldCreatedBy)
				fieldSeen[directorygrouphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorygrouphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldUpdatedBy)
				fieldSeen[directorygrouphistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorygrouphistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldDisplayID)
				fieldSeen[directorygrouphistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[directorygrouphistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldTags)
				fieldSeen[directorygrouphistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorygrouphistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldOwnerID)
				fieldSeen[directorygrouphistory.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorygrouphistory.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldIntegrationID)
				fieldSeen[directorygrouphistory.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directorygrouphistory.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldDirectorySyncRunID)
				fieldSeen[directorygrouphistory.FieldDirectorySyncRunID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[directorygrouphistory.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldExternalID)
				fieldSeen[directorygrouphistory.FieldExternalID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[directorygrouphistory.FieldEmail]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldEmail)
				fieldSeen[directorygrouphistory.FieldEmail] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[directorygrouphistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldDisplayName)
				fieldSeen[directorygrouphistory.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[directorygrouphistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldDescription)
				fieldSeen[directorygrouphistory.FieldDescription] = struct{}{}
			}
		case "classification":
			if _, ok := fieldSeen[directorygrouphistory.FieldClassification]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldClassification)
				fieldSeen[directorygrouphistory.FieldClassification] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directorygrouphistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldStatus)
				fieldSeen[directorygrouphistory.FieldStatus] = struct{}{}
			}
		case "externalSharingAllowed":
			if _, ok := fieldSeen[directorygrouphistory.FieldExternalSharingAllowed]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldExternalSharingAllowed)
				fieldSeen[directorygrouphistory.FieldExternalSharingAllowed] = struct{}{}
			}
		case "memberCount":
			if _, ok := fieldSeen[directorygrouphistory.FieldMemberCount]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldMemberCount)
				fieldSeen[directorygrouphistory.FieldMemberCount] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directorygrouphistory.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldObservedAt)
				fieldSeen[directorygrouphistory.FieldObservedAt] = struct{}{}
			}
		case "profileHash":
			if _, ok := fieldSeen[directorygrouphistory.FieldProfileHash]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldProfileHash)
				fieldSeen[directorygrouphistory.FieldProfileHash] = struct{}{}
			}
		case "profile":
			if _, ok := fieldSeen[directorygrouphistory.FieldProfile]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldProfile)
				fieldSeen[directorygrouphistory.FieldProfile] = struct{}{}
			}
		case "rawProfileFileID":
			if _, ok := fieldSeen[directorygrouphistory.FieldRawProfileFileID]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldRawProfileFileID)
				fieldSeen[directorygrouphistory.FieldRawProfileFileID] = struct{}{}
			}
		case "sourceVersion":
			if _, ok := fieldSeen[directorygrouphistory.FieldSourceVersion]; !ok {
				selectedFields = append(selectedFields, directorygrouphistory.FieldSourceVersion)
				fieldSeen[directorygrouphistory.FieldSourceVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorygrouphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryGroupHistoryPaginateOption
}

func newDirectoryGroupHistoryPaginateArgs(rv map[string]any) *directorygrouphistoryPaginateArgs {
	args := &directorygrouphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DirectoryGroupHistoryOrder{Field: &DirectoryGroupHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDirectoryGroupHistoryOrder(order))
			}
		case *DirectoryGroupHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDirectoryGroupHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DirectoryGroupHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryGroupHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorymembership.Columns))
		selectedFields = []string{directorymembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directorymembership.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldOwnerID)
				fieldSeen[directorymembership.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directorymembership.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldIntegrationID)
				fieldSeen[directorymembership.FieldIntegrationID] = struct{}{}
			}

		case "directorySyncRun":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
				return err
			}
			_q.withDirectorySyncRun = query
			if _, ok := fieldSeen[directorymembership.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectorySyncRunID)
				fieldSeen[directorymembership.FieldDirectorySyncRunID] = struct{}{}
			}

		case "directoryAccount":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryAccount = query
			if _, ok := fieldSeen[directorymembership.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryAccountID)
				fieldSeen[directorymembership.FieldDirectoryAccountID] = struct{}{}
			}

		case "directoryGroup":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryGroup = query
			if _, ok := fieldSeen[directorymembership.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryGroupID)
				fieldSeen[directorymembership.FieldDirectoryGroupID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_membership_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorymembership.EventsColumn), ids...))
						})
						if err := query.GroupBy(directorymembership.EventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorymembership.EventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorymembership.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(directorymembership.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorymembership.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directorymembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldCreatedAt)
				fieldSeen[directorymembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorymembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldUpdatedAt)
				fieldSeen[directorymembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorymembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldCreatedBy)
				fieldSeen[directorymembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorymembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldUpdatedBy)
				fieldSeen[directorymembership.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorymembership.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDisplayID)
				fieldSeen[directorymembership.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorymembership.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldOwnerID)
				fieldSeen[directorymembership.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorymembership.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldIntegrationID)
				fieldSeen[directorymembership.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directorymembership.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectorySyncRunID)
				fieldSeen[directorymembership.FieldDirectorySyncRunID] = struct{}{}
			}
		case "directoryAccountID":
			if _, ok := fieldSeen[directorymembership.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryAccountID)
				fieldSeen[directorymembership.FieldDirectoryAccountID] = struct{}{}
			}
		case "directoryGroupID":
			if _, ok := fieldSeen[directorymembership.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryGroupID)
				fieldSeen[directorymembership.FieldDirectoryGroupID] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[directorymembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldRole)
				fieldSeen[directorymembership.FieldRole] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[directorymembership.FieldSource]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldSource)
				fieldSeen[directorymembership.FieldSource] = struct{}{}
			}
		case "firstSeenAt":
			if _, ok := fieldSeen[directorymembership.FieldFirstSeenAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldFirstSeenAt)
				fieldSeen[directorymembership.FieldFirstSeenAt] = struct{}{}
			}
		case "lastSeenAt":
			if _, ok := fieldSeen[directorymembership.FieldLastSeenAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldLastSeenAt)
				fieldSeen[directorymembership.FieldLastSeenAt] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directorymembership.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldObservedAt)
				fieldSeen[directorymembership.FieldObservedAt] = struct{}{}
			}
		case "lastConfirmedRunID":
			if _, ok := fieldSeen[directorymembership.FieldLastConfirmedRunID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldLastConfirmedRunID)
				fieldSeen[directorymembership.FieldLastConfirmedRunID] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[directorymembership.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldMetadata)
				fieldSeen[directorymembership.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorymembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryMembershipPaginateOption
}

func newDirectoryMembershipPaginateArgs(rv map[string]any) *directorymembershipPaginateArgs {
	args := &directorymembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectoryMembershipOrder:
			args.opts = append(args.opts, WithDirectoryMembershipOrder(v))
		case []any:
			var orders []*DirectoryMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectoryMembershipOrder{Field: &DirectoryMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectoryMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectoryMembershipWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorymembershiphistory.Columns))
		selectedFields = []string{directorymembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[directorymembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldHistoryTime)
				fieldSeen[directorymembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[directorymembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldRef)
				fieldSeen[directorymembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[directorymembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldOperation)
				fieldSeen[directorymembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[directorymembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldCreatedAt)
				fieldSeen[directorymembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorymembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldUpdatedAt)
				fieldSeen[directorymembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorymembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldCreatedBy)
				fieldSeen[directorymembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorymembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldUpdatedBy)
				fieldSeen[directorymembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldDisplayID)
				fieldSeen[directorymembershiphistory.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldOwnerID)
				fieldSeen[directorymembershiphistory.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldIntegrationID)
				fieldSeen[directorymembershiphistory.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldDirectorySyncRunID)
				fieldSeen[directorymembershiphistory.FieldDirectorySyncRunID] = struct{}{}
			}
		case "directoryAccountID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldDirectoryAccountID)
				fieldSeen[directorymembershiphistory.FieldDirectoryAccountID] = struct{}{}
			}
		case "directoryGroupID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldDirectoryGroupID)
				fieldSeen[directorymembershiphistory.FieldDirectoryGroupID] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[directorymembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldRole)
				fieldSeen[directorymembershiphistory.FieldRole] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[directorymembershiphistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldSource)
				fieldSeen[directorymembershiphistory.FieldSource] = struct{}{}
			}
		case "firstSeenAt":
			if _, ok := fieldSeen[directorymembershiphistory.FieldFirstSeenAt]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldFirstSeenAt)
				fieldSeen[directorymembershiphistory.FieldFirstSeenAt] = struct{}{}
			}
		case "lastSeenAt":
			if _, ok := fieldSeen[directorymembershiphistory.FieldLastSeenAt]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldLastSeenAt)
				fieldSeen[directorymembershiphistory.FieldLastSeenAt] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directorymembershiphistory.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldObservedAt)
				fieldSeen[directorymembershiphistory.FieldObservedAt] = struct{}{}
			}
		case "lastConfirmedRunID":
			if _, ok := fieldSeen[directorymembershiphistory.FieldLastConfirmedRunID]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldLastConfirmedRunID)
				fieldSeen[directorymembershiphistory.FieldLastConfirmedRunID] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[directorymembershiphistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, directorymembershiphistory.FieldMetadata)
				fieldSeen[directorymembershiphistory.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorymembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryMembershipHistoryPaginateOption
}

func newDirectoryMembershipHistoryPaginateArgs(rv map[string]any) *directorymembershiphistoryPaginateArgs {
	args := &directorymembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DirectoryMembershipHistoryOrder{Field: &DirectoryMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDirectoryMembershipHistoryOrder(order))
			}
		case *DirectoryMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDirectoryMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DirectoryMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectorySyncRunQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectorySyncRunQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectorySyncRunQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorysyncrun.Columns))
		selectedFields = []string{directorysyncrun.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directorysyncrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldOwnerID)
				fieldSeen[directorysyncrun.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directorysyncrun.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldIntegrationID)
				fieldSeen[directorysyncrun.FieldIntegrationID] = struct{}{}
			}

		case "directoryAccounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectorySyncRun) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_sync_run_directory_accounts"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorysyncrun.DirectoryAccountsColumn), ids...))
						})
						if err := query.GroupBy(directorysyncrun.DirectoryAccountsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectorySyncRun) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryAccounts)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorysyncrun.DirectoryAccountsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "directoryGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectorySyncRun) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_sync_run_directory_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorysyncrun.DirectoryGroupsColumn), ids...))
						})
						if err := query.GroupBy(directorysyncrun.DirectoryGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectorySyncRun) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryGroups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorysyncrun.DirectoryGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "directoryMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectorySyncRun) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_sync_run_directory_memberships"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorysyncrun.DirectoryMembershipsColumn), ids...))
						})
						if err := query.GroupBy(directorysyncrun.DirectoryMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectorySyncRun) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryMemberships)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorysyncrun.DirectoryMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directorysyncrun.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldCreatedAt)
				fieldSeen[directorysyncrun.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorysyncrun.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldUpdatedAt)
				fieldSeen[directorysyncrun.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorysyncrun.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldCreatedBy)
				fieldSeen[directorysyncrun.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorysyncrun.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldUpdatedBy)
				fieldSeen[directorysyncrun.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorysyncrun.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldDisplayID)
				fieldSeen[directorysyncrun.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorysyncrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldOwnerID)
				fieldSeen[directorysyncrun.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorysyncrun.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldIntegrationID)
				fieldSeen[directorysyncrun.FieldIntegrationID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directorysyncrun.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldStatus)
				fieldSeen[directorysyncrun.FieldStatus] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[directorysyncrun.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldStartedAt)
				fieldSeen[directorysyncrun.FieldStartedAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[directorysyncrun.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldCompletedAt)
				fieldSeen[directorysyncrun.FieldCompletedAt] = struct{}{}
			}
		case "sourceCursor":
			if _, ok := fieldSeen[directorysyncrun.FieldSourceCursor]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldSourceCursor)
				fieldSeen[directorysyncrun.FieldSourceCursor] = struct{}{}
			}
		case "fullCount":
			if _, ok := fieldSeen[directorysyncrun.FieldFullCount]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldFullCount)
				fieldSeen[directorysyncrun.FieldFullCount] = struct{}{}
			}
		case "deltaCount":
			if _, ok := fieldSeen[directorysyncrun.FieldDeltaCount]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldDeltaCount)
				fieldSeen[directorysyncrun.FieldDeltaCount] = struct{}{}
			}
		case "error":
			if _, ok := fieldSeen[directorysyncrun.FieldError]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldError)
				fieldSeen[directorysyncrun.FieldError] = struct{}{}
			}
		case "rawManifestFileID":
			if _, ok := fieldSeen[directorysyncrun.FieldRawManifestFileID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldRawManifestFileID)
				fieldSeen[directorysyncrun.FieldRawManifestFileID] = struct{}{}
			}
		case "stats":
			if _, ok := fieldSeen[directorysyncrun.FieldStats]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldStats)
				fieldSeen[directorysyncrun.FieldStats] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorysyncrunPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectorySyncRunPaginateOption
}

func newDirectorySyncRunPaginateArgs(rv map[string]any) *directorysyncrunPaginateArgs {
	args := &directorysyncrunPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectorySyncRunOrder:
			args.opts = append(args.opts, WithDirectorySyncRunOrder(v))
		case []any:
			var orders []*DirectorySyncRunOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectorySyncRunOrder{Field: &DirectorySyncRunOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectorySyncRunOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectorySyncRunWhereInput); ok {
		args.opts = append(args.opts, WithDirectorySyncRunFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DocumentDataQuery) CollectFields(ctx context.Context, satisfies ...string) (*DocumentDataQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DocumentDataQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(documentdata.Columns))
		selectedFields = []string{documentdata.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[documentdata.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldOwnerID)
				fieldSeen[documentdata.FieldOwnerID] = struct{}{}
			}

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			_q.withTemplate = query
			if _, ok := fieldSeen[documentdata.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTemplateID)
				fieldSeen[documentdata.FieldTemplateID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DocumentData) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"document_data_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(documentdata.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(documentdata.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(documentdata.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(documentdata.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(documentdata.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DocumentData) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(documentdata.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DocumentData) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"document_data_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(documentdata.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(documentdata.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(documentdata.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(documentdata.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(documentdata.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DocumentData) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(documentdata.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[documentdata.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldCreatedAt)
				fieldSeen[documentdata.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[documentdata.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldUpdatedAt)
				fieldSeen[documentdata.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[documentdata.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldCreatedBy)
				fieldSeen[documentdata.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[documentdata.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldUpdatedBy)
				fieldSeen[documentdata.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[documentdata.FieldTags]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTags)
				fieldSeen[documentdata.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[documentdata.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldOwnerID)
				fieldSeen[documentdata.FieldOwnerID] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[documentdata.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTemplateID)
				fieldSeen[documentdata.FieldTemplateID] = struct{}{}
			}
		case "data":
			if _, ok := fieldSeen[documentdata.FieldData]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldData)
				fieldSeen[documentdata.FieldData] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type documentdataPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DocumentDataPaginateOption
}

func newDocumentDataPaginateArgs(rv map[string]any) *documentdataPaginateArgs {
	args := &documentdataPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DocumentDataOrder:
			args.opts = append(args.opts, WithDocumentDataOrder(v))
		case []any:
			var orders []*DocumentDataOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DocumentDataOrder{Field: &DocumentDataOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDocumentDataOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DocumentDataWhereInput); ok {
		args.opts = append(args.opts, WithDocumentDataFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DocumentDataHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*DocumentDataHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DocumentDataHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(documentdatahistory.Columns))
		selectedFields = []string{documentdatahistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[documentdatahistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldHistoryTime)
				fieldSeen[documentdatahistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[documentdatahistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldRef)
				fieldSeen[documentdatahistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[documentdatahistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldOperation)
				fieldSeen[documentdatahistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[documentdatahistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldCreatedAt)
				fieldSeen[documentdatahistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[documentdatahistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldUpdatedAt)
				fieldSeen[documentdatahistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[documentdatahistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldCreatedBy)
				fieldSeen[documentdatahistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[documentdatahistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldUpdatedBy)
				fieldSeen[documentdatahistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[documentdatahistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldTags)
				fieldSeen[documentdatahistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[documentdatahistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldOwnerID)
				fieldSeen[documentdatahistory.FieldOwnerID] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[documentdatahistory.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldTemplateID)
				fieldSeen[documentdatahistory.FieldTemplateID] = struct{}{}
			}
		case "data":
			if _, ok := fieldSeen[documentdatahistory.FieldData]; !ok {
				selectedFields = append(selectedFields, documentdatahistory.FieldData)
				fieldSeen[documentdatahistory.FieldData] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type documentdatahistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DocumentDataHistoryPaginateOption
}

func newDocumentDataHistoryPaginateArgs(rv map[string]any) *documentdatahistoryPaginateArgs {
	args := &documentdatahistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DocumentDataHistoryOrder{Field: &DocumentDataHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDocumentDataHistoryOrder(order))
			}
		case *DocumentDataHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithDocumentDataHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DocumentDataHistoryWhereInput); ok {
		args.opts = append(args.opts, WithDocumentDataHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EntityQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EntityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entity.Columns))
		selectedFields = []string{entity.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[entity.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entity.FieldOwnerID)
				fieldSeen[entity.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(entity.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(entity.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(entity.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "contacts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: _q.config}).Query()
			)
			args := newContactPaginateArgs(fieldArgs(ctx, new(ContactWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newContactPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.ContactsTable)
							s.Join(joinT).On(s.C(contact.FieldID), joinT.C(entity.ContactsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.ContactsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.ContactsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.ContactsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Contacts)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ContactsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedContacts(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.DocumentsTable)
							s.Join(joinT).On(s.C(documentdata.FieldID), joinT.C(entity.DocumentsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.DocumentsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.DocumentsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.DocumentsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.DocumentsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_notes"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.NotesColumn), ids...))
						})
						if err := query.GroupBy(entity.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(entity.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(entity.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.ScansColumn), ids...))
						})
						if err := query.GroupBy(entity.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entityType":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
				return err
			}
			_q.withEntityType = query
			if _, ok := fieldSeen[entity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entity.FieldEntityTypeID)
				fieldSeen[entity.FieldEntityTypeID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entity.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entity.FieldCreatedAt)
				fieldSeen[entity.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entity.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entity.FieldUpdatedAt)
				fieldSeen[entity.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entity.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entity.FieldCreatedBy)
				fieldSeen[entity.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entity.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entity.FieldUpdatedBy)
				fieldSeen[entity.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entity.FieldTags]; !ok {
				selectedFields = append(selectedFields, entity.FieldTags)
				fieldSeen[entity.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entity.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entity.FieldOwnerID)
				fieldSeen[entity.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[entity.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, entity.FieldSystemOwned)
				fieldSeen[entity.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[entity.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, entity.FieldInternalNotes)
				fieldSeen[entity.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[entity.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, entity.FieldSystemInternalID)
				fieldSeen[entity.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entity.FieldName]; !ok {
				selectedFields = append(selectedFields, entity.FieldName)
				fieldSeen[entity.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[entity.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, entity.FieldDisplayName)
				fieldSeen[entity.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[entity.FieldDescription]; !ok {
				selectedFields = append(selectedFields, entity.FieldDescription)
				fieldSeen[entity.FieldDescription] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[entity.FieldDomains]; !ok {
				selectedFields = append(selectedFields, entity.FieldDomains)
				fieldSeen[entity.FieldDomains] = struct{}{}
			}
		case "entityTypeID":
			if _, ok := fieldSeen[entity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entity.FieldEntityTypeID)
				fieldSeen[entity.FieldEntityTypeID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[entity.FieldStatus]; !ok {
				selectedFields = append(selectedFields, entity.FieldStatus)
				fieldSeen[entity.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type entityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityPaginateOption
}

func newEntityPaginateArgs(rv map[string]any) *entityPaginateArgs {
	args := &entityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EntityOrder:
			args.opts = append(args.opts, WithEntityOrder(v))
		case []any:
			var orders []*EntityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EntityOrder{Field: &EntityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEntityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EntityWhereInput); ok {
		args.opts = append(args.opts, WithEntityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EntityHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EntityHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entityhistory.Columns))
		selectedFields = []string{entityhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[entityhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldHistoryTime)
				fieldSeen[entityhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[entityhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldRef)
				fieldSeen[entityhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[entityhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldOperation)
				fieldSeen[entityhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entityhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldCreatedAt)
				fieldSeen[entityhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entityhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldUpdatedAt)
				fieldSeen[entityhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entityhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldCreatedBy)
				fieldSeen[entityhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entityhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldUpdatedBy)
				fieldSeen[entityhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entityhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldTags)
				fieldSeen[entityhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entityhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldOwnerID)
				fieldSeen[entityhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[entityhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldSystemOwned)
				fieldSeen[entityhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[entityhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldInternalNotes)
				fieldSeen[entityhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[entityhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldSystemInternalID)
				fieldSeen[entityhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entityhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldName)
				fieldSeen[entityhistory.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[entityhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldDisplayName)
				fieldSeen[entityhistory.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[entityhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldDescription)
				fieldSeen[entityhistory.FieldDescription] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[entityhistory.FieldDomains]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldDomains)
				fieldSeen[entityhistory.FieldDomains] = struct{}{}
			}
		case "entityTypeID":
			if _, ok := fieldSeen[entityhistory.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldEntityTypeID)
				fieldSeen[entityhistory.FieldEntityTypeID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[entityhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, entityhistory.FieldStatus)
				fieldSeen[entityhistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type entityhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityHistoryPaginateOption
}

func newEntityHistoryPaginateArgs(rv map[string]any) *entityhistoryPaginateArgs {
	args := &entityhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &EntityHistoryOrder{Field: &EntityHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithEntityHistoryOrder(order))
			}
		case *EntityHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithEntityHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*EntityHistoryWhereInput); ok {
		args.opts = append(args.opts, WithEntityHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EntityTypeQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityTypeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EntityTypeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entitytype.Columns))
		selectedFields = []string{entitytype.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[entitytype.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldOwnerID)
				fieldSeen[entitytype.FieldOwnerID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*EntityType) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_type_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entitytype.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(entitytype.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*EntityType) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entitytype.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[entitytype.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldCreatedAt)
				fieldSeen[entitytype.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entitytype.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldUpdatedAt)
				fieldSeen[entitytype.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entitytype.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldCreatedBy)
				fieldSeen[entitytype.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entitytype.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldUpdatedBy)
				fieldSeen[entitytype.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entitytype.FieldTags]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldTags)
				fieldSeen[entitytype.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entitytype.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldOwnerID)
				fieldSeen[entitytype.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[entitytype.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldSystemOwned)
				fieldSeen[entitytype.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[entitytype.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldInternalNotes)
				fieldSeen[entitytype.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[entitytype.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldSystemInternalID)
				fieldSeen[entitytype.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entitytype.FieldName]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldName)
				fieldSeen[entitytype.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type entitytypePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityTypePaginateOption
}

func newEntityTypePaginateArgs(rv map[string]any) *entitytypePaginateArgs {
	args := &entitytypePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EntityTypeOrder:
			args.opts = append(args.opts, WithEntityTypeOrder(v))
		case []any:
			var orders []*EntityTypeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EntityTypeOrder{Field: &EntityTypeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEntityTypeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EntityTypeWhereInput); ok {
		args.opts = append(args.opts, WithEntityTypeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EntityTypeHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityTypeHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EntityTypeHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entitytypehistory.Columns))
		selectedFields = []string{entitytypehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[entitytypehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldHistoryTime)
				fieldSeen[entitytypehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[entitytypehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldRef)
				fieldSeen[entitytypehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[entitytypehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldOperation)
				fieldSeen[entitytypehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entitytypehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldCreatedAt)
				fieldSeen[entitytypehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entitytypehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldUpdatedAt)
				fieldSeen[entitytypehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entitytypehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldCreatedBy)
				fieldSeen[entitytypehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entitytypehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldUpdatedBy)
				fieldSeen[entitytypehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entitytypehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldTags)
				fieldSeen[entitytypehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entitytypehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldOwnerID)
				fieldSeen[entitytypehistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[entitytypehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldSystemOwned)
				fieldSeen[entitytypehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[entitytypehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldInternalNotes)
				fieldSeen[entitytypehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[entitytypehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldSystemInternalID)
				fieldSeen[entitytypehistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entitytypehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, entitytypehistory.FieldName)
				fieldSeen[entitytypehistory.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type entitytypehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityTypeHistoryPaginateOption
}

func newEntityTypeHistoryPaginateArgs(rv map[string]any) *entitytypehistoryPaginateArgs {
	args := &entitytypehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &EntityTypeHistoryOrder{Field: &EntityTypeHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithEntityTypeHistoryOrder(order))
			}
		case *EntityTypeHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithEntityTypeHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*EntityTypeHistoryWhereInput); ok {
		args.opts = append(args.opts, WithEntityTypeHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EventQuery) CollectFields(ctx context.Context, satisfies ...string) (*EventQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EventQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(event.Columns))
		selectedFields = []string{event.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(event.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(event.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(event.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(event.OrganizationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrganizationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrganizationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrganizationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrganizationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "invites":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InviteClient{config: _q.config}).Query()
			)
			args := newInvitePaginateArgs(fieldArgs(ctx, new(InviteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInvitePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.InvitesTable)
							s.Join(joinT).On(s.C(invite.FieldID), joinT.C(event.InvitesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.InvitesPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.InvitesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.InvitesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Invites)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, inviteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.InvitesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInvites(alias, func(wq *InviteQuery) {
				*wq = *query
			})

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: _q.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.PersonalAccessTokensTable)
							s.Join(joinT).On(s.C(personalaccesstoken.FieldID), joinT.C(event.PersonalAccessTokensPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.PersonalAccessTokensPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.PersonalAccessTokensPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.PersonalAccessTokensPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.PersonalAccessTokensPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(event.SecretsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.SecretsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.SecretsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.SecretsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.SecretsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "orgMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: _q.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrgMembershipsTable)
							s.Join(joinT).On(s.C(orgmembership.FieldID), joinT.C(event.OrgMembershipsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrgMembershipsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrgMembershipsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrgMembershipsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgMemberships)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrgMembershipsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrgMemberships(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})

		case "groupMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: _q.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.GroupMembershipsTable)
							s.Join(joinT).On(s.C(groupmembership.FieldID), joinT.C(event.GroupMembershipsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.GroupMembershipsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.GroupMembershipsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.GroupMembershipsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupMemberships)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.GroupMembershipsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroupMemberships(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})

		case "subscribers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubscriberClient{config: _q.config}).Query()
			)
			args := newSubscriberPaginateArgs(fieldArgs(ctx, new(SubscriberWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubscriberPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.SubscribersTable)
							s.Join(joinT).On(s.C(subscriber.FieldID), joinT.C(event.SubscribersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.SubscribersPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.SubscribersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.SubscribersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subscribers)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subscriberImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.SubscribersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubscribers(alias, func(wq *SubscriberQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(event.FilesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.FilesPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.FilesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.FilesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.FilesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "orgSubscriptions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgSubscriptionClient{config: _q.config}).Query()
			)
			args := newOrgSubscriptionPaginateArgs(fieldArgs(ctx, new(OrgSubscriptionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgSubscriptionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrgSubscriptionsTable)
							s.Join(joinT).On(s.C(orgsubscription.FieldID), joinT.C(event.OrgSubscriptionsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrgSubscriptionsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrgSubscriptionsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrgSubscriptionsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgSubscriptions)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgsubscriptionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrgSubscriptionsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrgSubscriptions(alias, func(wq *OrgSubscriptionQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[event.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, event.FieldCreatedAt)
				fieldSeen[event.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[event.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, event.FieldUpdatedAt)
				fieldSeen[event.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[event.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, event.FieldCreatedBy)
				fieldSeen[event.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[event.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, event.FieldUpdatedBy)
				fieldSeen[event.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[event.FieldTags]; !ok {
				selectedFields = append(selectedFields, event.FieldTags)
				fieldSeen[event.FieldTags] = struct{}{}
			}
		case "eventID":
			if _, ok := fieldSeen[event.FieldEventID]; !ok {
				selectedFields = append(selectedFields, event.FieldEventID)
				fieldSeen[event.FieldEventID] = struct{}{}
			}
		case "correlationID":
			if _, ok := fieldSeen[event.FieldCorrelationID]; !ok {
				selectedFields = append(selectedFields, event.FieldCorrelationID)
				fieldSeen[event.FieldCorrelationID] = struct{}{}
			}
		case "eventType":
			if _, ok := fieldSeen[event.FieldEventType]; !ok {
				selectedFields = append(selectedFields, event.FieldEventType)
				fieldSeen[event.FieldEventType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[event.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, event.FieldMetadata)
				fieldSeen[event.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type eventPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EventPaginateOption
}

func newEventPaginateArgs(rv map[string]any) *eventPaginateArgs {
	args := &eventPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EventOrder:
			args.opts = append(args.opts, WithEventOrder(v))
		case []any:
			var orders []*EventOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EventOrder{Field: &EventOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEventOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EventWhereInput); ok {
		args.opts = append(args.opts, WithEventFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EvidenceQuery) CollectFields(ctx context.Context, satisfies ...string) (*EvidenceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EvidenceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(evidence.Columns))
		selectedFields = []string{evidence.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[evidence.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldOwnerID)
				fieldSeen[evidence.FieldOwnerID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(evidence.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(evidence.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(evidence.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_control_implementations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(evidence.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(evidence.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(evidence.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(evidence.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(evidence.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(evidence.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(evidence.TasksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(evidence.TasksPrimaryKey[1]), ids...))
							s.Select(joinT.C(evidence.TasksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.TasksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.TasksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[evidence.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreatedAt)
				fieldSeen[evidence.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[evidence.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, evidence.FieldUpdatedAt)
				fieldSeen[evidence.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[evidence.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreatedBy)
				fieldSeen[evidence.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[evidence.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, evidence.FieldUpdatedBy)
				fieldSeen[evidence.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[evidence.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldDisplayID)
				fieldSeen[evidence.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[evidence.FieldTags]; !ok {
				selectedFields = append(selectedFields, evidence.FieldTags)
				fieldSeen[evidence.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[evidence.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldOwnerID)
				fieldSeen[evidence.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[evidence.FieldName]; !ok {
				selectedFields = append(selectedFields, evidence.FieldName)
				fieldSeen[evidence.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[evidence.FieldDescription]; !ok {
				selectedFields = append(selectedFields, evidence.FieldDescription)
				fieldSeen[evidence.FieldDescription] = struct{}{}
			}
		case "collectionProcedure":
			if _, ok := fieldSeen[evidence.FieldCollectionProcedure]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCollectionProcedure)
				fieldSeen[evidence.FieldCollectionProcedure] = struct{}{}
			}
		case "creationDate":
			if _, ok := fieldSeen[evidence.FieldCreationDate]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreationDate)
				fieldSeen[evidence.FieldCreationDate] = struct{}{}
			}
		case "renewalDate":
			if _, ok := fieldSeen[evidence.FieldRenewalDate]; !ok {
				selectedFields = append(selectedFields, evidence.FieldRenewalDate)
				fieldSeen[evidence.FieldRenewalDate] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[evidence.FieldSource]; !ok {
				selectedFields = append(selectedFields, evidence.FieldSource)
				fieldSeen[evidence.FieldSource] = struct{}{}
			}
		case "isAutomated":
			if _, ok := fieldSeen[evidence.FieldIsAutomated]; !ok {
				selectedFields = append(selectedFields, evidence.FieldIsAutomated)
				fieldSeen[evidence.FieldIsAutomated] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[evidence.FieldURL]; !ok {
				selectedFields = append(selectedFields, evidence.FieldURL)
				fieldSeen[evidence.FieldURL] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[evidence.FieldStatus]; !ok {
				selectedFields = append(selectedFields, evidence.FieldStatus)
				fieldSeen[evidence.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type evidencePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EvidencePaginateOption
}

func newEvidencePaginateArgs(rv map[string]any) *evidencePaginateArgs {
	args := &evidencePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EvidenceOrder:
			args.opts = append(args.opts, WithEvidenceOrder(v))
		case []any:
			var orders []*EvidenceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EvidenceOrder{Field: &EvidenceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEvidenceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EvidenceWhereInput); ok {
		args.opts = append(args.opts, WithEvidenceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EvidenceHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*EvidenceHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EvidenceHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(evidencehistory.Columns))
		selectedFields = []string{evidencehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[evidencehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldHistoryTime)
				fieldSeen[evidencehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[evidencehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldRef)
				fieldSeen[evidencehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[evidencehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldOperation)
				fieldSeen[evidencehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[evidencehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCreatedAt)
				fieldSeen[evidencehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[evidencehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldUpdatedAt)
				fieldSeen[evidencehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[evidencehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCreatedBy)
				fieldSeen[evidencehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[evidencehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldUpdatedBy)
				fieldSeen[evidencehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[evidencehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldDisplayID)
				fieldSeen[evidencehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[evidencehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldTags)
				fieldSeen[evidencehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[evidencehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldOwnerID)
				fieldSeen[evidencehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[evidencehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldName)
				fieldSeen[evidencehistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[evidencehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldDescription)
				fieldSeen[evidencehistory.FieldDescription] = struct{}{}
			}
		case "collectionProcedure":
			if _, ok := fieldSeen[evidencehistory.FieldCollectionProcedure]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCollectionProcedure)
				fieldSeen[evidencehistory.FieldCollectionProcedure] = struct{}{}
			}
		case "creationDate":
			if _, ok := fieldSeen[evidencehistory.FieldCreationDate]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldCreationDate)
				fieldSeen[evidencehistory.FieldCreationDate] = struct{}{}
			}
		case "renewalDate":
			if _, ok := fieldSeen[evidencehistory.FieldRenewalDate]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldRenewalDate)
				fieldSeen[evidencehistory.FieldRenewalDate] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[evidencehistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldSource)
				fieldSeen[evidencehistory.FieldSource] = struct{}{}
			}
		case "isAutomated":
			if _, ok := fieldSeen[evidencehistory.FieldIsAutomated]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldIsAutomated)
				fieldSeen[evidencehistory.FieldIsAutomated] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[evidencehistory.FieldURL]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldURL)
				fieldSeen[evidencehistory.FieldURL] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[evidencehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, evidencehistory.FieldStatus)
				fieldSeen[evidencehistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type evidencehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EvidenceHistoryPaginateOption
}

func newEvidenceHistoryPaginateArgs(rv map[string]any) *evidencehistoryPaginateArgs {
	args := &evidencehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &EvidenceHistoryOrder{Field: &EvidenceHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithEvidenceHistoryOrder(order))
			}
		case *EvidenceHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithEvidenceHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*EvidenceHistoryWhereInput); ok {
		args.opts = append(args.opts, WithEvidenceHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ExportQuery) CollectFields(ctx context.Context, satisfies ...string) (*ExportQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ExportQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(export.Columns))
		selectedFields = []string{export.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[export.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, export.FieldOwnerID)
				fieldSeen[export.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Export) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"export_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(export.EventsColumn), ids...))
						})
						if err := query.GroupBy(export.EventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Export) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(export.EventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Export) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"export_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(export.FilesColumn), ids...))
						})
						if err := query.GroupBy(export.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Export) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(export.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[export.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, export.FieldCreatedAt)
				fieldSeen[export.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[export.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, export.FieldUpdatedAt)
				fieldSeen[export.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[export.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, export.FieldCreatedBy)
				fieldSeen[export.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[export.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, export.FieldUpdatedBy)
				fieldSeen[export.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[export.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, export.FieldOwnerID)
				fieldSeen[export.FieldOwnerID] = struct{}{}
			}
		case "exportType":
			if _, ok := fieldSeen[export.FieldExportType]; !ok {
				selectedFields = append(selectedFields, export.FieldExportType)
				fieldSeen[export.FieldExportType] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[export.FieldFormat]; !ok {
				selectedFields = append(selectedFields, export.FieldFormat)
				fieldSeen[export.FieldFormat] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[export.FieldStatus]; !ok {
				selectedFields = append(selectedFields, export.FieldStatus)
				fieldSeen[export.FieldStatus] = struct{}{}
			}
		case "requestorID":
			if _, ok := fieldSeen[export.FieldRequestorID]; !ok {
				selectedFields = append(selectedFields, export.FieldRequestorID)
				fieldSeen[export.FieldRequestorID] = struct{}{}
			}
		case "fields":
			if _, ok := fieldSeen[export.FieldFields]; !ok {
				selectedFields = append(selectedFields, export.FieldFields)
				fieldSeen[export.FieldFields] = struct{}{}
			}
		case "filters":
			if _, ok := fieldSeen[export.FieldFilters]; !ok {
				selectedFields = append(selectedFields, export.FieldFilters)
				fieldSeen[export.FieldFilters] = struct{}{}
			}
		case "errorMessage":
			if _, ok := fieldSeen[export.FieldErrorMessage]; !ok {
				selectedFields = append(selectedFields, export.FieldErrorMessage)
				fieldSeen[export.FieldErrorMessage] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type exportPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ExportPaginateOption
}

func newExportPaginateArgs(rv map[string]any) *exportPaginateArgs {
	args := &exportPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ExportOrder:
			args.opts = append(args.opts, WithExportOrder(v))
		case []any:
			var orders []*ExportOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ExportOrder{Field: &ExportOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithExportOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ExportWhereInput); ok {
		args.opts = append(args.opts, WithExportFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FileQuery) CollectFields(ctx context.Context, satisfies ...string) (*FileQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FileQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(file.Columns))
		selectedFields = []string{file.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.WithNamedOrganization(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(file.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(file.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(file.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(file.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "contact":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
				return err
			}
			_q.WithNamedContact(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "entity":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			_q.WithNamedEntity(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "organizationSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, organizationsettingImplementors)...); err != nil {
				return err
			}
			_q.WithNamedOrganizationSetting(alias, func(wq *OrganizationSettingQuery) {
				*wq = *query
			})

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTemplate(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "document":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
				return err
			}
			_q.WithNamedDocument(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "program":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
				return err
			}
			_q.WithNamedProgram(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
				return err
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(file.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(file.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(file.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(file.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "trustCenterSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTrustCenterSetting(alias, func(wq *TrustCenterSettingQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_integrations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(file.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(file.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(file.SecretsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(file.SecretsPrimaryKey[0]), ids...))
							s.Select(joinT.C(file.SecretsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(file.SecretsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.SecretsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "trustcenterEntity":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustcenterEntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, trustcenterentityImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTrustcenterEntity(alias, func(wq *TrustcenterEntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[file.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedAt)
				fieldSeen[file.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[file.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldUpdatedAt)
				fieldSeen[file.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[file.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedBy)
				fieldSeen[file.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[file.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, file.FieldUpdatedBy)
				fieldSeen[file.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[file.FieldTags]; !ok {
				selectedFields = append(selectedFields, file.FieldTags)
				fieldSeen[file.FieldTags] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[file.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, file.FieldSystemOwned)
				fieldSeen[file.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[file.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, file.FieldInternalNotes)
				fieldSeen[file.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[file.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, file.FieldSystemInternalID)
				fieldSeen[file.FieldSystemInternalID] = struct{}{}
			}
		case "providedFileName":
			if _, ok := fieldSeen[file.FieldProvidedFileName]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileName)
				fieldSeen[file.FieldProvidedFileName] = struct{}{}
			}
		case "providedFileExtension":
			if _, ok := fieldSeen[file.FieldProvidedFileExtension]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileExtension)
				fieldSeen[file.FieldProvidedFileExtension] = struct{}{}
			}
		case "providedFileSize":
			if _, ok := fieldSeen[file.FieldProvidedFileSize]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileSize)
				fieldSeen[file.FieldProvidedFileSize] = struct{}{}
			}
		case "persistedFileSize":
			if _, ok := fieldSeen[file.FieldPersistedFileSize]; !ok {
				selectedFields = append(selectedFields, file.FieldPersistedFileSize)
				fieldSeen[file.FieldPersistedFileSize] = struct{}{}
			}
		case "detectedMimeType":
			if _, ok := fieldSeen[file.FieldDetectedMimeType]; !ok {
				selectedFields = append(selectedFields, file.FieldDetectedMimeType)
				fieldSeen[file.FieldDetectedMimeType] = struct{}{}
			}
		case "md5Hash":
			if _, ok := fieldSeen[file.FieldMd5Hash]; !ok {
				selectedFields = append(selectedFields, file.FieldMd5Hash)
				fieldSeen[file.FieldMd5Hash] = struct{}{}
			}
		case "detectedContentType":
			if _, ok := fieldSeen[file.FieldDetectedContentType]; !ok {
				selectedFields = append(selectedFields, file.FieldDetectedContentType)
				fieldSeen[file.FieldDetectedContentType] = struct{}{}
			}
		case "storeKey":
			if _, ok := fieldSeen[file.FieldStoreKey]; !ok {
				selectedFields = append(selectedFields, file.FieldStoreKey)
				fieldSeen[file.FieldStoreKey] = struct{}{}
			}
		case "categoryType":
			if _, ok := fieldSeen[file.FieldCategoryType]; !ok {
				selectedFields = append(selectedFields, file.FieldCategoryType)
				fieldSeen[file.FieldCategoryType] = struct{}{}
			}
		case "uri":
			if _, ok := fieldSeen[file.FieldURI]; !ok {
				selectedFields = append(selectedFields, file.FieldURI)
				fieldSeen[file.FieldURI] = struct{}{}
			}
		case "storageScheme":
			if _, ok := fieldSeen[file.FieldStorageScheme]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageScheme)
				fieldSeen[file.FieldStorageScheme] = struct{}{}
			}
		case "storageVolume":
			if _, ok := fieldSeen[file.FieldStorageVolume]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageVolume)
				fieldSeen[file.FieldStorageVolume] = struct{}{}
			}
		case "storagePath":
			if _, ok := fieldSeen[file.FieldStoragePath]; !ok {
				selectedFields = append(selectedFields, file.FieldStoragePath)
				fieldSeen[file.FieldStoragePath] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[file.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, file.FieldMetadata)
				fieldSeen[file.FieldMetadata] = struct{}{}
			}
		case "storageRegion":
			if _, ok := fieldSeen[file.FieldStorageRegion]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageRegion)
				fieldSeen[file.FieldStorageRegion] = struct{}{}
			}
		case "storageProvider":
			if _, ok := fieldSeen[file.FieldStorageProvider]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageProvider)
				fieldSeen[file.FieldStorageProvider] = struct{}{}
			}
		case "lastAccessedAt":
			if _, ok := fieldSeen[file.FieldLastAccessedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldLastAccessedAt)
				fieldSeen[file.FieldLastAccessedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type filePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FilePaginateOption
}

func newFilePaginateArgs(rv map[string]any) *filePaginateArgs {
	args := &filePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FileOrder:
			args.opts = append(args.opts, WithFileOrder(v))
		case []any:
			var orders []*FileOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FileOrder{Field: &FileOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFileOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FileWhereInput); ok {
		args.opts = append(args.opts, WithFileFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FileHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*FileHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FileHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(filehistory.Columns))
		selectedFields = []string{filehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[filehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldHistoryTime)
				fieldSeen[filehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[filehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldRef)
				fieldSeen[filehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[filehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldOperation)
				fieldSeen[filehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[filehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldCreatedAt)
				fieldSeen[filehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[filehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldUpdatedAt)
				fieldSeen[filehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[filehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldCreatedBy)
				fieldSeen[filehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[filehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldUpdatedBy)
				fieldSeen[filehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[filehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldTags)
				fieldSeen[filehistory.FieldTags] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[filehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldSystemOwned)
				fieldSeen[filehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[filehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldInternalNotes)
				fieldSeen[filehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[filehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldSystemInternalID)
				fieldSeen[filehistory.FieldSystemInternalID] = struct{}{}
			}
		case "providedFileName":
			if _, ok := fieldSeen[filehistory.FieldProvidedFileName]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldProvidedFileName)
				fieldSeen[filehistory.FieldProvidedFileName] = struct{}{}
			}
		case "providedFileExtension":
			if _, ok := fieldSeen[filehistory.FieldProvidedFileExtension]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldProvidedFileExtension)
				fieldSeen[filehistory.FieldProvidedFileExtension] = struct{}{}
			}
		case "providedFileSize":
			if _, ok := fieldSeen[filehistory.FieldProvidedFileSize]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldProvidedFileSize)
				fieldSeen[filehistory.FieldProvidedFileSize] = struct{}{}
			}
		case "persistedFileSize":
			if _, ok := fieldSeen[filehistory.FieldPersistedFileSize]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldPersistedFileSize)
				fieldSeen[filehistory.FieldPersistedFileSize] = struct{}{}
			}
		case "detectedMimeType":
			if _, ok := fieldSeen[filehistory.FieldDetectedMimeType]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldDetectedMimeType)
				fieldSeen[filehistory.FieldDetectedMimeType] = struct{}{}
			}
		case "md5Hash":
			if _, ok := fieldSeen[filehistory.FieldMd5Hash]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldMd5Hash)
				fieldSeen[filehistory.FieldMd5Hash] = struct{}{}
			}
		case "detectedContentType":
			if _, ok := fieldSeen[filehistory.FieldDetectedContentType]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldDetectedContentType)
				fieldSeen[filehistory.FieldDetectedContentType] = struct{}{}
			}
		case "storeKey":
			if _, ok := fieldSeen[filehistory.FieldStoreKey]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStoreKey)
				fieldSeen[filehistory.FieldStoreKey] = struct{}{}
			}
		case "categoryType":
			if _, ok := fieldSeen[filehistory.FieldCategoryType]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldCategoryType)
				fieldSeen[filehistory.FieldCategoryType] = struct{}{}
			}
		case "uri":
			if _, ok := fieldSeen[filehistory.FieldURI]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldURI)
				fieldSeen[filehistory.FieldURI] = struct{}{}
			}
		case "storageScheme":
			if _, ok := fieldSeen[filehistory.FieldStorageScheme]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStorageScheme)
				fieldSeen[filehistory.FieldStorageScheme] = struct{}{}
			}
		case "storageVolume":
			if _, ok := fieldSeen[filehistory.FieldStorageVolume]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStorageVolume)
				fieldSeen[filehistory.FieldStorageVolume] = struct{}{}
			}
		case "storagePath":
			if _, ok := fieldSeen[filehistory.FieldStoragePath]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStoragePath)
				fieldSeen[filehistory.FieldStoragePath] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[filehistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldMetadata)
				fieldSeen[filehistory.FieldMetadata] = struct{}{}
			}
		case "storageRegion":
			if _, ok := fieldSeen[filehistory.FieldStorageRegion]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStorageRegion)
				fieldSeen[filehistory.FieldStorageRegion] = struct{}{}
			}
		case "storageProvider":
			if _, ok := fieldSeen[filehistory.FieldStorageProvider]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldStorageProvider)
				fieldSeen[filehistory.FieldStorageProvider] = struct{}{}
			}
		case "lastAccessedAt":
			if _, ok := fieldSeen[filehistory.FieldLastAccessedAt]; !ok {
				selectedFields = append(selectedFields, filehistory.FieldLastAccessedAt)
				fieldSeen[filehistory.FieldLastAccessedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type filehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FileHistoryPaginateOption
}

func newFileHistoryPaginateArgs(rv map[string]any) *filehistoryPaginateArgs {
	args := &filehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &FileHistoryOrder{Field: &FileHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithFileHistoryOrder(order))
			}
		case *FileHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithFileHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*FileHistoryWhereInput); ok {
		args.opts = append(args.opts, WithFileHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FindingQuery) CollectFields(ctx context.Context, satisfies ...string) (*FindingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FindingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(finding.Columns))
		selectedFields = []string{finding.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[finding.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, finding.FieldOwnerID)
				fieldSeen[finding.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(finding.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.EditorsColumn), ids...))
						})
						if err := query.GroupBy(finding.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ViewersColumn), ids...))
						})
						if err := query.GroupBy(finding.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(finding.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(finding.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(finding.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(finding.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(finding.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_vulnerabilities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(finding.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(finding.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(finding.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(finding.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(finding.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(finding.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(finding.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(finding.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(finding.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(finding.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(finding.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(finding.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.RisksColumn), ids...))
						})
						if err := query.GroupBy(finding.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(finding.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.AssetsColumn), ids...))
						})
						if err := query.GroupBy(finding.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(finding.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ScansColumn), ids...))
						})
						if err := query.GroupBy(finding.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.TasksColumn), ids...))
						})
						if err := query.GroupBy(finding.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_remediations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(finding.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_reviews"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(finding.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.CommentsColumn), ids...))
						})
						if err := query.GroupBy(finding.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.FilesColumn), ids...))
						})
						if err := query.GroupBy(finding.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(finding.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "controlMappings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingControlClient{config: _q.config}).Query()
			)
			args := newFindingControlPaginateArgs(fieldArgs(ctx, new(FindingControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ControlMappingsColumn), ids...))
						})
						if err := query.GroupBy(finding.ControlMappingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlMappings)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ControlMappingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlMappings(alias, func(wq *FindingControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[finding.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldCreatedAt)
				fieldSeen[finding.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[finding.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldUpdatedAt)
				fieldSeen[finding.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[finding.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, finding.FieldCreatedBy)
				fieldSeen[finding.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[finding.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, finding.FieldUpdatedBy)
				fieldSeen[finding.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[finding.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, finding.FieldDisplayID)
				fieldSeen[finding.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[finding.FieldTags]; !ok {
				selectedFields = append(selectedFields, finding.FieldTags)
				fieldSeen[finding.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[finding.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, finding.FieldOwnerID)
				fieldSeen[finding.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[finding.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, finding.FieldSystemOwned)
				fieldSeen[finding.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[finding.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, finding.FieldInternalNotes)
				fieldSeen[finding.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[finding.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, finding.FieldSystemInternalID)
				fieldSeen[finding.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[finding.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, finding.FieldExternalID)
				fieldSeen[finding.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[finding.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, finding.FieldExternalOwnerID)
				fieldSeen[finding.FieldExternalOwnerID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[finding.FieldSource]; !ok {
				selectedFields = append(selectedFields, finding.FieldSource)
				fieldSeen[finding.FieldSource] = struct{}{}
			}
		case "resourceName":
			if _, ok := fieldSeen[finding.FieldResourceName]; !ok {
				selectedFields = append(selectedFields, finding.FieldResourceName)
				fieldSeen[finding.FieldResourceName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[finding.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, finding.FieldDisplayName)
				fieldSeen[finding.FieldDisplayName] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[finding.FieldState]; !ok {
				selectedFields = append(selectedFields, finding.FieldState)
				fieldSeen[finding.FieldState] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[finding.FieldCategory]; !ok {
				selectedFields = append(selectedFields, finding.FieldCategory)
				fieldSeen[finding.FieldCategory] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[finding.FieldCategories]; !ok {
				selectedFields = append(selectedFields, finding.FieldCategories)
				fieldSeen[finding.FieldCategories] = struct{}{}
			}
		case "findingClass":
			if _, ok := fieldSeen[finding.FieldFindingClass]; !ok {
				selectedFields = append(selectedFields, finding.FieldFindingClass)
				fieldSeen[finding.FieldFindingClass] = struct{}{}
			}
		case "severity":
			if _, ok := fieldSeen[finding.FieldSeverity]; !ok {
				selectedFields = append(selectedFields, finding.FieldSeverity)
				fieldSeen[finding.FieldSeverity] = struct{}{}
			}
		case "numericSeverity":
			if _, ok := fieldSeen[finding.FieldNumericSeverity]; !ok {
				selectedFields = append(selectedFields, finding.FieldNumericSeverity)
				fieldSeen[finding.FieldNumericSeverity] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[finding.FieldScore]; !ok {
				selectedFields = append(selectedFields, finding.FieldScore)
				fieldSeen[finding.FieldScore] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[finding.FieldImpact]; !ok {
				selectedFields = append(selectedFields, finding.FieldImpact)
				fieldSeen[finding.FieldImpact] = struct{}{}
			}
		case "exploitability":
			if _, ok := fieldSeen[finding.FieldExploitability]; !ok {
				selectedFields = append(selectedFields, finding.FieldExploitability)
				fieldSeen[finding.FieldExploitability] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[finding.FieldPriority]; !ok {
				selectedFields = append(selectedFields, finding.FieldPriority)
				fieldSeen[finding.FieldPriority] = struct{}{}
			}
		case "open":
			if _, ok := fieldSeen[finding.FieldOpen]; !ok {
				selectedFields = append(selectedFields, finding.FieldOpen)
				fieldSeen[finding.FieldOpen] = struct{}{}
			}
		case "blocksProduction":
			if _, ok := fieldSeen[finding.FieldBlocksProduction]; !ok {
				selectedFields = append(selectedFields, finding.FieldBlocksProduction)
				fieldSeen[finding.FieldBlocksProduction] = struct{}{}
			}
		case "production":
			if _, ok := fieldSeen[finding.FieldProduction]; !ok {
				selectedFields = append(selectedFields, finding.FieldProduction)
				fieldSeen[finding.FieldProduction] = struct{}{}
			}
		case "public":
			if _, ok := fieldSeen[finding.FieldPublic]; !ok {
				selectedFields = append(selectedFields, finding.FieldPublic)
				fieldSeen[finding.FieldPublic] = struct{}{}
			}
		case "validated":
			if _, ok := fieldSeen[finding.FieldValidated]; !ok {
				selectedFields = append(selectedFields, finding.FieldValidated)
				fieldSeen[finding.FieldValidated] = struct{}{}
			}
		case "assessmentID":
			if _, ok := fieldSeen[finding.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, finding.FieldAssessmentID)
				fieldSeen[finding.FieldAssessmentID] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[finding.FieldDescription]; !ok {
				selectedFields = append(selectedFields, finding.FieldDescription)
				fieldSeen[finding.FieldDescription] = struct{}{}
			}
		case "recommendation":
			if _, ok := fieldSeen[finding.FieldRecommendation]; !ok {
				selectedFields = append(selectedFields, finding.FieldRecommendation)
				fieldSeen[finding.FieldRecommendation] = struct{}{}
			}
		case "recommendedActions":
			if _, ok := fieldSeen[finding.FieldRecommendedActions]; !ok {
				selectedFields = append(selectedFields, finding.FieldRecommendedActions)
				fieldSeen[finding.FieldRecommendedActions] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[finding.FieldReferences]; !ok {
				selectedFields = append(selectedFields, finding.FieldReferences)
				fieldSeen[finding.FieldReferences] = struct{}{}
			}
		case "stepsToReproduce":
			if _, ok := fieldSeen[finding.FieldStepsToReproduce]; !ok {
				selectedFields = append(selectedFields, finding.FieldStepsToReproduce)
				fieldSeen[finding.FieldStepsToReproduce] = struct{}{}
			}
		case "targets":
			if _, ok := fieldSeen[finding.FieldTargets]; !ok {
				selectedFields = append(selectedFields, finding.FieldTargets)
				fieldSeen[finding.FieldTargets] = struct{}{}
			}
		case "targetDetails":
			if _, ok := fieldSeen[finding.FieldTargetDetails]; !ok {
				selectedFields = append(selectedFields, finding.FieldTargetDetails)
				fieldSeen[finding.FieldTargetDetails] = struct{}{}
			}
		case "vector":
			if _, ok := fieldSeen[finding.FieldVector]; !ok {
				selectedFields = append(selectedFields, finding.FieldVector)
				fieldSeen[finding.FieldVector] = struct{}{}
			}
		case "remediationSLA":
			if _, ok := fieldSeen[finding.FieldRemediationSLA]; !ok {
				selectedFields = append(selectedFields, finding.FieldRemediationSLA)
				fieldSeen[finding.FieldRemediationSLA] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[finding.FieldStatus]; !ok {
				selectedFields = append(selectedFields, finding.FieldStatus)
				fieldSeen[finding.FieldStatus] = struct{}{}
			}
		case "eventTime":
			if _, ok := fieldSeen[finding.FieldEventTime]; !ok {
				selectedFields = append(selectedFields, finding.FieldEventTime)
				fieldSeen[finding.FieldEventTime] = struct{}{}
			}
		case "reportedAt":
			if _, ok := fieldSeen[finding.FieldReportedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldReportedAt)
				fieldSeen[finding.FieldReportedAt] = struct{}{}
			}
		case "sourceUpdatedAt":
			if _, ok := fieldSeen[finding.FieldSourceUpdatedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldSourceUpdatedAt)
				fieldSeen[finding.FieldSourceUpdatedAt] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[finding.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, finding.FieldExternalURI)
				fieldSeen[finding.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[finding.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, finding.FieldMetadata)
				fieldSeen[finding.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[finding.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, finding.FieldRawPayload)
				fieldSeen[finding.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type findingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FindingPaginateOption
}

func newFindingPaginateArgs(rv map[string]any) *findingPaginateArgs {
	args := &findingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FindingOrder:
			args.opts = append(args.opts, WithFindingOrder(v))
		case []any:
			var orders []*FindingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FindingOrder{Field: &FindingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFindingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FindingWhereInput); ok {
		args.opts = append(args.opts, WithFindingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FindingControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*FindingControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FindingControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(findingcontrol.Columns))
		selectedFields = []string{findingcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "finding":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
				return err
			}
			_q.withFinding = query
			if _, ok := fieldSeen[findingcontrol.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldFindingID)
				fieldSeen[findingcontrol.FieldFindingID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[findingcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldControlID)
				fieldSeen[findingcontrol.FieldControlID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[findingcontrol.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldStandardID)
				fieldSeen[findingcontrol.FieldStandardID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[findingcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldCreatedAt)
				fieldSeen[findingcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[findingcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldUpdatedAt)
				fieldSeen[findingcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[findingcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldCreatedBy)
				fieldSeen[findingcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[findingcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldUpdatedBy)
				fieldSeen[findingcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "findingID":
			if _, ok := fieldSeen[findingcontrol.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldFindingID)
				fieldSeen[findingcontrol.FieldFindingID] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[findingcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldControlID)
				fieldSeen[findingcontrol.FieldControlID] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[findingcontrol.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldStandardID)
				fieldSeen[findingcontrol.FieldStandardID] = struct{}{}
			}
		case "externalStandard":
			if _, ok := fieldSeen[findingcontrol.FieldExternalStandard]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldExternalStandard)
				fieldSeen[findingcontrol.FieldExternalStandard] = struct{}{}
			}
		case "externalStandardVersion":
			if _, ok := fieldSeen[findingcontrol.FieldExternalStandardVersion]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldExternalStandardVersion)
				fieldSeen[findingcontrol.FieldExternalStandardVersion] = struct{}{}
			}
		case "externalControlID":
			if _, ok := fieldSeen[findingcontrol.FieldExternalControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldExternalControlID)
				fieldSeen[findingcontrol.FieldExternalControlID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[findingcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldSource)
				fieldSeen[findingcontrol.FieldSource] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[findingcontrol.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldMetadata)
				fieldSeen[findingcontrol.FieldMetadata] = struct{}{}
			}
		case "discoveredAt":
			if _, ok := fieldSeen[findingcontrol.FieldDiscoveredAt]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldDiscoveredAt)
				fieldSeen[findingcontrol.FieldDiscoveredAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type findingcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FindingControlPaginateOption
}

func newFindingControlPaginateArgs(rv map[string]any) *findingcontrolPaginateArgs {
	args := &findingcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FindingControlOrder:
			args.opts = append(args.opts, WithFindingControlOrder(v))
		case []any:
			var orders []*FindingControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FindingControlOrder{Field: &FindingControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFindingControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FindingControlWhereInput); ok {
		args.opts = append(args.opts, WithFindingControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FindingControlHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*FindingControlHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FindingControlHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(findingcontrolhistory.Columns))
		selectedFields = []string{findingcontrolhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[findingcontrolhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldHistoryTime)
				fieldSeen[findingcontrolhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[findingcontrolhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldRef)
				fieldSeen[findingcontrolhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[findingcontrolhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldOperation)
				fieldSeen[findingcontrolhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[findingcontrolhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldCreatedAt)
				fieldSeen[findingcontrolhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[findingcontrolhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldUpdatedAt)
				fieldSeen[findingcontrolhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[findingcontrolhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldCreatedBy)
				fieldSeen[findingcontrolhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[findingcontrolhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldUpdatedBy)
				fieldSeen[findingcontrolhistory.FieldUpdatedBy] = struct{}{}
			}
		case "findingID":
			if _, ok := fieldSeen[findingcontrolhistory.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldFindingID)
				fieldSeen[findingcontrolhistory.FieldFindingID] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[findingcontrolhistory.FieldControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldControlID)
				fieldSeen[findingcontrolhistory.FieldControlID] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[findingcontrolhistory.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldStandardID)
				fieldSeen[findingcontrolhistory.FieldStandardID] = struct{}{}
			}
		case "externalStandard":
			if _, ok := fieldSeen[findingcontrolhistory.FieldExternalStandard]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldExternalStandard)
				fieldSeen[findingcontrolhistory.FieldExternalStandard] = struct{}{}
			}
		case "externalStandardVersion":
			if _, ok := fieldSeen[findingcontrolhistory.FieldExternalStandardVersion]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldExternalStandardVersion)
				fieldSeen[findingcontrolhistory.FieldExternalStandardVersion] = struct{}{}
			}
		case "externalControlID":
			if _, ok := fieldSeen[findingcontrolhistory.FieldExternalControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldExternalControlID)
				fieldSeen[findingcontrolhistory.FieldExternalControlID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[findingcontrolhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldSource)
				fieldSeen[findingcontrolhistory.FieldSource] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[findingcontrolhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldMetadata)
				fieldSeen[findingcontrolhistory.FieldMetadata] = struct{}{}
			}
		case "discoveredAt":
			if _, ok := fieldSeen[findingcontrolhistory.FieldDiscoveredAt]; !ok {
				selectedFields = append(selectedFields, findingcontrolhistory.FieldDiscoveredAt)
				fieldSeen[findingcontrolhistory.FieldDiscoveredAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type findingcontrolhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FindingControlHistoryPaginateOption
}

func newFindingControlHistoryPaginateArgs(rv map[string]any) *findingcontrolhistoryPaginateArgs {
	args := &findingcontrolhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &FindingControlHistoryOrder{Field: &FindingControlHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithFindingControlHistoryOrder(order))
			}
		case *FindingControlHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithFindingControlHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*FindingControlHistoryWhereInput); ok {
		args.opts = append(args.opts, WithFindingControlHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FindingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*FindingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FindingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(findinghistory.Columns))
		selectedFields = []string{findinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[findinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldHistoryTime)
				fieldSeen[findinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[findinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldRef)
				fieldSeen[findinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[findinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldOperation)
				fieldSeen[findinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[findinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldCreatedAt)
				fieldSeen[findinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[findinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldUpdatedAt)
				fieldSeen[findinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[findinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldCreatedBy)
				fieldSeen[findinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[findinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldUpdatedBy)
				fieldSeen[findinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[findinghistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldDisplayID)
				fieldSeen[findinghistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[findinghistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldTags)
				fieldSeen[findinghistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[findinghistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldOwnerID)
				fieldSeen[findinghistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[findinghistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldSystemOwned)
				fieldSeen[findinghistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[findinghistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldInternalNotes)
				fieldSeen[findinghistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[findinghistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldSystemInternalID)
				fieldSeen[findinghistory.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[findinghistory.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldExternalID)
				fieldSeen[findinghistory.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[findinghistory.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldExternalOwnerID)
				fieldSeen[findinghistory.FieldExternalOwnerID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[findinghistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldSource)
				fieldSeen[findinghistory.FieldSource] = struct{}{}
			}
		case "resourceName":
			if _, ok := fieldSeen[findinghistory.FieldResourceName]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldResourceName)
				fieldSeen[findinghistory.FieldResourceName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[findinghistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldDisplayName)
				fieldSeen[findinghistory.FieldDisplayName] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[findinghistory.FieldState]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldState)
				fieldSeen[findinghistory.FieldState] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[findinghistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldCategory)
				fieldSeen[findinghistory.FieldCategory] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[findinghistory.FieldCategories]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldCategories)
				fieldSeen[findinghistory.FieldCategories] = struct{}{}
			}
		case "findingClass":
			if _, ok := fieldSeen[findinghistory.FieldFindingClass]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldFindingClass)
				fieldSeen[findinghistory.FieldFindingClass] = struct{}{}
			}
		case "severity":
			if _, ok := fieldSeen[findinghistory.FieldSeverity]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldSeverity)
				fieldSeen[findinghistory.FieldSeverity] = struct{}{}
			}
		case "numericSeverity":
			if _, ok := fieldSeen[findinghistory.FieldNumericSeverity]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldNumericSeverity)
				fieldSeen[findinghistory.FieldNumericSeverity] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[findinghistory.FieldScore]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldScore)
				fieldSeen[findinghistory.FieldScore] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[findinghistory.FieldImpact]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldImpact)
				fieldSeen[findinghistory.FieldImpact] = struct{}{}
			}
		case "exploitability":
			if _, ok := fieldSeen[findinghistory.FieldExploitability]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldExploitability)
				fieldSeen[findinghistory.FieldExploitability] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[findinghistory.FieldPriority]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldPriority)
				fieldSeen[findinghistory.FieldPriority] = struct{}{}
			}
		case "open":
			if _, ok := fieldSeen[findinghistory.FieldOpen]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldOpen)
				fieldSeen[findinghistory.FieldOpen] = struct{}{}
			}
		case "blocksProduction":
			if _, ok := fieldSeen[findinghistory.FieldBlocksProduction]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldBlocksProduction)
				fieldSeen[findinghistory.FieldBlocksProduction] = struct{}{}
			}
		case "production":
			if _, ok := fieldSeen[findinghistory.FieldProduction]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldProduction)
				fieldSeen[findinghistory.FieldProduction] = struct{}{}
			}
		case "public":
			if _, ok := fieldSeen[findinghistory.FieldPublic]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldPublic)
				fieldSeen[findinghistory.FieldPublic] = struct{}{}
			}
		case "validated":
			if _, ok := fieldSeen[findinghistory.FieldValidated]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldValidated)
				fieldSeen[findinghistory.FieldValidated] = struct{}{}
			}
		case "assessmentID":
			if _, ok := fieldSeen[findinghistory.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldAssessmentID)
				fieldSeen[findinghistory.FieldAssessmentID] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[findinghistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldDescription)
				fieldSeen[findinghistory.FieldDescription] = struct{}{}
			}
		case "recommendation":
			if _, ok := fieldSeen[findinghistory.FieldRecommendation]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldRecommendation)
				fieldSeen[findinghistory.FieldRecommendation] = struct{}{}
			}
		case "recommendedActions":
			if _, ok := fieldSeen[findinghistory.FieldRecommendedActions]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldRecommendedActions)
				fieldSeen[findinghistory.FieldRecommendedActions] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[findinghistory.FieldReferences]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldReferences)
				fieldSeen[findinghistory.FieldReferences] = struct{}{}
			}
		case "stepsToReproduce":
			if _, ok := fieldSeen[findinghistory.FieldStepsToReproduce]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldStepsToReproduce)
				fieldSeen[findinghistory.FieldStepsToReproduce] = struct{}{}
			}
		case "targets":
			if _, ok := fieldSeen[findinghistory.FieldTargets]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldTargets)
				fieldSeen[findinghistory.FieldTargets] = struct{}{}
			}
		case "targetDetails":
			if _, ok := fieldSeen[findinghistory.FieldTargetDetails]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldTargetDetails)
				fieldSeen[findinghistory.FieldTargetDetails] = struct{}{}
			}
		case "vector":
			if _, ok := fieldSeen[findinghistory.FieldVector]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldVector)
				fieldSeen[findinghistory.FieldVector] = struct{}{}
			}
		case "remediationSLA":
			if _, ok := fieldSeen[findinghistory.FieldRemediationSLA]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldRemediationSLA)
				fieldSeen[findinghistory.FieldRemediationSLA] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[findinghistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldStatus)
				fieldSeen[findinghistory.FieldStatus] = struct{}{}
			}
		case "eventTime":
			if _, ok := fieldSeen[findinghistory.FieldEventTime]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldEventTime)
				fieldSeen[findinghistory.FieldEventTime] = struct{}{}
			}
		case "reportedAt":
			if _, ok := fieldSeen[findinghistory.FieldReportedAt]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldReportedAt)
				fieldSeen[findinghistory.FieldReportedAt] = struct{}{}
			}
		case "sourceUpdatedAt":
			if _, ok := fieldSeen[findinghistory.FieldSourceUpdatedAt]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldSourceUpdatedAt)
				fieldSeen[findinghistory.FieldSourceUpdatedAt] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[findinghistory.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldExternalURI)
				fieldSeen[findinghistory.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[findinghistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldMetadata)
				fieldSeen[findinghistory.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[findinghistory.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, findinghistory.FieldRawPayload)
				fieldSeen[findinghistory.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type findinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FindingHistoryPaginateOption
}

func newFindingHistoryPaginateArgs(rv map[string]any) *findinghistoryPaginateArgs {
	args := &findinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &FindingHistoryOrder{Field: &FindingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithFindingHistoryOrder(order))
			}
		case *FindingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithFindingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*FindingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithFindingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(group.Columns))
		selectedFields = []string{group.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[group.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, group.FieldOwnerID)
				fieldSeen[group.FieldOwnerID] = struct{}{}
			}

		case "programEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramEditorsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramEditors)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramEditors(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramBlockedGroupsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramBlockedGroups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramBlockedGroups(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramViewersTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramViewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramViewers(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "riskEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskEditorsTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskEditors)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskEditors(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskBlockedGroupsTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskBlockedGroups)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskBlockedGroups(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskViewersTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskViewers)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskViewers(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlObjectiveEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveEditorsTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveEditors)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveEditors(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlObjectiveBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveBlockedGroupsTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveBlockedGroups)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveBlockedGroups(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlObjectiveViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveViewersTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveViewers)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveViewers(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "narrativeEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeEditorsTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeEditors)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeEditors(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "narrativeBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeBlockedGroupsTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeBlockedGroups)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeBlockedGroups(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "narrativeViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeViewersTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeViewers)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeViewers(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "controlImplementationEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationEditorsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationEditors)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationEditors(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controlImplementationBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationBlockedGroupsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationBlockedGroups)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationBlockedGroups(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controlImplementationViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationViewersTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationViewers)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationViewers(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "scanEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanEditorsTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanEditors)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScanEditors(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "scanBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanBlockedGroupsTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanBlockedGroups)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScanBlockedGroups(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "scanViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanViewersTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanViewers)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScanViewers(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entityEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EntityEditorsTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(group.EntityEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.EntityEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.EntityEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EntityEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityEditors)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EntityEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityEditors(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EntityBlockedGroupsTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(group.EntityBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.EntityBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.EntityBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EntityBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityBlockedGroups)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EntityBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityBlockedGroups(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EntityViewersTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(group.EntityViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.EntityViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.EntityViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EntityViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityViewers)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EntityViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityViewers(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "procedureEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProcedureEditorsTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(group.ProcedureEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProcedureEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProcedureEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProcedureEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureEditors)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProcedureEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedureEditors(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "procedureBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProcedureBlockedGroupsTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(group.ProcedureBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureBlockedGroups)
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProcedureBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedureBlockedGroups(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicyEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.InternalPolicyEditorsTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(group.InternalPolicyEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyEditors)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.InternalPolicyEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicyEditors(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "internalPolicyBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.InternalPolicyBlockedGroupsTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyBlockedGroups)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.InternalPolicyBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicyBlockedGroups(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "controlEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlEditorsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(group.ControlEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlEditors)
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlEditors(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "controlBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlBlockedGroupsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(group.ControlBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlBlockedGroups)
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlBlockedGroups(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "mappedControlEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: _q.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.MappedControlEditorsTable)
							s.Join(joinT).On(s.C(mappedcontrol.FieldID), joinT.C(group.MappedControlEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.MappedControlEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.MappedControlEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.MappedControlEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlEditors)
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MappedControlEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControlEditors(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "mappedControlBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: _q.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.MappedControlBlockedGroupsTable)
							s.Join(joinT).On(s.C(mappedcontrol.FieldID), joinT.C(group.MappedControlBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlBlockedGroups)
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MappedControlBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControlBlockedGroups(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupsettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(group.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(group.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_integrations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(group.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(group.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(group.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(group.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: _q.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(group.MembersColumn), ids...))
						})
						if err := query.GroupBy(group.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[group.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, group.FieldCreatedAt)
				fieldSeen[group.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[group.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, group.FieldUpdatedAt)
				fieldSeen[group.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[group.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, group.FieldCreatedBy)
				fieldSeen[group.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[group.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, group.FieldUpdatedBy)
				fieldSeen[group.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[group.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, group.FieldDisplayID)
				fieldSeen[group.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[group.FieldTags]; !ok {
				selectedFields = append(selectedFields, group.FieldTags)
				fieldSeen[group.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[group.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, group.FieldOwnerID)
				fieldSeen[group.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[group.FieldName]; !ok {
				selectedFields = append(selectedFields, group.FieldName)
				fieldSeen[group.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[group.FieldDescription]; !ok {
				selectedFields = append(selectedFields, group.FieldDescription)
				fieldSeen[group.FieldDescription] = struct{}{}
			}
		case "isManaged":
			if _, ok := fieldSeen[group.FieldIsManaged]; !ok {
				selectedFields = append(selectedFields, group.FieldIsManaged)
				fieldSeen[group.FieldIsManaged] = struct{}{}
			}
		case "gravatarLogoURL":
			if _, ok := fieldSeen[group.FieldGravatarLogoURL]; !ok {
				selectedFields = append(selectedFields, group.FieldGravatarLogoURL)
				fieldSeen[group.FieldGravatarLogoURL] = struct{}{}
			}
		case "logoURL":
			if _, ok := fieldSeen[group.FieldLogoURL]; !ok {
				selectedFields = append(selectedFields, group.FieldLogoURL)
				fieldSeen[group.FieldLogoURL] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[group.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, group.FieldDisplayName)
				fieldSeen[group.FieldDisplayName] = struct{}{}
			}
		case "scimExternalID":
			if _, ok := fieldSeen[group.FieldScimExternalID]; !ok {
				selectedFields = append(selectedFields, group.FieldScimExternalID)
				fieldSeen[group.FieldScimExternalID] = struct{}{}
			}
		case "scimDisplayName":
			if _, ok := fieldSeen[group.FieldScimDisplayName]; !ok {
				selectedFields = append(selectedFields, group.FieldScimDisplayName)
				fieldSeen[group.FieldScimDisplayName] = struct{}{}
			}
		case "scimActive":
			if _, ok := fieldSeen[group.FieldScimActive]; !ok {
				selectedFields = append(selectedFields, group.FieldScimActive)
				fieldSeen[group.FieldScimActive] = struct{}{}
			}
		case "scimGroupMailing":
			if _, ok := fieldSeen[group.FieldScimGroupMailing]; !ok {
				selectedFields = append(selectedFields, group.FieldScimGroupMailing)
				fieldSeen[group.FieldScimGroupMailing] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupPaginateOption
}

func newGroupPaginateArgs(rv map[string]any) *groupPaginateArgs {
	args := &groupPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupOrder:
			args.opts = append(args.opts, WithGroupOrder(v))
		case []any:
			var orders []*GroupOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupOrder{Field: &GroupOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupWhereInput); ok {
		args.opts = append(args.opts, WithGroupFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(grouphistory.Columns))
		selectedFields = []string{grouphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[grouphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldHistoryTime)
				fieldSeen[grouphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[grouphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldRef)
				fieldSeen[grouphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[grouphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldOperation)
				fieldSeen[grouphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[grouphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldCreatedAt)
				fieldSeen[grouphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[grouphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldUpdatedAt)
				fieldSeen[grouphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[grouphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldCreatedBy)
				fieldSeen[grouphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[grouphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldUpdatedBy)
				fieldSeen[grouphistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[grouphistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldDisplayID)
				fieldSeen[grouphistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[grouphistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldTags)
				fieldSeen[grouphistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[grouphistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldOwnerID)
				fieldSeen[grouphistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[grouphistory.FieldName]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldName)
				fieldSeen[grouphistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[grouphistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldDescription)
				fieldSeen[grouphistory.FieldDescription] = struct{}{}
			}
		case "isManaged":
			if _, ok := fieldSeen[grouphistory.FieldIsManaged]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldIsManaged)
				fieldSeen[grouphistory.FieldIsManaged] = struct{}{}
			}
		case "gravatarLogoURL":
			if _, ok := fieldSeen[grouphistory.FieldGravatarLogoURL]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldGravatarLogoURL)
				fieldSeen[grouphistory.FieldGravatarLogoURL] = struct{}{}
			}
		case "logoURL":
			if _, ok := fieldSeen[grouphistory.FieldLogoURL]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldLogoURL)
				fieldSeen[grouphistory.FieldLogoURL] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[grouphistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldDisplayName)
				fieldSeen[grouphistory.FieldDisplayName] = struct{}{}
			}
		case "scimExternalID":
			if _, ok := fieldSeen[grouphistory.FieldScimExternalID]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldScimExternalID)
				fieldSeen[grouphistory.FieldScimExternalID] = struct{}{}
			}
		case "scimDisplayName":
			if _, ok := fieldSeen[grouphistory.FieldScimDisplayName]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldScimDisplayName)
				fieldSeen[grouphistory.FieldScimDisplayName] = struct{}{}
			}
		case "scimActive":
			if _, ok := fieldSeen[grouphistory.FieldScimActive]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldScimActive)
				fieldSeen[grouphistory.FieldScimActive] = struct{}{}
			}
		case "scimGroupMailing":
			if _, ok := fieldSeen[grouphistory.FieldScimGroupMailing]; !ok {
				selectedFields = append(selectedFields, grouphistory.FieldScimGroupMailing)
				fieldSeen[grouphistory.FieldScimGroupMailing] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type grouphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupHistoryPaginateOption
}

func newGroupHistoryPaginateArgs(rv map[string]any) *grouphistoryPaginateArgs {
	args := &grouphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &GroupHistoryOrder{Field: &GroupHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithGroupHistoryOrder(order))
			}
		case *GroupHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithGroupHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*GroupHistoryWhereInput); ok {
		args.opts = append(args.opts, WithGroupHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupmembership.Columns))
		selectedFields = []string{groupmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[groupmembership.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldGroupID)
				fieldSeen[groupmembership.FieldGroupID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[groupmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUserID)
				fieldSeen[groupmembership.FieldUserID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*GroupMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(groupmembership.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(groupmembership.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(groupmembership.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(groupmembership.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(groupmembership.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*GroupMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(groupmembership.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[groupmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldCreatedAt)
				fieldSeen[groupmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUpdatedAt)
				fieldSeen[groupmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldCreatedBy)
				fieldSeen[groupmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUpdatedBy)
				fieldSeen[groupmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[groupmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldRole)
				fieldSeen[groupmembership.FieldRole] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupmembership.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldGroupID)
				fieldSeen[groupmembership.FieldGroupID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[groupmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUserID)
				fieldSeen[groupmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupMembershipPaginateOption
}

func newGroupMembershipPaginateArgs(rv map[string]any) *groupmembershipPaginateArgs {
	args := &groupmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupMembershipOrder:
			args.opts = append(args.opts, WithGroupMembershipOrder(v))
		case []any:
			var orders []*GroupMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupMembershipOrder{Field: &GroupMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupMembershipWhereInput); ok {
		args.opts = append(args.opts, WithGroupMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupmembershiphistory.Columns))
		selectedFields = []string{groupmembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[groupmembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldHistoryTime)
				fieldSeen[groupmembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[groupmembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldRef)
				fieldSeen[groupmembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[groupmembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldOperation)
				fieldSeen[groupmembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupmembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldCreatedAt)
				fieldSeen[groupmembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupmembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldUpdatedAt)
				fieldSeen[groupmembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupmembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldCreatedBy)
				fieldSeen[groupmembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupmembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldUpdatedBy)
				fieldSeen[groupmembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[groupmembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldRole)
				fieldSeen[groupmembershiphistory.FieldRole] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupmembershiphistory.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldGroupID)
				fieldSeen[groupmembershiphistory.FieldGroupID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[groupmembershiphistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembershiphistory.FieldUserID)
				fieldSeen[groupmembershiphistory.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupmembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupMembershipHistoryPaginateOption
}

func newGroupMembershipHistoryPaginateArgs(rv map[string]any) *groupmembershiphistoryPaginateArgs {
	args := &groupmembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &GroupMembershipHistoryOrder{Field: &GroupMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithGroupMembershipHistoryOrder(order))
			}
		case *GroupMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithGroupMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*GroupMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithGroupMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupsetting.Columns))
		selectedFields = []string{groupsetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[groupsetting.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldGroupID)
				fieldSeen[groupsetting.FieldGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupsetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldCreatedAt)
				fieldSeen[groupsetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupsetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldUpdatedAt)
				fieldSeen[groupsetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupsetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldCreatedBy)
				fieldSeen[groupsetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupsetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldUpdatedBy)
				fieldSeen[groupsetting.FieldUpdatedBy] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[groupsetting.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldVisibility)
				fieldSeen[groupsetting.FieldVisibility] = struct{}{}
			}
		case "joinPolicy":
			if _, ok := fieldSeen[groupsetting.FieldJoinPolicy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldJoinPolicy)
				fieldSeen[groupsetting.FieldJoinPolicy] = struct{}{}
			}
		case "syncToSlack":
			if _, ok := fieldSeen[groupsetting.FieldSyncToSlack]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldSyncToSlack)
				fieldSeen[groupsetting.FieldSyncToSlack] = struct{}{}
			}
		case "syncToGithub":
			if _, ok := fieldSeen[groupsetting.FieldSyncToGithub]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldSyncToGithub)
				fieldSeen[groupsetting.FieldSyncToGithub] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupsetting.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldGroupID)
				fieldSeen[groupsetting.FieldGroupID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupsettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupSettingPaginateOption
}

func newGroupSettingPaginateArgs(rv map[string]any) *groupsettingPaginateArgs {
	args := &groupsettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupSettingOrder:
			args.opts = append(args.opts, WithGroupSettingOrder(v))
		case []any:
			var orders []*GroupSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupSettingOrder{Field: &GroupSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupSettingWhereInput); ok {
		args.opts = append(args.opts, WithGroupSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupsettinghistory.Columns))
		selectedFields = []string{groupsettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[groupsettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldHistoryTime)
				fieldSeen[groupsettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[groupsettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldRef)
				fieldSeen[groupsettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[groupsettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldOperation)
				fieldSeen[groupsettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupsettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldCreatedAt)
				fieldSeen[groupsettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupsettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldUpdatedAt)
				fieldSeen[groupsettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupsettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldCreatedBy)
				fieldSeen[groupsettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupsettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldUpdatedBy)
				fieldSeen[groupsettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[groupsettinghistory.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldVisibility)
				fieldSeen[groupsettinghistory.FieldVisibility] = struct{}{}
			}
		case "joinPolicy":
			if _, ok := fieldSeen[groupsettinghistory.FieldJoinPolicy]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldJoinPolicy)
				fieldSeen[groupsettinghistory.FieldJoinPolicy] = struct{}{}
			}
		case "syncToSlack":
			if _, ok := fieldSeen[groupsettinghistory.FieldSyncToSlack]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldSyncToSlack)
				fieldSeen[groupsettinghistory.FieldSyncToSlack] = struct{}{}
			}
		case "syncToGithub":
			if _, ok := fieldSeen[groupsettinghistory.FieldSyncToGithub]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldSyncToGithub)
				fieldSeen[groupsettinghistory.FieldSyncToGithub] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupsettinghistory.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsettinghistory.FieldGroupID)
				fieldSeen[groupsettinghistory.FieldGroupID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupsettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupSettingHistoryPaginateOption
}

func newGroupSettingHistoryPaginateArgs(rv map[string]any) *groupsettinghistoryPaginateArgs {
	args := &groupsettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &GroupSettingHistoryOrder{Field: &GroupSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithGroupSettingHistoryOrder(order))
			}
		case *GroupSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithGroupSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*GroupSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithGroupSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *HushQuery) CollectFields(ctx context.Context, satisfies ...string) (*HushQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *HushQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hush.Columns))
		selectedFields = []string{hush.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[hush.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hush.FieldOwnerID)
				fieldSeen[hush.FieldOwnerID] = struct{}{}
			}

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(hush.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(hush.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(hush.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(hush.FilesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(hush.FilesPrimaryKey[1]), ids...))
							s.Select(joinT.C(hush.FilesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.FilesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.FilesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(hush.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(hush.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(hush.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[hush.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldCreatedAt)
				fieldSeen[hush.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[hush.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldUpdatedAt)
				fieldSeen[hush.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[hush.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, hush.FieldCreatedBy)
				fieldSeen[hush.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[hush.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, hush.FieldUpdatedBy)
				fieldSeen[hush.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[hush.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hush.FieldOwnerID)
				fieldSeen[hush.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[hush.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, hush.FieldSystemOwned)
				fieldSeen[hush.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[hush.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, hush.FieldInternalNotes)
				fieldSeen[hush.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[hush.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, hush.FieldSystemInternalID)
				fieldSeen[hush.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[hush.FieldName]; !ok {
				selectedFields = append(selectedFields, hush.FieldName)
				fieldSeen[hush.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[hush.FieldDescription]; !ok {
				selectedFields = append(selectedFields, hush.FieldDescription)
				fieldSeen[hush.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[hush.FieldKind]; !ok {
				selectedFields = append(selectedFields, hush.FieldKind)
				fieldSeen[hush.FieldKind] = struct{}{}
			}
		case "secretName":
			if _, ok := fieldSeen[hush.FieldSecretName]; !ok {
				selectedFields = append(selectedFields, hush.FieldSecretName)
				fieldSeen[hush.FieldSecretName] = struct{}{}
			}
		case "credentialSet":
			if _, ok := fieldSeen[hush.FieldCredentialSet]; !ok {
				selectedFields = append(selectedFields, hush.FieldCredentialSet)
				fieldSeen[hush.FieldCredentialSet] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[hush.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, hush.FieldMetadata)
				fieldSeen[hush.FieldMetadata] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[hush.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldLastUsedAt)
				fieldSeen[hush.FieldLastUsedAt] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[hush.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldExpiresAt)
				fieldSeen[hush.FieldExpiresAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type hushPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HushPaginateOption
}

func newHushPaginateArgs(rv map[string]any) *hushPaginateArgs {
	args := &hushPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HushOrder:
			args.opts = append(args.opts, WithHushOrder(v))
		case []any:
			var orders []*HushOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HushOrder{Field: &HushOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHushOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HushWhereInput); ok {
		args.opts = append(args.opts, WithHushFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *HushHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*HushHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *HushHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hushhistory.Columns))
		selectedFields = []string{hushhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[hushhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldHistoryTime)
				fieldSeen[hushhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[hushhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldRef)
				fieldSeen[hushhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[hushhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldOperation)
				fieldSeen[hushhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[hushhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldCreatedAt)
				fieldSeen[hushhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[hushhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldUpdatedAt)
				fieldSeen[hushhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[hushhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldCreatedBy)
				fieldSeen[hushhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[hushhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldUpdatedBy)
				fieldSeen[hushhistory.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[hushhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldOwnerID)
				fieldSeen[hushhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[hushhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldSystemOwned)
				fieldSeen[hushhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[hushhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldInternalNotes)
				fieldSeen[hushhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[hushhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldSystemInternalID)
				fieldSeen[hushhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[hushhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldName)
				fieldSeen[hushhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[hushhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldDescription)
				fieldSeen[hushhistory.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[hushhistory.FieldKind]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldKind)
				fieldSeen[hushhistory.FieldKind] = struct{}{}
			}
		case "secretName":
			if _, ok := fieldSeen[hushhistory.FieldSecretName]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldSecretName)
				fieldSeen[hushhistory.FieldSecretName] = struct{}{}
			}
		case "credentialSet":
			if _, ok := fieldSeen[hushhistory.FieldCredentialSet]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldCredentialSet)
				fieldSeen[hushhistory.FieldCredentialSet] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[hushhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldMetadata)
				fieldSeen[hushhistory.FieldMetadata] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[hushhistory.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldLastUsedAt)
				fieldSeen[hushhistory.FieldLastUsedAt] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[hushhistory.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, hushhistory.FieldExpiresAt)
				fieldSeen[hushhistory.FieldExpiresAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type hushhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HushHistoryPaginateOption
}

func newHushHistoryPaginateArgs(rv map[string]any) *hushhistoryPaginateArgs {
	args := &hushhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &HushHistoryOrder{Field: &HushHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithHushHistoryOrder(order))
			}
		case *HushHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithHushHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*HushHistoryWhereInput); ok {
		args.opts = append(args.opts, WithHushHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *IntegrationQuery) CollectFields(ctx context.Context, satisfies ...string) (*IntegrationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *IntegrationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(integration.Columns))
		selectedFields = []string{integration.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[integration.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integration.FieldOwnerID)
				fieldSeen[integration.FieldOwnerID] = struct{}{}
			}

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(integration.SecretsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.SecretsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.SecretsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.SecretsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.SecretsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.FilesColumn), ids...))
						})
						if err := query.GroupBy(integration.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(integration.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.FindingsTable)
							s.Join(joinT).On(s.C(finding.FieldID), joinT.C(integration.FindingsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.FindingsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.FindingsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.FindingsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.FindingsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.VulnerabilitiesTable)
							s.Join(joinT).On(s.C(vulnerability.FieldID), joinT.C(integration.VulnerabilitiesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.VulnerabilitiesPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.VulnerabilitiesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.VulnerabilitiesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.VulnerabilitiesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.ReviewsTable)
							s.Join(joinT).On(s.C(review.FieldID), joinT.C(integration.ReviewsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.ReviewsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.ReviewsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.ReviewsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.ReviewsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.RemediationsTable)
							s.Join(joinT).On(s.C(remediation.FieldID), joinT.C(integration.RemediationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.RemediationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.RemediationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.RemediationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.RemediationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.TasksColumn), ids...))
						})
						if err := query.GroupBy(integration.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(integration.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "directoryAccounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_accounts"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectoryAccountsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectoryAccountsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryAccounts)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectoryAccountsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "directoryGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectoryGroupsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectoryGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryGroups)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectoryGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "directoryMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_memberships"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectoryMembershipsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectoryMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryMemberships)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectoryMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})

		case "directorySyncRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			args := newDirectorySyncRunPaginateArgs(fieldArgs(ctx, new(DirectorySyncRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectorySyncRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_sync_runs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectorySyncRunsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectorySyncRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectorySyncRuns)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectorySyncRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectorySyncRuns(alias, func(wq *DirectorySyncRunQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[integration.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, integration.FieldCreatedAt)
				fieldSeen[integration.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[integration.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, integration.FieldUpdatedAt)
				fieldSeen[integration.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[integration.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, integration.FieldCreatedBy)
				fieldSeen[integration.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[integration.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, integration.FieldUpdatedBy)
				fieldSeen[integration.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[integration.FieldTags]; !ok {
				selectedFields = append(selectedFields, integration.FieldTags)
				fieldSeen[integration.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[integration.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integration.FieldOwnerID)
				fieldSeen[integration.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[integration.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, integration.FieldSystemOwned)
				fieldSeen[integration.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[integration.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, integration.FieldInternalNotes)
				fieldSeen[integration.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[integration.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, integration.FieldSystemInternalID)
				fieldSeen[integration.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[integration.FieldName]; !ok {
				selectedFields = append(selectedFields, integration.FieldName)
				fieldSeen[integration.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[integration.FieldDescription]; !ok {
				selectedFields = append(selectedFields, integration.FieldDescription)
				fieldSeen[integration.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[integration.FieldKind]; !ok {
				selectedFields = append(selectedFields, integration.FieldKind)
				fieldSeen[integration.FieldKind] = struct{}{}
			}
		case "integrationType":
			if _, ok := fieldSeen[integration.FieldIntegrationType]; !ok {
				selectedFields = append(selectedFields, integration.FieldIntegrationType)
				fieldSeen[integration.FieldIntegrationType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[integration.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, integration.FieldMetadata)
				fieldSeen[integration.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type integrationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []IntegrationPaginateOption
}

func newIntegrationPaginateArgs(rv map[string]any) *integrationPaginateArgs {
	args := &integrationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*IntegrationOrder:
			args.opts = append(args.opts, WithIntegrationOrder(v))
		case []any:
			var orders []*IntegrationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &IntegrationOrder{Field: &IntegrationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithIntegrationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*IntegrationWhereInput); ok {
		args.opts = append(args.opts, WithIntegrationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *IntegrationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*IntegrationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *IntegrationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(integrationhistory.Columns))
		selectedFields = []string{integrationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[integrationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldHistoryTime)
				fieldSeen[integrationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[integrationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldRef)
				fieldSeen[integrationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[integrationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldOperation)
				fieldSeen[integrationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[integrationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldCreatedAt)
				fieldSeen[integrationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[integrationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldUpdatedAt)
				fieldSeen[integrationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[integrationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldCreatedBy)
				fieldSeen[integrationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[integrationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldUpdatedBy)
				fieldSeen[integrationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[integrationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldTags)
				fieldSeen[integrationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[integrationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldOwnerID)
				fieldSeen[integrationhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[integrationhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldSystemOwned)
				fieldSeen[integrationhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[integrationhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldInternalNotes)
				fieldSeen[integrationhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[integrationhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldSystemInternalID)
				fieldSeen[integrationhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[integrationhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldName)
				fieldSeen[integrationhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[integrationhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldDescription)
				fieldSeen[integrationhistory.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[integrationhistory.FieldKind]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldKind)
				fieldSeen[integrationhistory.FieldKind] = struct{}{}
			}
		case "integrationType":
			if _, ok := fieldSeen[integrationhistory.FieldIntegrationType]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldIntegrationType)
				fieldSeen[integrationhistory.FieldIntegrationType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[integrationhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, integrationhistory.FieldMetadata)
				fieldSeen[integrationhistory.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type integrationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []IntegrationHistoryPaginateOption
}

func newIntegrationHistoryPaginateArgs(rv map[string]any) *integrationhistoryPaginateArgs {
	args := &integrationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &IntegrationHistoryOrder{Field: &IntegrationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithIntegrationHistoryOrder(order))
			}
		case *IntegrationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithIntegrationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*IntegrationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithIntegrationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *InternalPolicyQuery) CollectFields(ctx context.Context, satisfies ...string) (*InternalPolicyQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *InternalPolicyQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(internalpolicy.Columns))
		selectedFields = []string{internalpolicy.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[internalpolicy.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldOwnerID)
				fieldSeen[internalpolicy.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(internalpolicy.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(internalpolicy.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withApprover = query
			if _, ok := fieldSeen[internalpolicy.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApproverID)
				fieldSeen[internalpolicy.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[internalpolicy.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDelegateID)
				fieldSeen[internalpolicy.FieldDelegateID] = struct{}{}
			}

		case "internalPolicyKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicyKind = query
			if _, ok := fieldSeen[internalpolicy.FieldInternalPolicyKindID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalPolicyKindID)
				fieldSeen[internalpolicy.FieldInternalPolicyKindID] = struct{}{}
			}

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(internalpolicy.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_control_implementations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(internalpolicy.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(internalpolicy.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(internalpolicy.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(internalpolicy.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(internalpolicy.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(internalpolicy.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(internalpolicy.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(internalpolicy.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[internalpolicy.FieldFileID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldFileID)
				fieldSeen[internalpolicy.FieldFileID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.CommentsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[internalpolicy.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldCreatedAt)
				fieldSeen[internalpolicy.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[internalpolicy.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldUpdatedAt)
				fieldSeen[internalpolicy.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[internalpolicy.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldCreatedBy)
				fieldSeen[internalpolicy.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[internalpolicy.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldUpdatedBy)
				fieldSeen[internalpolicy.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[internalpolicy.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDisplayID)
				fieldSeen[internalpolicy.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[internalpolicy.FieldTags]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldTags)
				fieldSeen[internalpolicy.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[internalpolicy.FieldRevision]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldRevision)
				fieldSeen[internalpolicy.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[internalpolicy.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldOwnerID)
				fieldSeen[internalpolicy.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[internalpolicy.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSystemOwned)
				fieldSeen[internalpolicy.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[internalpolicy.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalNotes)
				fieldSeen[internalpolicy.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[internalpolicy.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSystemInternalID)
				fieldSeen[internalpolicy.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[internalpolicy.FieldName]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldName)
				fieldSeen[internalpolicy.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[internalpolicy.FieldStatus]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldStatus)
				fieldSeen[internalpolicy.FieldStatus] = struct{}{}
			}
		case "policyType":
			if _, ok := fieldSeen[internalpolicy.FieldPolicyType]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldPolicyType)
				fieldSeen[internalpolicy.FieldPolicyType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[internalpolicy.FieldDetails]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDetails)
				fieldSeen[internalpolicy.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[internalpolicy.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApprovalRequired)
				fieldSeen[internalpolicy.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[internalpolicy.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldReviewDue)
				fieldSeen[internalpolicy.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[internalpolicy.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldReviewFrequency)
				fieldSeen[internalpolicy.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[internalpolicy.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApproverID)
				fieldSeen[internalpolicy.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[internalpolicy.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDelegateID)
				fieldSeen[internalpolicy.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[internalpolicy.FieldSummary]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSummary)
				fieldSeen[internalpolicy.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldTagSuggestions)
				fieldSeen[internalpolicy.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedTagSuggestions)
				fieldSeen[internalpolicy.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldControlSuggestions)
				fieldSeen[internalpolicy.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedControlSuggestions)
				fieldSeen[internalpolicy.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldImprovementSuggestions)
				fieldSeen[internalpolicy.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedImprovementSuggestions)
				fieldSeen[internalpolicy.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[internalpolicy.FieldURL]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldURL)
				fieldSeen[internalpolicy.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[internalpolicy.FieldFileID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldFileID)
				fieldSeen[internalpolicy.FieldFileID] = struct{}{}
			}
		case "internalPolicyKindName":
			if _, ok := fieldSeen[internalpolicy.FieldInternalPolicyKindName]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalPolicyKindName)
				fieldSeen[internalpolicy.FieldInternalPolicyKindName] = struct{}{}
			}
		case "internalPolicyKindID":
			if _, ok := fieldSeen[internalpolicy.FieldInternalPolicyKindID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalPolicyKindID)
				fieldSeen[internalpolicy.FieldInternalPolicyKindID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type internalpolicyPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InternalPolicyPaginateOption
}

func newInternalPolicyPaginateArgs(rv map[string]any) *internalpolicyPaginateArgs {
	args := &internalpolicyPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*InternalPolicyOrder:
			args.opts = append(args.opts, WithInternalPolicyOrder(v))
		case []any:
			var orders []*InternalPolicyOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &InternalPolicyOrder{Field: &InternalPolicyOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithInternalPolicyOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*InternalPolicyWhereInput); ok {
		args.opts = append(args.opts, WithInternalPolicyFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *InternalPolicyHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*InternalPolicyHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *InternalPolicyHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(internalpolicyhistory.Columns))
		selectedFields = []string{internalpolicyhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[internalpolicyhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldHistoryTime)
				fieldSeen[internalpolicyhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[internalpolicyhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldRef)
				fieldSeen[internalpolicyhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[internalpolicyhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldOperation)
				fieldSeen[internalpolicyhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[internalpolicyhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldCreatedAt)
				fieldSeen[internalpolicyhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[internalpolicyhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldUpdatedAt)
				fieldSeen[internalpolicyhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[internalpolicyhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldCreatedBy)
				fieldSeen[internalpolicyhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[internalpolicyhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldUpdatedBy)
				fieldSeen[internalpolicyhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDisplayID)
				fieldSeen[internalpolicyhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[internalpolicyhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldTags)
				fieldSeen[internalpolicyhistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[internalpolicyhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldRevision)
				fieldSeen[internalpolicyhistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldOwnerID)
				fieldSeen[internalpolicyhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[internalpolicyhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldSystemOwned)
				fieldSeen[internalpolicyhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[internalpolicyhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldInternalNotes)
				fieldSeen[internalpolicyhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldSystemInternalID)
				fieldSeen[internalpolicyhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[internalpolicyhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldName)
				fieldSeen[internalpolicyhistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[internalpolicyhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldStatus)
				fieldSeen[internalpolicyhistory.FieldStatus] = struct{}{}
			}
		case "policyType":
			if _, ok := fieldSeen[internalpolicyhistory.FieldPolicyType]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldPolicyType)
				fieldSeen[internalpolicyhistory.FieldPolicyType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDetails)
				fieldSeen[internalpolicyhistory.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[internalpolicyhistory.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldApprovalRequired)
				fieldSeen[internalpolicyhistory.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[internalpolicyhistory.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldReviewDue)
				fieldSeen[internalpolicyhistory.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[internalpolicyhistory.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldReviewFrequency)
				fieldSeen[internalpolicyhistory.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldApproverID)
				fieldSeen[internalpolicyhistory.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDelegateID)
				fieldSeen[internalpolicyhistory.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[internalpolicyhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldSummary)
				fieldSeen[internalpolicyhistory.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldTagSuggestions)
				fieldSeen[internalpolicyhistory.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDismissedTagSuggestions)
				fieldSeen[internalpolicyhistory.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldControlSuggestions)
				fieldSeen[internalpolicyhistory.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDismissedControlSuggestions)
				fieldSeen[internalpolicyhistory.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldImprovementSuggestions)
				fieldSeen[internalpolicyhistory.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[internalpolicyhistory.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldDismissedImprovementSuggestions)
				fieldSeen[internalpolicyhistory.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[internalpolicyhistory.FieldURL]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldURL)
				fieldSeen[internalpolicyhistory.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldFileID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldFileID)
				fieldSeen[internalpolicyhistory.FieldFileID] = struct{}{}
			}
		case "internalPolicyKindName":
			if _, ok := fieldSeen[internalpolicyhistory.FieldInternalPolicyKindName]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldInternalPolicyKindName)
				fieldSeen[internalpolicyhistory.FieldInternalPolicyKindName] = struct{}{}
			}
		case "internalPolicyKindID":
			if _, ok := fieldSeen[internalpolicyhistory.FieldInternalPolicyKindID]; !ok {
				selectedFields = append(selectedFields, internalpolicyhistory.FieldInternalPolicyKindID)
				fieldSeen[internalpolicyhistory.FieldInternalPolicyKindID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type internalpolicyhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InternalPolicyHistoryPaginateOption
}

func newInternalPolicyHistoryPaginateArgs(rv map[string]any) *internalpolicyhistoryPaginateArgs {
	args := &internalpolicyhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &InternalPolicyHistoryOrder{Field: &InternalPolicyHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithInternalPolicyHistoryOrder(order))
			}
		case *InternalPolicyHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithInternalPolicyHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*InternalPolicyHistoryWhereInput); ok {
		args.opts = append(args.opts, WithInternalPolicyHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *InviteQuery) CollectFields(ctx context.Context, satisfies ...string) (*InviteQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *InviteQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(invite.Columns))
		selectedFields = []string{invite.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[invite.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnerID)
				fieldSeen[invite.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Invite) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"invite_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(invite.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(invite.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(invite.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(invite.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(invite.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Invite) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(invite.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Invite) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"invite_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(invite.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(invite.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(invite.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(invite.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(invite.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Invite) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(invite.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[invite.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, invite.FieldCreatedAt)
				fieldSeen[invite.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[invite.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, invite.FieldUpdatedAt)
				fieldSeen[invite.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[invite.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, invite.FieldCreatedBy)
				fieldSeen[invite.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[invite.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, invite.FieldUpdatedBy)
				fieldSeen[invite.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[invite.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnerID)
				fieldSeen[invite.FieldOwnerID] = struct{}{}
			}
		case "expires":
			if _, ok := fieldSeen[invite.FieldExpires]; !ok {
				selectedFields = append(selectedFields, invite.FieldExpires)
				fieldSeen[invite.FieldExpires] = struct{}{}
			}
		case "recipient":
			if _, ok := fieldSeen[invite.FieldRecipient]; !ok {
				selectedFields = append(selectedFields, invite.FieldRecipient)
				fieldSeen[invite.FieldRecipient] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[invite.FieldStatus]; !ok {
				selectedFields = append(selectedFields, invite.FieldStatus)
				fieldSeen[invite.FieldStatus] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[invite.FieldRole]; !ok {
				selectedFields = append(selectedFields, invite.FieldRole)
				fieldSeen[invite.FieldRole] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[invite.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, invite.FieldSendAttempts)
				fieldSeen[invite.FieldSendAttempts] = struct{}{}
			}
		case "requestorID":
			if _, ok := fieldSeen[invite.FieldRequestorID]; !ok {
				selectedFields = append(selectedFields, invite.FieldRequestorID)
				fieldSeen[invite.FieldRequestorID] = struct{}{}
			}
		case "ownershipTransfer":
			if _, ok := fieldSeen[invite.FieldOwnershipTransfer]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnershipTransfer)
				fieldSeen[invite.FieldOwnershipTransfer] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type invitePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InvitePaginateOption
}

func newInvitePaginateArgs(rv map[string]any) *invitePaginateArgs {
	args := &invitePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*InviteOrder:
			args.opts = append(args.opts, WithInviteOrder(v))
		case []any:
			var orders []*InviteOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &InviteOrder{Field: &InviteOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithInviteOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*InviteWhereInput); ok {
		args.opts = append(args.opts, WithInviteFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobResultQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobResultQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobResultQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobresult.Columns))
		selectedFields = []string{jobresult.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobresult.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldOwnerID)
				fieldSeen[jobresult.FieldOwnerID] = struct{}{}
			}

		case "scheduledJob":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
				return err
			}
			_q.withScheduledJob = query
			if _, ok := fieldSeen[jobresult.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldScheduledJobID)
				fieldSeen[jobresult.FieldScheduledJobID] = struct{}{}
			}

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[jobresult.FieldFileID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFileID)
				fieldSeen[jobresult.FieldFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobresult.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldCreatedAt)
				fieldSeen[jobresult.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobresult.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldUpdatedAt)
				fieldSeen[jobresult.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobresult.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldCreatedBy)
				fieldSeen[jobresult.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobresult.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldUpdatedBy)
				fieldSeen[jobresult.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobresult.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldOwnerID)
				fieldSeen[jobresult.FieldOwnerID] = struct{}{}
			}
		case "scheduledJobID":
			if _, ok := fieldSeen[jobresult.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldScheduledJobID)
				fieldSeen[jobresult.FieldScheduledJobID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[jobresult.FieldStatus]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldStatus)
				fieldSeen[jobresult.FieldStatus] = struct{}{}
			}
		case "exitCode":
			if _, ok := fieldSeen[jobresult.FieldExitCode]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldExitCode)
				fieldSeen[jobresult.FieldExitCode] = struct{}{}
			}
		case "finishedAt":
			if _, ok := fieldSeen[jobresult.FieldFinishedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFinishedAt)
				fieldSeen[jobresult.FieldFinishedAt] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[jobresult.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldStartedAt)
				fieldSeen[jobresult.FieldStartedAt] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[jobresult.FieldFileID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFileID)
				fieldSeen[jobresult.FieldFileID] = struct{}{}
			}
		case "log":
			if _, ok := fieldSeen[jobresult.FieldLog]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldLog)
				fieldSeen[jobresult.FieldLog] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobresultPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobResultPaginateOption
}

func newJobResultPaginateArgs(rv map[string]any) *jobresultPaginateArgs {
	args := &jobresultPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobResultOrder:
			args.opts = append(args.opts, WithJobResultOrder(v))
		case []any:
			var orders []*JobResultOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobResultOrder{Field: &JobResultOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobResultOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobResultWhereInput); ok {
		args.opts = append(args.opts, WithJobResultFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobRunnerQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobRunnerQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunner.Columns))
		selectedFields = []string{jobrunner.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobrunner.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOwnerID)
				fieldSeen[jobrunner.FieldOwnerID] = struct{}{}
			}

		case "jobRunnerTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerTokenClient{config: _q.config}).Query()
			)
			args := newJobRunnerTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*JobRunner) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_runner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(jobrunner.JobRunnerTokensTable)
							s.Join(joinT).On(s.C(jobrunnertoken.FieldID), joinT.C(jobrunner.JobRunnerTokensPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]), ids...))
							s.Select(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*JobRunner) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerTokens)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnertokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobrunner.JobRunnerTokensPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunnerTokens(alias, func(wq *JobRunnerTokenQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobrunner.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldCreatedAt)
				fieldSeen[jobrunner.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunner.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldUpdatedAt)
				fieldSeen[jobrunner.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunner.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldCreatedBy)
				fieldSeen[jobrunner.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunner.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldUpdatedBy)
				fieldSeen[jobrunner.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[jobrunner.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldDisplayID)
				fieldSeen[jobrunner.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunner.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldTags)
				fieldSeen[jobrunner.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunner.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOwnerID)
				fieldSeen[jobrunner.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[jobrunner.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldSystemOwned)
				fieldSeen[jobrunner.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[jobrunner.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldInternalNotes)
				fieldSeen[jobrunner.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[jobrunner.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldSystemInternalID)
				fieldSeen[jobrunner.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[jobrunner.FieldName]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldName)
				fieldSeen[jobrunner.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[jobrunner.FieldStatus]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldStatus)
				fieldSeen[jobrunner.FieldStatus] = struct{}{}
			}
		case "ipAddress":
			if _, ok := fieldSeen[jobrunner.FieldIPAddress]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldIPAddress)
				fieldSeen[jobrunner.FieldIPAddress] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[jobrunner.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldLastSeen)
				fieldSeen[jobrunner.FieldLastSeen] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[jobrunner.FieldVersion]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldVersion)
				fieldSeen[jobrunner.FieldVersion] = struct{}{}
			}
		case "os":
			if _, ok := fieldSeen[jobrunner.FieldOs]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOs)
				fieldSeen[jobrunner.FieldOs] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobrunnerPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerPaginateOption
}

func newJobRunnerPaginateArgs(rv map[string]any) *jobrunnerPaginateArgs {
	args := &jobrunnerPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerOrder:
			args.opts = append(args.opts, WithJobRunnerOrder(v))
		case []any:
			var orders []*JobRunnerOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerOrder{Field: &JobRunnerOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobRunnerRegistrationTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerRegistrationTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobRunnerRegistrationTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunnerregistrationtoken.Columns))
		selectedFields = []string{jobrunnerregistrationtoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldOwnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldOwnerID] = struct{}{}
			}

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			_q.withJobRunner = query
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldJobRunnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldCreatedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldUpdatedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldCreatedBy)
				fieldSeen[jobrunnerregistrationtoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldUpdatedBy)
				fieldSeen[jobrunnerregistrationtoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldTags)
				fieldSeen[jobrunnerregistrationtoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldOwnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldOwnerID] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldToken)
				fieldSeen[jobrunnerregistrationtoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldExpiresAt)
				fieldSeen[jobrunnerregistrationtoken.FieldExpiresAt] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldLastUsedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldLastUsedAt] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldJobRunnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobrunnerregistrationtokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerRegistrationTokenPaginateOption
}

func newJobRunnerRegistrationTokenPaginateArgs(rv map[string]any) *jobrunnerregistrationtokenPaginateArgs {
	args := &jobrunnerregistrationtokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerRegistrationTokenOrder:
			args.opts = append(args.opts, WithJobRunnerRegistrationTokenOrder(v))
		case []any:
			var orders []*JobRunnerRegistrationTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerRegistrationTokenOrder{Field: &JobRunnerRegistrationTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerRegistrationTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerRegistrationTokenWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerRegistrationTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobRunnerTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobRunnerTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunnertoken.Columns))
		selectedFields = []string{jobrunnertoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobrunnertoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldOwnerID)
				fieldSeen[jobrunnertoken.FieldOwnerID] = struct{}{}
			}

		case "jobRunners":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			args := newJobRunnerPaginateArgs(fieldArgs(ctx, new(JobRunnerWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*JobRunnerToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_runner_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(jobrunnertoken.JobRunnersTable)
							s.Join(joinT).On(s.C(jobrunner.FieldID), joinT.C(jobrunnertoken.JobRunnersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]), ids...))
							s.Select(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*JobRunnerToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunners)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobrunnertoken.JobRunnersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunners(alias, func(wq *JobRunnerQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldCreatedAt)
				fieldSeen[jobrunnertoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldUpdatedAt)
				fieldSeen[jobrunnertoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldCreatedBy)
				fieldSeen[jobrunnertoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldUpdatedBy)
				fieldSeen[jobrunnertoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunnertoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldTags)
				fieldSeen[jobrunnertoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunnertoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldOwnerID)
				fieldSeen[jobrunnertoken.FieldOwnerID] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[jobrunnertoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldToken)
				fieldSeen[jobrunnertoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldExpiresAt)
				fieldSeen[jobrunnertoken.FieldExpiresAt] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldLastUsedAt)
				fieldSeen[jobrunnertoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[jobrunnertoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldIsActive)
				fieldSeen[jobrunnertoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedReason)
				fieldSeen[jobrunnertoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedBy)
				fieldSeen[jobrunnertoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedAt)
				fieldSeen[jobrunnertoken.FieldRevokedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobrunnertokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerTokenPaginateOption
}

func newJobRunnerTokenPaginateArgs(rv map[string]any) *jobrunnertokenPaginateArgs {
	args := &jobrunnertokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerTokenOrder:
			args.opts = append(args.opts, WithJobRunnerTokenOrder(v))
		case []any:
			var orders []*JobRunnerTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerTokenOrder{Field: &JobRunnerTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerTokenWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobTemplateQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobTemplateQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobTemplateQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobtemplate.Columns))
		selectedFields = []string{jobtemplate.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobtemplate.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldOwnerID)
				fieldSeen[jobtemplate.FieldOwnerID] = struct{}{}
			}

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*JobTemplate) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(jobtemplate.ScheduledJobsColumn), ids...))
						})
						if err := query.GroupBy(jobtemplate.ScheduledJobsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*JobTemplate) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobtemplate.ScheduledJobsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobtemplate.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldCreatedAt)
				fieldSeen[jobtemplate.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobtemplate.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldUpdatedAt)
				fieldSeen[jobtemplate.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobtemplate.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldCreatedBy)
				fieldSeen[jobtemplate.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobtemplate.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldUpdatedBy)
				fieldSeen[jobtemplate.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[jobtemplate.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldDisplayID)
				fieldSeen[jobtemplate.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobtemplate.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldTags)
				fieldSeen[jobtemplate.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobtemplate.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldOwnerID)
				fieldSeen[jobtemplate.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[jobtemplate.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldSystemOwned)
				fieldSeen[jobtemplate.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[jobtemplate.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldInternalNotes)
				fieldSeen[jobtemplate.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[jobtemplate.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldSystemInternalID)
				fieldSeen[jobtemplate.FieldSystemInternalID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[jobtemplate.FieldTitle]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldTitle)
				fieldSeen[jobtemplate.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[jobtemplate.FieldDescription]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldDescription)
				fieldSeen[jobtemplate.FieldDescription] = struct{}{}
			}
		case "platform":
			if _, ok := fieldSeen[jobtemplate.FieldPlatform]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldPlatform)
				fieldSeen[jobtemplate.FieldPlatform] = struct{}{}
			}
		case "downloadURL":
			if _, ok := fieldSeen[jobtemplate.FieldDownloadURL]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldDownloadURL)
				fieldSeen[jobtemplate.FieldDownloadURL] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[jobtemplate.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldConfiguration)
				fieldSeen[jobtemplate.FieldConfiguration] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[jobtemplate.FieldCron]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldCron)
				fieldSeen[jobtemplate.FieldCron] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobtemplatePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobTemplatePaginateOption
}

func newJobTemplatePaginateArgs(rv map[string]any) *jobtemplatePaginateArgs {
	args := &jobtemplatePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobTemplateOrder:
			args.opts = append(args.opts, WithJobTemplateOrder(v))
		case []any:
			var orders []*JobTemplateOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobTemplateOrder{Field: &JobTemplateOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobTemplateOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobTemplateWhereInput); ok {
		args.opts = append(args.opts, WithJobTemplateFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobTemplateHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobTemplateHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobTemplateHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobtemplatehistory.Columns))
		selectedFields = []string{jobtemplatehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[jobtemplatehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldHistoryTime)
				fieldSeen[jobtemplatehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[jobtemplatehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldRef)
				fieldSeen[jobtemplatehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[jobtemplatehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldOperation)
				fieldSeen[jobtemplatehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobtemplatehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldCreatedAt)
				fieldSeen[jobtemplatehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobtemplatehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldUpdatedAt)
				fieldSeen[jobtemplatehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobtemplatehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldCreatedBy)
				fieldSeen[jobtemplatehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobtemplatehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldUpdatedBy)
				fieldSeen[jobtemplatehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[jobtemplatehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldDisplayID)
				fieldSeen[jobtemplatehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobtemplatehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldTags)
				fieldSeen[jobtemplatehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobtemplatehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldOwnerID)
				fieldSeen[jobtemplatehistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[jobtemplatehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldSystemOwned)
				fieldSeen[jobtemplatehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[jobtemplatehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldInternalNotes)
				fieldSeen[jobtemplatehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[jobtemplatehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldSystemInternalID)
				fieldSeen[jobtemplatehistory.FieldSystemInternalID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[jobtemplatehistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldTitle)
				fieldSeen[jobtemplatehistory.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[jobtemplatehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldDescription)
				fieldSeen[jobtemplatehistory.FieldDescription] = struct{}{}
			}
		case "platform":
			if _, ok := fieldSeen[jobtemplatehistory.FieldPlatform]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldPlatform)
				fieldSeen[jobtemplatehistory.FieldPlatform] = struct{}{}
			}
		case "downloadURL":
			if _, ok := fieldSeen[jobtemplatehistory.FieldDownloadURL]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldDownloadURL)
				fieldSeen[jobtemplatehistory.FieldDownloadURL] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[jobtemplatehistory.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldConfiguration)
				fieldSeen[jobtemplatehistory.FieldConfiguration] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[jobtemplatehistory.FieldCron]; !ok {
				selectedFields = append(selectedFields, jobtemplatehistory.FieldCron)
				fieldSeen[jobtemplatehistory.FieldCron] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobtemplatehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobTemplateHistoryPaginateOption
}

func newJobTemplateHistoryPaginateArgs(rv map[string]any) *jobtemplatehistoryPaginateArgs {
	args := &jobtemplatehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &JobTemplateHistoryOrder{Field: &JobTemplateHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithJobTemplateHistoryOrder(order))
			}
		case *JobTemplateHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithJobTemplateHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*JobTemplateHistoryWhereInput); ok {
		args.opts = append(args.opts, WithJobTemplateHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *MappableDomainQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappableDomainQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *MappableDomainQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappabledomain.Columns))
		selectedFields = []string{mappabledomain.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappableDomain) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mappable_domain_custom_domains"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(mappabledomain.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(mappabledomain.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappableDomain) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappabledomain.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[mappabledomain.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldCreatedAt)
				fieldSeen[mappabledomain.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappabledomain.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldUpdatedAt)
				fieldSeen[mappabledomain.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappabledomain.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldCreatedBy)
				fieldSeen[mappabledomain.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappabledomain.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldUpdatedBy)
				fieldSeen[mappabledomain.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappabledomain.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldTags)
				fieldSeen[mappabledomain.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[mappabledomain.FieldName]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldName)
				fieldSeen[mappabledomain.FieldName] = struct{}{}
			}
		case "zoneID":
			if _, ok := fieldSeen[mappabledomain.FieldZoneID]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldZoneID)
				fieldSeen[mappabledomain.FieldZoneID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type mappabledomainPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappableDomainPaginateOption
}

func newMappableDomainPaginateArgs(rv map[string]any) *mappabledomainPaginateArgs {
	args := &mappabledomainPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*MappableDomainOrder:
			args.opts = append(args.opts, WithMappableDomainOrder(v))
		case []any:
			var orders []*MappableDomainOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &MappableDomainOrder{Field: &MappableDomainOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithMappableDomainOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*MappableDomainWhereInput); ok {
		args.opts = append(args.opts, WithMappableDomainFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *MappableDomainHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappableDomainHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *MappableDomainHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappabledomainhistory.Columns))
		selectedFields = []string{mappabledomainhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[mappabledomainhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldHistoryTime)
				fieldSeen[mappabledomainhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[mappabledomainhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldRef)
				fieldSeen[mappabledomainhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[mappabledomainhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldOperation)
				fieldSeen[mappabledomainhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[mappabledomainhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldCreatedAt)
				fieldSeen[mappabledomainhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappabledomainhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldUpdatedAt)
				fieldSeen[mappabledomainhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappabledomainhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldCreatedBy)
				fieldSeen[mappabledomainhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappabledomainhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldUpdatedBy)
				fieldSeen[mappabledomainhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappabledomainhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldTags)
				fieldSeen[mappabledomainhistory.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[mappabledomainhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldName)
				fieldSeen[mappabledomainhistory.FieldName] = struct{}{}
			}
		case "zoneID":
			if _, ok := fieldSeen[mappabledomainhistory.FieldZoneID]; !ok {
				selectedFields = append(selectedFields, mappabledomainhistory.FieldZoneID)
				fieldSeen[mappabledomainhistory.FieldZoneID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type mappabledomainhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappableDomainHistoryPaginateOption
}

func newMappableDomainHistoryPaginateArgs(rv map[string]any) *mappabledomainhistoryPaginateArgs {
	args := &mappabledomainhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &MappableDomainHistoryOrder{Field: &MappableDomainHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithMappableDomainHistoryOrder(order))
			}
		case *MappableDomainHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithMappableDomainHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*MappableDomainHistoryWhereInput); ok {
		args.opts = append(args.opts, WithMappableDomainHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *MappedControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappedControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *MappedControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappedcontrol.Columns))
		selectedFields = []string{mappedcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[mappedcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldOwnerID)
				fieldSeen[mappedcontrol.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(mappedcontrol.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "fromControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.FromControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(mappedcontrol.FromControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FromControls)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.FromControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFromControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "toControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.ToControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(mappedcontrol.ToControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ToControls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.ToControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedToControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "fromSubcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.FromSubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FromSubcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.FromSubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFromSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "toSubcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.ToSubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ToSubcontrols)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.ToSubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedToSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[mappedcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldCreatedAt)
				fieldSeen[mappedcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappedcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldUpdatedAt)
				fieldSeen[mappedcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappedcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldCreatedBy)
				fieldSeen[mappedcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappedcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldUpdatedBy)
				fieldSeen[mappedcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappedcontrol.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldTags)
				fieldSeen[mappedcontrol.FieldTags] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[mappedcontrol.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSystemOwned)
				fieldSeen[mappedcontrol.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[mappedcontrol.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldInternalNotes)
				fieldSeen[mappedcontrol.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[mappedcontrol.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSystemInternalID)
				fieldSeen[mappedcontrol.FieldSystemInternalID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[mappedcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldOwnerID)
				fieldSeen[mappedcontrol.FieldOwnerID] = struct{}{}
			}
		case "mappingType":
			if _, ok := fieldSeen[mappedcontrol.FieldMappingType]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldMappingType)
				fieldSeen[mappedcontrol.FieldMappingType] = struct{}{}
			}
		case "relation":
			if _, ok := fieldSeen[mappedcontrol.FieldRelation]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldRelation)
				fieldSeen[mappedcontrol.FieldRelation] = struct{}{}
			}
		case "confidence":
			if _, ok := fieldSeen[mappedcontrol.FieldConfidence]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldConfidence)
				fieldSeen[mappedcontrol.FieldConfidence] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[mappedcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSource)
				fieldSeen[mappedcontrol.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type mappedcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappedControlPaginateOption
}

func newMappedControlPaginateArgs(rv map[string]any) *mappedcontrolPaginateArgs {
	args := &mappedcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*MappedControlOrder:
			args.opts = append(args.opts, WithMappedControlOrder(v))
		case []any:
			var orders []*MappedControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &MappedControlOrder{Field: &MappedControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithMappedControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*MappedControlWhereInput); ok {
		args.opts = append(args.opts, WithMappedControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *MappedControlHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappedControlHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *MappedControlHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappedcontrolhistory.Columns))
		selectedFields = []string{mappedcontrolhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldHistoryTime)
				fieldSeen[mappedcontrolhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldRef)
				fieldSeen[mappedcontrolhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldOperation)
				fieldSeen[mappedcontrolhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldCreatedAt)
				fieldSeen[mappedcontrolhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldUpdatedAt)
				fieldSeen[mappedcontrolhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldCreatedBy)
				fieldSeen[mappedcontrolhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldUpdatedBy)
				fieldSeen[mappedcontrolhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldTags)
				fieldSeen[mappedcontrolhistory.FieldTags] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldSystemOwned)
				fieldSeen[mappedcontrolhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldInternalNotes)
				fieldSeen[mappedcontrolhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldSystemInternalID)
				fieldSeen[mappedcontrolhistory.FieldSystemInternalID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldOwnerID)
				fieldSeen[mappedcontrolhistory.FieldOwnerID] = struct{}{}
			}
		case "mappingType":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldMappingType]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldMappingType)
				fieldSeen[mappedcontrolhistory.FieldMappingType] = struct{}{}
			}
		case "relation":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldRelation]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldRelation)
				fieldSeen[mappedcontrolhistory.FieldRelation] = struct{}{}
			}
		case "confidence":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldConfidence]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldConfidence)
				fieldSeen[mappedcontrolhistory.FieldConfidence] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[mappedcontrolhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, mappedcontrolhistory.FieldSource)
				fieldSeen[mappedcontrolhistory.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type mappedcontrolhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappedControlHistoryPaginateOption
}

func newMappedControlHistoryPaginateArgs(rv map[string]any) *mappedcontrolhistoryPaginateArgs {
	args := &mappedcontrolhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &MappedControlHistoryOrder{Field: &MappedControlHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithMappedControlHistoryOrder(order))
			}
		case *MappedControlHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithMappedControlHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*MappedControlHistoryWhereInput); ok {
		args.opts = append(args.opts, WithMappedControlHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NarrativeQuery) CollectFields(ctx context.Context, satisfies ...string) (*NarrativeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NarrativeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(narrative.Columns))
		selectedFields = []string{narrative.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[narrative.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldOwnerID)
				fieldSeen[narrative.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "satisfies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.SatisfiesTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(narrative.SatisfiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.SatisfiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.SatisfiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.SatisfiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Satisfies)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.SatisfiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSatisfies(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(narrative.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(narrative.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(narrative.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[narrative.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, narrative.FieldCreatedAt)
				fieldSeen[narrative.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[narrative.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, narrative.FieldUpdatedAt)
				fieldSeen[narrative.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[narrative.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, narrative.FieldCreatedBy)
				fieldSeen[narrative.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[narrative.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, narrative.FieldUpdatedBy)
				fieldSeen[narrative.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[narrative.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDisplayID)
				fieldSeen[narrative.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[narrative.FieldTags]; !ok {
				selectedFields = append(selectedFields, narrative.FieldTags)
				fieldSeen[narrative.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[narrative.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldOwnerID)
				fieldSeen[narrative.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[narrative.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, narrative.FieldSystemOwned)
				fieldSeen[narrative.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[narrative.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, narrative.FieldInternalNotes)
				fieldSeen[narrative.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[narrative.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldSystemInternalID)
				fieldSeen[narrative.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[narrative.FieldName]; !ok {
				selectedFields = append(selectedFields, narrative.FieldName)
				fieldSeen[narrative.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[narrative.FieldDescription]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDescription)
				fieldSeen[narrative.FieldDescription] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[narrative.FieldDetails]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDetails)
				fieldSeen[narrative.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type narrativePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NarrativePaginateOption
}

func newNarrativePaginateArgs(rv map[string]any) *narrativePaginateArgs {
	args := &narrativePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*NarrativeOrder:
			args.opts = append(args.opts, WithNarrativeOrder(v))
		case []any:
			var orders []*NarrativeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &NarrativeOrder{Field: &NarrativeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithNarrativeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*NarrativeWhereInput); ok {
		args.opts = append(args.opts, WithNarrativeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NarrativeHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*NarrativeHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NarrativeHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(narrativehistory.Columns))
		selectedFields = []string{narrativehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[narrativehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldHistoryTime)
				fieldSeen[narrativehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[narrativehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldRef)
				fieldSeen[narrativehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[narrativehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldOperation)
				fieldSeen[narrativehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[narrativehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldCreatedAt)
				fieldSeen[narrativehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[narrativehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldUpdatedAt)
				fieldSeen[narrativehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[narrativehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldCreatedBy)
				fieldSeen[narrativehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[narrativehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldUpdatedBy)
				fieldSeen[narrativehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[narrativehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldDisplayID)
				fieldSeen[narrativehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[narrativehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldTags)
				fieldSeen[narrativehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[narrativehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldOwnerID)
				fieldSeen[narrativehistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[narrativehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldSystemOwned)
				fieldSeen[narrativehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[narrativehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldInternalNotes)
				fieldSeen[narrativehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[narrativehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldSystemInternalID)
				fieldSeen[narrativehistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[narrativehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldName)
				fieldSeen[narrativehistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[narrativehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldDescription)
				fieldSeen[narrativehistory.FieldDescription] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[narrativehistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, narrativehistory.FieldDetails)
				fieldSeen[narrativehistory.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type narrativehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NarrativeHistoryPaginateOption
}

func newNarrativeHistoryPaginateArgs(rv map[string]any) *narrativehistoryPaginateArgs {
	args := &narrativehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &NarrativeHistoryOrder{Field: &NarrativeHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithNarrativeHistoryOrder(order))
			}
		case *NarrativeHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithNarrativeHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*NarrativeHistoryWhereInput); ok {
		args.opts = append(args.opts, WithNarrativeHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NoteQuery) CollectFields(ctx context.Context, satisfies ...string) (*NoteQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NoteQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(note.Columns))
		selectedFields = []string{note.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[note.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, note.FieldOwnerID)
				fieldSeen[note.FieldOwnerID] = struct{}{}
			}

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			_q.withTask = query

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query

		case "subcontrol":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrol = query

		case "procedure":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
				return err
			}
			_q.withProcedure = query

		case "risk":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
				return err
			}
			_q.withRisk = query

		case "internalPolicy":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicy = query

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Note) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"note_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(note.FilesColumn), ids...))
						})
						if err := query.GroupBy(note.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Note) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(note.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[note.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, note.FieldCreatedAt)
				fieldSeen[note.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[note.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, note.FieldUpdatedAt)
				fieldSeen[note.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[note.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, note.FieldCreatedBy)
				fieldSeen[note.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[note.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, note.FieldUpdatedBy)
				fieldSeen[note.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[note.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, note.FieldDisplayID)
				fieldSeen[note.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[note.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, note.FieldOwnerID)
				fieldSeen[note.FieldOwnerID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[note.FieldText]; !ok {
				selectedFields = append(selectedFields, note.FieldText)
				fieldSeen[note.FieldText] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type notePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NotePaginateOption
}

func newNotePaginateArgs(rv map[string]any) *notePaginateArgs {
	args := &notePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*NoteOrder:
			args.opts = append(args.opts, WithNoteOrder(v))
		case []any:
			var orders []*NoteOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &NoteOrder{Field: &NoteOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithNoteOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*NoteWhereInput); ok {
		args.opts = append(args.opts, WithNoteFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NoteHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*NoteHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NoteHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(notehistory.Columns))
		selectedFields = []string{notehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[notehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldHistoryTime)
				fieldSeen[notehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[notehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldRef)
				fieldSeen[notehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[notehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldOperation)
				fieldSeen[notehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[notehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldCreatedAt)
				fieldSeen[notehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[notehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldUpdatedAt)
				fieldSeen[notehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[notehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldCreatedBy)
				fieldSeen[notehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[notehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldUpdatedBy)
				fieldSeen[notehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[notehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldDisplayID)
				fieldSeen[notehistory.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[notehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldOwnerID)
				fieldSeen[notehistory.FieldOwnerID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[notehistory.FieldText]; !ok {
				selectedFields = append(selectedFields, notehistory.FieldText)
				fieldSeen[notehistory.FieldText] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type notehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NoteHistoryPaginateOption
}

func newNoteHistoryPaginateArgs(rv map[string]any) *notehistoryPaginateArgs {
	args := &notehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &NoteHistoryOrder{Field: &NoteHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithNoteHistoryOrder(order))
			}
		case *NoteHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithNoteHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*NoteHistoryWhereInput); ok {
		args.opts = append(args.opts, WithNoteHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OnboardingQuery) CollectFields(ctx context.Context, satisfies ...string) (*OnboardingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OnboardingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(onboarding.Columns))
		selectedFields = []string{onboarding.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOrganization = query
			if _, ok := fieldSeen[onboarding.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldOrganizationID)
				fieldSeen[onboarding.FieldOrganizationID] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[onboarding.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldOrganizationID)
				fieldSeen[onboarding.FieldOrganizationID] = struct{}{}
			}
		case "companyName":
			if _, ok := fieldSeen[onboarding.FieldCompanyName]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompanyName)
				fieldSeen[onboarding.FieldCompanyName] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[onboarding.FieldDomains]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldDomains)
				fieldSeen[onboarding.FieldDomains] = struct{}{}
			}
		case "companyDetails":
			if _, ok := fieldSeen[onboarding.FieldCompanyDetails]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompanyDetails)
				fieldSeen[onboarding.FieldCompanyDetails] = struct{}{}
			}
		case "userDetails":
			if _, ok := fieldSeen[onboarding.FieldUserDetails]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldUserDetails)
				fieldSeen[onboarding.FieldUserDetails] = struct{}{}
			}
		case "compliance":
			if _, ok := fieldSeen[onboarding.FieldCompliance]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompliance)
				fieldSeen[onboarding.FieldCompliance] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type onboardingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OnboardingPaginateOption
}

func newOnboardingPaginateArgs(rv map[string]any) *onboardingPaginateArgs {
	args := &onboardingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[whereField].(*OnboardingWhereInput); ok {
		args.opts = append(args.opts, WithOnboardingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrgMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrgMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgmembership.Columns))
		selectedFields = []string{orgmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOrganization = query
			if _, ok := fieldSeen[orgmembership.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldOrganizationID)
				fieldSeen[orgmembership.FieldOrganizationID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[orgmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUserID)
				fieldSeen[orgmembership.FieldUserID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*OrgMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"org_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(orgmembership.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(orgmembership.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(orgmembership.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(orgmembership.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(orgmembership.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*OrgMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(orgmembership.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[orgmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldCreatedAt)
				fieldSeen[orgmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUpdatedAt)
				fieldSeen[orgmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldCreatedBy)
				fieldSeen[orgmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUpdatedBy)
				fieldSeen[orgmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[orgmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldRole)
				fieldSeen[orgmembership.FieldRole] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[orgmembership.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldOrganizationID)
				fieldSeen[orgmembership.FieldOrganizationID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[orgmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUserID)
				fieldSeen[orgmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type orgmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgMembershipPaginateOption
}

func newOrgMembershipPaginateArgs(rv map[string]any) *orgmembershipPaginateArgs {
	args := &orgmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrgMembershipOrder:
			args.opts = append(args.opts, WithOrgMembershipOrder(v))
		case []any:
			var orders []*OrgMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrgMembershipOrder{Field: &OrgMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrgMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrgMembershipWhereInput); ok {
		args.opts = append(args.opts, WithOrgMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrgMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrgMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgmembershiphistory.Columns))
		selectedFields = []string{orgmembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[orgmembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldHistoryTime)
				fieldSeen[orgmembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[orgmembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldRef)
				fieldSeen[orgmembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[orgmembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldOperation)
				fieldSeen[orgmembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[orgmembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldCreatedAt)
				fieldSeen[orgmembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgmembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldUpdatedAt)
				fieldSeen[orgmembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgmembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldCreatedBy)
				fieldSeen[orgmembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgmembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldUpdatedBy)
				fieldSeen[orgmembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[orgmembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldRole)
				fieldSeen[orgmembershiphistory.FieldRole] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[orgmembershiphistory.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldOrganizationID)
				fieldSeen[orgmembershiphistory.FieldOrganizationID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[orgmembershiphistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembershiphistory.FieldUserID)
				fieldSeen[orgmembershiphistory.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type orgmembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgMembershipHistoryPaginateOption
}

func newOrgMembershipHistoryPaginateArgs(rv map[string]any) *orgmembershiphistoryPaginateArgs {
	args := &orgmembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgMembershipHistoryOrder{Field: &OrgMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgMembershipHistoryOrder(order))
			}
		case *OrgMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrgMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrgSubscriptionQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgSubscriptionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrgSubscriptionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgsubscription.Columns))
		selectedFields = []string{orgsubscription.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[orgsubscription.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldOwnerID)
				fieldSeen[orgsubscription.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*OrgSubscription) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"org_subscription_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(orgsubscription.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(orgsubscription.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(orgsubscription.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(orgsubscription.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(orgsubscription.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*OrgSubscription) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(orgsubscription.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[orgsubscription.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldCreatedAt)
				fieldSeen[orgsubscription.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgsubscription.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldUpdatedAt)
				fieldSeen[orgsubscription.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgsubscription.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldCreatedBy)
				fieldSeen[orgsubscription.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgsubscription.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldUpdatedBy)
				fieldSeen[orgsubscription.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[orgsubscription.FieldTags]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldTags)
				fieldSeen[orgsubscription.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[orgsubscription.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldOwnerID)
				fieldSeen[orgsubscription.FieldOwnerID] = struct{}{}
			}
		case "stripeSubscriptionID":
			if _, ok := fieldSeen[orgsubscription.FieldStripeSubscriptionID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeSubscriptionID)
				fieldSeen[orgsubscription.FieldStripeSubscriptionID] = struct{}{}
			}
		case "stripeSubscriptionStatus":
			if _, ok := fieldSeen[orgsubscription.FieldStripeSubscriptionStatus]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeSubscriptionStatus)
				fieldSeen[orgsubscription.FieldStripeSubscriptionStatus] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[orgsubscription.FieldActive]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldActive)
				fieldSeen[orgsubscription.FieldActive] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[orgsubscription.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldExpiresAt)
				fieldSeen[orgsubscription.FieldExpiresAt] = struct{}{}
			}
		case "trialExpiresAt":
			if _, ok := fieldSeen[orgsubscription.FieldTrialExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldTrialExpiresAt)
				fieldSeen[orgsubscription.FieldTrialExpiresAt] = struct{}{}
			}
		case "daysUntilDue":
			if _, ok := fieldSeen[orgsubscription.FieldDaysUntilDue]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldDaysUntilDue)
				fieldSeen[orgsubscription.FieldDaysUntilDue] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type orgsubscriptionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgSubscriptionPaginateOption
}

func newOrgSubscriptionPaginateArgs(rv map[string]any) *orgsubscriptionPaginateArgs {
	args := &orgsubscriptionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgSubscriptionOrder{Field: &OrgSubscriptionOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgSubscriptionOrder(order))
			}
		case *OrgSubscriptionOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgSubscriptionOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgSubscriptionWhereInput); ok {
		args.opts = append(args.opts, WithOrgSubscriptionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrgSubscriptionHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgSubscriptionHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrgSubscriptionHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgsubscriptionhistory.Columns))
		selectedFields = []string{orgsubscriptionhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldHistoryTime)
				fieldSeen[orgsubscriptionhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldRef)
				fieldSeen[orgsubscriptionhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldOperation)
				fieldSeen[orgsubscriptionhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldCreatedAt)
				fieldSeen[orgsubscriptionhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldUpdatedAt)
				fieldSeen[orgsubscriptionhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldCreatedBy)
				fieldSeen[orgsubscriptionhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldUpdatedBy)
				fieldSeen[orgsubscriptionhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldTags)
				fieldSeen[orgsubscriptionhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldOwnerID)
				fieldSeen[orgsubscriptionhistory.FieldOwnerID] = struct{}{}
			}
		case "stripeSubscriptionID":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionID]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldStripeSubscriptionID)
				fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionID] = struct{}{}
			}
		case "stripeSubscriptionStatus":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionStatus]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldStripeSubscriptionStatus)
				fieldSeen[orgsubscriptionhistory.FieldStripeSubscriptionStatus] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldActive]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldActive)
				fieldSeen[orgsubscriptionhistory.FieldActive] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldExpiresAt)
				fieldSeen[orgsubscriptionhistory.FieldExpiresAt] = struct{}{}
			}
		case "trialExpiresAt":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldTrialExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldTrialExpiresAt)
				fieldSeen[orgsubscriptionhistory.FieldTrialExpiresAt] = struct{}{}
			}
		case "daysUntilDue":
			if _, ok := fieldSeen[orgsubscriptionhistory.FieldDaysUntilDue]; !ok {
				selectedFields = append(selectedFields, orgsubscriptionhistory.FieldDaysUntilDue)
				fieldSeen[orgsubscriptionhistory.FieldDaysUntilDue] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type orgsubscriptionhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgSubscriptionHistoryPaginateOption
}

func newOrgSubscriptionHistoryPaginateArgs(rv map[string]any) *orgsubscriptionhistoryPaginateArgs {
	args := &orgsubscriptionhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgSubscriptionHistoryOrder{Field: &OrgSubscriptionHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgSubscriptionHistoryOrder(order))
			}
		case *OrgSubscriptionHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgSubscriptionHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgSubscriptionHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrgSubscriptionHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrganizationQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrganizationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organization.Columns))
		selectedFields = []string{organization.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "controlCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlCreators)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlImplementationCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_implementation_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlImplementationCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlImplementationCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationCreators)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlImplementationCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlObjectiveCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_objective_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlObjectiveCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlObjectiveCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveCreators)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlObjectiveCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "evidenceCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_evidence_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EvidenceCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.EvidenceCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EvidenceCreators)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EvidenceCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidenceCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "groupCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_group_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.GroupCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.GroupCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupCreators)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.GroupCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroupCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "internalPolicyCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_internal_policy_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InternalPolicyCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.InternalPolicyCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyCreators)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InternalPolicyCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicyCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "mappedControlCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_mapped_control_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MappedControlCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.MappedControlCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlCreators)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MappedControlCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControlCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "narrativeCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_narrative_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NarrativeCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.NarrativeCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeCreators)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NarrativeCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "procedureCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_procedure_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProcedureCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProcedureCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureCreators)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProcedureCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedureCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_program_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProgramCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProgramCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramCreators)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProgramCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "riskCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_risk_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RiskCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.RiskCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskCreators)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RiskCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "scheduledJobCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_scheduled_job_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobCreators)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "standardCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_standard_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.StandardCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.StandardCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.StandardCreators)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.StandardCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedStandardCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "templateCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_template_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TemplateCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TemplateCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TemplateCreators)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TemplateCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTemplateCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "subprocessorCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_subprocessor_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubprocessorCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubprocessorCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.SubprocessorCreators)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubprocessorCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubprocessorCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "trustCenterDocCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_trust_center_doc_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCenterDocCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCenterDocCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterDocCreators)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCenterDocCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterDocCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "trustCenterSubprocessorCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_trust_center_subprocessor_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCenterSubprocessorCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCenterSubprocessorCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessorCreators)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCenterSubprocessorCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterSubprocessorCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "parent":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withParent = query
			if _, ok := fieldSeen[organization.FieldParentOrganizationID]; !ok {
				selectedFields = append(selectedFields, organization.FieldParentOrganizationID)
				fieldSeen[organization.FieldParentOrganizationID] = struct{}{}
			}

		case "children":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"parent_organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ChildrenColumn), ids...))
						})
						if err := query.GroupBy(organization.ChildrenColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Children)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ChildrenColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedChildren(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationsettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: _q.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.PersonalAccessTokensTable)
							s.Join(joinT).On(s.C(personalaccesstoken.FieldID), joinT.C(organization.PersonalAccessTokensPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.PersonalAccessTokensPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "apiTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APITokenClient{config: _q.config}).Query()
			)
			args := newAPITokenPaginateArgs(fieldArgs(ctx, new(APITokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAPITokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.APITokensColumn), ids...))
						})
						if err := query.GroupBy(organization.APITokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.APITokens)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, apitokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.APITokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAPITokens(alias, func(wq *APITokenQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(organization.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(organization.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(organization.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(organization.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(organization.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SecretsColumn), ids...))
						})
						if err := query.GroupBy(organization.SecretsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SecretsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "avatarFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withAvatarFile = query
			if _, ok := fieldSeen[organization.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarLocalFileID)
				fieldSeen[organization.FieldAvatarLocalFileID] = struct{}{}
			}

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.GroupsColumn), ids...))
						})
						if err := query.GroupBy(organization.GroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.GroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "templates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			args := newTemplatePaginateArgs(fieldArgs(ctx, new(TemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TemplatesColumn), ids...))
						})
						if err := query.GroupBy(organization.TemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Templates)
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTemplates(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(organization.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DocumentsColumn), ids...))
						})
						if err := query.GroupBy(organization.DocumentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DocumentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "orgSubscriptions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgSubscriptionClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, orgsubscriptionImplementors)...); err != nil {
				return err
			}
			_q.WithNamedOrgSubscriptions(alias, func(wq *OrgSubscriptionQuery) {
				*wq = *query
			})

		case "invites":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InviteClient{config: _q.config}).Query()
			)
			args := newInvitePaginateArgs(fieldArgs(ctx, new(InviteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInvitePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InvitesColumn), ids...))
						})
						if err := query.GroupBy(organization.InvitesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Invites)
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, inviteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InvitesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInvites(alias, func(wq *InviteQuery) {
				*wq = *query
			})

		case "subscribers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubscriberClient{config: _q.config}).Query()
			)
			args := newSubscriberPaginateArgs(fieldArgs(ctx, new(SubscriberWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubscriberPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubscribersColumn), ids...))
						})
						if err := query.GroupBy(organization.SubscribersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subscribers)
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subscriberImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubscribersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubscribers(alias, func(wq *SubscriberQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(organization.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityTypes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: _q.config}).Query()
			)
			args := newEntityTypePaginateArgs(fieldArgs(ctx, new(EntityTypeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityTypePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EntityTypesColumn), ids...))
						})
						if err := query.GroupBy(organization.EntityTypesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityTypes)
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EntityTypesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityTypes(alias, func(wq *EntityTypeQuery) {
				*wq = *query
			})

		case "contacts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: _q.config}).Query()
			)
			args := newContactPaginateArgs(fieldArgs(ctx, new(ContactWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newContactPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ContactsColumn), ids...))
						})
						if err := query.GroupBy(organization.ContactsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Contacts)
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ContactsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedContacts(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NotesColumn), ids...))
						})
						if err := query.GroupBy(organization.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TasksColumn), ids...))
						})
						if err := query.GroupBy(organization.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(organization.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[40] == nil {
								nodes[i].Edges.totalCount[40] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[40][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[40] == nil {
								nodes[i].Edges.totalCount[40] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[40][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InternalPoliciesColumn), ids...))
						})
						if err := query.GroupBy(organization.InternalPoliciesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[41] == nil {
								nodes[i].Edges.totalCount[41] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[41][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[41] == nil {
								nodes[i].Edges.totalCount[41] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[41][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InternalPoliciesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RisksColumn), ids...))
						})
						if err := query.GroupBy(organization.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[42] == nil {
								nodes[i].Edges.totalCount[42] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[42][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[42] == nil {
								nodes[i].Edges.totalCount[42] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[42][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlObjectivesColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlObjectivesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[43] == nil {
								nodes[i].Edges.totalCount[43] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[43][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[43] == nil {
								nodes[i].Edges.totalCount[43] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[43][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlObjectivesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(organization.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[44] == nil {
								nodes[i].Edges.totalCount[44] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[44][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[44] == nil {
								nodes[i].Edges.totalCount[44] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[44][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[45] == nil {
								nodes[i].Edges.totalCount[45] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[45][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[45] == nil {
								nodes[i].Edges.totalCount[45] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[45][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[46] == nil {
								nodes[i].Edges.totalCount[46] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[46][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[46] == nil {
								nodes[i].Edges.totalCount[46] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[46][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[47] == nil {
								nodes[i].Edges.totalCount[47] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[47][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[47] == nil {
								nodes[i].Edges.totalCount[47] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[47][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "mappedControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: _q.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MappedControlsColumn), ids...))
						})
						if err := query.GroupBy(organization.MappedControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[48] == nil {
								nodes[i].Edges.totalCount[48] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[48][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControls)
							if nodes[i].Edges.totalCount[48] == nil {
								nodes[i].Edges.totalCount[48] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[48][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MappedControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControls(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EvidenceColumn), ids...))
						})
						if err := query.GroupBy(organization.EvidenceColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[49] == nil {
								nodes[i].Edges.totalCount[49] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[49][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[49] == nil {
								nodes[i].Edges.totalCount[49] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[49][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EvidenceColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "standards":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			args := newStandardPaginateArgs(fieldArgs(ctx, new(StandardWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newStandardPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.StandardsColumn), ids...))
						})
						if err := query.GroupBy(organization.StandardsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[50] == nil {
								nodes[i].Edges.totalCount[50] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[50][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Standards)
							if nodes[i].Edges.totalCount[50] == nil {
								nodes[i].Edges.totalCount[50] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[50][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.StandardsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedStandards(alias, func(wq *StandardQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(organization.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[51] == nil {
								nodes[i].Edges.totalCount[51] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[51][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[51] == nil {
								nodes[i].Edges.totalCount[51] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[51][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(organization.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[52] == nil {
								nodes[i].Edges.totalCount[52] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[52][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[52] == nil {
								nodes[i].Edges.totalCount[52] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[52][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})

		case "jobRunners":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			args := newJobRunnerPaginateArgs(fieldArgs(ctx, new(JobRunnerWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnersColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[53] == nil {
								nodes[i].Edges.totalCount[53] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[53][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunners)
							if nodes[i].Edges.totalCount[53] == nil {
								nodes[i].Edges.totalCount[53] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[53][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunners(alias, func(wq *JobRunnerQuery) {
				*wq = *query
			})

		case "jobRunnerTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerTokenClient{config: _q.config}).Query()
			)
			args := newJobRunnerTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnerTokensColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnerTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[54] == nil {
								nodes[i].Edges.totalCount[54] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[54][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerTokens)
							if nodes[i].Edges.totalCount[54] == nil {
								nodes[i].Edges.totalCount[54] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[54][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnertokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnerTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunnerTokens(alias, func(wq *JobRunnerTokenQuery) {
				*wq = *query
			})

		case "jobRunnerRegistrationTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerRegistrationTokenClient{config: _q.config}).Query()
			)
			args := newJobRunnerRegistrationTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerRegistrationTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerRegistrationTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnerRegistrationTokensColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnerRegistrationTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[55] == nil {
								nodes[i].Edges.totalCount[55] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[55][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerRegistrationTokens)
							if nodes[i].Edges.totalCount[55] == nil {
								nodes[i].Edges.totalCount[55] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[55][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerregistrationtokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnerRegistrationTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunnerRegistrationTokens(alias, func(wq *JobRunnerRegistrationTokenQuery) {
				*wq = *query
			})

		case "dnsVerifications":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DNSVerificationClient{config: _q.config}).Query()
			)
			args := newDNSVerificationPaginateArgs(fieldArgs(ctx, new(DNSVerificationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDNSVerificationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DNSVerificationsColumn), ids...))
						})
						if err := query.GroupBy(organization.DNSVerificationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[56] == nil {
								nodes[i].Edges.totalCount[56] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[56][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DNSVerifications)
							if nodes[i].Edges.totalCount[56] == nil {
								nodes[i].Edges.totalCount[56] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[56][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, dnsverificationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DNSVerificationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDNSVerifications(alias, func(wq *DNSVerificationQuery) {
				*wq = *query
			})

		case "jobTemplates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobTemplateClient{config: _q.config}).Query()
			)
			args := newJobTemplatePaginateArgs(fieldArgs(ctx, new(JobTemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobTemplatesColumn), ids...))
						})
						if err := query.GroupBy(organization.JobTemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[57] == nil {
								nodes[i].Edges.totalCount[57] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[57][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobTemplates)
							if nodes[i].Edges.totalCount[57] == nil {
								nodes[i].Edges.totalCount[57] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[57][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobtemplateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobTemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobTemplates(alias, func(wq *JobTemplateQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[58] == nil {
								nodes[i].Edges.totalCount[58] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[58][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[58] == nil {
								nodes[i].Edges.totalCount[58] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[58][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})

		case "jobResults":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobResultClient{config: _q.config}).Query()
			)
			args := newJobResultPaginateArgs(fieldArgs(ctx, new(JobResultWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobResultPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobResultsColumn), ids...))
						})
						if err := query.GroupBy(organization.JobResultsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[59] == nil {
								nodes[i].Edges.totalCount[59] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[59][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobResults)
							if nodes[i].Edges.totalCount[59] == nil {
								nodes[i].Edges.totalCount[59] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[59][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobresultImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobResultsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobResults(alias, func(wq *JobResultQuery) {
				*wq = *query
			})

		case "scheduledJobRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobRunClient{config: _q.config}).Query()
			)
			args := newScheduledJobRunPaginateArgs(fieldArgs(ctx, new(ScheduledJobRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobRunsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[60] == nil {
								nodes[i].Edges.totalCount[60] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[60][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobRuns)
							if nodes[i].Edges.totalCount[60] == nil {
								nodes[i].Edges.totalCount[60] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[60][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobRuns(alias, func(wq *ScheduledJobRunQuery) {
				*wq = *query
			})

		case "trustCenters":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			args := newTrustCenterPaginateArgs(fieldArgs(ctx, new(TrustCenterWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCentersColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCentersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[61] == nil {
								nodes[i].Edges.totalCount[61] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[61][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenters)
							if nodes[i].Edges.totalCount[61] == nil {
								nodes[i].Edges.totalCount[61] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[61][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCentersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenters(alias, func(wq *TrustCenterQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssetsColumn), ids...))
						})
						if err := query.GroupBy(organization.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[62] == nil {
								nodes[i].Edges.totalCount[62] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[62][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[62] == nil {
								nodes[i].Edges.totalCount[62] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[62][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScansColumn), ids...))
						})
						if err := query.GroupBy(organization.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[63] == nil {
								nodes[i].Edges.totalCount[63] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[63][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[63] == nil {
								nodes[i].Edges.totalCount[63] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[63][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "subprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: _q.config}).Query()
			)
			args := newSubprocessorPaginateArgs(fieldArgs(ctx, new(SubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[64] == nil {
								nodes[i].Edges.totalCount[64] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[64][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subprocessors)
							if nodes[i].Edges.totalCount[64] == nil {
								nodes[i].Edges.totalCount[64] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[64][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubprocessors(alias, func(wq *SubprocessorQuery) {
				*wq = *query
			})

		case "exports":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ExportClient{config: _q.config}).Query()
			)
			args := newExportPaginateArgs(fieldArgs(ctx, new(ExportWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newExportPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ExportsColumn), ids...))
						})
						if err := query.GroupBy(organization.ExportsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[65] == nil {
								nodes[i].Edges.totalCount[65] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[65][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Exports)
							if nodes[i].Edges.totalCount[65] == nil {
								nodes[i].Edges.totalCount[65] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[65][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, exportImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ExportsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedExports(alias, func(wq *ExportQuery) {
				*wq = *query
			})

		case "trustCenterWatermarkConfigs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterWatermarkConfigClient{config: _q.config}).Query()
			)
			args := newTrustCenterWatermarkConfigPaginateArgs(fieldArgs(ctx, new(TrustCenterWatermarkConfigWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterWatermarkConfigPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCenterWatermarkConfigsColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCenterWatermarkConfigsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[66] == nil {
								nodes[i].Edges.totalCount[66] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[66][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterWatermarkConfigs)
							if nodes[i].Edges.totalCount[66] == nil {
								nodes[i].Edges.totalCount[66] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[66][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterwatermarkconfigImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCenterWatermarkConfigsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterWatermarkConfigs(alias, func(wq *TrustCenterWatermarkConfigQuery) {
				*wq = *query
			})

		case "assessments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentClient{config: _q.config}).Query()
			)
			args := newAssessmentPaginateArgs(fieldArgs(ctx, new(AssessmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssessmentsColumn), ids...))
						})
						if err := query.GroupBy(organization.AssessmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[67] == nil {
								nodes[i].Edges.totalCount[67] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[67][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assessments)
							if nodes[i].Edges.totalCount[67] == nil {
								nodes[i].Edges.totalCount[67] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[67][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssessmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessments(alias, func(wq *AssessmentQuery) {
				*wq = *query
			})

		case "assessmentResponses":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentResponseClient{config: _q.config}).Query()
			)
			args := newAssessmentResponsePaginateArgs(fieldArgs(ctx, new(AssessmentResponseWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentResponsePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssessmentResponsesColumn), ids...))
						})
						if err := query.GroupBy(organization.AssessmentResponsesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[68] == nil {
								nodes[i].Edges.totalCount[68] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[68][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssessmentResponses)
							if nodes[i].Edges.totalCount[68] == nil {
								nodes[i].Edges.totalCount[68] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[68][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentresponseImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssessmentResponsesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessmentResponses(alias, func(wq *AssessmentResponseQuery) {
				*wq = *query
			})

		case "customTypeEnums":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			args := newCustomTypeEnumPaginateArgs(fieldArgs(ctx, new(CustomTypeEnumWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomTypeEnumPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.CustomTypeEnumsColumn), ids...))
						})
						if err := query.GroupBy(organization.CustomTypeEnumsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[69] == nil {
								nodes[i].Edges.totalCount[69] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[69][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomTypeEnums)
							if nodes[i].Edges.totalCount[69] == nil {
								nodes[i].Edges.totalCount[69] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[69][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.CustomTypeEnumsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomTypeEnums(alias, func(wq *CustomTypeEnumQuery) {
				*wq = *query
			})

		case "tagDefinitions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TagDefinitionClient{config: _q.config}).Query()
			)
			args := newTagDefinitionPaginateArgs(fieldArgs(ctx, new(TagDefinitionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTagDefinitionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TagDefinitionsColumn), ids...))
						})
						if err := query.GroupBy(organization.TagDefinitionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[70] == nil {
								nodes[i].Edges.totalCount[70] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[70][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TagDefinitions)
							if nodes[i].Edges.totalCount[70] == nil {
								nodes[i].Edges.totalCount[70] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[70][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tagdefinitionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TagDefinitionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTagDefinitions(alias, func(wq *TagDefinitionQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(organization.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[71] == nil {
								nodes[i].Edges.totalCount[71] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[71][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[71] == nil {
								nodes[i].Edges.totalCount[71] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[71][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.FindingsColumn), ids...))
						})
						if err := query.GroupBy(organization.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[72] == nil {
								nodes[i].Edges.totalCount[72] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[72][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[72] == nil {
								nodes[i].Edges.totalCount[72] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[72][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(organization.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[73] == nil {
								nodes[i].Edges.totalCount[73] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[73][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[73] == nil {
								nodes[i].Edges.totalCount[73] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[73][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(organization.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[74] == nil {
								nodes[i].Edges.totalCount[74] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[74][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[74] == nil {
								nodes[i].Edges.totalCount[74] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[74][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "workflowDefinitions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowDefinitionClient{config: _q.config}).Query()
			)
			args := newWorkflowDefinitionPaginateArgs(fieldArgs(ctx, new(WorkflowDefinitionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowDefinitionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowDefinitionsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowDefinitionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[75] == nil {
								nodes[i].Edges.totalCount[75] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[75][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowDefinitions)
							if nodes[i].Edges.totalCount[75] == nil {
								nodes[i].Edges.totalCount[75] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[75][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowdefinitionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowDefinitionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowDefinitions(alias, func(wq *WorkflowDefinitionQuery) {
				*wq = *query
			})

		case "workflowInstances":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			args := newWorkflowInstancePaginateArgs(fieldArgs(ctx, new(WorkflowInstanceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowInstancePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowInstancesColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowInstancesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[76] == nil {
								nodes[i].Edges.totalCount[76] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[76][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowInstances)
							if nodes[i].Edges.totalCount[76] == nil {
								nodes[i].Edges.totalCount[76] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[76][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowInstancesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowInstances(alias, func(wq *WorkflowInstanceQuery) {
				*wq = *query
			})

		case "workflowEvents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowEventClient{config: _q.config}).Query()
			)
			args := newWorkflowEventPaginateArgs(fieldArgs(ctx, new(WorkflowEventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowEventsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowEventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[77] == nil {
								nodes[i].Edges.totalCount[77] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[77][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowEvents)
							if nodes[i].Edges.totalCount[77] == nil {
								nodes[i].Edges.totalCount[77] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[77][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workfloweventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowEventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowEvents(alias, func(wq *WorkflowEventQuery) {
				*wq = *query
			})

		case "workflowAssignments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowAssignmentsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowAssignmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[78] == nil {
								nodes[i].Edges.totalCount[78] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[78][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignments)
							if nodes[i].Edges.totalCount[78] == nil {
								nodes[i].Edges.totalCount[78] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[78][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowAssignmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignments(alias, func(wq *WorkflowAssignmentQuery) {
				*wq = *query
			})

		case "workflowAssignmentTargets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentTargetClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentTargetPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentTargetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentTargetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowAssignmentTargetsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowAssignmentTargetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[79] == nil {
								nodes[i].Edges.totalCount[79] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[79][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignmentTargets)
							if nodes[i].Edges.totalCount[79] == nil {
								nodes[i].Edges.totalCount[79] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[79][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmenttargetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowAssignmentTargetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignmentTargets(alias, func(wq *WorkflowAssignmentTargetQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[80] == nil {
								nodes[i].Edges.totalCount[80] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[80][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[80] == nil {
								nodes[i].Edges.totalCount[80] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[80][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "directoryAccounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectoryAccountsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectoryAccountsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[81] == nil {
								nodes[i].Edges.totalCount[81] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[81][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryAccounts)
							if nodes[i].Edges.totalCount[81] == nil {
								nodes[i].Edges.totalCount[81] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[81][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectoryAccountsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "directoryGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectoryGroupsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectoryGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[82] == nil {
								nodes[i].Edges.totalCount[82] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[82][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryGroups)
							if nodes[i].Edges.totalCount[82] == nil {
								nodes[i].Edges.totalCount[82] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[82][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectoryGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "directoryMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectoryMembershipsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectoryMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[83] == nil {
								nodes[i].Edges.totalCount[83] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[83][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryMemberships)
							if nodes[i].Edges.totalCount[83] == nil {
								nodes[i].Edges.totalCount[83] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[83][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectoryMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})

		case "directorySyncRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			args := newDirectorySyncRunPaginateArgs(fieldArgs(ctx, new(DirectorySyncRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectorySyncRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectorySyncRunsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectorySyncRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[84] == nil {
								nodes[i].Edges.totalCount[84] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[84][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectorySyncRuns)
							if nodes[i].Edges.totalCount[84] == nil {
								nodes[i].Edges.totalCount[84] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[84][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectorySyncRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectorySyncRuns(alias, func(wq *DirectorySyncRunQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: _q.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MembersColumn), ids...))
						})
						if err := query.GroupBy(organization.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[85] == nil {
								nodes[i].Edges.totalCount[85] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[85][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[85] == nil {
								nodes[i].Edges.totalCount[85] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[85][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[organization.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldCreatedAt)
				fieldSeen[organization.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organization.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldUpdatedAt)
				fieldSeen[organization.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organization.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organization.FieldCreatedBy)
				fieldSeen[organization.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organization.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organization.FieldUpdatedBy)
				fieldSeen[organization.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organization.FieldTags]; !ok {
				selectedFields = append(selectedFields, organization.FieldTags)
				fieldSeen[organization.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[organization.FieldName]; !ok {
				selectedFields = append(selectedFields, organization.FieldName)
				fieldSeen[organization.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[organization.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, organization.FieldDisplayName)
				fieldSeen[organization.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[organization.FieldDescription]; !ok {
				selectedFields = append(selectedFields, organization.FieldDescription)
				fieldSeen[organization.FieldDescription] = struct{}{}
			}
		case "personalOrg":
			if _, ok := fieldSeen[organization.FieldPersonalOrg]; !ok {
				selectedFields = append(selectedFields, organization.FieldPersonalOrg)
				fieldSeen[organization.FieldPersonalOrg] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[organization.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarRemoteURL)
				fieldSeen[organization.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[organization.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarLocalFileID)
				fieldSeen[organization.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[organization.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarUpdatedAt)
				fieldSeen[organization.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "dedicatedDb":
			if _, ok := fieldSeen[organization.FieldDedicatedDb]; !ok {
				selectedFields = append(selectedFields, organization.FieldDedicatedDb)
				fieldSeen[organization.FieldDedicatedDb] = struct{}{}
			}
		case "stripeCustomerID":
			if _, ok := fieldSeen[organization.FieldStripeCustomerID]; !ok {
				selectedFields = append(selectedFields, organization.FieldStripeCustomerID)
				fieldSeen[organization.FieldStripeCustomerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type organizationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationPaginateOption
}

func newOrganizationPaginateArgs(rv map[string]any) *organizationPaginateArgs {
	args := &organizationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrganizationOrder:
			args.opts = append(args.opts, WithOrganizationOrder(v))
		case []any:
			var orders []*OrganizationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrganizationOrder{Field: &OrganizationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrganizationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrganizationWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrganizationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrganizationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationhistory.Columns))
		selectedFields = []string{organizationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[organizationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldHistoryTime)
				fieldSeen[organizationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[organizationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldRef)
				fieldSeen[organizationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[organizationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldOperation)
				fieldSeen[organizationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[organizationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldCreatedAt)
				fieldSeen[organizationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldUpdatedAt)
				fieldSeen[organizationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldCreatedBy)
				fieldSeen[organizationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldUpdatedBy)
				fieldSeen[organizationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldTags)
				fieldSeen[organizationhistory.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[organizationhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldName)
				fieldSeen[organizationhistory.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[organizationhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldDisplayName)
				fieldSeen[organizationhistory.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[organizationhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldDescription)
				fieldSeen[organizationhistory.FieldDescription] = struct{}{}
			}
		case "personalOrg":
			if _, ok := fieldSeen[organizationhistory.FieldPersonalOrg]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldPersonalOrg)
				fieldSeen[organizationhistory.FieldPersonalOrg] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[organizationhistory.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldAvatarRemoteURL)
				fieldSeen[organizationhistory.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[organizationhistory.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldAvatarLocalFileID)
				fieldSeen[organizationhistory.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[organizationhistory.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldAvatarUpdatedAt)
				fieldSeen[organizationhistory.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "dedicatedDb":
			if _, ok := fieldSeen[organizationhistory.FieldDedicatedDb]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldDedicatedDb)
				fieldSeen[organizationhistory.FieldDedicatedDb] = struct{}{}
			}
		case "stripeCustomerID":
			if _, ok := fieldSeen[organizationhistory.FieldStripeCustomerID]; !ok {
				selectedFields = append(selectedFields, organizationhistory.FieldStripeCustomerID)
				fieldSeen[organizationhistory.FieldStripeCustomerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type organizationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationHistoryPaginateOption
}

func newOrganizationHistoryPaginateArgs(rv map[string]any) *organizationhistoryPaginateArgs {
	args := &organizationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrganizationHistoryOrder{Field: &OrganizationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrganizationHistoryOrder(order))
			}
		case *OrganizationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrganizationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrganizationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrganizationSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrganizationSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationsetting.Columns))
		selectedFields = []string{organizationsetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOrganization = query
			if _, ok := fieldSeen[organizationsetting.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOrganizationID)
				fieldSeen[organizationsetting.FieldOrganizationID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*OrganizationSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organizationsetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(organizationsetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organizationsetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(organizationsetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organizationsetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*OrganizationSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organizationsetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[organizationsetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldCreatedAt)
				fieldSeen[organizationsetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationsetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldUpdatedAt)
				fieldSeen[organizationsetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationsetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldCreatedBy)
				fieldSeen[organizationsetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationsetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldUpdatedBy)
				fieldSeen[organizationsetting.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationsetting.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldTags)
				fieldSeen[organizationsetting.FieldTags] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[organizationsetting.FieldDomains]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldDomains)
				fieldSeen[organizationsetting.FieldDomains] = struct{}{}
			}
		case "billingContact":
			if _, ok := fieldSeen[organizationsetting.FieldBillingContact]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingContact)
				fieldSeen[organizationsetting.FieldBillingContact] = struct{}{}
			}
		case "billingEmail":
			if _, ok := fieldSeen[organizationsetting.FieldBillingEmail]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingEmail)
				fieldSeen[organizationsetting.FieldBillingEmail] = struct{}{}
			}
		case "billingPhone":
			if _, ok := fieldSeen[organizationsetting.FieldBillingPhone]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingPhone)
				fieldSeen[organizationsetting.FieldBillingPhone] = struct{}{}
			}
		case "billingAddress":
			if _, ok := fieldSeen[organizationsetting.FieldBillingAddress]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingAddress)
				fieldSeen[organizationsetting.FieldBillingAddress] = struct{}{}
			}
		case "taxIdentifier":
			if _, ok := fieldSeen[organizationsetting.FieldTaxIdentifier]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldTaxIdentifier)
				fieldSeen[organizationsetting.FieldTaxIdentifier] = struct{}{}
			}
		case "geoLocation":
			if _, ok := fieldSeen[organizationsetting.FieldGeoLocation]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldGeoLocation)
				fieldSeen[organizationsetting.FieldGeoLocation] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[organizationsetting.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOrganizationID)
				fieldSeen[organizationsetting.FieldOrganizationID] = struct{}{}
			}
		case "billingNotificationsEnabled":
			if _, ok := fieldSeen[organizationsetting.FieldBillingNotificationsEnabled]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingNotificationsEnabled)
				fieldSeen[organizationsetting.FieldBillingNotificationsEnabled] = struct{}{}
			}
		case "allowedEmailDomains":
			if _, ok := fieldSeen[organizationsetting.FieldAllowedEmailDomains]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldAllowedEmailDomains)
				fieldSeen[organizationsetting.FieldAllowedEmailDomains] = struct{}{}
			}
		case "allowMatchingDomainsAutojoin":
			if _, ok := fieldSeen[organizationsetting.FieldAllowMatchingDomainsAutojoin]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldAllowMatchingDomainsAutojoin)
				fieldSeen[organizationsetting.FieldAllowMatchingDomainsAutojoin] = struct{}{}
			}
		case "identityProvider":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProvider]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProvider)
				fieldSeen[organizationsetting.FieldIdentityProvider] = struct{}{}
			}
		case "identityProviderClientID":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderClientID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderClientID)
				fieldSeen[organizationsetting.FieldIdentityProviderClientID] = struct{}{}
			}
		case "identityProviderClientSecret":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderClientSecret]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderClientSecret)
				fieldSeen[organizationsetting.FieldIdentityProviderClientSecret] = struct{}{}
			}
		case "identityProviderMetadataEndpoint":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderMetadataEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderMetadataEndpoint)
				fieldSeen[organizationsetting.FieldIdentityProviderMetadataEndpoint] = struct{}{}
			}
		case "identityProviderAuthTested":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderAuthTested]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderAuthTested)
				fieldSeen[organizationsetting.FieldIdentityProviderAuthTested] = struct{}{}
			}
		case "identityProviderEntityID":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderEntityID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderEntityID)
				fieldSeen[organizationsetting.FieldIdentityProviderEntityID] = struct{}{}
			}
		case "oidcDiscoveryEndpoint":
			if _, ok := fieldSeen[organizationsetting.FieldOidcDiscoveryEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOidcDiscoveryEndpoint)
				fieldSeen[organizationsetting.FieldOidcDiscoveryEndpoint] = struct{}{}
			}
		case "samlSigninURL":
			if _, ok := fieldSeen[organizationsetting.FieldSamlSigninURL]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldSamlSigninURL)
				fieldSeen[organizationsetting.FieldSamlSigninURL] = struct{}{}
			}
		case "samlIssuer":
			if _, ok := fieldSeen[organizationsetting.FieldSamlIssuer]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldSamlIssuer)
				fieldSeen[organizationsetting.FieldSamlIssuer] = struct{}{}
			}
		case "samlCert":
			if _, ok := fieldSeen[organizationsetting.FieldSamlCert]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldSamlCert)
				fieldSeen[organizationsetting.FieldSamlCert] = struct{}{}
			}
		case "identityProviderLoginEnforced":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderLoginEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderLoginEnforced)
				fieldSeen[organizationsetting.FieldIdentityProviderLoginEnforced] = struct{}{}
			}
		case "multifactorAuthEnforced":
			if _, ok := fieldSeen[organizationsetting.FieldMultifactorAuthEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldMultifactorAuthEnforced)
				fieldSeen[organizationsetting.FieldMultifactorAuthEnforced] = struct{}{}
			}
		case "complianceWebhookToken":
			if _, ok := fieldSeen[organizationsetting.FieldComplianceWebhookToken]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldComplianceWebhookToken)
				fieldSeen[organizationsetting.FieldComplianceWebhookToken] = struct{}{}
			}
		case "paymentMethodAdded":
			if _, ok := fieldSeen[organizationsetting.FieldPaymentMethodAdded]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldPaymentMethodAdded)
				fieldSeen[organizationsetting.FieldPaymentMethodAdded] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type organizationsettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationSettingPaginateOption
}

func newOrganizationSettingPaginateArgs(rv map[string]any) *organizationsettingPaginateArgs {
	args := &organizationsettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrganizationSettingOrder:
			args.opts = append(args.opts, WithOrganizationSettingOrder(v))
		case []any:
			var orders []*OrganizationSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrganizationSettingOrder{Field: &OrganizationSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrganizationSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrganizationSettingWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrganizationSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrganizationSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationsettinghistory.Columns))
		selectedFields = []string{organizationsettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[organizationsettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldHistoryTime)
				fieldSeen[organizationsettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[organizationsettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldRef)
				fieldSeen[organizationsettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[organizationsettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldOperation)
				fieldSeen[organizationsettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[organizationsettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldCreatedAt)
				fieldSeen[organizationsettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationsettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldUpdatedAt)
				fieldSeen[organizationsettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationsettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldCreatedBy)
				fieldSeen[organizationsettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationsettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldUpdatedBy)
				fieldSeen[organizationsettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationsettinghistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldTags)
				fieldSeen[organizationsettinghistory.FieldTags] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[organizationsettinghistory.FieldDomains]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldDomains)
				fieldSeen[organizationsettinghistory.FieldDomains] = struct{}{}
			}
		case "billingContact":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingContact]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingContact)
				fieldSeen[organizationsettinghistory.FieldBillingContact] = struct{}{}
			}
		case "billingEmail":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingEmail]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingEmail)
				fieldSeen[organizationsettinghistory.FieldBillingEmail] = struct{}{}
			}
		case "billingPhone":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingPhone]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingPhone)
				fieldSeen[organizationsettinghistory.FieldBillingPhone] = struct{}{}
			}
		case "billingAddress":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingAddress]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingAddress)
				fieldSeen[organizationsettinghistory.FieldBillingAddress] = struct{}{}
			}
		case "taxIdentifier":
			if _, ok := fieldSeen[organizationsettinghistory.FieldTaxIdentifier]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldTaxIdentifier)
				fieldSeen[organizationsettinghistory.FieldTaxIdentifier] = struct{}{}
			}
		case "geoLocation":
			if _, ok := fieldSeen[organizationsettinghistory.FieldGeoLocation]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldGeoLocation)
				fieldSeen[organizationsettinghistory.FieldGeoLocation] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[organizationsettinghistory.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldOrganizationID)
				fieldSeen[organizationsettinghistory.FieldOrganizationID] = struct{}{}
			}
		case "billingNotificationsEnabled":
			if _, ok := fieldSeen[organizationsettinghistory.FieldBillingNotificationsEnabled]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldBillingNotificationsEnabled)
				fieldSeen[organizationsettinghistory.FieldBillingNotificationsEnabled] = struct{}{}
			}
		case "allowedEmailDomains":
			if _, ok := fieldSeen[organizationsettinghistory.FieldAllowedEmailDomains]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldAllowedEmailDomains)
				fieldSeen[organizationsettinghistory.FieldAllowedEmailDomains] = struct{}{}
			}
		case "allowMatchingDomainsAutojoin":
			if _, ok := fieldSeen[organizationsettinghistory.FieldAllowMatchingDomainsAutojoin]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldAllowMatchingDomainsAutojoin)
				fieldSeen[organizationsettinghistory.FieldAllowMatchingDomainsAutojoin] = struct{}{}
			}
		case "identityProvider":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProvider]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProvider)
				fieldSeen[organizationsettinghistory.FieldIdentityProvider] = struct{}{}
			}
		case "identityProviderClientID":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderClientID]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderClientID)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderClientID] = struct{}{}
			}
		case "identityProviderClientSecret":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderClientSecret]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderClientSecret)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderClientSecret] = struct{}{}
			}
		case "identityProviderMetadataEndpoint":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderMetadataEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderMetadataEndpoint)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderMetadataEndpoint] = struct{}{}
			}
		case "identityProviderAuthTested":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderAuthTested]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderAuthTested)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderAuthTested] = struct{}{}
			}
		case "identityProviderEntityID":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderEntityID]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderEntityID)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderEntityID] = struct{}{}
			}
		case "oidcDiscoveryEndpoint":
			if _, ok := fieldSeen[organizationsettinghistory.FieldOidcDiscoveryEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldOidcDiscoveryEndpoint)
				fieldSeen[organizationsettinghistory.FieldOidcDiscoveryEndpoint] = struct{}{}
			}
		case "samlSigninURL":
			if _, ok := fieldSeen[organizationsettinghistory.FieldSamlSigninURL]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldSamlSigninURL)
				fieldSeen[organizationsettinghistory.FieldSamlSigninURL] = struct{}{}
			}
		case "samlIssuer":
			if _, ok := fieldSeen[organizationsettinghistory.FieldSamlIssuer]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldSamlIssuer)
				fieldSeen[organizationsettinghistory.FieldSamlIssuer] = struct{}{}
			}
		case "samlCert":
			if _, ok := fieldSeen[organizationsettinghistory.FieldSamlCert]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldSamlCert)
				fieldSeen[organizationsettinghistory.FieldSamlCert] = struct{}{}
			}
		case "identityProviderLoginEnforced":
			if _, ok := fieldSeen[organizationsettinghistory.FieldIdentityProviderLoginEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldIdentityProviderLoginEnforced)
				fieldSeen[organizationsettinghistory.FieldIdentityProviderLoginEnforced] = struct{}{}
			}
		case "multifactorAuthEnforced":
			if _, ok := fieldSeen[organizationsettinghistory.FieldMultifactorAuthEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldMultifactorAuthEnforced)
				fieldSeen[organizationsettinghistory.FieldMultifactorAuthEnforced] = struct{}{}
			}
		case "complianceWebhookToken":
			if _, ok := fieldSeen[organizationsettinghistory.FieldComplianceWebhookToken]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldComplianceWebhookToken)
				fieldSeen[organizationsettinghistory.FieldComplianceWebhookToken] = struct{}{}
			}
		case "paymentMethodAdded":
			if _, ok := fieldSeen[organizationsettinghistory.FieldPaymentMethodAdded]; !ok {
				selectedFields = append(selectedFields, organizationsettinghistory.FieldPaymentMethodAdded)
				fieldSeen[organizationsettinghistory.FieldPaymentMethodAdded] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type organizationsettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationSettingHistoryPaginateOption
}

func newOrganizationSettingHistoryPaginateArgs(rv map[string]any) *organizationsettinghistoryPaginateArgs {
	args := &organizationsettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrganizationSettingHistoryOrder{Field: &OrganizationSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrganizationSettingHistoryOrder(order))
			}
		case *OrganizationSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrganizationSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrganizationSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *PersonalAccessTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*PersonalAccessTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *PersonalAccessTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(personalaccesstoken.Columns))
		selectedFields = []string{personalaccesstoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[personalaccesstoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldOwnerID)
				fieldSeen[personalaccesstoken.FieldOwnerID] = struct{}{}
			}

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*PersonalAccessToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"personal_access_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(personalaccesstoken.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(personalaccesstoken.OrganizationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*PersonalAccessToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(personalaccesstoken.OrganizationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*PersonalAccessToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"personal_access_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(personalaccesstoken.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(personalaccesstoken.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(personalaccesstoken.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(personalaccesstoken.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(personalaccesstoken.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*PersonalAccessToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(personalaccesstoken.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldCreatedAt)
				fieldSeen[personalaccesstoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldUpdatedAt)
				fieldSeen[personalaccesstoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldCreatedBy)
				fieldSeen[personalaccesstoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldUpdatedBy)
				fieldSeen[personalaccesstoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[personalaccesstoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldTags)
				fieldSeen[personalaccesstoken.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[personalaccesstoken.FieldName]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldName)
				fieldSeen[personalaccesstoken.FieldName] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[personalaccesstoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldToken)
				fieldSeen[personalaccesstoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldExpiresAt)
				fieldSeen[personalaccesstoken.FieldExpiresAt] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[personalaccesstoken.FieldDescription]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldDescription)
				fieldSeen[personalaccesstoken.FieldDescription] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[personalaccesstoken.FieldScopes]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldScopes)
				fieldSeen[personalaccesstoken.FieldScopes] = struct{}{}
			}
		case "ssoAuthorizations":
			if _, ok := fieldSeen[personalaccesstoken.FieldSSOAuthorizations]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldSSOAuthorizations)
				fieldSeen[personalaccesstoken.FieldSSOAuthorizations] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldLastUsedAt)
				fieldSeen[personalaccesstoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[personalaccesstoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldIsActive)
				fieldSeen[personalaccesstoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedReason)
				fieldSeen[personalaccesstoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedBy)
				fieldSeen[personalaccesstoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedAt)
				fieldSeen[personalaccesstoken.FieldRevokedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type personalaccesstokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []PersonalAccessTokenPaginateOption
}

func newPersonalAccessTokenPaginateArgs(rv map[string]any) *personalaccesstokenPaginateArgs {
	args := &personalaccesstokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*PersonalAccessTokenOrder:
			args.opts = append(args.opts, WithPersonalAccessTokenOrder(v))
		case []any:
			var orders []*PersonalAccessTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &PersonalAccessTokenOrder{Field: &PersonalAccessTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithPersonalAccessTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*PersonalAccessTokenWhereInput); ok {
		args.opts = append(args.opts, WithPersonalAccessTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProcedureQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProcedureQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProcedureQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(procedure.Columns))
		selectedFields = []string{procedure.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[procedure.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldOwnerID)
				fieldSeen[procedure.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(procedure.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(procedure.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withApprover = query
			if _, ok := fieldSeen[procedure.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApproverID)
				fieldSeen[procedure.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[procedure.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDelegateID)
				fieldSeen[procedure.FieldDelegateID] = struct{}{}
			}

		case "procedureKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withProcedureKind = query
			if _, ok := fieldSeen[procedure.FieldProcedureKindID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureKindID)
				fieldSeen[procedure.FieldProcedureKindID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(procedure.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(procedure.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(procedure.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(procedure.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(procedure.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(procedure.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(procedure.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(procedure.CommentsColumn), ids...))
						})
						if err := query.GroupBy(procedure.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[procedure.FieldFileID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldFileID)
				fieldSeen[procedure.FieldFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[procedure.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, procedure.FieldCreatedAt)
				fieldSeen[procedure.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[procedure.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, procedure.FieldUpdatedAt)
				fieldSeen[procedure.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[procedure.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, procedure.FieldCreatedBy)
				fieldSeen[procedure.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[procedure.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, procedure.FieldUpdatedBy)
				fieldSeen[procedure.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[procedure.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDisplayID)
				fieldSeen[procedure.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[procedure.FieldTags]; !ok {
				selectedFields = append(selectedFields, procedure.FieldTags)
				fieldSeen[procedure.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[procedure.FieldRevision]; !ok {
				selectedFields = append(selectedFields, procedure.FieldRevision)
				fieldSeen[procedure.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[procedure.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldOwnerID)
				fieldSeen[procedure.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[procedure.FieldName]; !ok {
				selectedFields = append(selectedFields, procedure.FieldName)
				fieldSeen[procedure.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[procedure.FieldStatus]; !ok {
				selectedFields = append(selectedFields, procedure.FieldStatus)
				fieldSeen[procedure.FieldStatus] = struct{}{}
			}
		case "procedureType":
			if _, ok := fieldSeen[procedure.FieldProcedureType]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureType)
				fieldSeen[procedure.FieldProcedureType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[procedure.FieldDetails]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDetails)
				fieldSeen[procedure.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[procedure.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApprovalRequired)
				fieldSeen[procedure.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[procedure.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, procedure.FieldReviewDue)
				fieldSeen[procedure.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[procedure.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, procedure.FieldReviewFrequency)
				fieldSeen[procedure.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[procedure.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApproverID)
				fieldSeen[procedure.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[procedure.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDelegateID)
				fieldSeen[procedure.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[procedure.FieldSummary]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSummary)
				fieldSeen[procedure.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[procedure.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldTagSuggestions)
				fieldSeen[procedure.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedTagSuggestions)
				fieldSeen[procedure.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[procedure.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldControlSuggestions)
				fieldSeen[procedure.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedControlSuggestions)
				fieldSeen[procedure.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[procedure.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldImprovementSuggestions)
				fieldSeen[procedure.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedImprovementSuggestions)
				fieldSeen[procedure.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[procedure.FieldURL]; !ok {
				selectedFields = append(selectedFields, procedure.FieldURL)
				fieldSeen[procedure.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[procedure.FieldFileID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldFileID)
				fieldSeen[procedure.FieldFileID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[procedure.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSystemOwned)
				fieldSeen[procedure.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[procedure.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, procedure.FieldInternalNotes)
				fieldSeen[procedure.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[procedure.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSystemInternalID)
				fieldSeen[procedure.FieldSystemInternalID] = struct{}{}
			}
		case "procedureKindName":
			if _, ok := fieldSeen[procedure.FieldProcedureKindName]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureKindName)
				fieldSeen[procedure.FieldProcedureKindName] = struct{}{}
			}
		case "procedureKindID":
			if _, ok := fieldSeen[procedure.FieldProcedureKindID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureKindID)
				fieldSeen[procedure.FieldProcedureKindID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type procedurePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProcedurePaginateOption
}

func newProcedurePaginateArgs(rv map[string]any) *procedurePaginateArgs {
	args := &procedurePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProcedureOrder:
			args.opts = append(args.opts, WithProcedureOrder(v))
		case []any:
			var orders []*ProcedureOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProcedureOrder{Field: &ProcedureOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProcedureOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProcedureWhereInput); ok {
		args.opts = append(args.opts, WithProcedureFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProcedureHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProcedureHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProcedureHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(procedurehistory.Columns))
		selectedFields = []string{procedurehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[procedurehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldHistoryTime)
				fieldSeen[procedurehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[procedurehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldRef)
				fieldSeen[procedurehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[procedurehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldOperation)
				fieldSeen[procedurehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[procedurehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldCreatedAt)
				fieldSeen[procedurehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[procedurehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldUpdatedAt)
				fieldSeen[procedurehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[procedurehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldCreatedBy)
				fieldSeen[procedurehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[procedurehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldUpdatedBy)
				fieldSeen[procedurehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[procedurehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDisplayID)
				fieldSeen[procedurehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[procedurehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldTags)
				fieldSeen[procedurehistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[procedurehistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldRevision)
				fieldSeen[procedurehistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[procedurehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldOwnerID)
				fieldSeen[procedurehistory.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[procedurehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldName)
				fieldSeen[procedurehistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[procedurehistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldStatus)
				fieldSeen[procedurehistory.FieldStatus] = struct{}{}
			}
		case "procedureType":
			if _, ok := fieldSeen[procedurehistory.FieldProcedureType]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldProcedureType)
				fieldSeen[procedurehistory.FieldProcedureType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[procedurehistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDetails)
				fieldSeen[procedurehistory.FieldDetails] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[procedurehistory.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldApprovalRequired)
				fieldSeen[procedurehistory.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[procedurehistory.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldReviewDue)
				fieldSeen[procedurehistory.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[procedurehistory.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldReviewFrequency)
				fieldSeen[procedurehistory.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[procedurehistory.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldApproverID)
				fieldSeen[procedurehistory.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[procedurehistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDelegateID)
				fieldSeen[procedurehistory.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[procedurehistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldSummary)
				fieldSeen[procedurehistory.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldTagSuggestions)
				fieldSeen[procedurehistory.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDismissedTagSuggestions)
				fieldSeen[procedurehistory.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldControlSuggestions)
				fieldSeen[procedurehistory.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDismissedControlSuggestions)
				fieldSeen[procedurehistory.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldImprovementSuggestions)
				fieldSeen[procedurehistory.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[procedurehistory.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldDismissedImprovementSuggestions)
				fieldSeen[procedurehistory.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[procedurehistory.FieldURL]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldURL)
				fieldSeen[procedurehistory.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[procedurehistory.FieldFileID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldFileID)
				fieldSeen[procedurehistory.FieldFileID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[procedurehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldSystemOwned)
				fieldSeen[procedurehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[procedurehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldInternalNotes)
				fieldSeen[procedurehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[procedurehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldSystemInternalID)
				fieldSeen[procedurehistory.FieldSystemInternalID] = struct{}{}
			}
		case "procedureKindName":
			if _, ok := fieldSeen[procedurehistory.FieldProcedureKindName]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldProcedureKindName)
				fieldSeen[procedurehistory.FieldProcedureKindName] = struct{}{}
			}
		case "procedureKindID":
			if _, ok := fieldSeen[procedurehistory.FieldProcedureKindID]; !ok {
				selectedFields = append(selectedFields, procedurehistory.FieldProcedureKindID)
				fieldSeen[procedurehistory.FieldProcedureKindID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type procedurehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProcedureHistoryPaginateOption
}

func newProcedureHistoryPaginateArgs(rv map[string]any) *procedurehistoryPaginateArgs {
	args := &procedurehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProcedureHistoryOrder{Field: &ProcedureHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProcedureHistoryOrder(order))
			}
		case *ProcedureHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithProcedureHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProcedureHistoryWhereInput); ok {
		args.opts = append(args.opts, WithProcedureHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProgramQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProgramQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(program.Columns))
		selectedFields = []string{program.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[program.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldOwnerID)
				fieldSeen[program.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withProgramKind = query
			if _, ok := fieldSeen[program.FieldProgramKindID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramKindID)
				fieldSeen[program.FieldProgramKindID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(program.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(program.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(program.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(program.InternalPoliciesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.InternalPoliciesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.InternalPoliciesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.InternalPoliciesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.InternalPoliciesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(program.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(program.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(program.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_notes"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.NotesColumn), ids...))
						})
						if err := query.GroupBy(program.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(program.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(program.EvidencePrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.EvidencePrimaryKey[0]), ids...))
							s.Select(joinT.C(program.EvidencePrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.EvidencePrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.EvidencePrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(program.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(program.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(program.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(program.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(program.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(program.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "programOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withProgramOwner = query
			if _, ok := fieldSeen[program.FieldProgramOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramOwnerID)
				fieldSeen[program.FieldProgramOwnerID] = struct{}{}
			}

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramMembershipClient{config: _q.config}).Query()
			)
			args := newProgramMembershipPaginateArgs(fieldArgs(ctx, new(ProgramMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.MembersColumn), ids...))
						})
						if err := query.GroupBy(program.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *ProgramMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[program.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, program.FieldCreatedAt)
				fieldSeen[program.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[program.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, program.FieldUpdatedAt)
				fieldSeen[program.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[program.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, program.FieldCreatedBy)
				fieldSeen[program.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[program.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, program.FieldUpdatedBy)
				fieldSeen[program.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[program.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, program.FieldDisplayID)
				fieldSeen[program.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[program.FieldTags]; !ok {
				selectedFields = append(selectedFields, program.FieldTags)
				fieldSeen[program.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[program.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldOwnerID)
				fieldSeen[program.FieldOwnerID] = struct{}{}
			}
		case "programKindName":
			if _, ok := fieldSeen[program.FieldProgramKindName]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramKindName)
				fieldSeen[program.FieldProgramKindName] = struct{}{}
			}
		case "programKindID":
			if _, ok := fieldSeen[program.FieldProgramKindID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramKindID)
				fieldSeen[program.FieldProgramKindID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[program.FieldName]; !ok {
				selectedFields = append(selectedFields, program.FieldName)
				fieldSeen[program.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[program.FieldDescription]; !ok {
				selectedFields = append(selectedFields, program.FieldDescription)
				fieldSeen[program.FieldDescription] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[program.FieldStatus]; !ok {
				selectedFields = append(selectedFields, program.FieldStatus)
				fieldSeen[program.FieldStatus] = struct{}{}
			}
		case "programType":
			if _, ok := fieldSeen[program.FieldProgramType]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramType)
				fieldSeen[program.FieldProgramType] = struct{}{}
			}
		case "frameworkName":
			if _, ok := fieldSeen[program.FieldFrameworkName]; !ok {
				selectedFields = append(selectedFields, program.FieldFrameworkName)
				fieldSeen[program.FieldFrameworkName] = struct{}{}
			}
		case "startDate":
			if _, ok := fieldSeen[program.FieldStartDate]; !ok {
				selectedFields = append(selectedFields, program.FieldStartDate)
				fieldSeen[program.FieldStartDate] = struct{}{}
			}
		case "endDate":
			if _, ok := fieldSeen[program.FieldEndDate]; !ok {
				selectedFields = append(selectedFields, program.FieldEndDate)
				fieldSeen[program.FieldEndDate] = struct{}{}
			}
		case "auditorReady":
			if _, ok := fieldSeen[program.FieldAuditorReady]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorReady)
				fieldSeen[program.FieldAuditorReady] = struct{}{}
			}
		case "auditorWriteComments":
			if _, ok := fieldSeen[program.FieldAuditorWriteComments]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorWriteComments)
				fieldSeen[program.FieldAuditorWriteComments] = struct{}{}
			}
		case "auditorReadComments":
			if _, ok := fieldSeen[program.FieldAuditorReadComments]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorReadComments)
				fieldSeen[program.FieldAuditorReadComments] = struct{}{}
			}
		case "auditFirm":
			if _, ok := fieldSeen[program.FieldAuditFirm]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditFirm)
				fieldSeen[program.FieldAuditFirm] = struct{}{}
			}
		case "auditor":
			if _, ok := fieldSeen[program.FieldAuditor]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditor)
				fieldSeen[program.FieldAuditor] = struct{}{}
			}
		case "auditorEmail":
			if _, ok := fieldSeen[program.FieldAuditorEmail]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorEmail)
				fieldSeen[program.FieldAuditorEmail] = struct{}{}
			}
		case "programOwnerID":
			if _, ok := fieldSeen[program.FieldProgramOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramOwnerID)
				fieldSeen[program.FieldProgramOwnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type programPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramPaginateOption
}

func newProgramPaginateArgs(rv map[string]any) *programPaginateArgs {
	args := &programPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProgramOrder:
			args.opts = append(args.opts, WithProgramOrder(v))
		case []any:
			var orders []*ProgramOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProgramOrder{Field: &ProgramOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProgramOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProgramWhereInput); ok {
		args.opts = append(args.opts, WithProgramFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProgramHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProgramHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programhistory.Columns))
		selectedFields = []string{programhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[programhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldHistoryTime)
				fieldSeen[programhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[programhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldRef)
				fieldSeen[programhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[programhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldOperation)
				fieldSeen[programhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldCreatedAt)
				fieldSeen[programhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldUpdatedAt)
				fieldSeen[programhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldCreatedBy)
				fieldSeen[programhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldUpdatedBy)
				fieldSeen[programhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[programhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldDisplayID)
				fieldSeen[programhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[programhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldTags)
				fieldSeen[programhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[programhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldOwnerID)
				fieldSeen[programhistory.FieldOwnerID] = struct{}{}
			}
		case "programKindName":
			if _, ok := fieldSeen[programhistory.FieldProgramKindName]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldProgramKindName)
				fieldSeen[programhistory.FieldProgramKindName] = struct{}{}
			}
		case "programKindID":
			if _, ok := fieldSeen[programhistory.FieldProgramKindID]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldProgramKindID)
				fieldSeen[programhistory.FieldProgramKindID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[programhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldName)
				fieldSeen[programhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[programhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldDescription)
				fieldSeen[programhistory.FieldDescription] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[programhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldStatus)
				fieldSeen[programhistory.FieldStatus] = struct{}{}
			}
		case "programType":
			if _, ok := fieldSeen[programhistory.FieldProgramType]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldProgramType)
				fieldSeen[programhistory.FieldProgramType] = struct{}{}
			}
		case "frameworkName":
			if _, ok := fieldSeen[programhistory.FieldFrameworkName]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldFrameworkName)
				fieldSeen[programhistory.FieldFrameworkName] = struct{}{}
			}
		case "startDate":
			if _, ok := fieldSeen[programhistory.FieldStartDate]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldStartDate)
				fieldSeen[programhistory.FieldStartDate] = struct{}{}
			}
		case "endDate":
			if _, ok := fieldSeen[programhistory.FieldEndDate]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldEndDate)
				fieldSeen[programhistory.FieldEndDate] = struct{}{}
			}
		case "auditorReady":
			if _, ok := fieldSeen[programhistory.FieldAuditorReady]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorReady)
				fieldSeen[programhistory.FieldAuditorReady] = struct{}{}
			}
		case "auditorWriteComments":
			if _, ok := fieldSeen[programhistory.FieldAuditorWriteComments]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorWriteComments)
				fieldSeen[programhistory.FieldAuditorWriteComments] = struct{}{}
			}
		case "auditorReadComments":
			if _, ok := fieldSeen[programhistory.FieldAuditorReadComments]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorReadComments)
				fieldSeen[programhistory.FieldAuditorReadComments] = struct{}{}
			}
		case "auditFirm":
			if _, ok := fieldSeen[programhistory.FieldAuditFirm]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditFirm)
				fieldSeen[programhistory.FieldAuditFirm] = struct{}{}
			}
		case "auditor":
			if _, ok := fieldSeen[programhistory.FieldAuditor]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditor)
				fieldSeen[programhistory.FieldAuditor] = struct{}{}
			}
		case "auditorEmail":
			if _, ok := fieldSeen[programhistory.FieldAuditorEmail]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldAuditorEmail)
				fieldSeen[programhistory.FieldAuditorEmail] = struct{}{}
			}
		case "programOwnerID":
			if _, ok := fieldSeen[programhistory.FieldProgramOwnerID]; !ok {
				selectedFields = append(selectedFields, programhistory.FieldProgramOwnerID)
				fieldSeen[programhistory.FieldProgramOwnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type programhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramHistoryPaginateOption
}

func newProgramHistoryPaginateArgs(rv map[string]any) *programhistoryPaginateArgs {
	args := &programhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProgramHistoryOrder{Field: &ProgramHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProgramHistoryOrder(order))
			}
		case *ProgramHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithProgramHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProgramHistoryWhereInput); ok {
		args.opts = append(args.opts, WithProgramHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProgramMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProgramMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programmembership.Columns))
		selectedFields = []string{programmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "program":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
				return err
			}
			_q.withProgram = query
			if _, ok := fieldSeen[programmembership.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldProgramID)
				fieldSeen[programmembership.FieldProgramID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[programmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUserID)
				fieldSeen[programmembership.FieldUserID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldCreatedAt)
				fieldSeen[programmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUpdatedAt)
				fieldSeen[programmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldCreatedBy)
				fieldSeen[programmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUpdatedBy)
				fieldSeen[programmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[programmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldRole)
				fieldSeen[programmembership.FieldRole] = struct{}{}
			}
		case "programID":
			if _, ok := fieldSeen[programmembership.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldProgramID)
				fieldSeen[programmembership.FieldProgramID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[programmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUserID)
				fieldSeen[programmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type programmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramMembershipPaginateOption
}

func newProgramMembershipPaginateArgs(rv map[string]any) *programmembershipPaginateArgs {
	args := &programmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProgramMembershipOrder:
			args.opts = append(args.opts, WithProgramMembershipOrder(v))
		case []any:
			var orders []*ProgramMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProgramMembershipOrder{Field: &ProgramMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProgramMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProgramMembershipWhereInput); ok {
		args.opts = append(args.opts, WithProgramMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProgramMembershipHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramMembershipHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProgramMembershipHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programmembershiphistory.Columns))
		selectedFields = []string{programmembershiphistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[programmembershiphistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldHistoryTime)
				fieldSeen[programmembershiphistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[programmembershiphistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldRef)
				fieldSeen[programmembershiphistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[programmembershiphistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldOperation)
				fieldSeen[programmembershiphistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programmembershiphistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldCreatedAt)
				fieldSeen[programmembershiphistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programmembershiphistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldUpdatedAt)
				fieldSeen[programmembershiphistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programmembershiphistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldCreatedBy)
				fieldSeen[programmembershiphistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programmembershiphistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldUpdatedBy)
				fieldSeen[programmembershiphistory.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[programmembershiphistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldRole)
				fieldSeen[programmembershiphistory.FieldRole] = struct{}{}
			}
		case "programID":
			if _, ok := fieldSeen[programmembershiphistory.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldProgramID)
				fieldSeen[programmembershiphistory.FieldProgramID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[programmembershiphistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembershiphistory.FieldUserID)
				fieldSeen[programmembershiphistory.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type programmembershiphistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramMembershipHistoryPaginateOption
}

func newProgramMembershipHistoryPaginateArgs(rv map[string]any) *programmembershiphistoryPaginateArgs {
	args := &programmembershiphistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProgramMembershipHistoryOrder{Field: &ProgramMembershipHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProgramMembershipHistoryOrder(order))
			}
		case *ProgramMembershipHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithProgramMembershipHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProgramMembershipHistoryWhereInput); ok {
		args.opts = append(args.opts, WithProgramMembershipHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RemediationQuery) CollectFields(ctx context.Context, satisfies ...string) (*RemediationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RemediationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(remediation.Columns))
		selectedFields = []string{remediation.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[remediation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldOwnerID)
				fieldSeen[remediation.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(remediation.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.EditorsColumn), ids...))
						})
						if err := query.GroupBy(remediation.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ViewersColumn), ids...))
						})
						if err := query.GroupBy(remediation.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(remediation.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(remediation.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(remediation.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(remediation.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(remediation.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_findings"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.FindingsColumn), ids...))
						})
						if err := query.GroupBy(remediation.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_vulnerabilities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(remediation.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(remediation.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(remediation.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(remediation.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(remediation.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(remediation.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.TasksColumn), ids...))
						})
						if err := query.GroupBy(remediation.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ControlsColumn), ids...))
						})
						if err := query.GroupBy(remediation.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(remediation.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.RisksColumn), ids...))
						})
						if err := query.GroupBy(remediation.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(remediation.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.AssetsColumn), ids...))
						})
						if err := query.GroupBy(remediation.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(remediation.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_reviews"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(remediation.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.CommentsColumn), ids...))
						})
						if err := query.GroupBy(remediation.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.FilesColumn), ids...))
						})
						if err := query.GroupBy(remediation.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[remediation.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldCreatedAt)
				fieldSeen[remediation.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[remediation.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldUpdatedAt)
				fieldSeen[remediation.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[remediation.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, remediation.FieldCreatedBy)
				fieldSeen[remediation.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[remediation.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, remediation.FieldUpdatedBy)
				fieldSeen[remediation.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[remediation.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldDisplayID)
				fieldSeen[remediation.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[remediation.FieldTags]; !ok {
				selectedFields = append(selectedFields, remediation.FieldTags)
				fieldSeen[remediation.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[remediation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldOwnerID)
				fieldSeen[remediation.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[remediation.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSystemOwned)
				fieldSeen[remediation.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[remediation.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, remediation.FieldInternalNotes)
				fieldSeen[remediation.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[remediation.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSystemInternalID)
				fieldSeen[remediation.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[remediation.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExternalID)
				fieldSeen[remediation.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[remediation.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExternalOwnerID)
				fieldSeen[remediation.FieldExternalOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[remediation.FieldTitle]; !ok {
				selectedFields = append(selectedFields, remediation.FieldTitle)
				fieldSeen[remediation.FieldTitle] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[remediation.FieldState]; !ok {
				selectedFields = append(selectedFields, remediation.FieldState)
				fieldSeen[remediation.FieldState] = struct{}{}
			}
		case "intent":
			if _, ok := fieldSeen[remediation.FieldIntent]; !ok {
				selectedFields = append(selectedFields, remediation.FieldIntent)
				fieldSeen[remediation.FieldIntent] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[remediation.FieldSummary]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSummary)
				fieldSeen[remediation.FieldSummary] = struct{}{}
			}
		case "explanation":
			if _, ok := fieldSeen[remediation.FieldExplanation]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExplanation)
				fieldSeen[remediation.FieldExplanation] = struct{}{}
			}
		case "instructions":
			if _, ok := fieldSeen[remediation.FieldInstructions]; !ok {
				selectedFields = append(selectedFields, remediation.FieldInstructions)
				fieldSeen[remediation.FieldInstructions] = struct{}{}
			}
		case "ownerReference":
			if _, ok := fieldSeen[remediation.FieldOwnerReference]; !ok {
				selectedFields = append(selectedFields, remediation.FieldOwnerReference)
				fieldSeen[remediation.FieldOwnerReference] = struct{}{}
			}
		case "repositoryURI":
			if _, ok := fieldSeen[remediation.FieldRepositoryURI]; !ok {
				selectedFields = append(selectedFields, remediation.FieldRepositoryURI)
				fieldSeen[remediation.FieldRepositoryURI] = struct{}{}
			}
		case "pullRequestURI":
			if _, ok := fieldSeen[remediation.FieldPullRequestURI]; !ok {
				selectedFields = append(selectedFields, remediation.FieldPullRequestURI)
				fieldSeen[remediation.FieldPullRequestURI] = struct{}{}
			}
		case "ticketReference":
			if _, ok := fieldSeen[remediation.FieldTicketReference]; !ok {
				selectedFields = append(selectedFields, remediation.FieldTicketReference)
				fieldSeen[remediation.FieldTicketReference] = struct{}{}
			}
		case "dueAt":
			if _, ok := fieldSeen[remediation.FieldDueAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldDueAt)
				fieldSeen[remediation.FieldDueAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[remediation.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldCompletedAt)
				fieldSeen[remediation.FieldCompletedAt] = struct{}{}
			}
		case "prGeneratedAt":
			if _, ok := fieldSeen[remediation.FieldPrGeneratedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldPrGeneratedAt)
				fieldSeen[remediation.FieldPrGeneratedAt] = struct{}{}
			}
		case "error":
			if _, ok := fieldSeen[remediation.FieldError]; !ok {
				selectedFields = append(selectedFields, remediation.FieldError)
				fieldSeen[remediation.FieldError] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[remediation.FieldSource]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSource)
				fieldSeen[remediation.FieldSource] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[remediation.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExternalURI)
				fieldSeen[remediation.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[remediation.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, remediation.FieldMetadata)
				fieldSeen[remediation.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type remediationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RemediationPaginateOption
}

func newRemediationPaginateArgs(rv map[string]any) *remediationPaginateArgs {
	args := &remediationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*RemediationOrder:
			args.opts = append(args.opts, WithRemediationOrder(v))
		case []any:
			var orders []*RemediationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &RemediationOrder{Field: &RemediationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithRemediationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*RemediationWhereInput); ok {
		args.opts = append(args.opts, WithRemediationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RemediationHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*RemediationHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RemediationHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(remediationhistory.Columns))
		selectedFields = []string{remediationhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[remediationhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldHistoryTime)
				fieldSeen[remediationhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[remediationhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldRef)
				fieldSeen[remediationhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[remediationhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldOperation)
				fieldSeen[remediationhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[remediationhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldCreatedAt)
				fieldSeen[remediationhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[remediationhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldUpdatedAt)
				fieldSeen[remediationhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[remediationhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldCreatedBy)
				fieldSeen[remediationhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[remediationhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldUpdatedBy)
				fieldSeen[remediationhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[remediationhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldDisplayID)
				fieldSeen[remediationhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[remediationhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldTags)
				fieldSeen[remediationhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[remediationhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldOwnerID)
				fieldSeen[remediationhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[remediationhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldSystemOwned)
				fieldSeen[remediationhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[remediationhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldInternalNotes)
				fieldSeen[remediationhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[remediationhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldSystemInternalID)
				fieldSeen[remediationhistory.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[remediationhistory.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldExternalID)
				fieldSeen[remediationhistory.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[remediationhistory.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldExternalOwnerID)
				fieldSeen[remediationhistory.FieldExternalOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[remediationhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldTitle)
				fieldSeen[remediationhistory.FieldTitle] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[remediationhistory.FieldState]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldState)
				fieldSeen[remediationhistory.FieldState] = struct{}{}
			}
		case "intent":
			if _, ok := fieldSeen[remediationhistory.FieldIntent]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldIntent)
				fieldSeen[remediationhistory.FieldIntent] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[remediationhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldSummary)
				fieldSeen[remediationhistory.FieldSummary] = struct{}{}
			}
		case "explanation":
			if _, ok := fieldSeen[remediationhistory.FieldExplanation]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldExplanation)
				fieldSeen[remediationhistory.FieldExplanation] = struct{}{}
			}
		case "instructions":
			if _, ok := fieldSeen[remediationhistory.FieldInstructions]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldInstructions)
				fieldSeen[remediationhistory.FieldInstructions] = struct{}{}
			}
		case "ownerReference":
			if _, ok := fieldSeen[remediationhistory.FieldOwnerReference]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldOwnerReference)
				fieldSeen[remediationhistory.FieldOwnerReference] = struct{}{}
			}
		case "repositoryURI":
			if _, ok := fieldSeen[remediationhistory.FieldRepositoryURI]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldRepositoryURI)
				fieldSeen[remediationhistory.FieldRepositoryURI] = struct{}{}
			}
		case "pullRequestURI":
			if _, ok := fieldSeen[remediationhistory.FieldPullRequestURI]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldPullRequestURI)
				fieldSeen[remediationhistory.FieldPullRequestURI] = struct{}{}
			}
		case "ticketReference":
			if _, ok := fieldSeen[remediationhistory.FieldTicketReference]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldTicketReference)
				fieldSeen[remediationhistory.FieldTicketReference] = struct{}{}
			}
		case "dueAt":
			if _, ok := fieldSeen[remediationhistory.FieldDueAt]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldDueAt)
				fieldSeen[remediationhistory.FieldDueAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[remediationhistory.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldCompletedAt)
				fieldSeen[remediationhistory.FieldCompletedAt] = struct{}{}
			}
		case "prGeneratedAt":
			if _, ok := fieldSeen[remediationhistory.FieldPrGeneratedAt]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldPrGeneratedAt)
				fieldSeen[remediationhistory.FieldPrGeneratedAt] = struct{}{}
			}
		case "error":
			if _, ok := fieldSeen[remediationhistory.FieldError]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldError)
				fieldSeen[remediationhistory.FieldError] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[remediationhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldSource)
				fieldSeen[remediationhistory.FieldSource] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[remediationhistory.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldExternalURI)
				fieldSeen[remediationhistory.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[remediationhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, remediationhistory.FieldMetadata)
				fieldSeen[remediationhistory.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type remediationhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RemediationHistoryPaginateOption
}

func newRemediationHistoryPaginateArgs(rv map[string]any) *remediationhistoryPaginateArgs {
	args := &remediationhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RemediationHistoryOrder{Field: &RemediationHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRemediationHistoryOrder(order))
			}
		case *RemediationHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithRemediationHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RemediationHistoryWhereInput); ok {
		args.opts = append(args.opts, WithRemediationHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ReviewQuery) CollectFields(ctx context.Context, satisfies ...string) (*ReviewQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ReviewQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(review.Columns))
		selectedFields = []string{review.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[review.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, review.FieldOwnerID)
				fieldSeen[review.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(review.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.EditorsColumn), ids...))
						})
						if err := query.GroupBy(review.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.ViewersColumn), ids...))
						})
						if err := query.GroupBy(review.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(review.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(review.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(review.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(review.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(review.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_findings"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.FindingsColumn), ids...))
						})
						if err := query.GroupBy(review.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_vulnerabilities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(review.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(review.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(review.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(review.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(review.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(review.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_remediations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(review.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.ControlsColumn), ids...))
						})
						if err := query.GroupBy(review.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(review.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.RisksColumn), ids...))
						})
						if err := query.GroupBy(review.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(review.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.AssetsColumn), ids...))
						})
						if err := query.GroupBy(review.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(review.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.TasksColumn), ids...))
						})
						if err := query.GroupBy(review.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "reviewer":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withReviewer = query
			if _, ok := fieldSeen[review.FieldReviewerID]; !ok {
				selectedFields = append(selectedFields, review.FieldReviewerID)
				fieldSeen[review.FieldReviewerID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.CommentsColumn), ids...))
						})
						if err := query.GroupBy(review.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.FilesColumn), ids...))
						})
						if err := query.GroupBy(review.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[review.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldCreatedAt)
				fieldSeen[review.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[review.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldUpdatedAt)
				fieldSeen[review.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[review.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, review.FieldCreatedBy)
				fieldSeen[review.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[review.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, review.FieldUpdatedBy)
				fieldSeen[review.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[review.FieldTags]; !ok {
				selectedFields = append(selectedFields, review.FieldTags)
				fieldSeen[review.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[review.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, review.FieldOwnerID)
				fieldSeen[review.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[review.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, review.FieldSystemOwned)
				fieldSeen[review.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[review.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, review.FieldInternalNotes)
				fieldSeen[review.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[review.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, review.FieldSystemInternalID)
				fieldSeen[review.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[review.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, review.FieldExternalID)
				fieldSeen[review.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[review.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, review.FieldExternalOwnerID)
				fieldSeen[review.FieldExternalOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[review.FieldTitle]; !ok {
				selectedFields = append(selectedFields, review.FieldTitle)
				fieldSeen[review.FieldTitle] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[review.FieldState]; !ok {
				selectedFields = append(selectedFields, review.FieldState)
				fieldSeen[review.FieldState] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[review.FieldCategory]; !ok {
				selectedFields = append(selectedFields, review.FieldCategory)
				fieldSeen[review.FieldCategory] = struct{}{}
			}
		case "classification":
			if _, ok := fieldSeen[review.FieldClassification]; !ok {
				selectedFields = append(selectedFields, review.FieldClassification)
				fieldSeen[review.FieldClassification] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[review.FieldSummary]; !ok {
				selectedFields = append(selectedFields, review.FieldSummary)
				fieldSeen[review.FieldSummary] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[review.FieldDetails]; !ok {
				selectedFields = append(selectedFields, review.FieldDetails)
				fieldSeen[review.FieldDetails] = struct{}{}
			}
		case "reporter":
			if _, ok := fieldSeen[review.FieldReporter]; !ok {
				selectedFields = append(selectedFields, review.FieldReporter)
				fieldSeen[review.FieldReporter] = struct{}{}
			}
		case "approved":
			if _, ok := fieldSeen[review.FieldApproved]; !ok {
				selectedFields = append(selectedFields, review.FieldApproved)
				fieldSeen[review.FieldApproved] = struct{}{}
			}
		case "reviewedAt":
			if _, ok := fieldSeen[review.FieldReviewedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldReviewedAt)
				fieldSeen[review.FieldReviewedAt] = struct{}{}
			}
		case "reportedAt":
			if _, ok := fieldSeen[review.FieldReportedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldReportedAt)
				fieldSeen[review.FieldReportedAt] = struct{}{}
			}
		case "approvedAt":
			if _, ok := fieldSeen[review.FieldApprovedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldApprovedAt)
				fieldSeen[review.FieldApprovedAt] = struct{}{}
			}
		case "reviewerID":
			if _, ok := fieldSeen[review.FieldReviewerID]; !ok {
				selectedFields = append(selectedFields, review.FieldReviewerID)
				fieldSeen[review.FieldReviewerID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[review.FieldSource]; !ok {
				selectedFields = append(selectedFields, review.FieldSource)
				fieldSeen[review.FieldSource] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[review.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, review.FieldExternalURI)
				fieldSeen[review.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[review.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, review.FieldMetadata)
				fieldSeen[review.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[review.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, review.FieldRawPayload)
				fieldSeen[review.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type reviewPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ReviewPaginateOption
}

func newReviewPaginateArgs(rv map[string]any) *reviewPaginateArgs {
	args := &reviewPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ReviewOrder:
			args.opts = append(args.opts, WithReviewOrder(v))
		case []any:
			var orders []*ReviewOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ReviewOrder{Field: &ReviewOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithReviewOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ReviewWhereInput); ok {
		args.opts = append(args.opts, WithReviewFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ReviewHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ReviewHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ReviewHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(reviewhistory.Columns))
		selectedFields = []string{reviewhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[reviewhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldHistoryTime)
				fieldSeen[reviewhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[reviewhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldRef)
				fieldSeen[reviewhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[reviewhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldOperation)
				fieldSeen[reviewhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[reviewhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldCreatedAt)
				fieldSeen[reviewhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[reviewhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldUpdatedAt)
				fieldSeen[reviewhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[reviewhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldCreatedBy)
				fieldSeen[reviewhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[reviewhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldUpdatedBy)
				fieldSeen[reviewhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[reviewhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldTags)
				fieldSeen[reviewhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[reviewhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldOwnerID)
				fieldSeen[reviewhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[reviewhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldSystemOwned)
				fieldSeen[reviewhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[reviewhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldInternalNotes)
				fieldSeen[reviewhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[reviewhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldSystemInternalID)
				fieldSeen[reviewhistory.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[reviewhistory.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldExternalID)
				fieldSeen[reviewhistory.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[reviewhistory.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldExternalOwnerID)
				fieldSeen[reviewhistory.FieldExternalOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[reviewhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldTitle)
				fieldSeen[reviewhistory.FieldTitle] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[reviewhistory.FieldState]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldState)
				fieldSeen[reviewhistory.FieldState] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[reviewhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldCategory)
				fieldSeen[reviewhistory.FieldCategory] = struct{}{}
			}
		case "classification":
			if _, ok := fieldSeen[reviewhistory.FieldClassification]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldClassification)
				fieldSeen[reviewhistory.FieldClassification] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[reviewhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldSummary)
				fieldSeen[reviewhistory.FieldSummary] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[reviewhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldDetails)
				fieldSeen[reviewhistory.FieldDetails] = struct{}{}
			}
		case "reporter":
			if _, ok := fieldSeen[reviewhistory.FieldReporter]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldReporter)
				fieldSeen[reviewhistory.FieldReporter] = struct{}{}
			}
		case "approved":
			if _, ok := fieldSeen[reviewhistory.FieldApproved]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldApproved)
				fieldSeen[reviewhistory.FieldApproved] = struct{}{}
			}
		case "reviewedAt":
			if _, ok := fieldSeen[reviewhistory.FieldReviewedAt]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldReviewedAt)
				fieldSeen[reviewhistory.FieldReviewedAt] = struct{}{}
			}
		case "reportedAt":
			if _, ok := fieldSeen[reviewhistory.FieldReportedAt]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldReportedAt)
				fieldSeen[reviewhistory.FieldReportedAt] = struct{}{}
			}
		case "approvedAt":
			if _, ok := fieldSeen[reviewhistory.FieldApprovedAt]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldApprovedAt)
				fieldSeen[reviewhistory.FieldApprovedAt] = struct{}{}
			}
		case "reviewerID":
			if _, ok := fieldSeen[reviewhistory.FieldReviewerID]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldReviewerID)
				fieldSeen[reviewhistory.FieldReviewerID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[reviewhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldSource)
				fieldSeen[reviewhistory.FieldSource] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[reviewhistory.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldExternalURI)
				fieldSeen[reviewhistory.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[reviewhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldMetadata)
				fieldSeen[reviewhistory.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[reviewhistory.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, reviewhistory.FieldRawPayload)
				fieldSeen[reviewhistory.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type reviewhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ReviewHistoryPaginateOption
}

func newReviewHistoryPaginateArgs(rv map[string]any) *reviewhistoryPaginateArgs {
	args := &reviewhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ReviewHistoryOrder{Field: &ReviewHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithReviewHistoryOrder(order))
			}
		case *ReviewHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithReviewHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ReviewHistoryWhereInput); ok {
		args.opts = append(args.opts, WithReviewHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RiskQuery) CollectFields(ctx context.Context, satisfies ...string) (*RiskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RiskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(risk.Columns))
		selectedFields = []string{risk.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[risk.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, risk.FieldOwnerID)
				fieldSeen[risk.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "riskKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withRiskKind = query
			if _, ok := fieldSeen[risk.FieldRiskKindID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskKindID)
				fieldSeen[risk.FieldRiskKindID] = struct{}{}
			}

		case "riskCategory":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withRiskCategory = query
			if _, ok := fieldSeen[risk.FieldRiskCategoryID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskCategoryID)
				fieldSeen[risk.FieldRiskCategoryID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(risk.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(risk.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(risk.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(risk.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(risk.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(risk.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(risk.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.AssetsColumn), ids...))
						})
						if err := query.GroupBy(risk.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(risk.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.ScansColumn), ids...))
						})
						if err := query.GroupBy(risk.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "stakeholder":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withStakeholder = query
			if _, ok := fieldSeen[risk.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, risk.FieldStakeholderID)
				fieldSeen[risk.FieldStakeholderID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[risk.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDelegateID)
				fieldSeen[risk.FieldDelegateID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.CommentsColumn), ids...))
						})
						if err := query.GroupBy(risk.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[risk.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, risk.FieldCreatedAt)
				fieldSeen[risk.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[risk.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, risk.FieldUpdatedAt)
				fieldSeen[risk.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[risk.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, risk.FieldCreatedBy)
				fieldSeen[risk.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[risk.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, risk.FieldUpdatedBy)
				fieldSeen[risk.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[risk.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDisplayID)
				fieldSeen[risk.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[risk.FieldTags]; !ok {
				selectedFields = append(selectedFields, risk.FieldTags)
				fieldSeen[risk.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[risk.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, risk.FieldOwnerID)
				fieldSeen[risk.FieldOwnerID] = struct{}{}
			}
		case "riskKindName":
			if _, ok := fieldSeen[risk.FieldRiskKindName]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskKindName)
				fieldSeen[risk.FieldRiskKindName] = struct{}{}
			}
		case "riskKindID":
			if _, ok := fieldSeen[risk.FieldRiskKindID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskKindID)
				fieldSeen[risk.FieldRiskKindID] = struct{}{}
			}
		case "riskCategoryName":
			if _, ok := fieldSeen[risk.FieldRiskCategoryName]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskCategoryName)
				fieldSeen[risk.FieldRiskCategoryName] = struct{}{}
			}
		case "riskCategoryID":
			if _, ok := fieldSeen[risk.FieldRiskCategoryID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskCategoryID)
				fieldSeen[risk.FieldRiskCategoryID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[risk.FieldName]; !ok {
				selectedFields = append(selectedFields, risk.FieldName)
				fieldSeen[risk.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[risk.FieldStatus]; !ok {
				selectedFields = append(selectedFields, risk.FieldStatus)
				fieldSeen[risk.FieldStatus] = struct{}{}
			}
		case "riskType":
			if _, ok := fieldSeen[risk.FieldRiskType]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskType)
				fieldSeen[risk.FieldRiskType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[risk.FieldCategory]; !ok {
				selectedFields = append(selectedFields, risk.FieldCategory)
				fieldSeen[risk.FieldCategory] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[risk.FieldImpact]; !ok {
				selectedFields = append(selectedFields, risk.FieldImpact)
				fieldSeen[risk.FieldImpact] = struct{}{}
			}
		case "likelihood":
			if _, ok := fieldSeen[risk.FieldLikelihood]; !ok {
				selectedFields = append(selectedFields, risk.FieldLikelihood)
				fieldSeen[risk.FieldLikelihood] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[risk.FieldScore]; !ok {
				selectedFields = append(selectedFields, risk.FieldScore)
				fieldSeen[risk.FieldScore] = struct{}{}
			}
		case "mitigation":
			if _, ok := fieldSeen[risk.FieldMitigation]; !ok {
				selectedFields = append(selectedFields, risk.FieldMitigation)
				fieldSeen[risk.FieldMitigation] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[risk.FieldDetails]; !ok {
				selectedFields = append(selectedFields, risk.FieldDetails)
				fieldSeen[risk.FieldDetails] = struct{}{}
			}
		case "businessCosts":
			if _, ok := fieldSeen[risk.FieldBusinessCosts]; !ok {
				selectedFields = append(selectedFields, risk.FieldBusinessCosts)
				fieldSeen[risk.FieldBusinessCosts] = struct{}{}
			}
		case "stakeholderID":
			if _, ok := fieldSeen[risk.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, risk.FieldStakeholderID)
				fieldSeen[risk.FieldStakeholderID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[risk.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDelegateID)
				fieldSeen[risk.FieldDelegateID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type riskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RiskPaginateOption
}

func newRiskPaginateArgs(rv map[string]any) *riskPaginateArgs {
	args := &riskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*RiskOrder:
			args.opts = append(args.opts, WithRiskOrder(v))
		case []any:
			var orders []*RiskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &RiskOrder{Field: &RiskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithRiskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*RiskWhereInput); ok {
		args.opts = append(args.opts, WithRiskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RiskHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*RiskHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RiskHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(riskhistory.Columns))
		selectedFields = []string{riskhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[riskhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldHistoryTime)
				fieldSeen[riskhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[riskhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRef)
				fieldSeen[riskhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[riskhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldOperation)
				fieldSeen[riskhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[riskhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldCreatedAt)
				fieldSeen[riskhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[riskhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldUpdatedAt)
				fieldSeen[riskhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[riskhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldCreatedBy)
				fieldSeen[riskhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[riskhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldUpdatedBy)
				fieldSeen[riskhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[riskhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldDisplayID)
				fieldSeen[riskhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[riskhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldTags)
				fieldSeen[riskhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[riskhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldOwnerID)
				fieldSeen[riskhistory.FieldOwnerID] = struct{}{}
			}
		case "riskKindName":
			if _, ok := fieldSeen[riskhistory.FieldRiskKindName]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRiskKindName)
				fieldSeen[riskhistory.FieldRiskKindName] = struct{}{}
			}
		case "riskKindID":
			if _, ok := fieldSeen[riskhistory.FieldRiskKindID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRiskKindID)
				fieldSeen[riskhistory.FieldRiskKindID] = struct{}{}
			}
		case "riskCategoryName":
			if _, ok := fieldSeen[riskhistory.FieldRiskCategoryName]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRiskCategoryName)
				fieldSeen[riskhistory.FieldRiskCategoryName] = struct{}{}
			}
		case "riskCategoryID":
			if _, ok := fieldSeen[riskhistory.FieldRiskCategoryID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRiskCategoryID)
				fieldSeen[riskhistory.FieldRiskCategoryID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[riskhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldName)
				fieldSeen[riskhistory.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[riskhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldStatus)
				fieldSeen[riskhistory.FieldStatus] = struct{}{}
			}
		case "riskType":
			if _, ok := fieldSeen[riskhistory.FieldRiskType]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldRiskType)
				fieldSeen[riskhistory.FieldRiskType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[riskhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldCategory)
				fieldSeen[riskhistory.FieldCategory] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[riskhistory.FieldImpact]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldImpact)
				fieldSeen[riskhistory.FieldImpact] = struct{}{}
			}
		case "likelihood":
			if _, ok := fieldSeen[riskhistory.FieldLikelihood]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldLikelihood)
				fieldSeen[riskhistory.FieldLikelihood] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[riskhistory.FieldScore]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldScore)
				fieldSeen[riskhistory.FieldScore] = struct{}{}
			}
		case "mitigation":
			if _, ok := fieldSeen[riskhistory.FieldMitigation]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldMitigation)
				fieldSeen[riskhistory.FieldMitigation] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[riskhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldDetails)
				fieldSeen[riskhistory.FieldDetails] = struct{}{}
			}
		case "businessCosts":
			if _, ok := fieldSeen[riskhistory.FieldBusinessCosts]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldBusinessCosts)
				fieldSeen[riskhistory.FieldBusinessCosts] = struct{}{}
			}
		case "stakeholderID":
			if _, ok := fieldSeen[riskhistory.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldStakeholderID)
				fieldSeen[riskhistory.FieldStakeholderID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[riskhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, riskhistory.FieldDelegateID)
				fieldSeen[riskhistory.FieldDelegateID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type riskhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RiskHistoryPaginateOption
}

func newRiskHistoryPaginateArgs(rv map[string]any) *riskhistoryPaginateArgs {
	args := &riskhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RiskHistoryOrder{Field: &RiskHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRiskHistoryOrder(order))
			}
		case *RiskHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithRiskHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RiskHistoryWhereInput); ok {
		args.opts = append(args.opts, WithRiskHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScanQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScanQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScanQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scan.Columns))
		selectedFields = []string{scan.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[scan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scan.FieldOwnerID)
				fieldSeen[scan.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(scan.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(scan.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(scan.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[scan.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scan.FieldCreatedAt)
				fieldSeen[scan.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scan.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scan.FieldUpdatedAt)
				fieldSeen[scan.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scan.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scan.FieldCreatedBy)
				fieldSeen[scan.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scan.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scan.FieldUpdatedBy)
				fieldSeen[scan.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scan.FieldTags]; !ok {
				selectedFields = append(selectedFields, scan.FieldTags)
				fieldSeen[scan.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scan.FieldOwnerID)
				fieldSeen[scan.FieldOwnerID] = struct{}{}
			}
		case "target":
			if _, ok := fieldSeen[scan.FieldTarget]; !ok {
				selectedFields = append(selectedFields, scan.FieldTarget)
				fieldSeen[scan.FieldTarget] = struct{}{}
			}
		case "scanType":
			if _, ok := fieldSeen[scan.FieldScanType]; !ok {
				selectedFields = append(selectedFields, scan.FieldScanType)
				fieldSeen[scan.FieldScanType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[scan.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, scan.FieldMetadata)
				fieldSeen[scan.FieldMetadata] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scan.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scan.FieldStatus)
				fieldSeen[scan.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scanPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScanPaginateOption
}

func newScanPaginateArgs(rv map[string]any) *scanPaginateArgs {
	args := &scanPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScanOrder:
			args.opts = append(args.opts, WithScanOrder(v))
		case []any:
			var orders []*ScanOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScanOrder{Field: &ScanOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScanOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScanWhereInput); ok {
		args.opts = append(args.opts, WithScanFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScanHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScanHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScanHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scanhistory.Columns))
		selectedFields = []string{scanhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[scanhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldHistoryTime)
				fieldSeen[scanhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[scanhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldRef)
				fieldSeen[scanhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[scanhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldOperation)
				fieldSeen[scanhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scanhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldCreatedAt)
				fieldSeen[scanhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scanhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldUpdatedAt)
				fieldSeen[scanhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scanhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldCreatedBy)
				fieldSeen[scanhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scanhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldUpdatedBy)
				fieldSeen[scanhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scanhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldTags)
				fieldSeen[scanhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scanhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldOwnerID)
				fieldSeen[scanhistory.FieldOwnerID] = struct{}{}
			}
		case "target":
			if _, ok := fieldSeen[scanhistory.FieldTarget]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldTarget)
				fieldSeen[scanhistory.FieldTarget] = struct{}{}
			}
		case "scanType":
			if _, ok := fieldSeen[scanhistory.FieldScanType]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldScanType)
				fieldSeen[scanhistory.FieldScanType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[scanhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldMetadata)
				fieldSeen[scanhistory.FieldMetadata] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scanhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scanhistory.FieldStatus)
				fieldSeen[scanhistory.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scanhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScanHistoryPaginateOption
}

func newScanHistoryPaginateArgs(rv map[string]any) *scanhistoryPaginateArgs {
	args := &scanhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ScanHistoryOrder{Field: &ScanHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithScanHistoryOrder(order))
			}
		case *ScanHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithScanHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ScanHistoryWhereInput); ok {
		args.opts = append(args.opts, WithScanHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScheduledJobQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScheduledJobQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjob.Columns))
		selectedFields = []string{scheduledjob.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[scheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldOwnerID)
				fieldSeen[scheduledjob.FieldOwnerID] = struct{}{}
			}

		case "jobTemplate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobTemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobtemplateImplementors)...); err != nil {
				return err
			}
			_q.withJobTemplate = query
			if _, ok := fieldSeen[scheduledjob.FieldJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobID)
				fieldSeen[scheduledjob.FieldJobID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ScheduledJob) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scheduled_job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scheduledjob.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(scheduledjob.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scheduledjob.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scheduledjob.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scheduledjob.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ScheduledJob) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scheduledjob.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ScheduledJob) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scheduled_job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scheduledjob.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(scheduledjob.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scheduledjob.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scheduledjob.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scheduledjob.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ScheduledJob) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scheduledjob.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			_q.withJobRunner = query
			if _, ok := fieldSeen[scheduledjob.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobRunnerID)
				fieldSeen[scheduledjob.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjob.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCreatedAt)
				fieldSeen[scheduledjob.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjob.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldUpdatedAt)
				fieldSeen[scheduledjob.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjob.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCreatedBy)
				fieldSeen[scheduledjob.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjob.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldUpdatedBy)
				fieldSeen[scheduledjob.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[scheduledjob.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldDisplayID)
				fieldSeen[scheduledjob.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldOwnerID)
				fieldSeen[scheduledjob.FieldOwnerID] = struct{}{}
			}
		case "jobID":
			if _, ok := fieldSeen[scheduledjob.FieldJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobID)
				fieldSeen[scheduledjob.FieldJobID] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[scheduledjob.FieldActive]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldActive)
				fieldSeen[scheduledjob.FieldActive] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[scheduledjob.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldConfiguration)
				fieldSeen[scheduledjob.FieldConfiguration] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[scheduledjob.FieldCron]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCron)
				fieldSeen[scheduledjob.FieldCron] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[scheduledjob.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobRunnerID)
				fieldSeen[scheduledjob.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scheduledjobPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobPaginateOption
}

func newScheduledJobPaginateArgs(rv map[string]any) *scheduledjobPaginateArgs {
	args := &scheduledjobPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScheduledJobOrder:
			args.opts = append(args.opts, WithScheduledJobOrder(v))
		case []any:
			var orders []*ScheduledJobOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScheduledJobOrder{Field: &ScheduledJobOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScheduledJobOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScheduledJobHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScheduledJobHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjobhistory.Columns))
		selectedFields = []string{scheduledjobhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[scheduledjobhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldHistoryTime)
				fieldSeen[scheduledjobhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[scheduledjobhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldRef)
				fieldSeen[scheduledjobhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[scheduledjobhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldOperation)
				fieldSeen[scheduledjobhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCreatedAt)
				fieldSeen[scheduledjobhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjobhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldUpdatedAt)
				fieldSeen[scheduledjobhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCreatedBy)
				fieldSeen[scheduledjobhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjobhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldUpdatedBy)
				fieldSeen[scheduledjobhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[scheduledjobhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldDisplayID)
				fieldSeen[scheduledjobhistory.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjobhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldOwnerID)
				fieldSeen[scheduledjobhistory.FieldOwnerID] = struct{}{}
			}
		case "jobID":
			if _, ok := fieldSeen[scheduledjobhistory.FieldJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldJobID)
				fieldSeen[scheduledjobhistory.FieldJobID] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[scheduledjobhistory.FieldActive]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldActive)
				fieldSeen[scheduledjobhistory.FieldActive] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[scheduledjobhistory.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldConfiguration)
				fieldSeen[scheduledjobhistory.FieldConfiguration] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[scheduledjobhistory.FieldCron]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldCron)
				fieldSeen[scheduledjobhistory.FieldCron] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[scheduledjobhistory.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobhistory.FieldJobRunnerID)
				fieldSeen[scheduledjobhistory.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scheduledjobhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobHistoryPaginateOption
}

func newScheduledJobHistoryPaginateArgs(rv map[string]any) *scheduledjobhistoryPaginateArgs {
	args := &scheduledjobhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ScheduledJobHistoryOrder{Field: &ScheduledJobHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithScheduledJobHistoryOrder(order))
			}
		case *ScheduledJobHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithScheduledJobHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobHistoryWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScheduledJobRunQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobRunQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScheduledJobRunQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjobrun.Columns))
		selectedFields = []string{scheduledjobrun.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[scheduledjobrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldOwnerID)
				fieldSeen[scheduledjobrun.FieldOwnerID] = struct{}{}
			}

		case "scheduledJob":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
				return err
			}
			_q.withScheduledJob = query
			if _, ok := fieldSeen[scheduledjobrun.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScheduledJobID)
				fieldSeen[scheduledjobrun.FieldScheduledJobID] = struct{}{}
			}

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			_q.withJobRunner = query
			if _, ok := fieldSeen[scheduledjobrun.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldJobRunnerID)
				fieldSeen[scheduledjobrun.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjobrun.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldCreatedAt)
				fieldSeen[scheduledjobrun.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjobrun.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldUpdatedAt)
				fieldSeen[scheduledjobrun.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjobrun.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldCreatedBy)
				fieldSeen[scheduledjobrun.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjobrun.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldUpdatedBy)
				fieldSeen[scheduledjobrun.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjobrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldOwnerID)
				fieldSeen[scheduledjobrun.FieldOwnerID] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[scheduledjobrun.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldJobRunnerID)
				fieldSeen[scheduledjobrun.FieldJobRunnerID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scheduledjobrun.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldStatus)
				fieldSeen[scheduledjobrun.FieldStatus] = struct{}{}
			}
		case "scheduledJobID":
			if _, ok := fieldSeen[scheduledjobrun.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScheduledJobID)
				fieldSeen[scheduledjobrun.FieldScheduledJobID] = struct{}{}
			}
		case "expectedExecutionTime":
			if _, ok := fieldSeen[scheduledjobrun.FieldExpectedExecutionTime]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldExpectedExecutionTime)
				fieldSeen[scheduledjobrun.FieldExpectedExecutionTime] = struct{}{}
			}
		case "script":
			if _, ok := fieldSeen[scheduledjobrun.FieldScript]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScript)
				fieldSeen[scheduledjobrun.FieldScript] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scheduledjobrunPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobRunPaginateOption
}

func newScheduledJobRunPaginateArgs(rv map[string]any) *scheduledjobrunPaginateArgs {
	args := &scheduledjobrunPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScheduledJobRunOrder:
			args.opts = append(args.opts, WithScheduledJobRunOrder(v))
		case []any:
			var orders []*ScheduledJobRunOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScheduledJobRunOrder{Field: &ScheduledJobRunOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScheduledJobRunOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobRunWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobRunFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *StandardQuery) CollectFields(ctx context.Context, satisfies ...string) (*StandardQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *StandardQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(standard.Columns))
		selectedFields = []string{standard.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[standard.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standard.FieldOwnerID)
				fieldSeen[standard.FieldOwnerID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Standard) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"standard_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(standard.ControlsColumn), ids...))
						})
						if err := query.GroupBy(standard.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Standard) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(standard.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "trustCenterCompliances":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterComplianceClient{config: _q.config}).Query()
			)
			args := newTrustCenterCompliancePaginateArgs(fieldArgs(ctx, new(TrustCenterComplianceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterCompliancePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Standard) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"standard_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(standard.TrustCenterCompliancesColumn), ids...))
						})
						if err := query.GroupBy(standard.TrustCenterCompliancesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Standard) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterCompliances)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentercomplianceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(standard.TrustCenterCompliancesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterCompliances(alias, func(wq *TrustCenterComplianceQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[standard.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, standard.FieldCreatedAt)
				fieldSeen[standard.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[standard.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, standard.FieldUpdatedAt)
				fieldSeen[standard.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[standard.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, standard.FieldCreatedBy)
				fieldSeen[standard.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[standard.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, standard.FieldUpdatedBy)
				fieldSeen[standard.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[standard.FieldTags]; !ok {
				selectedFields = append(selectedFields, standard.FieldTags)
				fieldSeen[standard.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[standard.FieldRevision]; !ok {
				selectedFields = append(selectedFields, standard.FieldRevision)
				fieldSeen[standard.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[standard.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standard.FieldOwnerID)
				fieldSeen[standard.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[standard.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, standard.FieldSystemOwned)
				fieldSeen[standard.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[standard.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, standard.FieldInternalNotes)
				fieldSeen[standard.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[standard.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, standard.FieldSystemInternalID)
				fieldSeen[standard.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[standard.FieldName]; !ok {
				selectedFields = append(selectedFields, standard.FieldName)
				fieldSeen[standard.FieldName] = struct{}{}
			}
		case "shortName":
			if _, ok := fieldSeen[standard.FieldShortName]; !ok {
				selectedFields = append(selectedFields, standard.FieldShortName)
				fieldSeen[standard.FieldShortName] = struct{}{}
			}
		case "framework":
			if _, ok := fieldSeen[standard.FieldFramework]; !ok {
				selectedFields = append(selectedFields, standard.FieldFramework)
				fieldSeen[standard.FieldFramework] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[standard.FieldDescription]; !ok {
				selectedFields = append(selectedFields, standard.FieldDescription)
				fieldSeen[standard.FieldDescription] = struct{}{}
			}
		case "governingBodyLogoURL":
			if _, ok := fieldSeen[standard.FieldGoverningBodyLogoURL]; !ok {
				selectedFields = append(selectedFields, standard.FieldGoverningBodyLogoURL)
				fieldSeen[standard.FieldGoverningBodyLogoURL] = struct{}{}
			}
		case "governingBody":
			if _, ok := fieldSeen[standard.FieldGoverningBody]; !ok {
				selectedFields = append(selectedFields, standard.FieldGoverningBody)
				fieldSeen[standard.FieldGoverningBody] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[standard.FieldDomains]; !ok {
				selectedFields = append(selectedFields, standard.FieldDomains)
				fieldSeen[standard.FieldDomains] = struct{}{}
			}
		case "link":
			if _, ok := fieldSeen[standard.FieldLink]; !ok {
				selectedFields = append(selectedFields, standard.FieldLink)
				fieldSeen[standard.FieldLink] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[standard.FieldStatus]; !ok {
				selectedFields = append(selectedFields, standard.FieldStatus)
				fieldSeen[standard.FieldStatus] = struct{}{}
			}
		case "isPublic":
			if _, ok := fieldSeen[standard.FieldIsPublic]; !ok {
				selectedFields = append(selectedFields, standard.FieldIsPublic)
				fieldSeen[standard.FieldIsPublic] = struct{}{}
			}
		case "freeToUse":
			if _, ok := fieldSeen[standard.FieldFreeToUse]; !ok {
				selectedFields = append(selectedFields, standard.FieldFreeToUse)
				fieldSeen[standard.FieldFreeToUse] = struct{}{}
			}
		case "standardType":
			if _, ok := fieldSeen[standard.FieldStandardType]; !ok {
				selectedFields = append(selectedFields, standard.FieldStandardType)
				fieldSeen[standard.FieldStandardType] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[standard.FieldVersion]; !ok {
				selectedFields = append(selectedFields, standard.FieldVersion)
				fieldSeen[standard.FieldVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type standardPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []StandardPaginateOption
}

func newStandardPaginateArgs(rv map[string]any) *standardPaginateArgs {
	args := &standardPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*StandardOrder:
			args.opts = append(args.opts, WithStandardOrder(v))
		case []any:
			var orders []*StandardOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &StandardOrder{Field: &StandardOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithStandardOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*StandardWhereInput); ok {
		args.opts = append(args.opts, WithStandardFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *StandardHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*StandardHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *StandardHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(standardhistory.Columns))
		selectedFields = []string{standardhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[standardhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldHistoryTime)
				fieldSeen[standardhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[standardhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldRef)
				fieldSeen[standardhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[standardhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldOperation)
				fieldSeen[standardhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[standardhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldCreatedAt)
				fieldSeen[standardhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[standardhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldUpdatedAt)
				fieldSeen[standardhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[standardhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldCreatedBy)
				fieldSeen[standardhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[standardhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldUpdatedBy)
				fieldSeen[standardhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[standardhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldTags)
				fieldSeen[standardhistory.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[standardhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldRevision)
				fieldSeen[standardhistory.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[standardhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldOwnerID)
				fieldSeen[standardhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[standardhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldSystemOwned)
				fieldSeen[standardhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[standardhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldInternalNotes)
				fieldSeen[standardhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[standardhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldSystemInternalID)
				fieldSeen[standardhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[standardhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldName)
				fieldSeen[standardhistory.FieldName] = struct{}{}
			}
		case "shortName":
			if _, ok := fieldSeen[standardhistory.FieldShortName]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldShortName)
				fieldSeen[standardhistory.FieldShortName] = struct{}{}
			}
		case "framework":
			if _, ok := fieldSeen[standardhistory.FieldFramework]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldFramework)
				fieldSeen[standardhistory.FieldFramework] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[standardhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldDescription)
				fieldSeen[standardhistory.FieldDescription] = struct{}{}
			}
		case "governingBodyLogoURL":
			if _, ok := fieldSeen[standardhistory.FieldGoverningBodyLogoURL]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldGoverningBodyLogoURL)
				fieldSeen[standardhistory.FieldGoverningBodyLogoURL] = struct{}{}
			}
		case "governingBody":
			if _, ok := fieldSeen[standardhistory.FieldGoverningBody]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldGoverningBody)
				fieldSeen[standardhistory.FieldGoverningBody] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[standardhistory.FieldDomains]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldDomains)
				fieldSeen[standardhistory.FieldDomains] = struct{}{}
			}
		case "link":
			if _, ok := fieldSeen[standardhistory.FieldLink]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldLink)
				fieldSeen[standardhistory.FieldLink] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[standardhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldStatus)
				fieldSeen[standardhistory.FieldStatus] = struct{}{}
			}
		case "isPublic":
			if _, ok := fieldSeen[standardhistory.FieldIsPublic]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldIsPublic)
				fieldSeen[standardhistory.FieldIsPublic] = struct{}{}
			}
		case "freeToUse":
			if _, ok := fieldSeen[standardhistory.FieldFreeToUse]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldFreeToUse)
				fieldSeen[standardhistory.FieldFreeToUse] = struct{}{}
			}
		case "standardType":
			if _, ok := fieldSeen[standardhistory.FieldStandardType]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldStandardType)
				fieldSeen[standardhistory.FieldStandardType] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[standardhistory.FieldVersion]; !ok {
				selectedFields = append(selectedFields, standardhistory.FieldVersion)
				fieldSeen[standardhistory.FieldVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type standardhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []StandardHistoryPaginateOption
}

func newStandardHistoryPaginateArgs(rv map[string]any) *standardhistoryPaginateArgs {
	args := &standardhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &StandardHistoryOrder{Field: &StandardHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithStandardHistoryOrder(order))
			}
		case *StandardHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithStandardHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*StandardHistoryWhereInput); ok {
		args.opts = append(args.opts, WithStandardHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubcontrolQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubcontrolQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubcontrolQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subcontrol.Columns))
		selectedFields = []string{subcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(subcontrol.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(subcontrol.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(subcontrol.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_narratives"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(subcontrol.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(subcontrol.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(subcontrol.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.CommentsColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "controlOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withControlOwner = query
			if _, ok := fieldSeen[subcontrol.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlOwnerID)
				fieldSeen[subcontrol.FieldControlOwnerID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[subcontrol.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDelegateID)
				fieldSeen[subcontrol.FieldDelegateID] = struct{}{}
			}

		case "responsibleParty":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			_q.withResponsibleParty = query
			if _, ok := fieldSeen[subcontrol.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldResponsiblePartyID)
				fieldSeen[subcontrol.FieldResponsiblePartyID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[subcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldOwnerID)
				fieldSeen[subcontrol.FieldOwnerID] = struct{}{}
			}

		case "subcontrolKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrolKind = query
			if _, ok := fieldSeen[subcontrol.FieldSubcontrolKindID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcontrolKindID)
				fieldSeen[subcontrol.FieldSubcontrolKindID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[subcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlID)
				fieldSeen[subcontrol.FieldControlID] = struct{}{}
			}

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(subcontrol.ControlImplementationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ControlImplementationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ScheduledJobsTable)
							s.Join(joinT).On(s.C(scheduledjob.FieldID), joinT.C(subcontrol.ScheduledJobsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ScheduledJobsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCreatedAt)
				fieldSeen[subcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldUpdatedAt)
				fieldSeen[subcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCreatedBy)
				fieldSeen[subcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldUpdatedBy)
				fieldSeen[subcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[subcontrol.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDisplayID)
				fieldSeen[subcontrol.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subcontrol.FieldTags]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldTags)
				fieldSeen[subcontrol.FieldTags] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[subcontrol.FieldTitle]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldTitle)
				fieldSeen[subcontrol.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subcontrol.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDescription)
				fieldSeen[subcontrol.FieldDescription] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[subcontrol.FieldAliases]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAliases)
				fieldSeen[subcontrol.FieldAliases] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[subcontrol.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceID)
				fieldSeen[subcontrol.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[subcontrol.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAuditorReferenceID)
				fieldSeen[subcontrol.FieldAuditorReferenceID] = struct{}{}
			}
		case "responsiblePartyID":
			if _, ok := fieldSeen[subcontrol.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldResponsiblePartyID)
				fieldSeen[subcontrol.FieldResponsiblePartyID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[subcontrol.FieldStatus]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldStatus)
				fieldSeen[subcontrol.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[subcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSource)
				fieldSeen[subcontrol.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[subcontrol.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceFramework)
				fieldSeen[subcontrol.FieldReferenceFramework] = struct{}{}
			}
		case "referenceFrameworkRevision":
			if _, ok := fieldSeen[subcontrol.FieldReferenceFrameworkRevision]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceFrameworkRevision)
				fieldSeen[subcontrol.FieldReferenceFrameworkRevision] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[subcontrol.FieldControlType]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlType)
				fieldSeen[subcontrol.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[subcontrol.FieldCategory]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCategory)
				fieldSeen[subcontrol.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[subcontrol.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCategoryID)
				fieldSeen[subcontrol.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[subcontrol.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcategory)
				fieldSeen[subcontrol.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[subcontrol.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldMappedCategories)
				fieldSeen[subcontrol.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[subcontrol.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAssessmentObjectives)
				fieldSeen[subcontrol.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[subcontrol.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAssessmentMethods)
				fieldSeen[subcontrol.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[subcontrol.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlQuestions)
				fieldSeen[subcontrol.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[subcontrol.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldImplementationGuidance)
				fieldSeen[subcontrol.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[subcontrol.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldExampleEvidence)
				fieldSeen[subcontrol.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[subcontrol.FieldReferences]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferences)
				fieldSeen[subcontrol.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[subcontrol.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlOwnerID)
				fieldSeen[subcontrol.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[subcontrol.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDelegateID)
				fieldSeen[subcontrol.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldOwnerID)
				fieldSeen[subcontrol.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subcontrol.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSystemOwned)
				fieldSeen[subcontrol.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[subcontrol.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldInternalNotes)
				fieldSeen[subcontrol.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[subcontrol.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSystemInternalID)
				fieldSeen[subcontrol.FieldSystemInternalID] = struct{}{}
			}
		case "subcontrolKindName":
			if _, ok := fieldSeen[subcontrol.FieldSubcontrolKindName]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcontrolKindName)
				fieldSeen[subcontrol.FieldSubcontrolKindName] = struct{}{}
			}
		case "subcontrolKindID":
			if _, ok := fieldSeen[subcontrol.FieldSubcontrolKindID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcontrolKindID)
				fieldSeen[subcontrol.FieldSubcontrolKindID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[subcontrol.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldRefCode)
				fieldSeen[subcontrol.FieldRefCode] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[subcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlID)
				fieldSeen[subcontrol.FieldControlID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubcontrolPaginateOption
}

func newSubcontrolPaginateArgs(rv map[string]any) *subcontrolPaginateArgs {
	args := &subcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubcontrolOrder:
			args.opts = append(args.opts, WithSubcontrolOrder(v))
		case []any:
			var orders []*SubcontrolOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubcontrolOrder{Field: &SubcontrolOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubcontrolOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubcontrolWhereInput); ok {
		args.opts = append(args.opts, WithSubcontrolFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubcontrolHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubcontrolHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubcontrolHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subcontrolhistory.Columns))
		selectedFields = []string{subcontrolhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[subcontrolhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldHistoryTime)
				fieldSeen[subcontrolhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[subcontrolhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldRef)
				fieldSeen[subcontrolhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[subcontrolhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldOperation)
				fieldSeen[subcontrolhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[subcontrolhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCreatedAt)
				fieldSeen[subcontrolhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subcontrolhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldUpdatedAt)
				fieldSeen[subcontrolhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subcontrolhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCreatedBy)
				fieldSeen[subcontrolhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subcontrolhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldUpdatedBy)
				fieldSeen[subcontrolhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[subcontrolhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldDisplayID)
				fieldSeen[subcontrolhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subcontrolhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldTags)
				fieldSeen[subcontrolhistory.FieldTags] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[subcontrolhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldTitle)
				fieldSeen[subcontrolhistory.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subcontrolhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldDescription)
				fieldSeen[subcontrolhistory.FieldDescription] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[subcontrolhistory.FieldAliases]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAliases)
				fieldSeen[subcontrolhistory.FieldAliases] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferenceID)
				fieldSeen[subcontrolhistory.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[subcontrolhistory.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAuditorReferenceID)
				fieldSeen[subcontrolhistory.FieldAuditorReferenceID] = struct{}{}
			}
		case "responsiblePartyID":
			if _, ok := fieldSeen[subcontrolhistory.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldResponsiblePartyID)
				fieldSeen[subcontrolhistory.FieldResponsiblePartyID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[subcontrolhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldStatus)
				fieldSeen[subcontrolhistory.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[subcontrolhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSource)
				fieldSeen[subcontrolhistory.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferenceFramework)
				fieldSeen[subcontrolhistory.FieldReferenceFramework] = struct{}{}
			}
		case "referenceFrameworkRevision":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferenceFrameworkRevision]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferenceFrameworkRevision)
				fieldSeen[subcontrolhistory.FieldReferenceFrameworkRevision] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlType]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlType)
				fieldSeen[subcontrolhistory.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[subcontrolhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCategory)
				fieldSeen[subcontrolhistory.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[subcontrolhistory.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldCategoryID)
				fieldSeen[subcontrolhistory.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[subcontrolhistory.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSubcategory)
				fieldSeen[subcontrolhistory.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[subcontrolhistory.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldMappedCategories)
				fieldSeen[subcontrolhistory.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[subcontrolhistory.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAssessmentObjectives)
				fieldSeen[subcontrolhistory.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[subcontrolhistory.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldAssessmentMethods)
				fieldSeen[subcontrolhistory.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlQuestions)
				fieldSeen[subcontrolhistory.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[subcontrolhistory.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldImplementationGuidance)
				fieldSeen[subcontrolhistory.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[subcontrolhistory.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldExampleEvidence)
				fieldSeen[subcontrolhistory.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[subcontrolhistory.FieldReferences]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldReferences)
				fieldSeen[subcontrolhistory.FieldReferences] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlOwnerID)
				fieldSeen[subcontrolhistory.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[subcontrolhistory.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldDelegateID)
				fieldSeen[subcontrolhistory.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subcontrolhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldOwnerID)
				fieldSeen[subcontrolhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subcontrolhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSystemOwned)
				fieldSeen[subcontrolhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[subcontrolhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldInternalNotes)
				fieldSeen[subcontrolhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[subcontrolhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSystemInternalID)
				fieldSeen[subcontrolhistory.FieldSystemInternalID] = struct{}{}
			}
		case "subcontrolKindName":
			if _, ok := fieldSeen[subcontrolhistory.FieldSubcontrolKindName]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSubcontrolKindName)
				fieldSeen[subcontrolhistory.FieldSubcontrolKindName] = struct{}{}
			}
		case "subcontrolKindID":
			if _, ok := fieldSeen[subcontrolhistory.FieldSubcontrolKindID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldSubcontrolKindID)
				fieldSeen[subcontrolhistory.FieldSubcontrolKindID] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[subcontrolhistory.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldRefCode)
				fieldSeen[subcontrolhistory.FieldRefCode] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[subcontrolhistory.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrolhistory.FieldControlID)
				fieldSeen[subcontrolhistory.FieldControlID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subcontrolhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubcontrolHistoryPaginateOption
}

func newSubcontrolHistoryPaginateArgs(rv map[string]any) *subcontrolhistoryPaginateArgs {
	args := &subcontrolhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &SubcontrolHistoryOrder{Field: &SubcontrolHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithSubcontrolHistoryOrder(order))
			}
		case *SubcontrolHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithSubcontrolHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*SubcontrolHistoryWhereInput); ok {
		args.opts = append(args.opts, WithSubcontrolHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubprocessorQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubprocessorQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubprocessorQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subprocessor.Columns))
		selectedFields = []string{subprocessor.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[subprocessor.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldOwnerID)
				fieldSeen[subprocessor.FieldOwnerID] = struct{}{}
			}

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[subprocessor.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoFileID)
				fieldSeen[subprocessor.FieldLogoFileID] = struct{}{}
			}

		case "trustCenterSubprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSubprocessorClient{config: _q.config}).Query()
			)
			args := newTrustCenterSubprocessorPaginateArgs(fieldArgs(ctx, new(TrustCenterSubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subprocessor) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subprocessor_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subprocessor.TrustCenterSubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(subprocessor.TrustCenterSubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subprocessor) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentersubprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subprocessor.TrustCenterSubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterSubprocessors(alias, func(wq *TrustCenterSubprocessorQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subprocessor.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldCreatedAt)
				fieldSeen[subprocessor.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subprocessor.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldUpdatedAt)
				fieldSeen[subprocessor.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subprocessor.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldCreatedBy)
				fieldSeen[subprocessor.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subprocessor.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldUpdatedBy)
				fieldSeen[subprocessor.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subprocessor.FieldTags]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldTags)
				fieldSeen[subprocessor.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subprocessor.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldOwnerID)
				fieldSeen[subprocessor.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subprocessor.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldSystemOwned)
				fieldSeen[subprocessor.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[subprocessor.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldInternalNotes)
				fieldSeen[subprocessor.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[subprocessor.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldSystemInternalID)
				fieldSeen[subprocessor.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[subprocessor.FieldName]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldName)
				fieldSeen[subprocessor.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subprocessor.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldDescription)
				fieldSeen[subprocessor.FieldDescription] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[subprocessor.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoRemoteURL)
				fieldSeen[subprocessor.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[subprocessor.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoFileID)
				fieldSeen[subprocessor.FieldLogoFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subprocessorPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubprocessorPaginateOption
}

func newSubprocessorPaginateArgs(rv map[string]any) *subprocessorPaginateArgs {
	args := &subprocessorPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubprocessorOrder:
			args.opts = append(args.opts, WithSubprocessorOrder(v))
		case []any:
			var orders []*SubprocessorOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubprocessorOrder{Field: &SubprocessorOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubprocessorOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubprocessorWhereInput); ok {
		args.opts = append(args.opts, WithSubprocessorFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubprocessorHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubprocessorHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubprocessorHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subprocessorhistory.Columns))
		selectedFields = []string{subprocessorhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[subprocessorhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldHistoryTime)
				fieldSeen[subprocessorhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[subprocessorhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldRef)
				fieldSeen[subprocessorhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[subprocessorhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldOperation)
				fieldSeen[subprocessorhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[subprocessorhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldCreatedAt)
				fieldSeen[subprocessorhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subprocessorhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldUpdatedAt)
				fieldSeen[subprocessorhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subprocessorhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldCreatedBy)
				fieldSeen[subprocessorhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subprocessorhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldUpdatedBy)
				fieldSeen[subprocessorhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subprocessorhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldTags)
				fieldSeen[subprocessorhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subprocessorhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldOwnerID)
				fieldSeen[subprocessorhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subprocessorhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldSystemOwned)
				fieldSeen[subprocessorhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[subprocessorhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldInternalNotes)
				fieldSeen[subprocessorhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[subprocessorhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldSystemInternalID)
				fieldSeen[subprocessorhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[subprocessorhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldName)
				fieldSeen[subprocessorhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subprocessorhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldDescription)
				fieldSeen[subprocessorhistory.FieldDescription] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[subprocessorhistory.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldLogoRemoteURL)
				fieldSeen[subprocessorhistory.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[subprocessorhistory.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, subprocessorhistory.FieldLogoFileID)
				fieldSeen[subprocessorhistory.FieldLogoFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subprocessorhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubprocessorHistoryPaginateOption
}

func newSubprocessorHistoryPaginateArgs(rv map[string]any) *subprocessorhistoryPaginateArgs {
	args := &subprocessorhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &SubprocessorHistoryOrder{Field: &SubprocessorHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithSubprocessorHistoryOrder(order))
			}
		case *SubprocessorHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithSubprocessorHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*SubprocessorHistoryWhereInput); ok {
		args.opts = append(args.opts, WithSubprocessorHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubscriberQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubscriberQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubscriberQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subscriber.Columns))
		selectedFields = []string{subscriber.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[subscriber.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldOwnerID)
				fieldSeen[subscriber.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subscriber) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subscriber_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subscriber.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(subscriber.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subscriber.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(subscriber.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subscriber.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subscriber) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subscriber.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subscriber.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldCreatedAt)
				fieldSeen[subscriber.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subscriber.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUpdatedAt)
				fieldSeen[subscriber.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subscriber.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldCreatedBy)
				fieldSeen[subscriber.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subscriber.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUpdatedBy)
				fieldSeen[subscriber.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subscriber.FieldTags]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldTags)
				fieldSeen[subscriber.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subscriber.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldOwnerID)
				fieldSeen[subscriber.FieldOwnerID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[subscriber.FieldEmail]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldEmail)
				fieldSeen[subscriber.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[subscriber.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldPhoneNumber)
				fieldSeen[subscriber.FieldPhoneNumber] = struct{}{}
			}
		case "verifiedEmail":
			if _, ok := fieldSeen[subscriber.FieldVerifiedEmail]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldVerifiedEmail)
				fieldSeen[subscriber.FieldVerifiedEmail] = struct{}{}
			}
		case "verifiedPhone":
			if _, ok := fieldSeen[subscriber.FieldVerifiedPhone]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldVerifiedPhone)
				fieldSeen[subscriber.FieldVerifiedPhone] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[subscriber.FieldActive]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldActive)
				fieldSeen[subscriber.FieldActive] = struct{}{}
			}
		case "unsubscribed":
			if _, ok := fieldSeen[subscriber.FieldUnsubscribed]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUnsubscribed)
				fieldSeen[subscriber.FieldUnsubscribed] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[subscriber.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldSendAttempts)
				fieldSeen[subscriber.FieldSendAttempts] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subscriberPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubscriberPaginateOption
}

func newSubscriberPaginateArgs(rv map[string]any) *subscriberPaginateArgs {
	args := &subscriberPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubscriberOrder:
			args.opts = append(args.opts, WithSubscriberOrder(v))
		case []any:
			var orders []*SubscriberOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubscriberOrder{Field: &SubscriberOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubscriberOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubscriberWhereInput); ok {
		args.opts = append(args.opts, WithSubscriberFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TFASettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*TFASettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TFASettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tfasetting.Columns))
		selectedFields = []string{tfasetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[tfasetting.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldOwnerID)
				fieldSeen[tfasetting.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[tfasetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldCreatedAt)
				fieldSeen[tfasetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[tfasetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldUpdatedAt)
				fieldSeen[tfasetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[tfasetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldCreatedBy)
				fieldSeen[tfasetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[tfasetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldUpdatedBy)
				fieldSeen[tfasetting.FieldUpdatedBy] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[tfasetting.FieldVerified]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldVerified)
				fieldSeen[tfasetting.FieldVerified] = struct{}{}
			}
		case "totpAllowed":
			if _, ok := fieldSeen[tfasetting.FieldTotpAllowed]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldTotpAllowed)
				fieldSeen[tfasetting.FieldTotpAllowed] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type tfasettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TFASettingPaginateOption
}

func newTFASettingPaginateArgs(rv map[string]any) *tfasettingPaginateArgs {
	args := &tfasettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TFASettingOrder:
			args.opts = append(args.opts, WithTFASettingOrder(v))
		case []any:
			var orders []*TFASettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TFASettingOrder{Field: &TFASettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTFASettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TFASettingWhereInput); ok {
		args.opts = append(args.opts, WithTFASettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TagDefinitionQuery) CollectFields(ctx context.Context, satisfies ...string) (*TagDefinitionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TagDefinitionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tagdefinition.Columns))
		selectedFields = []string{tagdefinition.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[tagdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldOwnerID)
				fieldSeen[tagdefinition.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[tagdefinition.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldCreatedAt)
				fieldSeen[tagdefinition.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[tagdefinition.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldUpdatedAt)
				fieldSeen[tagdefinition.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[tagdefinition.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldCreatedBy)
				fieldSeen[tagdefinition.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[tagdefinition.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldUpdatedBy)
				fieldSeen[tagdefinition.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[tagdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldOwnerID)
				fieldSeen[tagdefinition.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[tagdefinition.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldSystemOwned)
				fieldSeen[tagdefinition.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[tagdefinition.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldInternalNotes)
				fieldSeen[tagdefinition.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[tagdefinition.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldSystemInternalID)
				fieldSeen[tagdefinition.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[tagdefinition.FieldName]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldName)
				fieldSeen[tagdefinition.FieldName] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[tagdefinition.FieldAliases]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldAliases)
				fieldSeen[tagdefinition.FieldAliases] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[tagdefinition.FieldSlug]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldSlug)
				fieldSeen[tagdefinition.FieldSlug] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[tagdefinition.FieldDescription]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldDescription)
				fieldSeen[tagdefinition.FieldDescription] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[tagdefinition.FieldColor]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldColor)
				fieldSeen[tagdefinition.FieldColor] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type tagdefinitionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TagDefinitionPaginateOption
}

func newTagDefinitionPaginateArgs(rv map[string]any) *tagdefinitionPaginateArgs {
	args := &tagdefinitionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TagDefinitionOrder:
			args.opts = append(args.opts, WithTagDefinitionOrder(v))
		case []any:
			var orders []*TagDefinitionOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TagDefinitionOrder{Field: &TagDefinitionOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTagDefinitionOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TagDefinitionWhereInput); ok {
		args.opts = append(args.opts, WithTagDefinitionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TaskQuery) CollectFields(ctx context.Context, satisfies ...string) (*TaskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TaskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(task.Columns))
		selectedFields = []string{task.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[task.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, task.FieldOwnerID)
				fieldSeen[task.FieldOwnerID] = struct{}{}
			}

		case "taskKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withTaskKind = query
			if _, ok := fieldSeen[task.FieldTaskKindID]; !ok {
				selectedFields = append(selectedFields, task.FieldTaskKindID)
				fieldSeen[task.FieldTaskKindID] = struct{}{}
			}

		case "assigner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withAssigner = query
			if _, ok := fieldSeen[task.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssignerID)
				fieldSeen[task.FieldAssignerID] = struct{}{}
			}

		case "assignee":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withAssignee = query
			if _, ok := fieldSeen[task.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssigneeID)
				fieldSeen[task.FieldAssigneeID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.CommentsColumn), ids...))
						})
						if err := query.GroupBy(task.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(task.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(task.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(task.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(task.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(task.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(task.ControlObjectivesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlObjectivesPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlObjectivesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlObjectivesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlObjectivesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(task.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(task.RisksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.RisksPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.RisksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.RisksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.RisksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(task.ControlImplementationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlImplementationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlImplementationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlImplementationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlImplementationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(task.ActionPlansPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ActionPlansPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ActionPlansPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ActionPlansPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ActionPlansPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(task.EvidencePrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(task.EvidencePrimaryKey[0]), ids...))
							s.Select(joinT.C(task.EvidencePrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(task.EvidencePrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.EvidencePrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(task.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[task.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedAt)
				fieldSeen[task.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[task.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldUpdatedAt)
				fieldSeen[task.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[task.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedBy)
				fieldSeen[task.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[task.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, task.FieldUpdatedBy)
				fieldSeen[task.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[task.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, task.FieldDisplayID)
				fieldSeen[task.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[task.FieldTags]; !ok {
				selectedFields = append(selectedFields, task.FieldTags)
				fieldSeen[task.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[task.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, task.FieldOwnerID)
				fieldSeen[task.FieldOwnerID] = struct{}{}
			}
		case "taskKindName":
			if _, ok := fieldSeen[task.FieldTaskKindName]; !ok {
				selectedFields = append(selectedFields, task.FieldTaskKindName)
				fieldSeen[task.FieldTaskKindName] = struct{}{}
			}
		case "taskKindID":
			if _, ok := fieldSeen[task.FieldTaskKindID]; !ok {
				selectedFields = append(selectedFields, task.FieldTaskKindID)
				fieldSeen[task.FieldTaskKindID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[task.FieldTitle]; !ok {
				selectedFields = append(selectedFields, task.FieldTitle)
				fieldSeen[task.FieldTitle] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[task.FieldDetails]; !ok {
				selectedFields = append(selectedFields, task.FieldDetails)
				fieldSeen[task.FieldDetails] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[task.FieldStatus]; !ok {
				selectedFields = append(selectedFields, task.FieldStatus)
				fieldSeen[task.FieldStatus] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[task.FieldCategory]; !ok {
				selectedFields = append(selectedFields, task.FieldCategory)
				fieldSeen[task.FieldCategory] = struct{}{}
			}
		case "due":
			if _, ok := fieldSeen[task.FieldDue]; !ok {
				selectedFields = append(selectedFields, task.FieldDue)
				fieldSeen[task.FieldDue] = struct{}{}
			}
		case "completed":
			if _, ok := fieldSeen[task.FieldCompleted]; !ok {
				selectedFields = append(selectedFields, task.FieldCompleted)
				fieldSeen[task.FieldCompleted] = struct{}{}
			}
		case "assigneeID":
			if _, ok := fieldSeen[task.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssigneeID)
				fieldSeen[task.FieldAssigneeID] = struct{}{}
			}
		case "assignerID":
			if _, ok := fieldSeen[task.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssignerID)
				fieldSeen[task.FieldAssignerID] = struct{}{}
			}
		case "systemGenerated":
			if _, ok := fieldSeen[task.FieldSystemGenerated]; !ok {
				selectedFields = append(selectedFields, task.FieldSystemGenerated)
				fieldSeen[task.FieldSystemGenerated] = struct{}{}
			}
		case "idempotencyKey":
			if _, ok := fieldSeen[task.FieldIdempotencyKey]; !ok {
				selectedFields = append(selectedFields, task.FieldIdempotencyKey)
				fieldSeen[task.FieldIdempotencyKey] = struct{}{}
			}
		case "externalReferenceURL":
			if _, ok := fieldSeen[task.FieldExternalReferenceURL]; !ok {
				selectedFields = append(selectedFields, task.FieldExternalReferenceURL)
				fieldSeen[task.FieldExternalReferenceURL] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type taskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TaskPaginateOption
}

func newTaskPaginateArgs(rv map[string]any) *taskPaginateArgs {
	args := &taskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TaskOrder:
			args.opts = append(args.opts, WithTaskOrder(v))
		case []any:
			var orders []*TaskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TaskOrder{Field: &TaskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTaskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TaskWhereInput); ok {
		args.opts = append(args.opts, WithTaskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TaskHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TaskHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TaskHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(taskhistory.Columns))
		selectedFields = []string{taskhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[taskhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldHistoryTime)
				fieldSeen[taskhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[taskhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldRef)
				fieldSeen[taskhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[taskhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldOperation)
				fieldSeen[taskhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[taskhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCreatedAt)
				fieldSeen[taskhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[taskhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldUpdatedAt)
				fieldSeen[taskhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[taskhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCreatedBy)
				fieldSeen[taskhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[taskhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldUpdatedBy)
				fieldSeen[taskhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[taskhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldDisplayID)
				fieldSeen[taskhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[taskhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldTags)
				fieldSeen[taskhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[taskhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldOwnerID)
				fieldSeen[taskhistory.FieldOwnerID] = struct{}{}
			}
		case "taskKindName":
			if _, ok := fieldSeen[taskhistory.FieldTaskKindName]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldTaskKindName)
				fieldSeen[taskhistory.FieldTaskKindName] = struct{}{}
			}
		case "taskKindID":
			if _, ok := fieldSeen[taskhistory.FieldTaskKindID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldTaskKindID)
				fieldSeen[taskhistory.FieldTaskKindID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[taskhistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldTitle)
				fieldSeen[taskhistory.FieldTitle] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[taskhistory.FieldDetails]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldDetails)
				fieldSeen[taskhistory.FieldDetails] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[taskhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldStatus)
				fieldSeen[taskhistory.FieldStatus] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[taskhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCategory)
				fieldSeen[taskhistory.FieldCategory] = struct{}{}
			}
		case "due":
			if _, ok := fieldSeen[taskhistory.FieldDue]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldDue)
				fieldSeen[taskhistory.FieldDue] = struct{}{}
			}
		case "completed":
			if _, ok := fieldSeen[taskhistory.FieldCompleted]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldCompleted)
				fieldSeen[taskhistory.FieldCompleted] = struct{}{}
			}
		case "assigneeID":
			if _, ok := fieldSeen[taskhistory.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldAssigneeID)
				fieldSeen[taskhistory.FieldAssigneeID] = struct{}{}
			}
		case "assignerID":
			if _, ok := fieldSeen[taskhistory.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldAssignerID)
				fieldSeen[taskhistory.FieldAssignerID] = struct{}{}
			}
		case "systemGenerated":
			if _, ok := fieldSeen[taskhistory.FieldSystemGenerated]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldSystemGenerated)
				fieldSeen[taskhistory.FieldSystemGenerated] = struct{}{}
			}
		case "idempotencyKey":
			if _, ok := fieldSeen[taskhistory.FieldIdempotencyKey]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldIdempotencyKey)
				fieldSeen[taskhistory.FieldIdempotencyKey] = struct{}{}
			}
		case "externalReferenceURL":
			if _, ok := fieldSeen[taskhistory.FieldExternalReferenceURL]; !ok {
				selectedFields = append(selectedFields, taskhistory.FieldExternalReferenceURL)
				fieldSeen[taskhistory.FieldExternalReferenceURL] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type taskhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TaskHistoryPaginateOption
}

func newTaskHistoryPaginateArgs(rv map[string]any) *taskhistoryPaginateArgs {
	args := &taskhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TaskHistoryOrder{Field: &TaskHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTaskHistoryOrder(order))
			}
		case *TaskHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTaskHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TaskHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTaskHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TemplateQuery) CollectFields(ctx context.Context, satisfies ...string) (*TemplateQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TemplateQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(template.Columns))
		selectedFields = []string{template.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[template.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, template.FieldOwnerID)
				fieldSeen[template.FieldOwnerID] = struct{}{}
			}

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(template.DocumentsColumn), ids...))
						})
						if err := query.GroupBy(template.DocumentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.DocumentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(template.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(template.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(template.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(template.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(template.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[template.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, template.FieldTrustCenterID)
				fieldSeen[template.FieldTrustCenterID] = struct{}{}
			}

		case "assessments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentClient{config: _q.config}).Query()
			)
			args := newAssessmentPaginateArgs(fieldArgs(ctx, new(AssessmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(template.AssessmentsColumn), ids...))
						})
						if err := query.GroupBy(template.AssessmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assessments)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.AssessmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessments(alias, func(wq *AssessmentQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[template.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, template.FieldCreatedAt)
				fieldSeen[template.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[template.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, template.FieldUpdatedAt)
				fieldSeen[template.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[template.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, template.FieldCreatedBy)
				fieldSeen[template.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[template.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, template.FieldUpdatedBy)
				fieldSeen[template.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[template.FieldTags]; !ok {
				selectedFields = append(selectedFields, template.FieldTags)
				fieldSeen[template.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[template.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, template.FieldOwnerID)
				fieldSeen[template.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[template.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, template.FieldSystemOwned)
				fieldSeen[template.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[template.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, template.FieldInternalNotes)
				fieldSeen[template.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[template.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, template.FieldSystemInternalID)
				fieldSeen[template.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[template.FieldName]; !ok {
				selectedFields = append(selectedFields, template.FieldName)
				fieldSeen[template.FieldName] = struct{}{}
			}
		case "templateType":
			if _, ok := fieldSeen[template.FieldTemplateType]; !ok {
				selectedFields = append(selectedFields, template.FieldTemplateType)
				fieldSeen[template.FieldTemplateType] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[template.FieldDescription]; !ok {
				selectedFields = append(selectedFields, template.FieldDescription)
				fieldSeen[template.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[template.FieldKind]; !ok {
				selectedFields = append(selectedFields, template.FieldKind)
				fieldSeen[template.FieldKind] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[template.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, template.FieldJsonconfig)
				fieldSeen[template.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[template.FieldUischema]; !ok {
				selectedFields = append(selectedFields, template.FieldUischema)
				fieldSeen[template.FieldUischema] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[template.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, template.FieldTrustCenterID)
				fieldSeen[template.FieldTrustCenterID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type templatePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TemplatePaginateOption
}

func newTemplatePaginateArgs(rv map[string]any) *templatePaginateArgs {
	args := &templatePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TemplateOrder:
			args.opts = append(args.opts, WithTemplateOrder(v))
		case []any:
			var orders []*TemplateOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TemplateOrder{Field: &TemplateOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTemplateOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TemplateWhereInput); ok {
		args.opts = append(args.opts, WithTemplateFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TemplateHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TemplateHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TemplateHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(templatehistory.Columns))
		selectedFields = []string{templatehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[templatehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldHistoryTime)
				fieldSeen[templatehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[templatehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldRef)
				fieldSeen[templatehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[templatehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldOperation)
				fieldSeen[templatehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[templatehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldCreatedAt)
				fieldSeen[templatehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[templatehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldUpdatedAt)
				fieldSeen[templatehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[templatehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldCreatedBy)
				fieldSeen[templatehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[templatehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldUpdatedBy)
				fieldSeen[templatehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[templatehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldTags)
				fieldSeen[templatehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[templatehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldOwnerID)
				fieldSeen[templatehistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[templatehistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldSystemOwned)
				fieldSeen[templatehistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[templatehistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldInternalNotes)
				fieldSeen[templatehistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[templatehistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldSystemInternalID)
				fieldSeen[templatehistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[templatehistory.FieldName]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldName)
				fieldSeen[templatehistory.FieldName] = struct{}{}
			}
		case "templateType":
			if _, ok := fieldSeen[templatehistory.FieldTemplateType]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldTemplateType)
				fieldSeen[templatehistory.FieldTemplateType] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[templatehistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldDescription)
				fieldSeen[templatehistory.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[templatehistory.FieldKind]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldKind)
				fieldSeen[templatehistory.FieldKind] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[templatehistory.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldJsonconfig)
				fieldSeen[templatehistory.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[templatehistory.FieldUischema]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldUischema)
				fieldSeen[templatehistory.FieldUischema] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[templatehistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, templatehistory.FieldTrustCenterID)
				fieldSeen[templatehistory.FieldTrustCenterID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type templatehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TemplateHistoryPaginateOption
}

func newTemplateHistoryPaginateArgs(rv map[string]any) *templatehistoryPaginateArgs {
	args := &templatehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TemplateHistoryOrder{Field: &TemplateHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTemplateHistoryOrder(order))
			}
		case *TemplateHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTemplateHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TemplateHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTemplateHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenter.Columns))
		selectedFields = []string{trustcenter.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[trustcenter.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldOwnerID)
				fieldSeen[trustcenter.FieldOwnerID] = struct{}{}
			}

		case "customDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
				return err
			}
			_q.withCustomDomain = query
			if _, ok := fieldSeen[trustcenter.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCustomDomainID)
				fieldSeen[trustcenter.FieldCustomDomainID] = struct{}{}
			}

		case "previewDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
				return err
			}
			_q.withPreviewDomain = query
			if _, ok := fieldSeen[trustcenter.FieldPreviewDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPreviewDomainID)
				fieldSeen[trustcenter.FieldPreviewDomainID] = struct{}{}
			}

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "previewSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			_q.withPreviewSetting = query

		case "watermarkConfig":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterWatermarkConfigClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterwatermarkconfigImplementors)...); err != nil {
				return err
			}
			_q.withWatermarkConfig = query

		case "trustCenterSubprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSubprocessorClient{config: _q.config}).Query()
			)
			args := newTrustCenterSubprocessorPaginateArgs(fieldArgs(ctx, new(TrustCenterSubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterSubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterSubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessors)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentersubprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterSubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterSubprocessors(alias, func(wq *TrustCenterSubprocessorQuery) {
				*wq = *query
			})

		case "trustCenterDocs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterDocClient{config: _q.config}).Query()
			)
			args := newTrustCenterDocPaginateArgs(fieldArgs(ctx, new(TrustCenterDocWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterDocPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterDocsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterDocsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterDocs)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterdocImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterDocsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterDocs(alias, func(wq *TrustCenterDocQuery) {
				*wq = *query
			})

		case "trustCenterCompliances":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterComplianceClient{config: _q.config}).Query()
			)
			args := newTrustCenterCompliancePaginateArgs(fieldArgs(ctx, new(TrustCenterComplianceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterCompliancePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterCompliancesColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterCompliancesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterCompliances)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentercomplianceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterCompliancesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterCompliances(alias, func(wq *TrustCenterComplianceQuery) {
				*wq = *query
			})

		case "templates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			args := newTemplatePaginateArgs(fieldArgs(ctx, new(TemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TemplatesColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Templates)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTemplates(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "posts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_posts"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.PostsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.PostsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Posts)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.PostsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPosts(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "trustcenterEntities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustcenterEntityClient{config: _q.config}).Query()
			)
			args := newTrustcenterEntityPaginateArgs(fieldArgs(ctx, new(TrustcenterEntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustcenterEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_trustcenter_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustcenterEntitiesColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustcenterEntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustcenterEntities)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterentityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustcenterEntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustcenterEntities(alias, func(wq *TrustcenterEntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[trustcenter.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCreatedAt)
				fieldSeen[trustcenter.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenter.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldUpdatedAt)
				fieldSeen[trustcenter.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenter.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCreatedBy)
				fieldSeen[trustcenter.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenter.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldUpdatedBy)
				fieldSeen[trustcenter.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenter.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldTags)
				fieldSeen[trustcenter.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenter.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldOwnerID)
				fieldSeen[trustcenter.FieldOwnerID] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[trustcenter.FieldSlug]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldSlug)
				fieldSeen[trustcenter.FieldSlug] = struct{}{}
			}
		case "customDomainID":
			if _, ok := fieldSeen[trustcenter.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCustomDomainID)
				fieldSeen[trustcenter.FieldCustomDomainID] = struct{}{}
			}
		case "previewDomainID":
			if _, ok := fieldSeen[trustcenter.FieldPreviewDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPreviewDomainID)
				fieldSeen[trustcenter.FieldPreviewDomainID] = struct{}{}
			}
		case "pirschDomainID":
			if _, ok := fieldSeen[trustcenter.FieldPirschDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPirschDomainID)
				fieldSeen[trustcenter.FieldPirschDomainID] = struct{}{}
			}
		case "pirschIdentificationCode":
			if _, ok := fieldSeen[trustcenter.FieldPirschIdentificationCode]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPirschIdentificationCode)
				fieldSeen[trustcenter.FieldPirschIdentificationCode] = struct{}{}
			}
		case "previewStatus":
			if _, ok := fieldSeen[trustcenter.FieldPreviewStatus]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPreviewStatus)
				fieldSeen[trustcenter.FieldPreviewStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterPaginateOption
}

func newTrustCenterPaginateArgs(rv map[string]any) *trustcenterPaginateArgs {
	args := &trustcenterPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterOrder:
			args.opts = append(args.opts, WithTrustCenterOrder(v))
		case []any:
			var orders []*TrustCenterOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterOrder{Field: &TrustCenterOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterComplianceQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterComplianceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterComplianceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentercompliance.Columns))
		selectedFields = []string{trustcentercompliance.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcentercompliance.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTrustCenterID)
				fieldSeen[trustcentercompliance.FieldTrustCenterID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[trustcentercompliance.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldStandardID)
				fieldSeen[trustcentercompliance.FieldStandardID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentercompliance.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldCreatedAt)
				fieldSeen[trustcentercompliance.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentercompliance.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldUpdatedAt)
				fieldSeen[trustcentercompliance.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentercompliance.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldCreatedBy)
				fieldSeen[trustcentercompliance.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentercompliance.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldUpdatedBy)
				fieldSeen[trustcentercompliance.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcentercompliance.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTags)
				fieldSeen[trustcentercompliance.FieldTags] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[trustcentercompliance.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldStandardID)
				fieldSeen[trustcentercompliance.FieldStandardID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentercompliance.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTrustCenterID)
				fieldSeen[trustcentercompliance.FieldTrustCenterID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentercompliancePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterCompliancePaginateOption
}

func newTrustCenterCompliancePaginateArgs(rv map[string]any) *trustcentercompliancePaginateArgs {
	args := &trustcentercompliancePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterComplianceOrder:
			args.opts = append(args.opts, WithTrustCenterComplianceOrder(v))
		case []any:
			var orders []*TrustCenterComplianceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterComplianceOrder{Field: &TrustCenterComplianceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterComplianceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterComplianceWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterComplianceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterComplianceHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterComplianceHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterComplianceHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentercompliancehistory.Columns))
		selectedFields = []string{trustcentercompliancehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldHistoryTime)
				fieldSeen[trustcentercompliancehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldRef)
				fieldSeen[trustcentercompliancehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldOperation)
				fieldSeen[trustcentercompliancehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldCreatedAt)
				fieldSeen[trustcentercompliancehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldUpdatedAt)
				fieldSeen[trustcentercompliancehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldCreatedBy)
				fieldSeen[trustcentercompliancehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldUpdatedBy)
				fieldSeen[trustcentercompliancehistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldTags)
				fieldSeen[trustcentercompliancehistory.FieldTags] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldStandardID)
				fieldSeen[trustcentercompliancehistory.FieldStandardID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentercompliancehistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliancehistory.FieldTrustCenterID)
				fieldSeen[trustcentercompliancehistory.FieldTrustCenterID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentercompliancehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterComplianceHistoryPaginateOption
}

func newTrustCenterComplianceHistoryPaginateArgs(rv map[string]any) *trustcentercompliancehistoryPaginateArgs {
	args := &trustcentercompliancehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterComplianceHistoryOrder{Field: &TrustCenterComplianceHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterComplianceHistoryOrder(order))
			}
		case *TrustCenterComplianceHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterComplianceHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterComplianceHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterComplianceHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterDocQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterDocQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterDocQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterdoc.Columns))
		selectedFields = []string{trustcenterdoc.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcenterdoc.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTrustCenterID)
				fieldSeen[trustcenterdoc.FieldTrustCenterID] = struct{}{}
			}

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[trustcenterdoc.FieldFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldFileID)
				fieldSeen[trustcenterdoc.FieldFileID] = struct{}{}
			}

		case "originalFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withOriginalFile = query
			if _, ok := fieldSeen[trustcenterdoc.FieldOriginalFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldOriginalFileID)
				fieldSeen[trustcenterdoc.FieldOriginalFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterdoc.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldCreatedAt)
				fieldSeen[trustcenterdoc.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterdoc.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldUpdatedAt)
				fieldSeen[trustcenterdoc.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterdoc.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldCreatedBy)
				fieldSeen[trustcenterdoc.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterdoc.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldUpdatedBy)
				fieldSeen[trustcenterdoc.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenterdoc.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTags)
				fieldSeen[trustcenterdoc.FieldTags] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterdoc.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTrustCenterID)
				fieldSeen[trustcenterdoc.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcenterdoc.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTitle)
				fieldSeen[trustcenterdoc.FieldTitle] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcenterdoc.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldCategory)
				fieldSeen[trustcenterdoc.FieldCategory] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[trustcenterdoc.FieldFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldFileID)
				fieldSeen[trustcenterdoc.FieldFileID] = struct{}{}
			}
		case "originalFileID":
			if _, ok := fieldSeen[trustcenterdoc.FieldOriginalFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldOriginalFileID)
				fieldSeen[trustcenterdoc.FieldOriginalFileID] = struct{}{}
			}
		case "watermarkingEnabled":
			if _, ok := fieldSeen[trustcenterdoc.FieldWatermarkingEnabled]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldWatermarkingEnabled)
				fieldSeen[trustcenterdoc.FieldWatermarkingEnabled] = struct{}{}
			}
		case "watermarkStatus":
			if _, ok := fieldSeen[trustcenterdoc.FieldWatermarkStatus]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldWatermarkStatus)
				fieldSeen[trustcenterdoc.FieldWatermarkStatus] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[trustcenterdoc.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldVisibility)
				fieldSeen[trustcenterdoc.FieldVisibility] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterdocPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterDocPaginateOption
}

func newTrustCenterDocPaginateArgs(rv map[string]any) *trustcenterdocPaginateArgs {
	args := &trustcenterdocPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterDocOrder:
			args.opts = append(args.opts, WithTrustCenterDocOrder(v))
		case []any:
			var orders []*TrustCenterDocOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterDocOrder{Field: &TrustCenterDocOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterDocOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterDocWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterDocFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterDocHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterDocHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterDocHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterdochistory.Columns))
		selectedFields = []string{trustcenterdochistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcenterdochistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldHistoryTime)
				fieldSeen[trustcenterdochistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcenterdochistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldRef)
				fieldSeen[trustcenterdochistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcenterdochistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldOperation)
				fieldSeen[trustcenterdochistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterdochistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldCreatedAt)
				fieldSeen[trustcenterdochistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterdochistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldUpdatedAt)
				fieldSeen[trustcenterdochistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterdochistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldCreatedBy)
				fieldSeen[trustcenterdochistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterdochistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldUpdatedBy)
				fieldSeen[trustcenterdochistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenterdochistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldTags)
				fieldSeen[trustcenterdochistory.FieldTags] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterdochistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldTrustCenterID)
				fieldSeen[trustcenterdochistory.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcenterdochistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldTitle)
				fieldSeen[trustcenterdochistory.FieldTitle] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcenterdochistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldCategory)
				fieldSeen[trustcenterdochistory.FieldCategory] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[trustcenterdochistory.FieldFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldFileID)
				fieldSeen[trustcenterdochistory.FieldFileID] = struct{}{}
			}
		case "originalFileID":
			if _, ok := fieldSeen[trustcenterdochistory.FieldOriginalFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldOriginalFileID)
				fieldSeen[trustcenterdochistory.FieldOriginalFileID] = struct{}{}
			}
		case "watermarkingEnabled":
			if _, ok := fieldSeen[trustcenterdochistory.FieldWatermarkingEnabled]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldWatermarkingEnabled)
				fieldSeen[trustcenterdochistory.FieldWatermarkingEnabled] = struct{}{}
			}
		case "watermarkStatus":
			if _, ok := fieldSeen[trustcenterdochistory.FieldWatermarkStatus]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldWatermarkStatus)
				fieldSeen[trustcenterdochistory.FieldWatermarkStatus] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[trustcenterdochistory.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, trustcenterdochistory.FieldVisibility)
				fieldSeen[trustcenterdochistory.FieldVisibility] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterdochistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterDocHistoryPaginateOption
}

func newTrustCenterDocHistoryPaginateArgs(rv map[string]any) *trustcenterdochistoryPaginateArgs {
	args := &trustcenterdochistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterDocHistoryOrder{Field: &TrustCenterDocHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterDocHistoryOrder(order))
			}
		case *TrustCenterDocHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterDocHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterDocHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterDocHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterhistory.Columns))
		selectedFields = []string{trustcenterhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcenterhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldHistoryTime)
				fieldSeen[trustcenterhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcenterhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldRef)
				fieldSeen[trustcenterhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcenterhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldOperation)
				fieldSeen[trustcenterhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldCreatedAt)
				fieldSeen[trustcenterhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldUpdatedAt)
				fieldSeen[trustcenterhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldCreatedBy)
				fieldSeen[trustcenterhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldUpdatedBy)
				fieldSeen[trustcenterhistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenterhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldTags)
				fieldSeen[trustcenterhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenterhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldOwnerID)
				fieldSeen[trustcenterhistory.FieldOwnerID] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[trustcenterhistory.FieldSlug]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldSlug)
				fieldSeen[trustcenterhistory.FieldSlug] = struct{}{}
			}
		case "customDomainID":
			if _, ok := fieldSeen[trustcenterhistory.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldCustomDomainID)
				fieldSeen[trustcenterhistory.FieldCustomDomainID] = struct{}{}
			}
		case "previewDomainID":
			if _, ok := fieldSeen[trustcenterhistory.FieldPreviewDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldPreviewDomainID)
				fieldSeen[trustcenterhistory.FieldPreviewDomainID] = struct{}{}
			}
		case "pirschDomainID":
			if _, ok := fieldSeen[trustcenterhistory.FieldPirschDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldPirschDomainID)
				fieldSeen[trustcenterhistory.FieldPirschDomainID] = struct{}{}
			}
		case "pirschIdentificationCode":
			if _, ok := fieldSeen[trustcenterhistory.FieldPirschIdentificationCode]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldPirschIdentificationCode)
				fieldSeen[trustcenterhistory.FieldPirschIdentificationCode] = struct{}{}
			}
		case "previewStatus":
			if _, ok := fieldSeen[trustcenterhistory.FieldPreviewStatus]; !ok {
				selectedFields = append(selectedFields, trustcenterhistory.FieldPreviewStatus)
				fieldSeen[trustcenterhistory.FieldPreviewStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterHistoryPaginateOption
}

func newTrustCenterHistoryPaginateArgs(rv map[string]any) *trustcenterhistoryPaginateArgs {
	args := &trustcenterhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterHistoryOrder{Field: &TrustCenterHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterHistoryOrder(order))
			}
		case *TrustCenterHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersetting.Columns))
		selectedFields = []string{trustcentersetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenterSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(trustcentersetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(trustcentersetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(trustcentersetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(trustcentersetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(trustcentersetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenterSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcentersetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[trustcentersetting.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoLocalFileID)
				fieldSeen[trustcentersetting.FieldLogoLocalFileID] = struct{}{}
			}

		case "faviconFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFaviconFile = query
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconLocalFileID)
				fieldSeen[trustcentersetting.FieldFaviconLocalFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldCreatedAt)
				fieldSeen[trustcentersetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldUpdatedAt)
				fieldSeen[trustcentersetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldCreatedBy)
				fieldSeen[trustcentersetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldUpdatedBy)
				fieldSeen[trustcentersetting.FieldUpdatedBy] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersetting.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTrustCenterID)
				fieldSeen[trustcentersetting.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcentersetting.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTitle)
				fieldSeen[trustcentersetting.FieldTitle] = struct{}{}
			}
		case "overview":
			if _, ok := fieldSeen[trustcentersetting.FieldOverview]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldOverview)
				fieldSeen[trustcentersetting.FieldOverview] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[trustcentersetting.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoRemoteURL)
				fieldSeen[trustcentersetting.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[trustcentersetting.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoLocalFileID)
				fieldSeen[trustcentersetting.FieldLogoLocalFileID] = struct{}{}
			}
		case "faviconRemoteURL":
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconRemoteURL)
				fieldSeen[trustcentersetting.FieldFaviconRemoteURL] = struct{}{}
			}
		case "faviconLocalFileID":
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconLocalFileID)
				fieldSeen[trustcentersetting.FieldFaviconLocalFileID] = struct{}{}
			}
		case "themeMode":
			if _, ok := fieldSeen[trustcentersetting.FieldThemeMode]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldThemeMode)
				fieldSeen[trustcentersetting.FieldThemeMode] = struct{}{}
			}
		case "primaryColor":
			if _, ok := fieldSeen[trustcentersetting.FieldPrimaryColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldPrimaryColor)
				fieldSeen[trustcentersetting.FieldPrimaryColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcentersetting.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFont)
				fieldSeen[trustcentersetting.FieldFont] = struct{}{}
			}
		case "foregroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldForegroundColor)
				fieldSeen[trustcentersetting.FieldForegroundColor] = struct{}{}
			}
		case "backgroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldBackgroundColor)
				fieldSeen[trustcentersetting.FieldBackgroundColor] = struct{}{}
			}
		case "accentColor":
			if _, ok := fieldSeen[trustcentersetting.FieldAccentColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldAccentColor)
				fieldSeen[trustcentersetting.FieldAccentColor] = struct{}{}
			}
		case "secondaryBackgroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldSecondaryBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldSecondaryBackgroundColor)
				fieldSeen[trustcentersetting.FieldSecondaryBackgroundColor] = struct{}{}
			}
		case "secondaryForegroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldSecondaryForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldSecondaryForegroundColor)
				fieldSeen[trustcentersetting.FieldSecondaryForegroundColor] = struct{}{}
			}
		case "environment":
			if _, ok := fieldSeen[trustcentersetting.FieldEnvironment]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldEnvironment)
				fieldSeen[trustcentersetting.FieldEnvironment] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentersettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSettingPaginateOption
}

func newTrustCenterSettingPaginateArgs(rv map[string]any) *trustcentersettingPaginateArgs {
	args := &trustcentersettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterSettingOrder:
			args.opts = append(args.opts, WithTrustCenterSettingOrder(v))
		case []any:
			var orders []*TrustCenterSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterSettingOrder{Field: &TrustCenterSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSettingWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersettinghistory.Columns))
		selectedFields = []string{trustcentersettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldHistoryTime)
				fieldSeen[trustcentersettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldRef)
				fieldSeen[trustcentersettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldOperation)
				fieldSeen[trustcentersettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldCreatedAt)
				fieldSeen[trustcentersettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldUpdatedAt)
				fieldSeen[trustcentersettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldCreatedBy)
				fieldSeen[trustcentersettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldUpdatedBy)
				fieldSeen[trustcentersettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldTrustCenterID)
				fieldSeen[trustcentersettinghistory.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldTitle)
				fieldSeen[trustcentersettinghistory.FieldTitle] = struct{}{}
			}
		case "overview":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldOverview]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldOverview)
				fieldSeen[trustcentersettinghistory.FieldOverview] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldLogoRemoteURL)
				fieldSeen[trustcentersettinghistory.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldLogoLocalFileID)
				fieldSeen[trustcentersettinghistory.FieldLogoLocalFileID] = struct{}{}
			}
		case "faviconRemoteURL":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldFaviconRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldFaviconRemoteURL)
				fieldSeen[trustcentersettinghistory.FieldFaviconRemoteURL] = struct{}{}
			}
		case "faviconLocalFileID":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldFaviconLocalFileID)
				fieldSeen[trustcentersettinghistory.FieldFaviconLocalFileID] = struct{}{}
			}
		case "themeMode":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldThemeMode]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldThemeMode)
				fieldSeen[trustcentersettinghistory.FieldThemeMode] = struct{}{}
			}
		case "primaryColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldPrimaryColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldPrimaryColor)
				fieldSeen[trustcentersettinghistory.FieldPrimaryColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldFont)
				fieldSeen[trustcentersettinghistory.FieldFont] = struct{}{}
			}
		case "foregroundColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldForegroundColor)
				fieldSeen[trustcentersettinghistory.FieldForegroundColor] = struct{}{}
			}
		case "backgroundColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldBackgroundColor)
				fieldSeen[trustcentersettinghistory.FieldBackgroundColor] = struct{}{}
			}
		case "accentColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldAccentColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldAccentColor)
				fieldSeen[trustcentersettinghistory.FieldAccentColor] = struct{}{}
			}
		case "secondaryBackgroundColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldSecondaryBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldSecondaryBackgroundColor)
				fieldSeen[trustcentersettinghistory.FieldSecondaryBackgroundColor] = struct{}{}
			}
		case "secondaryForegroundColor":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldSecondaryForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldSecondaryForegroundColor)
				fieldSeen[trustcentersettinghistory.FieldSecondaryForegroundColor] = struct{}{}
			}
		case "environment":
			if _, ok := fieldSeen[trustcentersettinghistory.FieldEnvironment]; !ok {
				selectedFields = append(selectedFields, trustcentersettinghistory.FieldEnvironment)
				fieldSeen[trustcentersettinghistory.FieldEnvironment] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentersettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSettingHistoryPaginateOption
}

func newTrustCenterSettingHistoryPaginateArgs(rv map[string]any) *trustcentersettinghistoryPaginateArgs {
	args := &trustcentersettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterSettingHistoryOrder{Field: &TrustCenterSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterSettingHistoryOrder(order))
			}
		case *TrustCenterSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterSubprocessorQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSubprocessorQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterSubprocessorQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersubprocessor.Columns))
		selectedFields = []string{trustcentersubprocessor.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcentersubprocessor.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessor.FieldTrustCenterID] = struct{}{}
			}

		case "subprocessor":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
				return err
			}
			_q.withSubprocessor = query
			if _, ok := fieldSeen[trustcentersubprocessor.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessor.FieldSubprocessorID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCreatedAt)
				fieldSeen[trustcentersubprocessor.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldUpdatedAt)
				fieldSeen[trustcentersubprocessor.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCreatedBy)
				fieldSeen[trustcentersubprocessor.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldUpdatedBy)
				fieldSeen[trustcentersubprocessor.FieldUpdatedBy] = struct{}{}
			}
		case "subprocessorID":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessor.FieldSubprocessorID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessor.FieldTrustCenterID] = struct{}{}
			}
		case "countries":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCountries]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCountries)
				fieldSeen[trustcentersubprocessor.FieldCountries] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCategory)
				fieldSeen[trustcentersubprocessor.FieldCategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentersubprocessorPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSubprocessorPaginateOption
}

func newTrustCenterSubprocessorPaginateArgs(rv map[string]any) *trustcentersubprocessorPaginateArgs {
	args := &trustcentersubprocessorPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterSubprocessorOrder:
			args.opts = append(args.opts, WithTrustCenterSubprocessorOrder(v))
		case []any:
			var orders []*TrustCenterSubprocessorOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterSubprocessorOrder{Field: &TrustCenterSubprocessorOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterSubprocessorOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSubprocessorWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSubprocessorFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterSubprocessorHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSubprocessorHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterSubprocessorHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersubprocessorhistory.Columns))
		selectedFields = []string{trustcentersubprocessorhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldHistoryTime)
				fieldSeen[trustcentersubprocessorhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldRef)
				fieldSeen[trustcentersubprocessorhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldOperation)
				fieldSeen[trustcentersubprocessorhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCreatedAt)
				fieldSeen[trustcentersubprocessorhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldUpdatedAt)
				fieldSeen[trustcentersubprocessorhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCreatedBy)
				fieldSeen[trustcentersubprocessorhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldUpdatedBy)
				fieldSeen[trustcentersubprocessorhistory.FieldUpdatedBy] = struct{}{}
			}
		case "subprocessorID":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessorhistory.FieldSubprocessorID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessorhistory.FieldTrustCenterID] = struct{}{}
			}
		case "countries":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCountries]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCountries)
				fieldSeen[trustcentersubprocessorhistory.FieldCountries] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcentersubprocessorhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessorhistory.FieldCategory)
				fieldSeen[trustcentersubprocessorhistory.FieldCategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentersubprocessorhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSubprocessorHistoryPaginateOption
}

func newTrustCenterSubprocessorHistoryPaginateArgs(rv map[string]any) *trustcentersubprocessorhistoryPaginateArgs {
	args := &trustcentersubprocessorhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterSubprocessorHistoryOrder{Field: &TrustCenterSubprocessorHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterSubprocessorHistoryOrder(order))
			}
		case *TrustCenterSubprocessorHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterSubprocessorHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSubprocessorHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSubprocessorHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterWatermarkConfigQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterWatermarkConfigQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterWatermarkConfigQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterwatermarkconfig.Columns))
		selectedFields = []string{trustcenterwatermarkconfig.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldOwnerID)
				fieldSeen[trustcenterwatermarkconfig.FieldOwnerID] = struct{}{}
			}

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTrustCenter(alias, func(wq *TrustCenterQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldLogoID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldLogoID)
				fieldSeen[trustcenterwatermarkconfig.FieldLogoID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldCreatedAt)
				fieldSeen[trustcenterwatermarkconfig.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldUpdatedAt)
				fieldSeen[trustcenterwatermarkconfig.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldCreatedBy)
				fieldSeen[trustcenterwatermarkconfig.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldUpdatedBy)
				fieldSeen[trustcenterwatermarkconfig.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldOwnerID)
				fieldSeen[trustcenterwatermarkconfig.FieldOwnerID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldTrustCenterID)
				fieldSeen[trustcenterwatermarkconfig.FieldTrustCenterID] = struct{}{}
			}
		case "isEnabled":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldIsEnabled]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldIsEnabled)
				fieldSeen[trustcenterwatermarkconfig.FieldIsEnabled] = struct{}{}
			}
		case "logoID":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldLogoID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldLogoID)
				fieldSeen[trustcenterwatermarkconfig.FieldLogoID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldText]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldText)
				fieldSeen[trustcenterwatermarkconfig.FieldText] = struct{}{}
			}
		case "fontSize":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldFontSize]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldFontSize)
				fieldSeen[trustcenterwatermarkconfig.FieldFontSize] = struct{}{}
			}
		case "opacity":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldOpacity]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldOpacity)
				fieldSeen[trustcenterwatermarkconfig.FieldOpacity] = struct{}{}
			}
		case "rotation":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldRotation]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldRotation)
				fieldSeen[trustcenterwatermarkconfig.FieldRotation] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldColor]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldColor)
				fieldSeen[trustcenterwatermarkconfig.FieldColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldFont)
				fieldSeen[trustcenterwatermarkconfig.FieldFont] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterwatermarkconfigPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterWatermarkConfigPaginateOption
}

func newTrustCenterWatermarkConfigPaginateArgs(rv map[string]any) *trustcenterwatermarkconfigPaginateArgs {
	args := &trustcenterwatermarkconfigPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterWatermarkConfigOrder:
			args.opts = append(args.opts, WithTrustCenterWatermarkConfigOrder(v))
		case []any:
			var orders []*TrustCenterWatermarkConfigOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterWatermarkConfigOrder{Field: &TrustCenterWatermarkConfigOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterWatermarkConfigOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterWatermarkConfigWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterWatermarkConfigFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterWatermarkConfigHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterWatermarkConfigHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterWatermarkConfigHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterwatermarkconfighistory.Columns))
		selectedFields = []string{trustcenterwatermarkconfighistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldHistoryTime)
				fieldSeen[trustcenterwatermarkconfighistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldRef)
				fieldSeen[trustcenterwatermarkconfighistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldOperation)
				fieldSeen[trustcenterwatermarkconfighistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldCreatedAt)
				fieldSeen[trustcenterwatermarkconfighistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldUpdatedAt)
				fieldSeen[trustcenterwatermarkconfighistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldCreatedBy)
				fieldSeen[trustcenterwatermarkconfighistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldUpdatedBy)
				fieldSeen[trustcenterwatermarkconfighistory.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldOwnerID)
				fieldSeen[trustcenterwatermarkconfighistory.FieldOwnerID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldTrustCenterID)
				fieldSeen[trustcenterwatermarkconfighistory.FieldTrustCenterID] = struct{}{}
			}
		case "isEnabled":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldIsEnabled]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldIsEnabled)
				fieldSeen[trustcenterwatermarkconfighistory.FieldIsEnabled] = struct{}{}
			}
		case "logoID":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldLogoID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldLogoID)
				fieldSeen[trustcenterwatermarkconfighistory.FieldLogoID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldText]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldText)
				fieldSeen[trustcenterwatermarkconfighistory.FieldText] = struct{}{}
			}
		case "fontSize":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldFontSize]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldFontSize)
				fieldSeen[trustcenterwatermarkconfighistory.FieldFontSize] = struct{}{}
			}
		case "opacity":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldOpacity]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldOpacity)
				fieldSeen[trustcenterwatermarkconfighistory.FieldOpacity] = struct{}{}
			}
		case "rotation":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldRotation]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldRotation)
				fieldSeen[trustcenterwatermarkconfighistory.FieldRotation] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldColor]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldColor)
				fieldSeen[trustcenterwatermarkconfighistory.FieldColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcenterwatermarkconfighistory.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfighistory.FieldFont)
				fieldSeen[trustcenterwatermarkconfighistory.FieldFont] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterwatermarkconfighistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterWatermarkConfigHistoryPaginateOption
}

func newTrustCenterWatermarkConfigHistoryPaginateArgs(rv map[string]any) *trustcenterwatermarkconfighistoryPaginateArgs {
	args := &trustcenterwatermarkconfighistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustCenterWatermarkConfigHistoryOrder{Field: &TrustCenterWatermarkConfigHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustCenterWatermarkConfigHistoryOrder(order))
			}
		case *TrustCenterWatermarkConfigHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustCenterWatermarkConfigHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustCenterWatermarkConfigHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterWatermarkConfigHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustcenterEntityQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustcenterEntityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustcenterEntityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterentity.Columns))
		selectedFields = []string{trustcenterentity.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[trustcenterentity.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldLogoFileID)
				fieldSeen[trustcenterentity.FieldLogoFileID] = struct{}{}
			}

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcenterentity.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldTrustCenterID)
				fieldSeen[trustcenterentity.FieldTrustCenterID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustcenterEntity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trustcenter_entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(trustcenterentity.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(trustcenterentity.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(trustcenterentity.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(trustcenterentity.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(trustcenterentity.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustcenterEntity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenterentity.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[trustcenterentity.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldCreatedAt)
				fieldSeen[trustcenterentity.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterentity.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldUpdatedAt)
				fieldSeen[trustcenterentity.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterentity.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldCreatedBy)
				fieldSeen[trustcenterentity.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterentity.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldUpdatedBy)
				fieldSeen[trustcenterentity.FieldUpdatedBy] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[trustcenterentity.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldLogoFileID)
				fieldSeen[trustcenterentity.FieldLogoFileID] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[trustcenterentity.FieldURL]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldURL)
				fieldSeen[trustcenterentity.FieldURL] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterentity.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldTrustCenterID)
				fieldSeen[trustcenterentity.FieldTrustCenterID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[trustcenterentity.FieldName]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldName)
				fieldSeen[trustcenterentity.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterentityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustcenterEntityPaginateOption
}

func newTrustcenterEntityPaginateArgs(rv map[string]any) *trustcenterentityPaginateArgs {
	args := &trustcenterentityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustcenterEntityOrder:
			args.opts = append(args.opts, WithTrustcenterEntityOrder(v))
		case []any:
			var orders []*TrustcenterEntityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustcenterEntityOrder{Field: &TrustcenterEntityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustcenterEntityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustcenterEntityWhereInput); ok {
		args.opts = append(args.opts, WithTrustcenterEntityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustcenterEntityHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustcenterEntityHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustcenterEntityHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterentityhistory.Columns))
		selectedFields = []string{trustcenterentityhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldHistoryTime)
				fieldSeen[trustcenterentityhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldRef)
				fieldSeen[trustcenterentityhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldOperation)
				fieldSeen[trustcenterentityhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldCreatedAt)
				fieldSeen[trustcenterentityhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldUpdatedAt)
				fieldSeen[trustcenterentityhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldCreatedBy)
				fieldSeen[trustcenterentityhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldUpdatedBy)
				fieldSeen[trustcenterentityhistory.FieldUpdatedBy] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldLogoFileID)
				fieldSeen[trustcenterentityhistory.FieldLogoFileID] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldURL]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldURL)
				fieldSeen[trustcenterentityhistory.FieldURL] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldTrustCenterID)
				fieldSeen[trustcenterentityhistory.FieldTrustCenterID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[trustcenterentityhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, trustcenterentityhistory.FieldName)
				fieldSeen[trustcenterentityhistory.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterentityhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustcenterEntityHistoryPaginateOption
}

func newTrustcenterEntityHistoryPaginateArgs(rv map[string]any) *trustcenterentityhistoryPaginateArgs {
	args := &trustcenterentityhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TrustcenterEntityHistoryOrder{Field: &TrustcenterEntityHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTrustcenterEntityHistoryOrder(order))
			}
		case *TrustcenterEntityHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithTrustcenterEntityHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TrustcenterEntityHistoryWhereInput); ok {
		args.opts = append(args.opts, WithTrustcenterEntityHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(user.Columns))
		selectedFields = []string{user.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: _q.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.PersonalAccessTokensColumn), ids...))
						})
						if err := query.GroupBy(user.PersonalAccessTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.PersonalAccessTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "tfaSettings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TFASettingClient{config: _q.config}).Query()
			)
			args := newTFASettingPaginateArgs(fieldArgs(ctx, new(TFASettingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTFASettingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.TfaSettingsColumn), ids...))
						})
						if err := query.GroupBy(user.TfaSettingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TfaSettings)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tfasettingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.TfaSettingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTfaSettings(alias, func(wq *TFASettingQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, usersettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(user.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(user.OrganizationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.OrganizationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.OrganizationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.OrganizationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.OrganizationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "webauthns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WebauthnClient{config: _q.config}).Query()
			)
			args := newWebauthnPaginateArgs(fieldArgs(ctx, new(WebauthnWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWebauthnPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.WebauthnsColumn), ids...))
						})
						if err := query.GroupBy(user.WebauthnsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Webauthns)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, webauthnImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.WebauthnsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWebauthns(alias, func(wq *WebauthnQuery) {
				*wq = *query
			})

		case "avatarFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withAvatarFile = query
			if _, ok := fieldSeen[user.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarLocalFileID)
				fieldSeen[user.FieldAvatarLocalFileID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(user.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(user.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(user.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "assignerTasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assigner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.AssignerTasksColumn), ids...))
						})
						if err := query.GroupBy(user.AssignerTasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssignerTasks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.AssignerTasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssignerTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "assigneeTasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assignee_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.AssigneeTasksColumn), ids...))
						})
						if err := query.GroupBy(user.AssigneeTasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssigneeTasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.AssigneeTasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssigneeTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(user.ProgramsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.ProgramsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.ProgramsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.ProgramsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programsOwned":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ProgramsOwnedColumn), ids...))
						})
						if err := query.GroupBy(user.ProgramsOwnedColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramsOwned)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramsOwnedColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramsOwned(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "groupMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: _q.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.GroupMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.GroupMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupMemberships)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.GroupMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroupMemberships(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})

		case "orgMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: _q.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.OrgMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.OrgMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgMemberships)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.OrgMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrgMemberships(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})

		case "programMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramMembershipClient{config: _q.config}).Query()
			)
			args := newProgramMembershipPaginateArgs(fieldArgs(ctx, new(ProgramMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ProgramMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.ProgramMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramMemberships)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramMemberships(alias, func(wq *ProgramMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[user.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedAt)
				fieldSeen[user.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[user.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedAt)
				fieldSeen[user.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[user.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedBy)
				fieldSeen[user.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[user.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedBy)
				fieldSeen[user.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[user.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, user.FieldDisplayID)
				fieldSeen[user.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[user.FieldTags]; !ok {
				selectedFields = append(selectedFields, user.FieldTags)
				fieldSeen[user.FieldTags] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[user.FieldEmail]; !ok {
				selectedFields = append(selectedFields, user.FieldEmail)
				fieldSeen[user.FieldEmail] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[user.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, user.FieldFirstName)
				fieldSeen[user.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[user.FieldLastName]; !ok {
				selectedFields = append(selectedFields, user.FieldLastName)
				fieldSeen[user.FieldLastName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[user.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, user.FieldDisplayName)
				fieldSeen[user.FieldDisplayName] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[user.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarRemoteURL)
				fieldSeen[user.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[user.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarLocalFileID)
				fieldSeen[user.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[user.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarUpdatedAt)
				fieldSeen[user.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[user.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, user.FieldLastSeen)
				fieldSeen[user.FieldLastSeen] = struct{}{}
			}
		case "lastLoginProvider":
			if _, ok := fieldSeen[user.FieldLastLoginProvider]; !ok {
				selectedFields = append(selectedFields, user.FieldLastLoginProvider)
				fieldSeen[user.FieldLastLoginProvider] = struct{}{}
			}
		case "sub":
			if _, ok := fieldSeen[user.FieldSub]; !ok {
				selectedFields = append(selectedFields, user.FieldSub)
				fieldSeen[user.FieldSub] = struct{}{}
			}
		case "authProvider":
			if _, ok := fieldSeen[user.FieldAuthProvider]; !ok {
				selectedFields = append(selectedFields, user.FieldAuthProvider)
				fieldSeen[user.FieldAuthProvider] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[user.FieldRole]; !ok {
				selectedFields = append(selectedFields, user.FieldRole)
				fieldSeen[user.FieldRole] = struct{}{}
			}
		case "scimExternalID":
			if _, ok := fieldSeen[user.FieldScimExternalID]; !ok {
				selectedFields = append(selectedFields, user.FieldScimExternalID)
				fieldSeen[user.FieldScimExternalID] = struct{}{}
			}
		case "scimUsername":
			if _, ok := fieldSeen[user.FieldScimUsername]; !ok {
				selectedFields = append(selectedFields, user.FieldScimUsername)
				fieldSeen[user.FieldScimUsername] = struct{}{}
			}
		case "scimActive":
			if _, ok := fieldSeen[user.FieldScimActive]; !ok {
				selectedFields = append(selectedFields, user.FieldScimActive)
				fieldSeen[user.FieldScimActive] = struct{}{}
			}
		case "scimPreferredLanguage":
			if _, ok := fieldSeen[user.FieldScimPreferredLanguage]; !ok {
				selectedFields = append(selectedFields, user.FieldScimPreferredLanguage)
				fieldSeen[user.FieldScimPreferredLanguage] = struct{}{}
			}
		case "scimLocale":
			if _, ok := fieldSeen[user.FieldScimLocale]; !ok {
				selectedFields = append(selectedFields, user.FieldScimLocale)
				fieldSeen[user.FieldScimLocale] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type userPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserPaginateOption
}

func newUserPaginateArgs(rv map[string]any) *userPaginateArgs {
	args := &userPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserOrder:
			args.opts = append(args.opts, WithUserOrder(v))
		case []any:
			var orders []*UserOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserOrder{Field: &UserOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserWhereInput); ok {
		args.opts = append(args.opts, WithUserFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(userhistory.Columns))
		selectedFields = []string{userhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[userhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldHistoryTime)
				fieldSeen[userhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[userhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldRef)
				fieldSeen[userhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[userhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldOperation)
				fieldSeen[userhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[userhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldCreatedAt)
				fieldSeen[userhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[userhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldUpdatedAt)
				fieldSeen[userhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[userhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldCreatedBy)
				fieldSeen[userhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[userhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldUpdatedBy)
				fieldSeen[userhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[userhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldDisplayID)
				fieldSeen[userhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[userhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldTags)
				fieldSeen[userhistory.FieldTags] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[userhistory.FieldEmail]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldEmail)
				fieldSeen[userhistory.FieldEmail] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[userhistory.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldFirstName)
				fieldSeen[userhistory.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[userhistory.FieldLastName]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldLastName)
				fieldSeen[userhistory.FieldLastName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[userhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldDisplayName)
				fieldSeen[userhistory.FieldDisplayName] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[userhistory.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAvatarRemoteURL)
				fieldSeen[userhistory.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[userhistory.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAvatarLocalFileID)
				fieldSeen[userhistory.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[userhistory.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAvatarUpdatedAt)
				fieldSeen[userhistory.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[userhistory.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldLastSeen)
				fieldSeen[userhistory.FieldLastSeen] = struct{}{}
			}
		case "lastLoginProvider":
			if _, ok := fieldSeen[userhistory.FieldLastLoginProvider]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldLastLoginProvider)
				fieldSeen[userhistory.FieldLastLoginProvider] = struct{}{}
			}
		case "sub":
			if _, ok := fieldSeen[userhistory.FieldSub]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldSub)
				fieldSeen[userhistory.FieldSub] = struct{}{}
			}
		case "authProvider":
			if _, ok := fieldSeen[userhistory.FieldAuthProvider]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldAuthProvider)
				fieldSeen[userhistory.FieldAuthProvider] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[userhistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldRole)
				fieldSeen[userhistory.FieldRole] = struct{}{}
			}
		case "scimExternalID":
			if _, ok := fieldSeen[userhistory.FieldScimExternalID]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldScimExternalID)
				fieldSeen[userhistory.FieldScimExternalID] = struct{}{}
			}
		case "scimUsername":
			if _, ok := fieldSeen[userhistory.FieldScimUsername]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldScimUsername)
				fieldSeen[userhistory.FieldScimUsername] = struct{}{}
			}
		case "scimActive":
			if _, ok := fieldSeen[userhistory.FieldScimActive]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldScimActive)
				fieldSeen[userhistory.FieldScimActive] = struct{}{}
			}
		case "scimPreferredLanguage":
			if _, ok := fieldSeen[userhistory.FieldScimPreferredLanguage]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldScimPreferredLanguage)
				fieldSeen[userhistory.FieldScimPreferredLanguage] = struct{}{}
			}
		case "scimLocale":
			if _, ok := fieldSeen[userhistory.FieldScimLocale]; !ok {
				selectedFields = append(selectedFields, userhistory.FieldScimLocale)
				fieldSeen[userhistory.FieldScimLocale] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type userhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserHistoryPaginateOption
}

func newUserHistoryPaginateArgs(rv map[string]any) *userhistoryPaginateArgs {
	args := &userhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserHistoryOrder{Field: &UserHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserHistoryOrder(order))
			}
		case *UserHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserHistoryWhereInput); ok {
		args.opts = append(args.opts, WithUserHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usersetting.Columns))
		selectedFields = []string{usersetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[usersetting.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUserID)
				fieldSeen[usersetting.FieldUserID] = struct{}{}
			}

		case "defaultOrg":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withDefaultOrg = query
		case "createdAt":
			if _, ok := fieldSeen[usersetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldCreatedAt)
				fieldSeen[usersetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usersetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUpdatedAt)
				fieldSeen[usersetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[usersetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldCreatedBy)
				fieldSeen[usersetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[usersetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUpdatedBy)
				fieldSeen[usersetting.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[usersetting.FieldTags]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldTags)
				fieldSeen[usersetting.FieldTags] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[usersetting.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUserID)
				fieldSeen[usersetting.FieldUserID] = struct{}{}
			}
		case "locked":
			if _, ok := fieldSeen[usersetting.FieldLocked]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldLocked)
				fieldSeen[usersetting.FieldLocked] = struct{}{}
			}
		case "silencedAt":
			if _, ok := fieldSeen[usersetting.FieldSilencedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldSilencedAt)
				fieldSeen[usersetting.FieldSilencedAt] = struct{}{}
			}
		case "suspendedAt":
			if _, ok := fieldSeen[usersetting.FieldSuspendedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldSuspendedAt)
				fieldSeen[usersetting.FieldSuspendedAt] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[usersetting.FieldStatus]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldStatus)
				fieldSeen[usersetting.FieldStatus] = struct{}{}
			}
		case "emailConfirmed":
			if _, ok := fieldSeen[usersetting.FieldEmailConfirmed]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldEmailConfirmed)
				fieldSeen[usersetting.FieldEmailConfirmed] = struct{}{}
			}
		case "isWebauthnAllowed":
			if _, ok := fieldSeen[usersetting.FieldIsWebauthnAllowed]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldIsWebauthnAllowed)
				fieldSeen[usersetting.FieldIsWebauthnAllowed] = struct{}{}
			}
		case "isTfaEnabled":
			if _, ok := fieldSeen[usersetting.FieldIsTfaEnabled]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldIsTfaEnabled)
				fieldSeen[usersetting.FieldIsTfaEnabled] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type usersettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserSettingPaginateOption
}

func newUserSettingPaginateArgs(rv map[string]any) *usersettingPaginateArgs {
	args := &usersettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserSettingOrder:
			args.opts = append(args.opts, WithUserSettingOrder(v))
		case []any:
			var orders []*UserSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserSettingOrder{Field: &UserSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserSettingWhereInput); ok {
		args.opts = append(args.opts, WithUserSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserSettingHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserSettingHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserSettingHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usersettinghistory.Columns))
		selectedFields = []string{usersettinghistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[usersettinghistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldHistoryTime)
				fieldSeen[usersettinghistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[usersettinghistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldRef)
				fieldSeen[usersettinghistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[usersettinghistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldOperation)
				fieldSeen[usersettinghistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[usersettinghistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldCreatedAt)
				fieldSeen[usersettinghistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usersettinghistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldUpdatedAt)
				fieldSeen[usersettinghistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[usersettinghistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldCreatedBy)
				fieldSeen[usersettinghistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[usersettinghistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldUpdatedBy)
				fieldSeen[usersettinghistory.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[usersettinghistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldTags)
				fieldSeen[usersettinghistory.FieldTags] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[usersettinghistory.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldUserID)
				fieldSeen[usersettinghistory.FieldUserID] = struct{}{}
			}
		case "locked":
			if _, ok := fieldSeen[usersettinghistory.FieldLocked]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldLocked)
				fieldSeen[usersettinghistory.FieldLocked] = struct{}{}
			}
		case "silencedAt":
			if _, ok := fieldSeen[usersettinghistory.FieldSilencedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldSilencedAt)
				fieldSeen[usersettinghistory.FieldSilencedAt] = struct{}{}
			}
		case "suspendedAt":
			if _, ok := fieldSeen[usersettinghistory.FieldSuspendedAt]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldSuspendedAt)
				fieldSeen[usersettinghistory.FieldSuspendedAt] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[usersettinghistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldStatus)
				fieldSeen[usersettinghistory.FieldStatus] = struct{}{}
			}
		case "emailConfirmed":
			if _, ok := fieldSeen[usersettinghistory.FieldEmailConfirmed]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldEmailConfirmed)
				fieldSeen[usersettinghistory.FieldEmailConfirmed] = struct{}{}
			}
		case "isWebauthnAllowed":
			if _, ok := fieldSeen[usersettinghistory.FieldIsWebauthnAllowed]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldIsWebauthnAllowed)
				fieldSeen[usersettinghistory.FieldIsWebauthnAllowed] = struct{}{}
			}
		case "isTfaEnabled":
			if _, ok := fieldSeen[usersettinghistory.FieldIsTfaEnabled]; !ok {
				selectedFields = append(selectedFields, usersettinghistory.FieldIsTfaEnabled)
				fieldSeen[usersettinghistory.FieldIsTfaEnabled] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type usersettinghistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserSettingHistoryPaginateOption
}

func newUserSettingHistoryPaginateArgs(rv map[string]any) *usersettinghistoryPaginateArgs {
	args := &usersettinghistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserSettingHistoryOrder{Field: &UserSettingHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserSettingHistoryOrder(order))
			}
		case *UserSettingHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserSettingHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserSettingHistoryWhereInput); ok {
		args.opts = append(args.opts, WithUserSettingHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *VulnerabilityQuery) CollectFields(ctx context.Context, satisfies ...string) (*VulnerabilityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *VulnerabilityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(vulnerability.Columns))
		selectedFields = []string{vulnerability.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[vulnerability.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldOwnerID)
				fieldSeen[vulnerability.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.EditorsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ViewersColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(vulnerability.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(vulnerability.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(vulnerability.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(vulnerability.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(vulnerability.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_findings"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.FindingsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(vulnerability.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(vulnerability.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(vulnerability.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(vulnerability.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(vulnerability.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ControlsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.RisksColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.AssetsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ScansColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.TasksColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_remediations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_reviews"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.CommentsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.FilesColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[vulnerability.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCreatedAt)
				fieldSeen[vulnerability.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[vulnerability.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldUpdatedAt)
				fieldSeen[vulnerability.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[vulnerability.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCreatedBy)
				fieldSeen[vulnerability.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[vulnerability.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldUpdatedBy)
				fieldSeen[vulnerability.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[vulnerability.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDisplayID)
				fieldSeen[vulnerability.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[vulnerability.FieldTags]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldTags)
				fieldSeen[vulnerability.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[vulnerability.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldOwnerID)
				fieldSeen[vulnerability.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[vulnerability.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSystemOwned)
				fieldSeen[vulnerability.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[vulnerability.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldInternalNotes)
				fieldSeen[vulnerability.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[vulnerability.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSystemInternalID)
				fieldSeen[vulnerability.FieldSystemInternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[vulnerability.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExternalOwnerID)
				fieldSeen[vulnerability.FieldExternalOwnerID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[vulnerability.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExternalID)
				fieldSeen[vulnerability.FieldExternalID] = struct{}{}
			}
		case "cveID":
			if _, ok := fieldSeen[vulnerability.FieldCveID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCveID)
				fieldSeen[vulnerability.FieldCveID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[vulnerability.FieldSource]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSource)
				fieldSeen[vulnerability.FieldSource] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[vulnerability.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDisplayName)
				fieldSeen[vulnerability.FieldDisplayName] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[vulnerability.FieldCategory]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCategory)
				fieldSeen[vulnerability.FieldCategory] = struct{}{}
			}
		case "severity":
			if _, ok := fieldSeen[vulnerability.FieldSeverity]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSeverity)
				fieldSeen[vulnerability.FieldSeverity] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[vulnerability.FieldScore]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldScore)
				fieldSeen[vulnerability.FieldScore] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[vulnerability.FieldImpact]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldImpact)
				fieldSeen[vulnerability.FieldImpact] = struct{}{}
			}
		case "exploitability":
			if _, ok := fieldSeen[vulnerability.FieldExploitability]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExploitability)
				fieldSeen[vulnerability.FieldExploitability] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[vulnerability.FieldPriority]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldPriority)
				fieldSeen[vulnerability.FieldPriority] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[vulnerability.FieldStatus]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldStatus)
				fieldSeen[vulnerability.FieldStatus] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[vulnerability.FieldSummary]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSummary)
				fieldSeen[vulnerability.FieldSummary] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[vulnerability.FieldDescription]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDescription)
				fieldSeen[vulnerability.FieldDescription] = struct{}{}
			}
		case "vector":
			if _, ok := fieldSeen[vulnerability.FieldVector]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldVector)
				fieldSeen[vulnerability.FieldVector] = struct{}{}
			}
		case "remediationSLA":
			if _, ok := fieldSeen[vulnerability.FieldRemediationSLA]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldRemediationSLA)
				fieldSeen[vulnerability.FieldRemediationSLA] = struct{}{}
			}
		case "open":
			if _, ok := fieldSeen[vulnerability.FieldOpen]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldOpen)
				fieldSeen[vulnerability.FieldOpen] = struct{}{}
			}
		case "blocking":
			if _, ok := fieldSeen[vulnerability.FieldBlocking]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldBlocking)
				fieldSeen[vulnerability.FieldBlocking] = struct{}{}
			}
		case "production":
			if _, ok := fieldSeen[vulnerability.FieldProduction]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldProduction)
				fieldSeen[vulnerability.FieldProduction] = struct{}{}
			}
		case "public":
			if _, ok := fieldSeen[vulnerability.FieldPublic]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldPublic)
				fieldSeen[vulnerability.FieldPublic] = struct{}{}
			}
		case "validated":
			if _, ok := fieldSeen[vulnerability.FieldValidated]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldValidated)
				fieldSeen[vulnerability.FieldValidated] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[vulnerability.FieldReferences]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldReferences)
				fieldSeen[vulnerability.FieldReferences] = struct{}{}
			}
		case "impacts":
			if _, ok := fieldSeen[vulnerability.FieldImpacts]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldImpacts)
				fieldSeen[vulnerability.FieldImpacts] = struct{}{}
			}
		case "publishedAt":
			if _, ok := fieldSeen[vulnerability.FieldPublishedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldPublishedAt)
				fieldSeen[vulnerability.FieldPublishedAt] = struct{}{}
			}
		case "discoveredAt":
			if _, ok := fieldSeen[vulnerability.FieldDiscoveredAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDiscoveredAt)
				fieldSeen[vulnerability.FieldDiscoveredAt] = struct{}{}
			}
		case "sourceUpdatedAt":
			if _, ok := fieldSeen[vulnerability.FieldSourceUpdatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSourceUpdatedAt)
				fieldSeen[vulnerability.FieldSourceUpdatedAt] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[vulnerability.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExternalURI)
				fieldSeen[vulnerability.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[vulnerability.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldMetadata)
				fieldSeen[vulnerability.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[vulnerability.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldRawPayload)
				fieldSeen[vulnerability.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type vulnerabilityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []VulnerabilityPaginateOption
}

func newVulnerabilityPaginateArgs(rv map[string]any) *vulnerabilityPaginateArgs {
	args := &vulnerabilityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*VulnerabilityOrder:
			args.opts = append(args.opts, WithVulnerabilityOrder(v))
		case []any:
			var orders []*VulnerabilityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &VulnerabilityOrder{Field: &VulnerabilityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithVulnerabilityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*VulnerabilityWhereInput); ok {
		args.opts = append(args.opts, WithVulnerabilityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *VulnerabilityHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*VulnerabilityHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *VulnerabilityHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(vulnerabilityhistory.Columns))
		selectedFields = []string{vulnerabilityhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldHistoryTime)
				fieldSeen[vulnerabilityhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldRef)
				fieldSeen[vulnerabilityhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldOperation)
				fieldSeen[vulnerabilityhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldCreatedAt)
				fieldSeen[vulnerabilityhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldUpdatedAt)
				fieldSeen[vulnerabilityhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldCreatedBy)
				fieldSeen[vulnerabilityhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldUpdatedBy)
				fieldSeen[vulnerabilityhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldDisplayID)
				fieldSeen[vulnerabilityhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldTags)
				fieldSeen[vulnerabilityhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldOwnerID)
				fieldSeen[vulnerabilityhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldSystemOwned)
				fieldSeen[vulnerabilityhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldInternalNotes)
				fieldSeen[vulnerabilityhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldSystemInternalID)
				fieldSeen[vulnerabilityhistory.FieldSystemInternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldExternalOwnerID)
				fieldSeen[vulnerabilityhistory.FieldExternalOwnerID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldExternalID)
				fieldSeen[vulnerabilityhistory.FieldExternalID] = struct{}{}
			}
		case "cveID":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldCveID]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldCveID)
				fieldSeen[vulnerabilityhistory.FieldCveID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldSource]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldSource)
				fieldSeen[vulnerabilityhistory.FieldSource] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldDisplayName)
				fieldSeen[vulnerabilityhistory.FieldDisplayName] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldCategory]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldCategory)
				fieldSeen[vulnerabilityhistory.FieldCategory] = struct{}{}
			}
		case "severity":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldSeverity]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldSeverity)
				fieldSeen[vulnerabilityhistory.FieldSeverity] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldScore]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldScore)
				fieldSeen[vulnerabilityhistory.FieldScore] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldImpact]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldImpact)
				fieldSeen[vulnerabilityhistory.FieldImpact] = struct{}{}
			}
		case "exploitability":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldExploitability]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldExploitability)
				fieldSeen[vulnerabilityhistory.FieldExploitability] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldPriority]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldPriority)
				fieldSeen[vulnerabilityhistory.FieldPriority] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldStatus)
				fieldSeen[vulnerabilityhistory.FieldStatus] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldSummary]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldSummary)
				fieldSeen[vulnerabilityhistory.FieldSummary] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldDescription)
				fieldSeen[vulnerabilityhistory.FieldDescription] = struct{}{}
			}
		case "vector":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldVector]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldVector)
				fieldSeen[vulnerabilityhistory.FieldVector] = struct{}{}
			}
		case "remediationSLA":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldRemediationSLA]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldRemediationSLA)
				fieldSeen[vulnerabilityhistory.FieldRemediationSLA] = struct{}{}
			}
		case "open":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldOpen]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldOpen)
				fieldSeen[vulnerabilityhistory.FieldOpen] = struct{}{}
			}
		case "blocking":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldBlocking]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldBlocking)
				fieldSeen[vulnerabilityhistory.FieldBlocking] = struct{}{}
			}
		case "production":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldProduction]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldProduction)
				fieldSeen[vulnerabilityhistory.FieldProduction] = struct{}{}
			}
		case "public":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldPublic]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldPublic)
				fieldSeen[vulnerabilityhistory.FieldPublic] = struct{}{}
			}
		case "validated":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldValidated]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldValidated)
				fieldSeen[vulnerabilityhistory.FieldValidated] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldReferences]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldReferences)
				fieldSeen[vulnerabilityhistory.FieldReferences] = struct{}{}
			}
		case "impacts":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldImpacts]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldImpacts)
				fieldSeen[vulnerabilityhistory.FieldImpacts] = struct{}{}
			}
		case "publishedAt":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldPublishedAt]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldPublishedAt)
				fieldSeen[vulnerabilityhistory.FieldPublishedAt] = struct{}{}
			}
		case "discoveredAt":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldDiscoveredAt]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldDiscoveredAt)
				fieldSeen[vulnerabilityhistory.FieldDiscoveredAt] = struct{}{}
			}
		case "sourceUpdatedAt":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldSourceUpdatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldSourceUpdatedAt)
				fieldSeen[vulnerabilityhistory.FieldSourceUpdatedAt] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldExternalURI)
				fieldSeen[vulnerabilityhistory.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldMetadata)
				fieldSeen[vulnerabilityhistory.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[vulnerabilityhistory.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, vulnerabilityhistory.FieldRawPayload)
				fieldSeen[vulnerabilityhistory.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type vulnerabilityhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []VulnerabilityHistoryPaginateOption
}

func newVulnerabilityHistoryPaginateArgs(rv map[string]any) *vulnerabilityhistoryPaginateArgs {
	args := &vulnerabilityhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &VulnerabilityHistoryOrder{Field: &VulnerabilityHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithVulnerabilityHistoryOrder(order))
			}
		case *VulnerabilityHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithVulnerabilityHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*VulnerabilityHistoryWhereInput); ok {
		args.opts = append(args.opts, WithVulnerabilityHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WebauthnQuery) CollectFields(ctx context.Context, satisfies ...string) (*WebauthnQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WebauthnQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(webauthn.Columns))
		selectedFields = []string{webauthn.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[webauthn.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldOwnerID)
				fieldSeen[webauthn.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[webauthn.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldCreatedAt)
				fieldSeen[webauthn.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[webauthn.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldUpdatedAt)
				fieldSeen[webauthn.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[webauthn.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldCreatedBy)
				fieldSeen[webauthn.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[webauthn.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldUpdatedBy)
				fieldSeen[webauthn.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[webauthn.FieldTags]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldTags)
				fieldSeen[webauthn.FieldTags] = struct{}{}
			}
		case "aaguid":
			if _, ok := fieldSeen[webauthn.FieldAaguid]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldAaguid)
				fieldSeen[webauthn.FieldAaguid] = struct{}{}
			}
		case "backupEligible":
			if _, ok := fieldSeen[webauthn.FieldBackupEligible]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldBackupEligible)
				fieldSeen[webauthn.FieldBackupEligible] = struct{}{}
			}
		case "backupState":
			if _, ok := fieldSeen[webauthn.FieldBackupState]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldBackupState)
				fieldSeen[webauthn.FieldBackupState] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type webauthnPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WebauthnPaginateOption
}

func newWebauthnPaginateArgs(rv map[string]any) *webauthnPaginateArgs {
	args := &webauthnPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WebauthnOrder{Field: &WebauthnOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWebauthnOrder(order))
			}
		case *WebauthnOrder:
			if v != nil {
				args.opts = append(args.opts, WithWebauthnOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WebauthnWhereInput); ok {
		args.opts = append(args.opts, WithWebauthnFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowAssignmentQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowAssignmentQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowAssignmentQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowassignment.Columns))
		selectedFields = []string{workflowassignment.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowassignment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldOwnerID)
				fieldSeen[workflowassignment.FieldOwnerID] = struct{}{}
			}

		case "workflowInstance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowInstance = query
			if _, ok := fieldSeen[workflowassignment.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldWorkflowInstanceID)
				fieldSeen[workflowassignment.FieldWorkflowInstanceID] = struct{}{}
			}

		case "workflowAssignmentTargets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentTargetClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentTargetPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentTargetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentTargetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowAssignment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_assignment_workflow_assignment_targets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowassignment.WorkflowAssignmentTargetsColumn), ids...))
						})
						if err := query.GroupBy(workflowassignment.WorkflowAssignmentTargetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowAssignment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignmentTargets)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmenttargetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowassignment.WorkflowAssignmentTargetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignmentTargets(alias, func(wq *WorkflowAssignmentTargetQuery) {
				*wq = *query
			})

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[workflowassignment.FieldActorUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorUserID)
				fieldSeen[workflowassignment.FieldActorUserID] = struct{}{}
			}

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[workflowassignment.FieldActorGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorGroupID)
				fieldSeen[workflowassignment.FieldActorGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowassignment.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldCreatedAt)
				fieldSeen[workflowassignment.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowassignment.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldUpdatedAt)
				fieldSeen[workflowassignment.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowassignment.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldCreatedBy)
				fieldSeen[workflowassignment.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowassignment.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldUpdatedBy)
				fieldSeen[workflowassignment.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowassignment.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldDisplayID)
				fieldSeen[workflowassignment.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowassignment.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldTags)
				fieldSeen[workflowassignment.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowassignment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldOwnerID)
				fieldSeen[workflowassignment.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowassignment.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldWorkflowInstanceID)
				fieldSeen[workflowassignment.FieldWorkflowInstanceID] = struct{}{}
			}
		case "assignmentKey":
			if _, ok := fieldSeen[workflowassignment.FieldAssignmentKey]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldAssignmentKey)
				fieldSeen[workflowassignment.FieldAssignmentKey] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[workflowassignment.FieldRole]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldRole)
				fieldSeen[workflowassignment.FieldRole] = struct{}{}
			}
		case "label":
			if _, ok := fieldSeen[workflowassignment.FieldLabel]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldLabel)
				fieldSeen[workflowassignment.FieldLabel] = struct{}{}
			}
		case "required":
			if _, ok := fieldSeen[workflowassignment.FieldRequired]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldRequired)
				fieldSeen[workflowassignment.FieldRequired] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[workflowassignment.FieldStatus]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldStatus)
				fieldSeen[workflowassignment.FieldStatus] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[workflowassignment.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldMetadata)
				fieldSeen[workflowassignment.FieldMetadata] = struct{}{}
			}
		case "decidedAt":
			if _, ok := fieldSeen[workflowassignment.FieldDecidedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldDecidedAt)
				fieldSeen[workflowassignment.FieldDecidedAt] = struct{}{}
			}
		case "actorUserID":
			if _, ok := fieldSeen[workflowassignment.FieldActorUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorUserID)
				fieldSeen[workflowassignment.FieldActorUserID] = struct{}{}
			}
		case "actorGroupID":
			if _, ok := fieldSeen[workflowassignment.FieldActorGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorGroupID)
				fieldSeen[workflowassignment.FieldActorGroupID] = struct{}{}
			}
		case "notes":
			if _, ok := fieldSeen[workflowassignment.FieldNotes]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldNotes)
				fieldSeen[workflowassignment.FieldNotes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowassignmentPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowAssignmentPaginateOption
}

func newWorkflowAssignmentPaginateArgs(rv map[string]any) *workflowassignmentPaginateArgs {
	args := &workflowassignmentPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowAssignmentOrder:
			args.opts = append(args.opts, WithWorkflowAssignmentOrder(v))
		case []any:
			var orders []*WorkflowAssignmentOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowAssignmentOrder{Field: &WorkflowAssignmentOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowAssignmentOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowAssignmentWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowAssignmentFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowAssignmentHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowAssignmentHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowAssignmentHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowassignmenthistory.Columns))
		selectedFields = []string{workflowassignmenthistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldHistoryTime)
				fieldSeen[workflowassignmenthistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldRef)
				fieldSeen[workflowassignmenthistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldOperation)
				fieldSeen[workflowassignmenthistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldCreatedAt)
				fieldSeen[workflowassignmenthistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldUpdatedAt)
				fieldSeen[workflowassignmenthistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldCreatedBy)
				fieldSeen[workflowassignmenthistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldUpdatedBy)
				fieldSeen[workflowassignmenthistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldDisplayID)
				fieldSeen[workflowassignmenthistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldTags)
				fieldSeen[workflowassignmenthistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldOwnerID)
				fieldSeen[workflowassignmenthistory.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldWorkflowInstanceID)
				fieldSeen[workflowassignmenthistory.FieldWorkflowInstanceID] = struct{}{}
			}
		case "assignmentKey":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldAssignmentKey]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldAssignmentKey)
				fieldSeen[workflowassignmenthistory.FieldAssignmentKey] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldRole]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldRole)
				fieldSeen[workflowassignmenthistory.FieldRole] = struct{}{}
			}
		case "label":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldLabel]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldLabel)
				fieldSeen[workflowassignmenthistory.FieldLabel] = struct{}{}
			}
		case "required":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldRequired]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldRequired)
				fieldSeen[workflowassignmenthistory.FieldRequired] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldStatus]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldStatus)
				fieldSeen[workflowassignmenthistory.FieldStatus] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldMetadata)
				fieldSeen[workflowassignmenthistory.FieldMetadata] = struct{}{}
			}
		case "decidedAt":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldDecidedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldDecidedAt)
				fieldSeen[workflowassignmenthistory.FieldDecidedAt] = struct{}{}
			}
		case "actorUserID":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldActorUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldActorUserID)
				fieldSeen[workflowassignmenthistory.FieldActorUserID] = struct{}{}
			}
		case "actorGroupID":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldActorGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldActorGroupID)
				fieldSeen[workflowassignmenthistory.FieldActorGroupID] = struct{}{}
			}
		case "notes":
			if _, ok := fieldSeen[workflowassignmenthistory.FieldNotes]; !ok {
				selectedFields = append(selectedFields, workflowassignmenthistory.FieldNotes)
				fieldSeen[workflowassignmenthistory.FieldNotes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowassignmenthistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowAssignmentHistoryPaginateOption
}

func newWorkflowAssignmentHistoryPaginateArgs(rv map[string]any) *workflowassignmenthistoryPaginateArgs {
	args := &workflowassignmenthistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WorkflowAssignmentHistoryOrder{Field: &WorkflowAssignmentHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWorkflowAssignmentHistoryOrder(order))
			}
		case *WorkflowAssignmentHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithWorkflowAssignmentHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WorkflowAssignmentHistoryWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowAssignmentHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowAssignmentTargetQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowAssignmentTargetQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowAssignmentTargetQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowassignmenttarget.Columns))
		selectedFields = []string{workflowassignmenttarget.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldOwnerID)
				fieldSeen[workflowassignmenttarget.FieldOwnerID] = struct{}{}
			}

		case "workflowAssignment":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowassignmentImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowAssignment = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldWorkflowAssignmentID)
				fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetUserID)
				fieldSeen[workflowassignmenttarget.FieldTargetUserID] = struct{}{}
			}

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetGroupID)
				fieldSeen[workflowassignmenttarget.FieldTargetGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldCreatedAt)
				fieldSeen[workflowassignmenttarget.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldUpdatedAt)
				fieldSeen[workflowassignmenttarget.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldCreatedBy)
				fieldSeen[workflowassignmenttarget.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldUpdatedBy)
				fieldSeen[workflowassignmenttarget.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldDisplayID)
				fieldSeen[workflowassignmenttarget.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTags)
				fieldSeen[workflowassignmenttarget.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldOwnerID)
				fieldSeen[workflowassignmenttarget.FieldOwnerID] = struct{}{}
			}
		case "workflowAssignmentID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldWorkflowAssignmentID)
				fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID] = struct{}{}
			}
		case "targetType":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetType]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetType)
				fieldSeen[workflowassignmenttarget.FieldTargetType] = struct{}{}
			}
		case "targetUserID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetUserID)
				fieldSeen[workflowassignmenttarget.FieldTargetUserID] = struct{}{}
			}
		case "targetGroupID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetGroupID)
				fieldSeen[workflowassignmenttarget.FieldTargetGroupID] = struct{}{}
			}
		case "resolverKey":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldResolverKey]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldResolverKey)
				fieldSeen[workflowassignmenttarget.FieldResolverKey] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowassignmenttargetPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowAssignmentTargetPaginateOption
}

func newWorkflowAssignmentTargetPaginateArgs(rv map[string]any) *workflowassignmenttargetPaginateArgs {
	args := &workflowassignmenttargetPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowAssignmentTargetOrder:
			args.opts = append(args.opts, WithWorkflowAssignmentTargetOrder(v))
		case []any:
			var orders []*WorkflowAssignmentTargetOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowAssignmentTargetOrder{Field: &WorkflowAssignmentTargetOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowAssignmentTargetOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowAssignmentTargetWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowAssignmentTargetFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowAssignmentTargetHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowAssignmentTargetHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowAssignmentTargetHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowassignmenttargethistory.Columns))
		selectedFields = []string{workflowassignmenttargethistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldHistoryTime)
				fieldSeen[workflowassignmenttargethistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldRef)
				fieldSeen[workflowassignmenttargethistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldOperation)
				fieldSeen[workflowassignmenttargethistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldCreatedAt)
				fieldSeen[workflowassignmenttargethistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldUpdatedAt)
				fieldSeen[workflowassignmenttargethistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldCreatedBy)
				fieldSeen[workflowassignmenttargethistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldUpdatedBy)
				fieldSeen[workflowassignmenttargethistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldDisplayID)
				fieldSeen[workflowassignmenttargethistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldTags)
				fieldSeen[workflowassignmenttargethistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldOwnerID)
				fieldSeen[workflowassignmenttargethistory.FieldOwnerID] = struct{}{}
			}
		case "workflowAssignmentID":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldWorkflowAssignmentID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldWorkflowAssignmentID)
				fieldSeen[workflowassignmenttargethistory.FieldWorkflowAssignmentID] = struct{}{}
			}
		case "targetType":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldTargetType]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldTargetType)
				fieldSeen[workflowassignmenttargethistory.FieldTargetType] = struct{}{}
			}
		case "targetUserID":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldTargetUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldTargetUserID)
				fieldSeen[workflowassignmenttargethistory.FieldTargetUserID] = struct{}{}
			}
		case "targetGroupID":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldTargetGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldTargetGroupID)
				fieldSeen[workflowassignmenttargethistory.FieldTargetGroupID] = struct{}{}
			}
		case "resolverKey":
			if _, ok := fieldSeen[workflowassignmenttargethistory.FieldResolverKey]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttargethistory.FieldResolverKey)
				fieldSeen[workflowassignmenttargethistory.FieldResolverKey] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowassignmenttargethistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowAssignmentTargetHistoryPaginateOption
}

func newWorkflowAssignmentTargetHistoryPaginateArgs(rv map[string]any) *workflowassignmenttargethistoryPaginateArgs {
	args := &workflowassignmenttargethistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WorkflowAssignmentTargetHistoryOrder{Field: &WorkflowAssignmentTargetHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWorkflowAssignmentTargetHistoryOrder(order))
			}
		case *WorkflowAssignmentTargetHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithWorkflowAssignmentTargetHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WorkflowAssignmentTargetHistoryWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowAssignmentTargetHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowDefinitionQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowDefinitionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowDefinitionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowdefinition.Columns))
		selectedFields = []string{workflowdefinition.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldOwnerID)
				fieldSeen[workflowdefinition.FieldOwnerID] = struct{}{}
			}

		case "tagDefinitions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TagDefinitionClient{config: _q.config}).Query()
			)
			args := newTagDefinitionPaginateArgs(fieldArgs(ctx, new(TagDefinitionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTagDefinitionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowDefinition) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_definition_tag_definitions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowdefinition.TagDefinitionsColumn), ids...))
						})
						if err := query.GroupBy(workflowdefinition.TagDefinitionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowDefinition) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TagDefinitions)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tagdefinitionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowdefinition.TagDefinitionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTagDefinitions(alias, func(wq *TagDefinitionQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowDefinition) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_definition_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowdefinition.GroupsColumn), ids...))
						})
						if err := query.GroupBy(workflowdefinition.GroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowDefinition) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowdefinition.GroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[workflowdefinition.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldCreatedAt)
				fieldSeen[workflowdefinition.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowdefinition.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldUpdatedAt)
				fieldSeen[workflowdefinition.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowdefinition.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldCreatedBy)
				fieldSeen[workflowdefinition.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowdefinition.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldUpdatedBy)
				fieldSeen[workflowdefinition.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowdefinition.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDisplayID)
				fieldSeen[workflowdefinition.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowdefinition.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldTags)
				fieldSeen[workflowdefinition.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldOwnerID)
				fieldSeen[workflowdefinition.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[workflowdefinition.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldSystemOwned)
				fieldSeen[workflowdefinition.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[workflowdefinition.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldInternalNotes)
				fieldSeen[workflowdefinition.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[workflowdefinition.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldSystemInternalID)
				fieldSeen[workflowdefinition.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[workflowdefinition.FieldName]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldName)
				fieldSeen[workflowdefinition.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[workflowdefinition.FieldDescription]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDescription)
				fieldSeen[workflowdefinition.FieldDescription] = struct{}{}
			}
		case "workflowKind":
			if _, ok := fieldSeen[workflowdefinition.FieldWorkflowKind]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldWorkflowKind)
				fieldSeen[workflowdefinition.FieldWorkflowKind] = struct{}{}
			}
		case "schemaType":
			if _, ok := fieldSeen[workflowdefinition.FieldSchemaType]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldSchemaType)
				fieldSeen[workflowdefinition.FieldSchemaType] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[workflowdefinition.FieldRevision]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldRevision)
				fieldSeen[workflowdefinition.FieldRevision] = struct{}{}
			}
		case "draft":
			if _, ok := fieldSeen[workflowdefinition.FieldDraft]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDraft)
				fieldSeen[workflowdefinition.FieldDraft] = struct{}{}
			}
		case "publishedAt":
			if _, ok := fieldSeen[workflowdefinition.FieldPublishedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldPublishedAt)
				fieldSeen[workflowdefinition.FieldPublishedAt] = struct{}{}
			}
		case "cooldownSeconds":
			if _, ok := fieldSeen[workflowdefinition.FieldCooldownSeconds]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldCooldownSeconds)
				fieldSeen[workflowdefinition.FieldCooldownSeconds] = struct{}{}
			}
		case "isDefault":
			if _, ok := fieldSeen[workflowdefinition.FieldIsDefault]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldIsDefault)
				fieldSeen[workflowdefinition.FieldIsDefault] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[workflowdefinition.FieldActive]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldActive)
				fieldSeen[workflowdefinition.FieldActive] = struct{}{}
			}
		case "triggerOperations":
			if _, ok := fieldSeen[workflowdefinition.FieldTriggerOperations]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldTriggerOperations)
				fieldSeen[workflowdefinition.FieldTriggerOperations] = struct{}{}
			}
		case "triggerFields":
			if _, ok := fieldSeen[workflowdefinition.FieldTriggerFields]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldTriggerFields)
				fieldSeen[workflowdefinition.FieldTriggerFields] = struct{}{}
			}
		case "definitionJSON":
			if _, ok := fieldSeen[workflowdefinition.FieldDefinitionJSON]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDefinitionJSON)
				fieldSeen[workflowdefinition.FieldDefinitionJSON] = struct{}{}
			}
		case "trackedFields":
			if _, ok := fieldSeen[workflowdefinition.FieldTrackedFields]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldTrackedFields)
				fieldSeen[workflowdefinition.FieldTrackedFields] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowdefinitionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowDefinitionPaginateOption
}

func newWorkflowDefinitionPaginateArgs(rv map[string]any) *workflowdefinitionPaginateArgs {
	args := &workflowdefinitionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowDefinitionOrder:
			args.opts = append(args.opts, WithWorkflowDefinitionOrder(v))
		case []any:
			var orders []*WorkflowDefinitionOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowDefinitionOrder{Field: &WorkflowDefinitionOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowDefinitionOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowDefinitionWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowDefinitionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowDefinitionHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowDefinitionHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowDefinitionHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowdefinitionhistory.Columns))
		selectedFields = []string{workflowdefinitionhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldHistoryTime)
				fieldSeen[workflowdefinitionhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldRef)
				fieldSeen[workflowdefinitionhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldOperation)
				fieldSeen[workflowdefinitionhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldCreatedAt)
				fieldSeen[workflowdefinitionhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldUpdatedAt)
				fieldSeen[workflowdefinitionhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldCreatedBy)
				fieldSeen[workflowdefinitionhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldUpdatedBy)
				fieldSeen[workflowdefinitionhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldDisplayID)
				fieldSeen[workflowdefinitionhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldTags)
				fieldSeen[workflowdefinitionhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldOwnerID)
				fieldSeen[workflowdefinitionhistory.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldSystemOwned)
				fieldSeen[workflowdefinitionhistory.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldInternalNotes)
				fieldSeen[workflowdefinitionhistory.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldSystemInternalID)
				fieldSeen[workflowdefinitionhistory.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldName]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldName)
				fieldSeen[workflowdefinitionhistory.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldDescription]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldDescription)
				fieldSeen[workflowdefinitionhistory.FieldDescription] = struct{}{}
			}
		case "workflowKind":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldWorkflowKind]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldWorkflowKind)
				fieldSeen[workflowdefinitionhistory.FieldWorkflowKind] = struct{}{}
			}
		case "schemaType":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldSchemaType]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldSchemaType)
				fieldSeen[workflowdefinitionhistory.FieldSchemaType] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldRevision]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldRevision)
				fieldSeen[workflowdefinitionhistory.FieldRevision] = struct{}{}
			}
		case "draft":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldDraft]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldDraft)
				fieldSeen[workflowdefinitionhistory.FieldDraft] = struct{}{}
			}
		case "publishedAt":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldPublishedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldPublishedAt)
				fieldSeen[workflowdefinitionhistory.FieldPublishedAt] = struct{}{}
			}
		case "cooldownSeconds":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldCooldownSeconds]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldCooldownSeconds)
				fieldSeen[workflowdefinitionhistory.FieldCooldownSeconds] = struct{}{}
			}
		case "isDefault":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldIsDefault]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldIsDefault)
				fieldSeen[workflowdefinitionhistory.FieldIsDefault] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldActive]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldActive)
				fieldSeen[workflowdefinitionhistory.FieldActive] = struct{}{}
			}
		case "triggerOperations":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldTriggerOperations]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldTriggerOperations)
				fieldSeen[workflowdefinitionhistory.FieldTriggerOperations] = struct{}{}
			}
		case "triggerFields":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldTriggerFields]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldTriggerFields)
				fieldSeen[workflowdefinitionhistory.FieldTriggerFields] = struct{}{}
			}
		case "definitionJSON":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldDefinitionJSON]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldDefinitionJSON)
				fieldSeen[workflowdefinitionhistory.FieldDefinitionJSON] = struct{}{}
			}
		case "trackedFields":
			if _, ok := fieldSeen[workflowdefinitionhistory.FieldTrackedFields]; !ok {
				selectedFields = append(selectedFields, workflowdefinitionhistory.FieldTrackedFields)
				fieldSeen[workflowdefinitionhistory.FieldTrackedFields] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowdefinitionhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowDefinitionHistoryPaginateOption
}

func newWorkflowDefinitionHistoryPaginateArgs(rv map[string]any) *workflowdefinitionhistoryPaginateArgs {
	args := &workflowdefinitionhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WorkflowDefinitionHistoryOrder{Field: &WorkflowDefinitionHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWorkflowDefinitionHistoryOrder(order))
			}
		case *WorkflowDefinitionHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithWorkflowDefinitionHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WorkflowDefinitionHistoryWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowDefinitionHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowEventQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowEventQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowEventQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowevent.Columns))
		selectedFields = []string{workflowevent.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowevent.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldOwnerID)
				fieldSeen[workflowevent.FieldOwnerID] = struct{}{}
			}

		case "workflowInstance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowInstance = query
			if _, ok := fieldSeen[workflowevent.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldWorkflowInstanceID)
				fieldSeen[workflowevent.FieldWorkflowInstanceID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowevent.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldCreatedAt)
				fieldSeen[workflowevent.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowevent.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldUpdatedAt)
				fieldSeen[workflowevent.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowevent.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldCreatedBy)
				fieldSeen[workflowevent.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowevent.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldUpdatedBy)
				fieldSeen[workflowevent.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowevent.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldDisplayID)
				fieldSeen[workflowevent.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowevent.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldTags)
				fieldSeen[workflowevent.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowevent.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldOwnerID)
				fieldSeen[workflowevent.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowevent.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldWorkflowInstanceID)
				fieldSeen[workflowevent.FieldWorkflowInstanceID] = struct{}{}
			}
		case "eventType":
			if _, ok := fieldSeen[workflowevent.FieldEventType]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldEventType)
				fieldSeen[workflowevent.FieldEventType] = struct{}{}
			}
		case "payload":
			if _, ok := fieldSeen[workflowevent.FieldPayload]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldPayload)
				fieldSeen[workflowevent.FieldPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workfloweventPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowEventPaginateOption
}

func newWorkflowEventPaginateArgs(rv map[string]any) *workfloweventPaginateArgs {
	args := &workfloweventPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowEventOrder:
			args.opts = append(args.opts, WithWorkflowEventOrder(v))
		case []any:
			var orders []*WorkflowEventOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowEventOrder{Field: &WorkflowEventOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowEventOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowEventWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowEventFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowEventHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowEventHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowEventHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workfloweventhistory.Columns))
		selectedFields = []string{workfloweventhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[workfloweventhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldHistoryTime)
				fieldSeen[workfloweventhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[workfloweventhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldRef)
				fieldSeen[workfloweventhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[workfloweventhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldOperation)
				fieldSeen[workfloweventhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workfloweventhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldCreatedAt)
				fieldSeen[workfloweventhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workfloweventhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldUpdatedAt)
				fieldSeen[workfloweventhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workfloweventhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldCreatedBy)
				fieldSeen[workfloweventhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workfloweventhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldUpdatedBy)
				fieldSeen[workfloweventhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workfloweventhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldDisplayID)
				fieldSeen[workfloweventhistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workfloweventhistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldTags)
				fieldSeen[workfloweventhistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workfloweventhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldOwnerID)
				fieldSeen[workfloweventhistory.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workfloweventhistory.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldWorkflowInstanceID)
				fieldSeen[workfloweventhistory.FieldWorkflowInstanceID] = struct{}{}
			}
		case "eventType":
			if _, ok := fieldSeen[workfloweventhistory.FieldEventType]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldEventType)
				fieldSeen[workfloweventhistory.FieldEventType] = struct{}{}
			}
		case "payload":
			if _, ok := fieldSeen[workfloweventhistory.FieldPayload]; !ok {
				selectedFields = append(selectedFields, workfloweventhistory.FieldPayload)
				fieldSeen[workfloweventhistory.FieldPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workfloweventhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowEventHistoryPaginateOption
}

func newWorkflowEventHistoryPaginateArgs(rv map[string]any) *workfloweventhistoryPaginateArgs {
	args := &workfloweventhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WorkflowEventHistoryOrder{Field: &WorkflowEventHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWorkflowEventHistoryOrder(order))
			}
		case *WorkflowEventHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithWorkflowEventHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WorkflowEventHistoryWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowEventHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowInstanceQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowInstanceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowInstanceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowinstance.Columns))
		selectedFields = []string{workflowinstance.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowinstance.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldOwnerID)
				fieldSeen[workflowinstance.FieldOwnerID] = struct{}{}
			}

		case "workflowDefinition":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowDefinitionClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowdefinitionImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowDefinition = query
			if _, ok := fieldSeen[workflowinstance.FieldWorkflowDefinitionID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldWorkflowDefinitionID)
				fieldSeen[workflowinstance.FieldWorkflowDefinitionID] = struct{}{}
			}

		case "workflowAssignments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowInstance) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_instance_workflow_assignments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowinstance.WorkflowAssignmentsColumn), ids...))
						})
						if err := query.GroupBy(workflowinstance.WorkflowAssignmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowInstance) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignments)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowinstance.WorkflowAssignmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignments(alias, func(wq *WorkflowAssignmentQuery) {
				*wq = *query
			})

		case "workflowEvents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowEventClient{config: _q.config}).Query()
			)
			args := newWorkflowEventPaginateArgs(fieldArgs(ctx, new(WorkflowEventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowInstance) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_instance_workflow_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowinstance.WorkflowEventsColumn), ids...))
						})
						if err := query.GroupBy(workflowinstance.WorkflowEventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowInstance) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowEvents)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workfloweventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowinstance.WorkflowEventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowEvents(alias, func(wq *WorkflowEventQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowInstance) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_instance_workflow_object_refs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowinstance.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(workflowinstance.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowInstance) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowinstance.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[workflowinstance.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldCreatedAt)
				fieldSeen[workflowinstance.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowinstance.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldUpdatedAt)
				fieldSeen[workflowinstance.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowinstance.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldCreatedBy)
				fieldSeen[workflowinstance.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowinstance.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldUpdatedBy)
				fieldSeen[workflowinstance.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowinstance.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldDisplayID)
				fieldSeen[workflowinstance.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowinstance.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldTags)
				fieldSeen[workflowinstance.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowinstance.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldOwnerID)
				fieldSeen[workflowinstance.FieldOwnerID] = struct{}{}
			}
		case "workflowDefinitionID":
			if _, ok := fieldSeen[workflowinstance.FieldWorkflowDefinitionID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldWorkflowDefinitionID)
				fieldSeen[workflowinstance.FieldWorkflowDefinitionID] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[workflowinstance.FieldState]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldState)
				fieldSeen[workflowinstance.FieldState] = struct{}{}
			}
		case "context":
			if _, ok := fieldSeen[workflowinstance.FieldContext]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldContext)
				fieldSeen[workflowinstance.FieldContext] = struct{}{}
			}
		case "lastEvaluatedAt":
			if _, ok := fieldSeen[workflowinstance.FieldLastEvaluatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldLastEvaluatedAt)
				fieldSeen[workflowinstance.FieldLastEvaluatedAt] = struct{}{}
			}
		case "definitionSnapshot":
			if _, ok := fieldSeen[workflowinstance.FieldDefinitionSnapshot]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldDefinitionSnapshot)
				fieldSeen[workflowinstance.FieldDefinitionSnapshot] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowinstancePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowInstancePaginateOption
}

func newWorkflowInstancePaginateArgs(rv map[string]any) *workflowinstancePaginateArgs {
	args := &workflowinstancePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowInstanceOrder:
			args.opts = append(args.opts, WithWorkflowInstanceOrder(v))
		case []any:
			var orders []*WorkflowInstanceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowInstanceOrder{Field: &WorkflowInstanceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowInstanceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowInstanceWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowInstanceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowInstanceHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowInstanceHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowInstanceHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowinstancehistory.Columns))
		selectedFields = []string{workflowinstancehistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[workflowinstancehistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldHistoryTime)
				fieldSeen[workflowinstancehistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[workflowinstancehistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldRef)
				fieldSeen[workflowinstancehistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[workflowinstancehistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldOperation)
				fieldSeen[workflowinstancehistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowinstancehistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldCreatedAt)
				fieldSeen[workflowinstancehistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowinstancehistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldUpdatedAt)
				fieldSeen[workflowinstancehistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowinstancehistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldCreatedBy)
				fieldSeen[workflowinstancehistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowinstancehistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldUpdatedBy)
				fieldSeen[workflowinstancehistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowinstancehistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldDisplayID)
				fieldSeen[workflowinstancehistory.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowinstancehistory.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldTags)
				fieldSeen[workflowinstancehistory.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowinstancehistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldOwnerID)
				fieldSeen[workflowinstancehistory.FieldOwnerID] = struct{}{}
			}
		case "workflowDefinitionID":
			if _, ok := fieldSeen[workflowinstancehistory.FieldWorkflowDefinitionID]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldWorkflowDefinitionID)
				fieldSeen[workflowinstancehistory.FieldWorkflowDefinitionID] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[workflowinstancehistory.FieldState]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldState)
				fieldSeen[workflowinstancehistory.FieldState] = struct{}{}
			}
		case "context":
			if _, ok := fieldSeen[workflowinstancehistory.FieldContext]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldContext)
				fieldSeen[workflowinstancehistory.FieldContext] = struct{}{}
			}
		case "lastEvaluatedAt":
			if _, ok := fieldSeen[workflowinstancehistory.FieldLastEvaluatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldLastEvaluatedAt)
				fieldSeen[workflowinstancehistory.FieldLastEvaluatedAt] = struct{}{}
			}
		case "definitionSnapshot":
			if _, ok := fieldSeen[workflowinstancehistory.FieldDefinitionSnapshot]; !ok {
				selectedFields = append(selectedFields, workflowinstancehistory.FieldDefinitionSnapshot)
				fieldSeen[workflowinstancehistory.FieldDefinitionSnapshot] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowinstancehistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowInstanceHistoryPaginateOption
}

func newWorkflowInstanceHistoryPaginateArgs(rv map[string]any) *workflowinstancehistoryPaginateArgs {
	args := &workflowinstancehistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WorkflowInstanceHistoryOrder{Field: &WorkflowInstanceHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWorkflowInstanceHistoryOrder(order))
			}
		case *WorkflowInstanceHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithWorkflowInstanceHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WorkflowInstanceHistoryWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowInstanceHistoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowObjectRefQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowObjectRefQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowObjectRefQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowobjectref.Columns))
		selectedFields = []string{workflowobjectref.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowobjectref.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldOwnerID)
				fieldSeen[workflowobjectref.FieldOwnerID] = struct{}{}
			}

		case "workflowInstance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowInstance = query
			if _, ok := fieldSeen[workflowobjectref.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldWorkflowInstanceID)
				fieldSeen[workflowobjectref.FieldWorkflowInstanceID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[workflowobjectref.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldControlID)
				fieldSeen[workflowobjectref.FieldControlID] = struct{}{}
			}

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			_q.withTask = query
			if _, ok := fieldSeen[workflowobjectref.FieldTaskID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldTaskID)
				fieldSeen[workflowobjectref.FieldTaskID] = struct{}{}
			}

		case "internalPolicy":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicy = query
			if _, ok := fieldSeen[workflowobjectref.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldInternalPolicyID)
				fieldSeen[workflowobjectref.FieldInternalPolicyID] = struct{}{}
			}

		case "finding":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
				return err
			}
			_q.withFinding = query
			if _, ok := fieldSeen[workflowobjectref.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldFindingID)
				fieldSeen[workflowobjectref.FieldFindingID] = struct{}{}
			}

		case "directoryAccount":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryAccount = query
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryAccountID)
				fieldSeen[workflowobjectref.FieldDirectoryAccountID] = struct{}{}
			}

		case "directoryGroup":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryGroup = query
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryGroupID)
				fieldSeen[workflowobjectref.FieldDirectoryGroupID] = struct{}{}
			}

		case "directoryMembership":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryMembership = query
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryMembershipID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryMembershipID)
				fieldSeen[workflowobjectref.FieldDirectoryMembershipID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowobjectref.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldCreatedAt)
				fieldSeen[workflowobjectref.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowobjectref.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldUpdatedAt)
				fieldSeen[workflowobjectref.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowobjectref.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldCreatedBy)
				fieldSeen[workflowobjectref.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowobjectref.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldUpdatedBy)
				fieldSeen[workflowobjectref.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowobjectref.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDisplayID)
				fieldSeen[workflowobjectref.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowobjectref.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldOwnerID)
				fieldSeen[workflowobjectref.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowobjectref.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldWorkflowInstanceID)
				fieldSeen[workflowobjectref.FieldWorkflowInstanceID] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[workflowobjectref.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldControlID)
				fieldSeen[workflowobjectref.FieldControlID] = struct{}{}
			}
		case "taskID":
			if _, ok := fieldSeen[workflowobjectref.FieldTaskID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldTaskID)
				fieldSeen[workflowobjectref.FieldTaskID] = struct{}{}
			}
		case "internalPolicyID":
			if _, ok := fieldSeen[workflowobjectref.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldInternalPolicyID)
				fieldSeen[workflowobjectref.FieldInternalPolicyID] = struct{}{}
			}
		case "findingID":
			if _, ok := fieldSeen[workflowobjectref.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldFindingID)
				fieldSeen[workflowobjectref.FieldFindingID] = struct{}{}
			}
		case "directoryAccountID":
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryAccountID)
				fieldSeen[workflowobjectref.FieldDirectoryAccountID] = struct{}{}
			}
		case "directoryGroupID":
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryGroupID)
				fieldSeen[workflowobjectref.FieldDirectoryGroupID] = struct{}{}
			}
		case "directoryMembershipID":
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryMembershipID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryMembershipID)
				fieldSeen[workflowobjectref.FieldDirectoryMembershipID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowobjectrefPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowObjectRefPaginateOption
}

func newWorkflowObjectRefPaginateArgs(rv map[string]any) *workflowobjectrefPaginateArgs {
	args := &workflowobjectrefPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowObjectRefOrder:
			args.opts = append(args.opts, WithWorkflowObjectRefOrder(v))
		case []any:
			var orders []*WorkflowObjectRefOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowObjectRefOrder{Field: &WorkflowObjectRefOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowObjectRefOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowObjectRefWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowObjectRefFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowObjectRefHistoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowObjectRefHistoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowObjectRefHistoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowobjectrefhistory.Columns))
		selectedFields = []string{workflowobjectrefhistory.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "historyTime":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldHistoryTime]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldHistoryTime)
				fieldSeen[workflowobjectrefhistory.FieldHistoryTime] = struct{}{}
			}
		case "ref":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldRef]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldRef)
				fieldSeen[workflowobjectrefhistory.FieldRef] = struct{}{}
			}
		case "operation":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldOperation]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldOperation)
				fieldSeen[workflowobjectrefhistory.FieldOperation] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldCreatedAt)
				fieldSeen[workflowobjectrefhistory.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldUpdatedAt)
				fieldSeen[workflowobjectrefhistory.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldCreatedBy)
				fieldSeen[workflowobjectrefhistory.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldUpdatedBy)
				fieldSeen[workflowobjectrefhistory.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldDisplayID)
				fieldSeen[workflowobjectrefhistory.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldOwnerID)
				fieldSeen[workflowobjectrefhistory.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldWorkflowInstanceID)
				fieldSeen[workflowobjectrefhistory.FieldWorkflowInstanceID] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldControlID)
				fieldSeen[workflowobjectrefhistory.FieldControlID] = struct{}{}
			}
		case "taskID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldTaskID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldTaskID)
				fieldSeen[workflowobjectrefhistory.FieldTaskID] = struct{}{}
			}
		case "internalPolicyID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldInternalPolicyID)
				fieldSeen[workflowobjectrefhistory.FieldInternalPolicyID] = struct{}{}
			}
		case "findingID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldFindingID)
				fieldSeen[workflowobjectrefhistory.FieldFindingID] = struct{}{}
			}
		case "directoryAccountID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldDirectoryAccountID)
				fieldSeen[workflowobjectrefhistory.FieldDirectoryAccountID] = struct{}{}
			}
		case "directoryGroupID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldDirectoryGroupID)
				fieldSeen[workflowobjectrefhistory.FieldDirectoryGroupID] = struct{}{}
			}
		case "directoryMembershipID":
			if _, ok := fieldSeen[workflowobjectrefhistory.FieldDirectoryMembershipID]; !ok {
				selectedFields = append(selectedFields, workflowobjectrefhistory.FieldDirectoryMembershipID)
				fieldSeen[workflowobjectrefhistory.FieldDirectoryMembershipID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowobjectrefhistoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowObjectRefHistoryPaginateOption
}

func newWorkflowObjectRefHistoryPaginateArgs(rv map[string]any) *workflowobjectrefhistoryPaginateArgs {
	args := &workflowobjectrefhistoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WorkflowObjectRefHistoryOrder{Field: &WorkflowObjectRefHistoryOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWorkflowObjectRefHistoryOrder(order))
			}
		case *WorkflowObjectRefHistoryOrder:
			if v != nil {
				args.opts = append(args.opts, WithWorkflowObjectRefHistoryOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WorkflowObjectRefHistoryWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowObjectRefHistoryFilter(v.Filter))
	}
	return args
}

const (
	afterField     = "after"
	firstField     = "first"
	beforeField    = "before"
	lastField      = "last"
	orderByField   = "orderBy"
	directionField = "direction"
	fieldField     = "field"
	whereField     = "where"
)

func fieldArgs(ctx context.Context, whereInput any, path ...string) map[string]any {
	field := collectedField(ctx, path...)
	if field == nil || field.Arguments == nil {
		return nil
	}
	oc := graphql.GetOperationContext(ctx)
	args := field.ArgumentMap(oc.Variables)
	return unmarshalArgs(ctx, whereInput, args)
}

// unmarshalArgs allows extracting the field arguments from their raw representation.
func unmarshalArgs(ctx context.Context, whereInput any, args map[string]any) map[string]any {
	for _, k := range []string{firstField, lastField} {
		v, ok := args[k]
		if !ok || v == nil {
			continue
		}
		i, err := graphql.UnmarshalInt(v)
		if err == nil {
			args[k] = &i
		}
	}
	for _, k := range []string{beforeField, afterField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		c := &Cursor{}
		if c.UnmarshalGQL(v) == nil {
			args[k] = c
		}
	}
	if v, ok := args[whereField]; ok && whereInput != nil {
		if err := graphql.UnmarshalInputFromContext(ctx, v, whereInput); err == nil {
			args[whereField] = whereInput
		}
	}

	return args
}

// mayAddCondition appends another type condition to the satisfies list
// if it does not exist in the list.
func mayAddCondition(satisfies []string, typeCond []string) []string {
Cond:
	for _, c := range typeCond {
		for _, s := range satisfies {
			if c == s {
				continue Cond
			}
		}
		satisfies = append(satisfies, c)
	}
	return satisfies
}
