// Code generated by ent, DO NOT EDIT.

package generated

import (
	"context"
	"database/sql/driver"
	"fmt"

	"entgo.io/contrib/entgql"
	"entgo.io/ent/dialect/sql"
	"github.com/99designs/gqlgen/graphql"
	"github.com/theopenlane/core/internal/ent/generated/actionplan"
	"github.com/theopenlane/core/internal/ent/generated/apitoken"
	"github.com/theopenlane/core/internal/ent/generated/assessment"
	"github.com/theopenlane/core/internal/ent/generated/assessmentresponse"
	"github.com/theopenlane/core/internal/ent/generated/asset"
	"github.com/theopenlane/core/internal/ent/generated/contact"
	"github.com/theopenlane/core/internal/ent/generated/control"
	"github.com/theopenlane/core/internal/ent/generated/controlimplementation"
	"github.com/theopenlane/core/internal/ent/generated/controlobjective"
	"github.com/theopenlane/core/internal/ent/generated/customdomain"
	"github.com/theopenlane/core/internal/ent/generated/customtypeenum"
	"github.com/theopenlane/core/internal/ent/generated/directoryaccount"
	"github.com/theopenlane/core/internal/ent/generated/directorygroup"
	"github.com/theopenlane/core/internal/ent/generated/directorymembership"
	"github.com/theopenlane/core/internal/ent/generated/directorysyncrun"
	"github.com/theopenlane/core/internal/ent/generated/discussion"
	"github.com/theopenlane/core/internal/ent/generated/dnsverification"
	"github.com/theopenlane/core/internal/ent/generated/documentdata"
	"github.com/theopenlane/core/internal/ent/generated/entity"
	"github.com/theopenlane/core/internal/ent/generated/entitytype"
	"github.com/theopenlane/core/internal/ent/generated/event"
	"github.com/theopenlane/core/internal/ent/generated/evidence"
	"github.com/theopenlane/core/internal/ent/generated/export"
	"github.com/theopenlane/core/internal/ent/generated/file"
	"github.com/theopenlane/core/internal/ent/generated/finding"
	"github.com/theopenlane/core/internal/ent/generated/findingcontrol"
	"github.com/theopenlane/core/internal/ent/generated/group"
	"github.com/theopenlane/core/internal/ent/generated/groupmembership"
	"github.com/theopenlane/core/internal/ent/generated/groupsetting"
	"github.com/theopenlane/core/internal/ent/generated/hush"
	"github.com/theopenlane/core/internal/ent/generated/integration"
	"github.com/theopenlane/core/internal/ent/generated/internalpolicy"
	"github.com/theopenlane/core/internal/ent/generated/invite"
	"github.com/theopenlane/core/internal/ent/generated/jobresult"
	"github.com/theopenlane/core/internal/ent/generated/jobrunner"
	"github.com/theopenlane/core/internal/ent/generated/jobrunnerregistrationtoken"
	"github.com/theopenlane/core/internal/ent/generated/jobrunnertoken"
	"github.com/theopenlane/core/internal/ent/generated/jobtemplate"
	"github.com/theopenlane/core/internal/ent/generated/mappabledomain"
	"github.com/theopenlane/core/internal/ent/generated/mappedcontrol"
	"github.com/theopenlane/core/internal/ent/generated/narrative"
	"github.com/theopenlane/core/internal/ent/generated/note"
	"github.com/theopenlane/core/internal/ent/generated/notification"
	"github.com/theopenlane/core/internal/ent/generated/onboarding"
	"github.com/theopenlane/core/internal/ent/generated/organization"
	"github.com/theopenlane/core/internal/ent/generated/organizationsetting"
	"github.com/theopenlane/core/internal/ent/generated/orgmembership"
	"github.com/theopenlane/core/internal/ent/generated/orgsubscription"
	"github.com/theopenlane/core/internal/ent/generated/personalaccesstoken"
	"github.com/theopenlane/core/internal/ent/generated/procedure"
	"github.com/theopenlane/core/internal/ent/generated/program"
	"github.com/theopenlane/core/internal/ent/generated/programmembership"
	"github.com/theopenlane/core/internal/ent/generated/remediation"
	"github.com/theopenlane/core/internal/ent/generated/review"
	"github.com/theopenlane/core/internal/ent/generated/risk"
	"github.com/theopenlane/core/internal/ent/generated/scan"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjob"
	"github.com/theopenlane/core/internal/ent/generated/scheduledjobrun"
	"github.com/theopenlane/core/internal/ent/generated/standard"
	"github.com/theopenlane/core/internal/ent/generated/subcontrol"
	"github.com/theopenlane/core/internal/ent/generated/subprocessor"
	"github.com/theopenlane/core/internal/ent/generated/subscriber"
	"github.com/theopenlane/core/internal/ent/generated/tagdefinition"
	"github.com/theopenlane/core/internal/ent/generated/task"
	"github.com/theopenlane/core/internal/ent/generated/template"
	"github.com/theopenlane/core/internal/ent/generated/tfasetting"
	"github.com/theopenlane/core/internal/ent/generated/trustcenter"
	"github.com/theopenlane/core/internal/ent/generated/trustcentercompliance"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterdoc"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterentity"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersetting"
	"github.com/theopenlane/core/internal/ent/generated/trustcentersubprocessor"
	"github.com/theopenlane/core/internal/ent/generated/trustcenterwatermarkconfig"
	"github.com/theopenlane/core/internal/ent/generated/user"
	"github.com/theopenlane/core/internal/ent/generated/usersetting"
	"github.com/theopenlane/core/internal/ent/generated/vulnerability"
	"github.com/theopenlane/core/internal/ent/generated/webauthn"
	"github.com/theopenlane/core/internal/ent/generated/workflowassignment"
	"github.com/theopenlane/core/internal/ent/generated/workflowassignmenttarget"
	"github.com/theopenlane/core/internal/ent/generated/workflowdefinition"
	"github.com/theopenlane/core/internal/ent/generated/workflowevent"
	"github.com/theopenlane/core/internal/ent/generated/workflowinstance"
	"github.com/theopenlane/core/internal/ent/generated/workflowobjectref"
)

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *APITokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*APITokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *APITokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(apitoken.Columns))
		selectedFields = []string{apitoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[apitoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldOwnerID)
				fieldSeen[apitoken.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[apitoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldCreatedAt)
				fieldSeen[apitoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[apitoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldUpdatedAt)
				fieldSeen[apitoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[apitoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldCreatedBy)
				fieldSeen[apitoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[apitoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldUpdatedBy)
				fieldSeen[apitoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[apitoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldTags)
				fieldSeen[apitoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[apitoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldOwnerID)
				fieldSeen[apitoken.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[apitoken.FieldName]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldName)
				fieldSeen[apitoken.FieldName] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[apitoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldToken)
				fieldSeen[apitoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[apitoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldExpiresAt)
				fieldSeen[apitoken.FieldExpiresAt] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[apitoken.FieldDescription]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldDescription)
				fieldSeen[apitoken.FieldDescription] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[apitoken.FieldScopes]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldScopes)
				fieldSeen[apitoken.FieldScopes] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[apitoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldLastUsedAt)
				fieldSeen[apitoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[apitoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldIsActive)
				fieldSeen[apitoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[apitoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedReason)
				fieldSeen[apitoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[apitoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedBy)
				fieldSeen[apitoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[apitoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldRevokedAt)
				fieldSeen[apitoken.FieldRevokedAt] = struct{}{}
			}
		case "ssoAuthorizations":
			if _, ok := fieldSeen[apitoken.FieldSSOAuthorizations]; !ok {
				selectedFields = append(selectedFields, apitoken.FieldSSOAuthorizations)
				fieldSeen[apitoken.FieldSSOAuthorizations] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type apitokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []APITokenPaginateOption
}

func newAPITokenPaginateArgs(rv map[string]any) *apitokenPaginateArgs {
	args := &apitokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*APITokenOrder:
			args.opts = append(args.opts, WithAPITokenOrder(v))
		case []any:
			var orders []*APITokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &APITokenOrder{Field: &APITokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAPITokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*APITokenWhereInput); ok {
		args.opts = append(args.opts, WithAPITokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ActionPlanQuery) CollectFields(ctx context.Context, satisfies ...string) (*ActionPlanQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ActionPlanQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(actionplan.Columns))
		selectedFields = []string{actionplan.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withApprover = query
			if _, ok := fieldSeen[actionplan.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApproverID)
				fieldSeen[actionplan.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[actionplan.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDelegateID)
				fieldSeen[actionplan.FieldDelegateID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[actionplan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldOwnerID)
				fieldSeen[actionplan.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(actionplan.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(actionplan.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(actionplan.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(actionplan.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(actionplan.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(actionplan.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(actionplan.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(actionplan.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(actionplan.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "actionPlanKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withActionPlanKind = query
			if _, ok := fieldSeen[actionplan.FieldActionPlanKindID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanKindID)
				fieldSeen[actionplan.FieldActionPlanKindID] = struct{}{}
			}

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(actionplan.RisksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.RisksPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.RisksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.RisksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.RisksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(actionplan.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(actionplan.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.FindingsTable)
							s.Join(joinT).On(s.C(finding.FieldID), joinT.C(actionplan.FindingsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.FindingsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.FindingsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.FindingsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.FindingsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.VulnerabilitiesTable)
							s.Join(joinT).On(s.C(vulnerability.FieldID), joinT.C(actionplan.VulnerabilitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.VulnerabilitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.VulnerabilitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.VulnerabilitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.VulnerabilitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.ReviewsTable)
							s.Join(joinT).On(s.C(review.FieldID), joinT.C(actionplan.ReviewsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.ReviewsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.ReviewsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.ReviewsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.ReviewsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.RemediationsTable)
							s.Join(joinT).On(s.C(remediation.FieldID), joinT.C(actionplan.RemediationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.RemediationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.RemediationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.RemediationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.RemediationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(actionplan.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(actionplan.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(actionplan.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(actionplan.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(actionplan.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(actionplan.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(actionplan.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(actionplan.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[actionplan.FieldFileID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldFileID)
				fieldSeen[actionplan.FieldFileID] = struct{}{}
			}

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ActionPlan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"action_plan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(actionplan.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(actionplan.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ActionPlan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(actionplan.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[actionplan.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCreatedAt)
				fieldSeen[actionplan.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[actionplan.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldUpdatedAt)
				fieldSeen[actionplan.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[actionplan.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCreatedBy)
				fieldSeen[actionplan.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[actionplan.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldUpdatedBy)
				fieldSeen[actionplan.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[actionplan.FieldTags]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTags)
				fieldSeen[actionplan.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[actionplan.FieldRevision]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRevision)
				fieldSeen[actionplan.FieldRevision] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[actionplan.FieldName]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldName)
				fieldSeen[actionplan.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[actionplan.FieldStatus]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldStatus)
				fieldSeen[actionplan.FieldStatus] = struct{}{}
			}
		case "actionPlanType":
			if _, ok := fieldSeen[actionplan.FieldActionPlanType]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanType)
				fieldSeen[actionplan.FieldActionPlanType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[actionplan.FieldDetails]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDetails)
				fieldSeen[actionplan.FieldDetails] = struct{}{}
			}
		case "detailsJSON":
			if _, ok := fieldSeen[actionplan.FieldDetailsJSON]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDetailsJSON)
				fieldSeen[actionplan.FieldDetailsJSON] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[actionplan.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApprovalRequired)
				fieldSeen[actionplan.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[actionplan.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldReviewDue)
				fieldSeen[actionplan.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[actionplan.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldReviewFrequency)
				fieldSeen[actionplan.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[actionplan.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldApproverID)
				fieldSeen[actionplan.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[actionplan.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDelegateID)
				fieldSeen[actionplan.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[actionplan.FieldSummary]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSummary)
				fieldSeen[actionplan.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[actionplan.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTagSuggestions)
				fieldSeen[actionplan.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedTagSuggestions)
				fieldSeen[actionplan.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[actionplan.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldControlSuggestions)
				fieldSeen[actionplan.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedControlSuggestions)
				fieldSeen[actionplan.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[actionplan.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldImprovementSuggestions)
				fieldSeen[actionplan.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[actionplan.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDismissedImprovementSuggestions)
				fieldSeen[actionplan.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[actionplan.FieldURL]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldURL)
				fieldSeen[actionplan.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[actionplan.FieldFileID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldFileID)
				fieldSeen[actionplan.FieldFileID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[actionplan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldOwnerID)
				fieldSeen[actionplan.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[actionplan.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSystemOwned)
				fieldSeen[actionplan.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[actionplan.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldInternalNotes)
				fieldSeen[actionplan.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[actionplan.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSystemInternalID)
				fieldSeen[actionplan.FieldSystemInternalID] = struct{}{}
			}
		case "actionPlanKindName":
			if _, ok := fieldSeen[actionplan.FieldActionPlanKindName]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanKindName)
				fieldSeen[actionplan.FieldActionPlanKindName] = struct{}{}
			}
		case "actionPlanKindID":
			if _, ok := fieldSeen[actionplan.FieldActionPlanKindID]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldActionPlanKindID)
				fieldSeen[actionplan.FieldActionPlanKindID] = struct{}{}
			}
		case "workflowEligibleMarker":
			if _, ok := fieldSeen[actionplan.FieldWorkflowEligibleMarker]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldWorkflowEligibleMarker)
				fieldSeen[actionplan.FieldWorkflowEligibleMarker] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[actionplan.FieldTitle]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldTitle)
				fieldSeen[actionplan.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[actionplan.FieldDescription]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDescription)
				fieldSeen[actionplan.FieldDescription] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[actionplan.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldDueDate)
				fieldSeen[actionplan.FieldDueDate] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[actionplan.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldCompletedAt)
				fieldSeen[actionplan.FieldCompletedAt] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[actionplan.FieldPriority]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldPriority)
				fieldSeen[actionplan.FieldPriority] = struct{}{}
			}
		case "requiresApproval":
			if _, ok := fieldSeen[actionplan.FieldRequiresApproval]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRequiresApproval)
				fieldSeen[actionplan.FieldRequiresApproval] = struct{}{}
			}
		case "blocked":
			if _, ok := fieldSeen[actionplan.FieldBlocked]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldBlocked)
				fieldSeen[actionplan.FieldBlocked] = struct{}{}
			}
		case "blockerReason":
			if _, ok := fieldSeen[actionplan.FieldBlockerReason]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldBlockerReason)
				fieldSeen[actionplan.FieldBlockerReason] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[actionplan.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldMetadata)
				fieldSeen[actionplan.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[actionplan.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldRawPayload)
				fieldSeen[actionplan.FieldRawPayload] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[actionplan.FieldSource]; !ok {
				selectedFields = append(selectedFields, actionplan.FieldSource)
				fieldSeen[actionplan.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type actionplanPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ActionPlanPaginateOption
}

func newActionPlanPaginateArgs(rv map[string]any) *actionplanPaginateArgs {
	args := &actionplanPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ActionPlanOrder:
			args.opts = append(args.opts, WithActionPlanOrder(v))
		case []any:
			var orders []*ActionPlanOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ActionPlanOrder{Field: &ActionPlanOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithActionPlanOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ActionPlanWhereInput); ok {
		args.opts = append(args.opts, WithActionPlanFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssessmentQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssessmentQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssessmentQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assessment.Columns))
		selectedFields = []string{assessment.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[assessment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldOwnerID)
				fieldSeen[assessment.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(assessment.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.EditorsColumn), ids...))
						})
						if err := query.GroupBy(assessment.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.ViewersColumn), ids...))
						})
						if err := query.GroupBy(assessment.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			_q.withTemplate = query
			if _, ok := fieldSeen[assessment.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldTemplateID)
				fieldSeen[assessment.FieldTemplateID] = struct{}{}
			}

		case "assessmentResponses":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentResponseClient{config: _q.config}).Query()
			)
			args := newAssessmentResponsePaginateArgs(fieldArgs(ctx, new(AssessmentResponseWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentResponsePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Assessment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assessment_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(assessment.AssessmentResponsesColumn), ids...))
						})
						if err := query.GroupBy(assessment.AssessmentResponsesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Assessment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssessmentResponses)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentresponseImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(assessment.AssessmentResponsesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessmentResponses(alias, func(wq *AssessmentResponseQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[assessment.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assessment.FieldCreatedAt)
				fieldSeen[assessment.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assessment.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assessment.FieldUpdatedAt)
				fieldSeen[assessment.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assessment.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assessment.FieldCreatedBy)
				fieldSeen[assessment.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assessment.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assessment.FieldUpdatedBy)
				fieldSeen[assessment.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[assessment.FieldTags]; !ok {
				selectedFields = append(selectedFields, assessment.FieldTags)
				fieldSeen[assessment.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assessment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldOwnerID)
				fieldSeen[assessment.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[assessment.FieldName]; !ok {
				selectedFields = append(selectedFields, assessment.FieldName)
				fieldSeen[assessment.FieldName] = struct{}{}
			}
		case "assessmentType":
			if _, ok := fieldSeen[assessment.FieldAssessmentType]; !ok {
				selectedFields = append(selectedFields, assessment.FieldAssessmentType)
				fieldSeen[assessment.FieldAssessmentType] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[assessment.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, assessment.FieldTemplateID)
				fieldSeen[assessment.FieldTemplateID] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[assessment.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, assessment.FieldJsonconfig)
				fieldSeen[assessment.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[assessment.FieldUischema]; !ok {
				selectedFields = append(selectedFields, assessment.FieldUischema)
				fieldSeen[assessment.FieldUischema] = struct{}{}
			}
		case "responseDueDuration":
			if _, ok := fieldSeen[assessment.FieldResponseDueDuration]; !ok {
				selectedFields = append(selectedFields, assessment.FieldResponseDueDuration)
				fieldSeen[assessment.FieldResponseDueDuration] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assessmentPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssessmentPaginateOption
}

func newAssessmentPaginateArgs(rv map[string]any) *assessmentPaginateArgs {
	args := &assessmentPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssessmentOrder:
			args.opts = append(args.opts, WithAssessmentOrder(v))
		case []any:
			var orders []*AssessmentOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssessmentOrder{Field: &AssessmentOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssessmentOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssessmentWhereInput); ok {
		args.opts = append(args.opts, WithAssessmentFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssessmentResponseQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssessmentResponseQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssessmentResponseQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(assessmentresponse.Columns))
		selectedFields = []string{assessmentresponse.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[assessmentresponse.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldOwnerID)
				fieldSeen[assessmentresponse.FieldOwnerID] = struct{}{}
			}

		case "assessment":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, assessmentImplementors)...); err != nil {
				return err
			}
			_q.withAssessment = query
			if _, ok := fieldSeen[assessmentresponse.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldAssessmentID)
				fieldSeen[assessmentresponse.FieldAssessmentID] = struct{}{}
			}

		case "document":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
				return err
			}
			_q.withDocument = query
			if _, ok := fieldSeen[assessmentresponse.FieldDocumentDataID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldDocumentDataID)
				fieldSeen[assessmentresponse.FieldDocumentDataID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[assessmentresponse.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldCreatedAt)
				fieldSeen[assessmentresponse.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldUpdatedAt)
				fieldSeen[assessmentresponse.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[assessmentresponse.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldCreatedBy)
				fieldSeen[assessmentresponse.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[assessmentresponse.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldUpdatedBy)
				fieldSeen[assessmentresponse.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[assessmentresponse.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldOwnerID)
				fieldSeen[assessmentresponse.FieldOwnerID] = struct{}{}
			}
		case "assessmentID":
			if _, ok := fieldSeen[assessmentresponse.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldAssessmentID)
				fieldSeen[assessmentresponse.FieldAssessmentID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[assessmentresponse.FieldEmail]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldEmail)
				fieldSeen[assessmentresponse.FieldEmail] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[assessmentresponse.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldSendAttempts)
				fieldSeen[assessmentresponse.FieldSendAttempts] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[assessmentresponse.FieldStatus]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldStatus)
				fieldSeen[assessmentresponse.FieldStatus] = struct{}{}
			}
		case "assignedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldAssignedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldAssignedAt)
				fieldSeen[assessmentresponse.FieldAssignedAt] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldStartedAt)
				fieldSeen[assessmentresponse.FieldStartedAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[assessmentresponse.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldCompletedAt)
				fieldSeen[assessmentresponse.FieldCompletedAt] = struct{}{}
			}
		case "dueDate":
			if _, ok := fieldSeen[assessmentresponse.FieldDueDate]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldDueDate)
				fieldSeen[assessmentresponse.FieldDueDate] = struct{}{}
			}
		case "documentDataID":
			if _, ok := fieldSeen[assessmentresponse.FieldDocumentDataID]; !ok {
				selectedFields = append(selectedFields, assessmentresponse.FieldDocumentDataID)
				fieldSeen[assessmentresponse.FieldDocumentDataID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assessmentresponsePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssessmentResponsePaginateOption
}

func newAssessmentResponsePaginateArgs(rv map[string]any) *assessmentresponsePaginateArgs {
	args := &assessmentresponsePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssessmentResponseOrder:
			args.opts = append(args.opts, WithAssessmentResponseOrder(v))
		case []any:
			var orders []*AssessmentResponseOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssessmentResponseOrder{Field: &AssessmentResponseOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssessmentResponseOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssessmentResponseWhereInput); ok {
		args.opts = append(args.opts, WithAssessmentResponseFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *AssetQuery) CollectFields(ctx context.Context, satisfies ...string) (*AssetQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *AssetQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(asset.Columns))
		selectedFields = []string{asset.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[asset.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, asset.FieldOwnerID)
				fieldSeen[asset.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(asset.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.EditorsColumn), ids...))
						})
						if err := query.GroupBy(asset.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(asset.ViewersColumn), ids...))
						})
						if err := query.GroupBy(asset.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.ScansTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(asset.ScansPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.ScansPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.ScansPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.ScansPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ScansPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(asset.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Asset) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"asset_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(asset.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(asset.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(asset.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(asset.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(asset.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Asset) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(asset.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[asset.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, asset.FieldCreatedAt)
				fieldSeen[asset.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[asset.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, asset.FieldUpdatedAt)
				fieldSeen[asset.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[asset.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, asset.FieldCreatedBy)
				fieldSeen[asset.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[asset.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, asset.FieldUpdatedBy)
				fieldSeen[asset.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[asset.FieldTags]; !ok {
				selectedFields = append(selectedFields, asset.FieldTags)
				fieldSeen[asset.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[asset.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, asset.FieldOwnerID)
				fieldSeen[asset.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[asset.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, asset.FieldSystemOwned)
				fieldSeen[asset.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[asset.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, asset.FieldInternalNotes)
				fieldSeen[asset.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[asset.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, asset.FieldSystemInternalID)
				fieldSeen[asset.FieldSystemInternalID] = struct{}{}
			}
		case "assetType":
			if _, ok := fieldSeen[asset.FieldAssetType]; !ok {
				selectedFields = append(selectedFields, asset.FieldAssetType)
				fieldSeen[asset.FieldAssetType] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[asset.FieldName]; !ok {
				selectedFields = append(selectedFields, asset.FieldName)
				fieldSeen[asset.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[asset.FieldDescription]; !ok {
				selectedFields = append(selectedFields, asset.FieldDescription)
				fieldSeen[asset.FieldDescription] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[asset.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, asset.FieldIdentifier)
				fieldSeen[asset.FieldIdentifier] = struct{}{}
			}
		case "website":
			if _, ok := fieldSeen[asset.FieldWebsite]; !ok {
				selectedFields = append(selectedFields, asset.FieldWebsite)
				fieldSeen[asset.FieldWebsite] = struct{}{}
			}
		case "cpe":
			if _, ok := fieldSeen[asset.FieldCpe]; !ok {
				selectedFields = append(selectedFields, asset.FieldCpe)
				fieldSeen[asset.FieldCpe] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[asset.FieldCategories]; !ok {
				selectedFields = append(selectedFields, asset.FieldCategories)
				fieldSeen[asset.FieldCategories] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type assetPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []AssetPaginateOption
}

func newAssetPaginateArgs(rv map[string]any) *assetPaginateArgs {
	args := &assetPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*AssetOrder:
			args.opts = append(args.opts, WithAssetOrder(v))
		case []any:
			var orders []*AssetOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &AssetOrder{Field: &AssetOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithAssetOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*AssetWhereInput); ok {
		args.opts = append(args.opts, WithAssetFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ContactQuery) CollectFields(ctx context.Context, satisfies ...string) (*ContactQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ContactQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(contact.Columns))
		selectedFields = []string{contact.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[contact.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contact.FieldOwnerID)
				fieldSeen[contact.FieldOwnerID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Contact) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"contact_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(contact.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(contact.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(contact.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(contact.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(contact.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Contact) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(contact.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Contact) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"contact_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(contact.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(contact.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(contact.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(contact.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(contact.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Contact) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(contact.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[contact.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, contact.FieldCreatedAt)
				fieldSeen[contact.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[contact.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, contact.FieldUpdatedAt)
				fieldSeen[contact.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[contact.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, contact.FieldCreatedBy)
				fieldSeen[contact.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[contact.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, contact.FieldUpdatedBy)
				fieldSeen[contact.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[contact.FieldTags]; !ok {
				selectedFields = append(selectedFields, contact.FieldTags)
				fieldSeen[contact.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[contact.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, contact.FieldOwnerID)
				fieldSeen[contact.FieldOwnerID] = struct{}{}
			}
		case "fullName":
			if _, ok := fieldSeen[contact.FieldFullName]; !ok {
				selectedFields = append(selectedFields, contact.FieldFullName)
				fieldSeen[contact.FieldFullName] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[contact.FieldTitle]; !ok {
				selectedFields = append(selectedFields, contact.FieldTitle)
				fieldSeen[contact.FieldTitle] = struct{}{}
			}
		case "company":
			if _, ok := fieldSeen[contact.FieldCompany]; !ok {
				selectedFields = append(selectedFields, contact.FieldCompany)
				fieldSeen[contact.FieldCompany] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[contact.FieldEmail]; !ok {
				selectedFields = append(selectedFields, contact.FieldEmail)
				fieldSeen[contact.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[contact.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, contact.FieldPhoneNumber)
				fieldSeen[contact.FieldPhoneNumber] = struct{}{}
			}
		case "address":
			if _, ok := fieldSeen[contact.FieldAddress]; !ok {
				selectedFields = append(selectedFields, contact.FieldAddress)
				fieldSeen[contact.FieldAddress] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[contact.FieldStatus]; !ok {
				selectedFields = append(selectedFields, contact.FieldStatus)
				fieldSeen[contact.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type contactPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ContactPaginateOption
}

func newContactPaginateArgs(rv map[string]any) *contactPaginateArgs {
	args := &contactPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ContactOrder:
			args.opts = append(args.opts, WithContactOrder(v))
		case []any:
			var orders []*ContactOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ContactOrder{Field: &ContactOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithContactOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ContactWhereInput); ok {
		args.opts = append(args.opts, WithContactFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(control.Columns))
		selectedFields = []string{control.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(control.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(control.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(control.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(control.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(control.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(control.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(control.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(control.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(control.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.CommentsColumn), ids...))
						})
						if err := query.GroupBy(control.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "discussions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			args := newDiscussionPaginateArgs(fieldArgs(ctx, new(DiscussionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDiscussionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_discussions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.DiscussionsColumn), ids...))
						})
						if err := query.GroupBy(control.DiscussionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Discussions)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.DiscussionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDiscussions(alias, func(wq *DiscussionQuery) {
				*wq = *query
			})

		case "controlOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withControlOwner = query
			if _, ok := fieldSeen[control.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlOwnerID)
				fieldSeen[control.FieldControlOwnerID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[control.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, control.FieldDelegateID)
				fieldSeen[control.FieldDelegateID] = struct{}{}
			}

		case "responsibleParty":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			_q.withResponsibleParty = query
			if _, ok := fieldSeen[control.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, control.FieldResponsiblePartyID)
				fieldSeen[control.FieldResponsiblePartyID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[control.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldOwnerID)
				fieldSeen[control.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(control.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(control.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withControlKind = query
			if _, ok := fieldSeen[control.FieldControlKindID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlKindID)
				fieldSeen[control.FieldControlKindID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[control.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, control.FieldStandardID)
				fieldSeen[control.FieldStandardID] = struct{}{}
			}

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(control.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(control.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.ScansColumn), ids...))
						})
						if err := query.GroupBy(control.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.FindingsTable)
							s.Join(joinT).On(s.C(finding.FieldID), joinT.C(control.FindingsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.FindingsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.FindingsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.FindingsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.FindingsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(control.ControlImplementationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(control.ControlImplementationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(control.ControlImplementationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ControlImplementationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlImplementationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(control.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(control.ScheduledJobsTable)
							s.Join(joinT).On(s.C(scheduledjob.FieldID), joinT.C(control.ScheduledJobsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(control.ScheduledJobsPrimaryKey[1]), ids...))
							s.Select(joinT.C(control.ScheduledJobsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(control.ScheduledJobsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ScheduledJobsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(control.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "controlMappings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingControlClient{config: _q.config}).Query()
			)
			args := newFindingControlPaginateArgs(fieldArgs(ctx, new(FindingControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Control) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(control.ControlMappingsColumn), ids...))
						})
						if err := query.GroupBy(control.ControlMappingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Control) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlMappings)
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(control.ControlMappingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlMappings(alias, func(wq *FindingControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[control.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, control.FieldCreatedAt)
				fieldSeen[control.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[control.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, control.FieldUpdatedAt)
				fieldSeen[control.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[control.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, control.FieldCreatedBy)
				fieldSeen[control.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[control.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, control.FieldUpdatedBy)
				fieldSeen[control.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[control.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, control.FieldDisplayID)
				fieldSeen[control.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[control.FieldTags]; !ok {
				selectedFields = append(selectedFields, control.FieldTags)
				fieldSeen[control.FieldTags] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[control.FieldTitle]; !ok {
				selectedFields = append(selectedFields, control.FieldTitle)
				fieldSeen[control.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[control.FieldDescription]; !ok {
				selectedFields = append(selectedFields, control.FieldDescription)
				fieldSeen[control.FieldDescription] = struct{}{}
			}
		case "descriptionJSON":
			if _, ok := fieldSeen[control.FieldDescriptionJSON]; !ok {
				selectedFields = append(selectedFields, control.FieldDescriptionJSON)
				fieldSeen[control.FieldDescriptionJSON] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[control.FieldAliases]; !ok {
				selectedFields = append(selectedFields, control.FieldAliases)
				fieldSeen[control.FieldAliases] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[control.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceID)
				fieldSeen[control.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[control.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, control.FieldAuditorReferenceID)
				fieldSeen[control.FieldAuditorReferenceID] = struct{}{}
			}
		case "responsiblePartyID":
			if _, ok := fieldSeen[control.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, control.FieldResponsiblePartyID)
				fieldSeen[control.FieldResponsiblePartyID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[control.FieldStatus]; !ok {
				selectedFields = append(selectedFields, control.FieldStatus)
				fieldSeen[control.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[control.FieldSource]; !ok {
				selectedFields = append(selectedFields, control.FieldSource)
				fieldSeen[control.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[control.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceFramework)
				fieldSeen[control.FieldReferenceFramework] = struct{}{}
			}
		case "referenceFrameworkRevision":
			if _, ok := fieldSeen[control.FieldReferenceFrameworkRevision]; !ok {
				selectedFields = append(selectedFields, control.FieldReferenceFrameworkRevision)
				fieldSeen[control.FieldReferenceFrameworkRevision] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[control.FieldControlType]; !ok {
				selectedFields = append(selectedFields, control.FieldControlType)
				fieldSeen[control.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[control.FieldCategory]; !ok {
				selectedFields = append(selectedFields, control.FieldCategory)
				fieldSeen[control.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[control.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, control.FieldCategoryID)
				fieldSeen[control.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[control.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, control.FieldSubcategory)
				fieldSeen[control.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[control.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, control.FieldMappedCategories)
				fieldSeen[control.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[control.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, control.FieldAssessmentObjectives)
				fieldSeen[control.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[control.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, control.FieldAssessmentMethods)
				fieldSeen[control.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[control.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, control.FieldControlQuestions)
				fieldSeen[control.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[control.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, control.FieldImplementationGuidance)
				fieldSeen[control.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[control.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, control.FieldExampleEvidence)
				fieldSeen[control.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[control.FieldReferences]; !ok {
				selectedFields = append(selectedFields, control.FieldReferences)
				fieldSeen[control.FieldReferences] = struct{}{}
			}
		case "testingProcedures":
			if _, ok := fieldSeen[control.FieldTestingProcedures]; !ok {
				selectedFields = append(selectedFields, control.FieldTestingProcedures)
				fieldSeen[control.FieldTestingProcedures] = struct{}{}
			}
		case "evidenceRequests":
			if _, ok := fieldSeen[control.FieldEvidenceRequests]; !ok {
				selectedFields = append(selectedFields, control.FieldEvidenceRequests)
				fieldSeen[control.FieldEvidenceRequests] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[control.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlOwnerID)
				fieldSeen[control.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[control.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, control.FieldDelegateID)
				fieldSeen[control.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[control.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, control.FieldOwnerID)
				fieldSeen[control.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[control.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, control.FieldSystemOwned)
				fieldSeen[control.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[control.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, control.FieldInternalNotes)
				fieldSeen[control.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[control.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, control.FieldSystemInternalID)
				fieldSeen[control.FieldSystemInternalID] = struct{}{}
			}
		case "controlKindName":
			if _, ok := fieldSeen[control.FieldControlKindName]; !ok {
				selectedFields = append(selectedFields, control.FieldControlKindName)
				fieldSeen[control.FieldControlKindName] = struct{}{}
			}
		case "controlKindID":
			if _, ok := fieldSeen[control.FieldControlKindID]; !ok {
				selectedFields = append(selectedFields, control.FieldControlKindID)
				fieldSeen[control.FieldControlKindID] = struct{}{}
			}
		case "workflowEligibleMarker":
			if _, ok := fieldSeen[control.FieldWorkflowEligibleMarker]; !ok {
				selectedFields = append(selectedFields, control.FieldWorkflowEligibleMarker)
				fieldSeen[control.FieldWorkflowEligibleMarker] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[control.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, control.FieldRefCode)
				fieldSeen[control.FieldRefCode] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[control.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, control.FieldStandardID)
				fieldSeen[control.FieldStandardID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlPaginateOption
}

func newControlPaginateArgs(rv map[string]any) *controlPaginateArgs {
	args := &controlPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlOrder:
			args.opts = append(args.opts, WithControlOrder(v))
		case []any:
			var orders []*ControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlOrder{Field: &ControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlWhereInput); ok {
		args.opts = append(args.opts, WithControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlImplementationQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlImplementationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlImplementationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlimplementation.Columns))
		selectedFields = []string{controlimplementation.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[controlimplementation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldOwnerID)
				fieldSeen[controlimplementation.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlimplementation.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlimplementation.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlimplementation.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlimplementation.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlimplementation.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlImplementation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_implementation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlimplementation.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(controlimplementation.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlimplementation.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlimplementation.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlimplementation.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlImplementation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlimplementation.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[controlimplementation.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldCreatedAt)
				fieldSeen[controlimplementation.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlimplementation.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldUpdatedAt)
				fieldSeen[controlimplementation.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlimplementation.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldCreatedBy)
				fieldSeen[controlimplementation.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlimplementation.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldUpdatedBy)
				fieldSeen[controlimplementation.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlimplementation.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldTags)
				fieldSeen[controlimplementation.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlimplementation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldOwnerID)
				fieldSeen[controlimplementation.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlimplementation.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldSystemOwned)
				fieldSeen[controlimplementation.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlimplementation.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldInternalNotes)
				fieldSeen[controlimplementation.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlimplementation.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldSystemInternalID)
				fieldSeen[controlimplementation.FieldSystemInternalID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlimplementation.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldStatus)
				fieldSeen[controlimplementation.FieldStatus] = struct{}{}
			}
		case "implementationDate":
			if _, ok := fieldSeen[controlimplementation.FieldImplementationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldImplementationDate)
				fieldSeen[controlimplementation.FieldImplementationDate] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[controlimplementation.FieldVerified]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldVerified)
				fieldSeen[controlimplementation.FieldVerified] = struct{}{}
			}
		case "verificationDate":
			if _, ok := fieldSeen[controlimplementation.FieldVerificationDate]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldVerificationDate)
				fieldSeen[controlimplementation.FieldVerificationDate] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[controlimplementation.FieldDetails]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldDetails)
				fieldSeen[controlimplementation.FieldDetails] = struct{}{}
			}
		case "detailsJSON":
			if _, ok := fieldSeen[controlimplementation.FieldDetailsJSON]; !ok {
				selectedFields = append(selectedFields, controlimplementation.FieldDetailsJSON)
				fieldSeen[controlimplementation.FieldDetailsJSON] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlimplementationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlImplementationPaginateOption
}

func newControlImplementationPaginateArgs(rv map[string]any) *controlimplementationPaginateArgs {
	args := &controlimplementationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlImplementationOrder:
			args.opts = append(args.opts, WithControlImplementationOrder(v))
		case []any:
			var orders []*ControlImplementationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlImplementationOrder{Field: &ControlImplementationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlImplementationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlImplementationWhereInput); ok {
		args.opts = append(args.opts, WithControlImplementationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ControlObjectiveQuery) CollectFields(ctx context.Context, satisfies ...string) (*ControlObjectiveQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ControlObjectiveQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(controlobjective.Columns))
		selectedFields = []string{controlobjective.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[controlobjective.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldOwnerID)
				fieldSeen[controlobjective.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(controlobjective.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(controlobjective.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(controlobjective.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(controlobjective.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(controlobjective.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(controlobjective.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_procedures"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.RisksColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_narratives"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(controlobjective.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(controlobjective.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ControlObjective) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"control_objective_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(controlobjective.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(controlobjective.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(controlobjective.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(controlobjective.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(controlobjective.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ControlObjective) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(controlobjective.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[controlobjective.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCreatedAt)
				fieldSeen[controlobjective.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[controlobjective.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldUpdatedAt)
				fieldSeen[controlobjective.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[controlobjective.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCreatedBy)
				fieldSeen[controlobjective.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[controlobjective.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldUpdatedBy)
				fieldSeen[controlobjective.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[controlobjective.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDisplayID)
				fieldSeen[controlobjective.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[controlobjective.FieldTags]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldTags)
				fieldSeen[controlobjective.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[controlobjective.FieldRevision]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldRevision)
				fieldSeen[controlobjective.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[controlobjective.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldOwnerID)
				fieldSeen[controlobjective.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[controlobjective.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSystemOwned)
				fieldSeen[controlobjective.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[controlobjective.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldInternalNotes)
				fieldSeen[controlobjective.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[controlobjective.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSystemInternalID)
				fieldSeen[controlobjective.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[controlobjective.FieldName]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldName)
				fieldSeen[controlobjective.FieldName] = struct{}{}
			}
		case "desiredOutcome":
			if _, ok := fieldSeen[controlobjective.FieldDesiredOutcome]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDesiredOutcome)
				fieldSeen[controlobjective.FieldDesiredOutcome] = struct{}{}
			}
		case "desiredOutcomeJSON":
			if _, ok := fieldSeen[controlobjective.FieldDesiredOutcomeJSON]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldDesiredOutcomeJSON)
				fieldSeen[controlobjective.FieldDesiredOutcomeJSON] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[controlobjective.FieldStatus]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldStatus)
				fieldSeen[controlobjective.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[controlobjective.FieldSource]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSource)
				fieldSeen[controlobjective.FieldSource] = struct{}{}
			}
		case "controlObjectiveType":
			if _, ok := fieldSeen[controlobjective.FieldControlObjectiveType]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldControlObjectiveType)
				fieldSeen[controlobjective.FieldControlObjectiveType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[controlobjective.FieldCategory]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldCategory)
				fieldSeen[controlobjective.FieldCategory] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[controlobjective.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, controlobjective.FieldSubcategory)
				fieldSeen[controlobjective.FieldSubcategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type controlobjectivePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ControlObjectivePaginateOption
}

func newControlObjectivePaginateArgs(rv map[string]any) *controlobjectivePaginateArgs {
	args := &controlobjectivePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ControlObjectiveOrder:
			args.opts = append(args.opts, WithControlObjectiveOrder(v))
		case []any:
			var orders []*ControlObjectiveOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ControlObjectiveOrder{Field: &ControlObjectiveOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithControlObjectiveOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ControlObjectiveWhereInput); ok {
		args.opts = append(args.opts, WithControlObjectiveFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *CustomDomainQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomDomainQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *CustomDomainQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customdomain.Columns))
		selectedFields = []string{customdomain.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[customdomain.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldOwnerID)
				fieldSeen[customdomain.FieldOwnerID] = struct{}{}
			}

		case "mappableDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappableDomainClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, mappabledomainImplementors)...); err != nil {
				return err
			}
			_q.withMappableDomain = query
			if _, ok := fieldSeen[customdomain.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldMappableDomainID)
				fieldSeen[customdomain.FieldMappableDomainID] = struct{}{}
			}

		case "dnsVerification":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DNSVerificationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, dnsverificationImplementors)...); err != nil {
				return err
			}
			_q.withDNSVerification = query
			if _, ok := fieldSeen[customdomain.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldDNSVerificationID)
				fieldSeen[customdomain.FieldDNSVerificationID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[customdomain.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCreatedAt)
				fieldSeen[customdomain.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customdomain.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldUpdatedAt)
				fieldSeen[customdomain.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customdomain.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCreatedBy)
				fieldSeen[customdomain.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customdomain.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldUpdatedBy)
				fieldSeen[customdomain.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[customdomain.FieldTags]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldTags)
				fieldSeen[customdomain.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customdomain.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldOwnerID)
				fieldSeen[customdomain.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[customdomain.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldSystemOwned)
				fieldSeen[customdomain.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[customdomain.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldInternalNotes)
				fieldSeen[customdomain.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[customdomain.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldSystemInternalID)
				fieldSeen[customdomain.FieldSystemInternalID] = struct{}{}
			}
		case "cnameRecord":
			if _, ok := fieldSeen[customdomain.FieldCnameRecord]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldCnameRecord)
				fieldSeen[customdomain.FieldCnameRecord] = struct{}{}
			}
		case "mappableDomainID":
			if _, ok := fieldSeen[customdomain.FieldMappableDomainID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldMappableDomainID)
				fieldSeen[customdomain.FieldMappableDomainID] = struct{}{}
			}
		case "dnsVerificationID":
			if _, ok := fieldSeen[customdomain.FieldDNSVerificationID]; !ok {
				selectedFields = append(selectedFields, customdomain.FieldDNSVerificationID)
				fieldSeen[customdomain.FieldDNSVerificationID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type customdomainPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomDomainPaginateOption
}

func newCustomDomainPaginateArgs(rv map[string]any) *customdomainPaginateArgs {
	args := &customdomainPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*CustomDomainOrder:
			args.opts = append(args.opts, WithCustomDomainOrder(v))
		case []any:
			var orders []*CustomDomainOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &CustomDomainOrder{Field: &CustomDomainOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithCustomDomainOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*CustomDomainWhereInput); ok {
		args.opts = append(args.opts, WithCustomDomainFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *CustomTypeEnumQuery) CollectFields(ctx context.Context, satisfies ...string) (*CustomTypeEnumQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *CustomTypeEnumQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(customtypeenum.Columns))
		selectedFields = []string{customtypeenum.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[customtypeenum.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldOwnerID)
				fieldSeen[customtypeenum.FieldOwnerID] = struct{}{}
			}

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.TasksColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ControlsColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.RisksColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskCategories":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_risk_categories"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.RiskCategoriesColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.RiskCategoriesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskCategories)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.RiskCategoriesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskCategories(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_internal_policies"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.InternalPoliciesColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.InternalPoliciesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.InternalPoliciesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_procedures"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*CustomTypeEnum) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"custom_type_enum_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(customtypeenum.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(customtypeenum.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*CustomTypeEnum) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(customtypeenum.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[customtypeenum.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldCreatedAt)
				fieldSeen[customtypeenum.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[customtypeenum.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldUpdatedAt)
				fieldSeen[customtypeenum.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[customtypeenum.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldCreatedBy)
				fieldSeen[customtypeenum.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[customtypeenum.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldUpdatedBy)
				fieldSeen[customtypeenum.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[customtypeenum.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldOwnerID)
				fieldSeen[customtypeenum.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[customtypeenum.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldSystemOwned)
				fieldSeen[customtypeenum.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[customtypeenum.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldInternalNotes)
				fieldSeen[customtypeenum.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[customtypeenum.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldSystemInternalID)
				fieldSeen[customtypeenum.FieldSystemInternalID] = struct{}{}
			}
		case "objectType":
			if _, ok := fieldSeen[customtypeenum.FieldObjectType]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldObjectType)
				fieldSeen[customtypeenum.FieldObjectType] = struct{}{}
			}
		case "field":
			if _, ok := fieldSeen[customtypeenum.FieldField]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldField)
				fieldSeen[customtypeenum.FieldField] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[customtypeenum.FieldName]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldName)
				fieldSeen[customtypeenum.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[customtypeenum.FieldDescription]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldDescription)
				fieldSeen[customtypeenum.FieldDescription] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[customtypeenum.FieldColor]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldColor)
				fieldSeen[customtypeenum.FieldColor] = struct{}{}
			}
		case "icon":
			if _, ok := fieldSeen[customtypeenum.FieldIcon]; !ok {
				selectedFields = append(selectedFields, customtypeenum.FieldIcon)
				fieldSeen[customtypeenum.FieldIcon] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type customtypeenumPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []CustomTypeEnumPaginateOption
}

func newCustomTypeEnumPaginateArgs(rv map[string]any) *customtypeenumPaginateArgs {
	args := &customtypeenumPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*CustomTypeEnumOrder:
			args.opts = append(args.opts, WithCustomTypeEnumOrder(v))
		case []any:
			var orders []*CustomTypeEnumOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &CustomTypeEnumOrder{Field: &CustomTypeEnumOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithCustomTypeEnumOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*CustomTypeEnumWhereInput); ok {
		args.opts = append(args.opts, WithCustomTypeEnumFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DNSVerificationQuery) CollectFields(ctx context.Context, satisfies ...string) (*DNSVerificationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DNSVerificationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(dnsverification.Columns))
		selectedFields = []string{dnsverification.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[dnsverification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldOwnerID)
				fieldSeen[dnsverification.FieldOwnerID] = struct{}{}
			}

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DNSVerification) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"dns_verification_custom_domains"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(dnsverification.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(dnsverification.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DNSVerification) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(dnsverification.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[dnsverification.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCreatedAt)
				fieldSeen[dnsverification.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[dnsverification.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldUpdatedAt)
				fieldSeen[dnsverification.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[dnsverification.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCreatedBy)
				fieldSeen[dnsverification.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[dnsverification.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldUpdatedBy)
				fieldSeen[dnsverification.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[dnsverification.FieldTags]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldTags)
				fieldSeen[dnsverification.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[dnsverification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldOwnerID)
				fieldSeen[dnsverification.FieldOwnerID] = struct{}{}
			}
		case "cloudflareHostnameID":
			if _, ok := fieldSeen[dnsverification.FieldCloudflareHostnameID]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldCloudflareHostnameID)
				fieldSeen[dnsverification.FieldCloudflareHostnameID] = struct{}{}
			}
		case "dnsTxtRecord":
			if _, ok := fieldSeen[dnsverification.FieldDNSTxtRecord]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSTxtRecord)
				fieldSeen[dnsverification.FieldDNSTxtRecord] = struct{}{}
			}
		case "dnsTxtValue":
			if _, ok := fieldSeen[dnsverification.FieldDNSTxtValue]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSTxtValue)
				fieldSeen[dnsverification.FieldDNSTxtValue] = struct{}{}
			}
		case "dnsVerificationStatus":
			if _, ok := fieldSeen[dnsverification.FieldDNSVerificationStatus]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSVerificationStatus)
				fieldSeen[dnsverification.FieldDNSVerificationStatus] = struct{}{}
			}
		case "dnsVerificationStatusReason":
			if _, ok := fieldSeen[dnsverification.FieldDNSVerificationStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldDNSVerificationStatusReason)
				fieldSeen[dnsverification.FieldDNSVerificationStatusReason] = struct{}{}
			}
		case "acmeChallengePath":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengePath]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengePath)
				fieldSeen[dnsverification.FieldAcmeChallengePath] = struct{}{}
			}
		case "expectedAcmeChallengeValue":
			if _, ok := fieldSeen[dnsverification.FieldExpectedAcmeChallengeValue]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldExpectedAcmeChallengeValue)
				fieldSeen[dnsverification.FieldExpectedAcmeChallengeValue] = struct{}{}
			}
		case "acmeChallengeStatus":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengeStatus]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengeStatus)
				fieldSeen[dnsverification.FieldAcmeChallengeStatus] = struct{}{}
			}
		case "acmeChallengeStatusReason":
			if _, ok := fieldSeen[dnsverification.FieldAcmeChallengeStatusReason]; !ok {
				selectedFields = append(selectedFields, dnsverification.FieldAcmeChallengeStatusReason)
				fieldSeen[dnsverification.FieldAcmeChallengeStatusReason] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type dnsverificationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DNSVerificationPaginateOption
}

func newDNSVerificationPaginateArgs(rv map[string]any) *dnsverificationPaginateArgs {
	args := &dnsverificationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DNSVerificationOrder:
			args.opts = append(args.opts, WithDNSVerificationOrder(v))
		case []any:
			var orders []*DNSVerificationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DNSVerificationOrder{Field: &DNSVerificationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDNSVerificationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DNSVerificationWhereInput); ok {
		args.opts = append(args.opts, WithDNSVerificationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryAccountQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryAccountQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryAccountQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directoryaccount.Columns))
		selectedFields = []string{directoryaccount.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directoryaccount.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldOwnerID)
				fieldSeen[directoryaccount.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directoryaccount.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldIntegrationID)
				fieldSeen[directoryaccount.FieldIntegrationID] = struct{}{}
			}

		case "directorySyncRun":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
				return err
			}
			_q.withDirectorySyncRun = query
			if _, ok := fieldSeen[directoryaccount.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDirectorySyncRunID)
				fieldSeen[directoryaccount.FieldDirectorySyncRunID] = struct{}{}
			}

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryAccount) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_account_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(directoryaccount.GroupsTable)
							s.Join(joinT).On(s.C(directorygroup.FieldID), joinT.C(directoryaccount.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(directoryaccount.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(directoryaccount.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(directoryaccount.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryAccount) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directoryaccount.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryAccount) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_account_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directoryaccount.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(directoryaccount.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryAccount) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directoryaccount.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "memberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryAccount) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_account_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directoryaccount.MembershipsColumn), ids...))
						})
						if err := query.GroupBy(directoryaccount.MembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryAccount) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Memberships)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directoryaccount.MembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directoryaccount.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldCreatedAt)
				fieldSeen[directoryaccount.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directoryaccount.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldUpdatedAt)
				fieldSeen[directoryaccount.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directoryaccount.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldCreatedBy)
				fieldSeen[directoryaccount.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directoryaccount.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldUpdatedBy)
				fieldSeen[directoryaccount.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directoryaccount.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDisplayID)
				fieldSeen[directoryaccount.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[directoryaccount.FieldTags]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldTags)
				fieldSeen[directoryaccount.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directoryaccount.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldOwnerID)
				fieldSeen[directoryaccount.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directoryaccount.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldIntegrationID)
				fieldSeen[directoryaccount.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directoryaccount.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDirectorySyncRunID)
				fieldSeen[directoryaccount.FieldDirectorySyncRunID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[directoryaccount.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldExternalID)
				fieldSeen[directoryaccount.FieldExternalID] = struct{}{}
			}
		case "secondaryKey":
			if _, ok := fieldSeen[directoryaccount.FieldSecondaryKey]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldSecondaryKey)
				fieldSeen[directoryaccount.FieldSecondaryKey] = struct{}{}
			}
		case "canonicalEmail":
			if _, ok := fieldSeen[directoryaccount.FieldCanonicalEmail]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldCanonicalEmail)
				fieldSeen[directoryaccount.FieldCanonicalEmail] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[directoryaccount.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDisplayName)
				fieldSeen[directoryaccount.FieldDisplayName] = struct{}{}
			}
		case "givenName":
			if _, ok := fieldSeen[directoryaccount.FieldGivenName]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldGivenName)
				fieldSeen[directoryaccount.FieldGivenName] = struct{}{}
			}
		case "familyName":
			if _, ok := fieldSeen[directoryaccount.FieldFamilyName]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldFamilyName)
				fieldSeen[directoryaccount.FieldFamilyName] = struct{}{}
			}
		case "jobTitle":
			if _, ok := fieldSeen[directoryaccount.FieldJobTitle]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldJobTitle)
				fieldSeen[directoryaccount.FieldJobTitle] = struct{}{}
			}
		case "department":
			if _, ok := fieldSeen[directoryaccount.FieldDepartment]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldDepartment)
				fieldSeen[directoryaccount.FieldDepartment] = struct{}{}
			}
		case "organizationUnit":
			if _, ok := fieldSeen[directoryaccount.FieldOrganizationUnit]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldOrganizationUnit)
				fieldSeen[directoryaccount.FieldOrganizationUnit] = struct{}{}
			}
		case "accountType":
			if _, ok := fieldSeen[directoryaccount.FieldAccountType]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldAccountType)
				fieldSeen[directoryaccount.FieldAccountType] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directoryaccount.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldStatus)
				fieldSeen[directoryaccount.FieldStatus] = struct{}{}
			}
		case "mfaState":
			if _, ok := fieldSeen[directoryaccount.FieldMfaState]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldMfaState)
				fieldSeen[directoryaccount.FieldMfaState] = struct{}{}
			}
		case "lastSeenIP":
			if _, ok := fieldSeen[directoryaccount.FieldLastSeenIP]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldLastSeenIP)
				fieldSeen[directoryaccount.FieldLastSeenIP] = struct{}{}
			}
		case "lastLoginAt":
			if _, ok := fieldSeen[directoryaccount.FieldLastLoginAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldLastLoginAt)
				fieldSeen[directoryaccount.FieldLastLoginAt] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directoryaccount.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldObservedAt)
				fieldSeen[directoryaccount.FieldObservedAt] = struct{}{}
			}
		case "profileHash":
			if _, ok := fieldSeen[directoryaccount.FieldProfileHash]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldProfileHash)
				fieldSeen[directoryaccount.FieldProfileHash] = struct{}{}
			}
		case "profile":
			if _, ok := fieldSeen[directoryaccount.FieldProfile]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldProfile)
				fieldSeen[directoryaccount.FieldProfile] = struct{}{}
			}
		case "rawProfileFileID":
			if _, ok := fieldSeen[directoryaccount.FieldRawProfileFileID]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldRawProfileFileID)
				fieldSeen[directoryaccount.FieldRawProfileFileID] = struct{}{}
			}
		case "sourceVersion":
			if _, ok := fieldSeen[directoryaccount.FieldSourceVersion]; !ok {
				selectedFields = append(selectedFields, directoryaccount.FieldSourceVersion)
				fieldSeen[directoryaccount.FieldSourceVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directoryaccountPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryAccountPaginateOption
}

func newDirectoryAccountPaginateArgs(rv map[string]any) *directoryaccountPaginateArgs {
	args := &directoryaccountPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectoryAccountOrder:
			args.opts = append(args.opts, WithDirectoryAccountOrder(v))
		case []any:
			var orders []*DirectoryAccountOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectoryAccountOrder{Field: &DirectoryAccountOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectoryAccountOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectoryAccountWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryAccountFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryGroupQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryGroupQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryGroupQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorygroup.Columns))
		selectedFields = []string{directorygroup.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directorygroup.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldOwnerID)
				fieldSeen[directorygroup.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directorygroup.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldIntegrationID)
				fieldSeen[directorygroup.FieldIntegrationID] = struct{}{}
			}

		case "directorySyncRun":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
				return err
			}
			_q.withDirectorySyncRun = query
			if _, ok := fieldSeen[directorygroup.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDirectorySyncRunID)
				fieldSeen[directorygroup.FieldDirectorySyncRunID] = struct{}{}
			}

		case "accounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryGroup) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(directorygroup.AccountsTable)
							s.Join(joinT).On(s.C(directoryaccount.FieldID), joinT.C(directorygroup.AccountsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(directorygroup.AccountsPrimaryKey[1]), ids...))
							s.Select(joinT.C(directorygroup.AccountsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(directorygroup.AccountsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryGroup) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Accounts)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorygroup.AccountsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryGroup) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorygroup.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(directorygroup.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryGroup) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorygroup.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryGroup) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorygroup.MembersColumn), ids...))
						})
						if err := query.GroupBy(directorygroup.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryGroup) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorygroup.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directorygroup.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldCreatedAt)
				fieldSeen[directorygroup.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorygroup.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldUpdatedAt)
				fieldSeen[directorygroup.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorygroup.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldCreatedBy)
				fieldSeen[directorygroup.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorygroup.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldUpdatedBy)
				fieldSeen[directorygroup.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorygroup.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDisplayID)
				fieldSeen[directorygroup.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[directorygroup.FieldTags]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldTags)
				fieldSeen[directorygroup.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorygroup.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldOwnerID)
				fieldSeen[directorygroup.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorygroup.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldIntegrationID)
				fieldSeen[directorygroup.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directorygroup.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDirectorySyncRunID)
				fieldSeen[directorygroup.FieldDirectorySyncRunID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[directorygroup.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldExternalID)
				fieldSeen[directorygroup.FieldExternalID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[directorygroup.FieldEmail]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldEmail)
				fieldSeen[directorygroup.FieldEmail] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[directorygroup.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDisplayName)
				fieldSeen[directorygroup.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[directorygroup.FieldDescription]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldDescription)
				fieldSeen[directorygroup.FieldDescription] = struct{}{}
			}
		case "classification":
			if _, ok := fieldSeen[directorygroup.FieldClassification]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldClassification)
				fieldSeen[directorygroup.FieldClassification] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directorygroup.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldStatus)
				fieldSeen[directorygroup.FieldStatus] = struct{}{}
			}
		case "externalSharingAllowed":
			if _, ok := fieldSeen[directorygroup.FieldExternalSharingAllowed]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldExternalSharingAllowed)
				fieldSeen[directorygroup.FieldExternalSharingAllowed] = struct{}{}
			}
		case "memberCount":
			if _, ok := fieldSeen[directorygroup.FieldMemberCount]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldMemberCount)
				fieldSeen[directorygroup.FieldMemberCount] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directorygroup.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldObservedAt)
				fieldSeen[directorygroup.FieldObservedAt] = struct{}{}
			}
		case "profileHash":
			if _, ok := fieldSeen[directorygroup.FieldProfileHash]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldProfileHash)
				fieldSeen[directorygroup.FieldProfileHash] = struct{}{}
			}
		case "profile":
			if _, ok := fieldSeen[directorygroup.FieldProfile]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldProfile)
				fieldSeen[directorygroup.FieldProfile] = struct{}{}
			}
		case "rawProfileFileID":
			if _, ok := fieldSeen[directorygroup.FieldRawProfileFileID]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldRawProfileFileID)
				fieldSeen[directorygroup.FieldRawProfileFileID] = struct{}{}
			}
		case "sourceVersion":
			if _, ok := fieldSeen[directorygroup.FieldSourceVersion]; !ok {
				selectedFields = append(selectedFields, directorygroup.FieldSourceVersion)
				fieldSeen[directorygroup.FieldSourceVersion] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorygroupPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryGroupPaginateOption
}

func newDirectoryGroupPaginateArgs(rv map[string]any) *directorygroupPaginateArgs {
	args := &directorygroupPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectoryGroupOrder:
			args.opts = append(args.opts, WithDirectoryGroupOrder(v))
		case []any:
			var orders []*DirectoryGroupOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectoryGroupOrder{Field: &DirectoryGroupOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectoryGroupOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectoryGroupWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryGroupFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectoryMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectoryMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectoryMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorymembership.Columns))
		selectedFields = []string{directorymembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directorymembership.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldOwnerID)
				fieldSeen[directorymembership.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directorymembership.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldIntegrationID)
				fieldSeen[directorymembership.FieldIntegrationID] = struct{}{}
			}

		case "directorySyncRun":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
				return err
			}
			_q.withDirectorySyncRun = query
			if _, ok := fieldSeen[directorymembership.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectorySyncRunID)
				fieldSeen[directorymembership.FieldDirectorySyncRunID] = struct{}{}
			}

		case "directoryAccount":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryAccount = query
			if _, ok := fieldSeen[directorymembership.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryAccountID)
				fieldSeen[directorymembership.FieldDirectoryAccountID] = struct{}{}
			}

		case "directoryGroup":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryGroup = query
			if _, ok := fieldSeen[directorymembership.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryGroupID)
				fieldSeen[directorymembership.FieldDirectoryGroupID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_membership_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorymembership.EventsColumn), ids...))
						})
						if err := query.GroupBy(directorymembership.EventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorymembership.EventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectoryMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorymembership.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(directorymembership.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectoryMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorymembership.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directorymembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldCreatedAt)
				fieldSeen[directorymembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorymembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldUpdatedAt)
				fieldSeen[directorymembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorymembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldCreatedBy)
				fieldSeen[directorymembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorymembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldUpdatedBy)
				fieldSeen[directorymembership.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorymembership.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDisplayID)
				fieldSeen[directorymembership.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorymembership.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldOwnerID)
				fieldSeen[directorymembership.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorymembership.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldIntegrationID)
				fieldSeen[directorymembership.FieldIntegrationID] = struct{}{}
			}
		case "directorySyncRunID":
			if _, ok := fieldSeen[directorymembership.FieldDirectorySyncRunID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectorySyncRunID)
				fieldSeen[directorymembership.FieldDirectorySyncRunID] = struct{}{}
			}
		case "directoryAccountID":
			if _, ok := fieldSeen[directorymembership.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryAccountID)
				fieldSeen[directorymembership.FieldDirectoryAccountID] = struct{}{}
			}
		case "directoryGroupID":
			if _, ok := fieldSeen[directorymembership.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldDirectoryGroupID)
				fieldSeen[directorymembership.FieldDirectoryGroupID] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[directorymembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldRole)
				fieldSeen[directorymembership.FieldRole] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[directorymembership.FieldSource]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldSource)
				fieldSeen[directorymembership.FieldSource] = struct{}{}
			}
		case "firstSeenAt":
			if _, ok := fieldSeen[directorymembership.FieldFirstSeenAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldFirstSeenAt)
				fieldSeen[directorymembership.FieldFirstSeenAt] = struct{}{}
			}
		case "lastSeenAt":
			if _, ok := fieldSeen[directorymembership.FieldLastSeenAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldLastSeenAt)
				fieldSeen[directorymembership.FieldLastSeenAt] = struct{}{}
			}
		case "observedAt":
			if _, ok := fieldSeen[directorymembership.FieldObservedAt]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldObservedAt)
				fieldSeen[directorymembership.FieldObservedAt] = struct{}{}
			}
		case "lastConfirmedRunID":
			if _, ok := fieldSeen[directorymembership.FieldLastConfirmedRunID]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldLastConfirmedRunID)
				fieldSeen[directorymembership.FieldLastConfirmedRunID] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[directorymembership.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, directorymembership.FieldMetadata)
				fieldSeen[directorymembership.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorymembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectoryMembershipPaginateOption
}

func newDirectoryMembershipPaginateArgs(rv map[string]any) *directorymembershipPaginateArgs {
	args := &directorymembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectoryMembershipOrder:
			args.opts = append(args.opts, WithDirectoryMembershipOrder(v))
		case []any:
			var orders []*DirectoryMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectoryMembershipOrder{Field: &DirectoryMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectoryMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectoryMembershipWhereInput); ok {
		args.opts = append(args.opts, WithDirectoryMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DirectorySyncRunQuery) CollectFields(ctx context.Context, satisfies ...string) (*DirectorySyncRunQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DirectorySyncRunQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(directorysyncrun.Columns))
		selectedFields = []string{directorysyncrun.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[directorysyncrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldOwnerID)
				fieldSeen[directorysyncrun.FieldOwnerID] = struct{}{}
			}

		case "integration":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
				return err
			}
			_q.withIntegration = query
			if _, ok := fieldSeen[directorysyncrun.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldIntegrationID)
				fieldSeen[directorysyncrun.FieldIntegrationID] = struct{}{}
			}

		case "directoryAccounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectorySyncRun) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_sync_run_directory_accounts"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorysyncrun.DirectoryAccountsColumn), ids...))
						})
						if err := query.GroupBy(directorysyncrun.DirectoryAccountsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectorySyncRun) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryAccounts)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorysyncrun.DirectoryAccountsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "directoryGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectorySyncRun) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_sync_run_directory_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorysyncrun.DirectoryGroupsColumn), ids...))
						})
						if err := query.GroupBy(directorysyncrun.DirectoryGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectorySyncRun) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryGroups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorysyncrun.DirectoryGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "directoryMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DirectorySyncRun) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"directory_sync_run_directory_memberships"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(directorysyncrun.DirectoryMembershipsColumn), ids...))
						})
						if err := query.GroupBy(directorysyncrun.DirectoryMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DirectorySyncRun) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryMemberships)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(directorysyncrun.DirectoryMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[directorysyncrun.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldCreatedAt)
				fieldSeen[directorysyncrun.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[directorysyncrun.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldUpdatedAt)
				fieldSeen[directorysyncrun.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[directorysyncrun.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldCreatedBy)
				fieldSeen[directorysyncrun.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[directorysyncrun.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldUpdatedBy)
				fieldSeen[directorysyncrun.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[directorysyncrun.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldDisplayID)
				fieldSeen[directorysyncrun.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[directorysyncrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldOwnerID)
				fieldSeen[directorysyncrun.FieldOwnerID] = struct{}{}
			}
		case "integrationID":
			if _, ok := fieldSeen[directorysyncrun.FieldIntegrationID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldIntegrationID)
				fieldSeen[directorysyncrun.FieldIntegrationID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[directorysyncrun.FieldStatus]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldStatus)
				fieldSeen[directorysyncrun.FieldStatus] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[directorysyncrun.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldStartedAt)
				fieldSeen[directorysyncrun.FieldStartedAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[directorysyncrun.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldCompletedAt)
				fieldSeen[directorysyncrun.FieldCompletedAt] = struct{}{}
			}
		case "sourceCursor":
			if _, ok := fieldSeen[directorysyncrun.FieldSourceCursor]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldSourceCursor)
				fieldSeen[directorysyncrun.FieldSourceCursor] = struct{}{}
			}
		case "fullCount":
			if _, ok := fieldSeen[directorysyncrun.FieldFullCount]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldFullCount)
				fieldSeen[directorysyncrun.FieldFullCount] = struct{}{}
			}
		case "deltaCount":
			if _, ok := fieldSeen[directorysyncrun.FieldDeltaCount]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldDeltaCount)
				fieldSeen[directorysyncrun.FieldDeltaCount] = struct{}{}
			}
		case "error":
			if _, ok := fieldSeen[directorysyncrun.FieldError]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldError)
				fieldSeen[directorysyncrun.FieldError] = struct{}{}
			}
		case "rawManifestFileID":
			if _, ok := fieldSeen[directorysyncrun.FieldRawManifestFileID]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldRawManifestFileID)
				fieldSeen[directorysyncrun.FieldRawManifestFileID] = struct{}{}
			}
		case "stats":
			if _, ok := fieldSeen[directorysyncrun.FieldStats]; !ok {
				selectedFields = append(selectedFields, directorysyncrun.FieldStats)
				fieldSeen[directorysyncrun.FieldStats] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type directorysyncrunPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DirectorySyncRunPaginateOption
}

func newDirectorySyncRunPaginateArgs(rv map[string]any) *directorysyncrunPaginateArgs {
	args := &directorysyncrunPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DirectorySyncRunOrder:
			args.opts = append(args.opts, WithDirectorySyncRunOrder(v))
		case []any:
			var orders []*DirectorySyncRunOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DirectorySyncRunOrder{Field: &DirectorySyncRunOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDirectorySyncRunOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DirectorySyncRunWhereInput); ok {
		args.opts = append(args.opts, WithDirectorySyncRunFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DiscussionQuery) CollectFields(ctx context.Context, satisfies ...string) (*DiscussionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DiscussionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(discussion.Columns))
		selectedFields = []string{discussion.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[discussion.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, discussion.FieldOwnerID)
				fieldSeen[discussion.FieldOwnerID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Discussion) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"discussion_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(discussion.CommentsColumn), ids...))
						})
						if err := query.GroupBy(discussion.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Discussion) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(discussion.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query

		case "subcontrol":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrol = query

		case "procedure":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
				return err
			}
			_q.withProcedure = query

		case "risk":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
				return err
			}
			_q.withRisk = query

		case "internalPolicy":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicy = query
		case "createdAt":
			if _, ok := fieldSeen[discussion.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, discussion.FieldCreatedAt)
				fieldSeen[discussion.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[discussion.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, discussion.FieldUpdatedAt)
				fieldSeen[discussion.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[discussion.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, discussion.FieldCreatedBy)
				fieldSeen[discussion.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[discussion.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, discussion.FieldUpdatedBy)
				fieldSeen[discussion.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[discussion.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, discussion.FieldOwnerID)
				fieldSeen[discussion.FieldOwnerID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[discussion.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, discussion.FieldExternalID)
				fieldSeen[discussion.FieldExternalID] = struct{}{}
			}
		case "isResolved":
			if _, ok := fieldSeen[discussion.FieldIsResolved]; !ok {
				selectedFields = append(selectedFields, discussion.FieldIsResolved)
				fieldSeen[discussion.FieldIsResolved] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type discussionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DiscussionPaginateOption
}

func newDiscussionPaginateArgs(rv map[string]any) *discussionPaginateArgs {
	args := &discussionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DiscussionOrder:
			args.opts = append(args.opts, WithDiscussionOrder(v))
		case []any:
			var orders []*DiscussionOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DiscussionOrder{Field: &DiscussionOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDiscussionOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DiscussionWhereInput); ok {
		args.opts = append(args.opts, WithDiscussionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DocumentDataQuery) CollectFields(ctx context.Context, satisfies ...string) (*DocumentDataQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DocumentDataQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(documentdata.Columns))
		selectedFields = []string{documentdata.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[documentdata.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldOwnerID)
				fieldSeen[documentdata.FieldOwnerID] = struct{}{}
			}

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			_q.withTemplate = query
			if _, ok := fieldSeen[documentdata.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTemplateID)
				fieldSeen[documentdata.FieldTemplateID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DocumentData) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"document_data_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(documentdata.EntitiesTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(documentdata.EntitiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(documentdata.EntitiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(documentdata.EntitiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(documentdata.EntitiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DocumentData) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(documentdata.EntitiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DocumentData) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"document_data_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(documentdata.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(documentdata.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(documentdata.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(documentdata.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(documentdata.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DocumentData) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(documentdata.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[documentdata.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldCreatedAt)
				fieldSeen[documentdata.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[documentdata.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldUpdatedAt)
				fieldSeen[documentdata.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[documentdata.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldCreatedBy)
				fieldSeen[documentdata.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[documentdata.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldUpdatedBy)
				fieldSeen[documentdata.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[documentdata.FieldTags]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTags)
				fieldSeen[documentdata.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[documentdata.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldOwnerID)
				fieldSeen[documentdata.FieldOwnerID] = struct{}{}
			}
		case "templateID":
			if _, ok := fieldSeen[documentdata.FieldTemplateID]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldTemplateID)
				fieldSeen[documentdata.FieldTemplateID] = struct{}{}
			}
		case "data":
			if _, ok := fieldSeen[documentdata.FieldData]; !ok {
				selectedFields = append(selectedFields, documentdata.FieldData)
				fieldSeen[documentdata.FieldData] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type documentdataPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DocumentDataPaginateOption
}

func newDocumentDataPaginateArgs(rv map[string]any) *documentdataPaginateArgs {
	args := &documentdataPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*DocumentDataOrder:
			args.opts = append(args.opts, WithDocumentDataOrder(v))
		case []any:
			var orders []*DocumentDataOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &DocumentDataOrder{Field: &DocumentDataOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithDocumentDataOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*DocumentDataWhereInput); ok {
		args.opts = append(args.opts, WithDocumentDataFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EntityQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EntityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entity.Columns))
		selectedFields = []string{entity.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[entity.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entity.FieldOwnerID)
				fieldSeen[entity.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(entity.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(entity.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(entity.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "contacts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: _q.config}).Query()
			)
			args := newContactPaginateArgs(fieldArgs(ctx, new(ContactWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newContactPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.ContactsTable)
							s.Join(joinT).On(s.C(contact.FieldID), joinT.C(entity.ContactsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.ContactsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.ContactsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.ContactsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Contacts)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ContactsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedContacts(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.DocumentsTable)
							s.Join(joinT).On(s.C(documentdata.FieldID), joinT.C(entity.DocumentsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.DocumentsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.DocumentsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.DocumentsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.DocumentsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_notes"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.NotesColumn), ids...))
						})
						if err := query.GroupBy(entity.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(entity.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(entity.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(entity.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(entity.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(entity.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(entity.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Entity) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entity.ScansColumn), ids...))
						})
						if err := query.GroupBy(entity.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Entity) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entity.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entityType":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
				return err
			}
			_q.withEntityType = query
			if _, ok := fieldSeen[entity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entity.FieldEntityTypeID)
				fieldSeen[entity.FieldEntityTypeID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[entity.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entity.FieldCreatedAt)
				fieldSeen[entity.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entity.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entity.FieldUpdatedAt)
				fieldSeen[entity.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entity.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entity.FieldCreatedBy)
				fieldSeen[entity.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entity.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entity.FieldUpdatedBy)
				fieldSeen[entity.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entity.FieldTags]; !ok {
				selectedFields = append(selectedFields, entity.FieldTags)
				fieldSeen[entity.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entity.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entity.FieldOwnerID)
				fieldSeen[entity.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[entity.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, entity.FieldSystemOwned)
				fieldSeen[entity.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[entity.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, entity.FieldInternalNotes)
				fieldSeen[entity.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[entity.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, entity.FieldSystemInternalID)
				fieldSeen[entity.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entity.FieldName]; !ok {
				selectedFields = append(selectedFields, entity.FieldName)
				fieldSeen[entity.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[entity.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, entity.FieldDisplayName)
				fieldSeen[entity.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[entity.FieldDescription]; !ok {
				selectedFields = append(selectedFields, entity.FieldDescription)
				fieldSeen[entity.FieldDescription] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[entity.FieldDomains]; !ok {
				selectedFields = append(selectedFields, entity.FieldDomains)
				fieldSeen[entity.FieldDomains] = struct{}{}
			}
		case "entityTypeID":
			if _, ok := fieldSeen[entity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, entity.FieldEntityTypeID)
				fieldSeen[entity.FieldEntityTypeID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[entity.FieldStatus]; !ok {
				selectedFields = append(selectedFields, entity.FieldStatus)
				fieldSeen[entity.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type entityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityPaginateOption
}

func newEntityPaginateArgs(rv map[string]any) *entityPaginateArgs {
	args := &entityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EntityOrder:
			args.opts = append(args.opts, WithEntityOrder(v))
		case []any:
			var orders []*EntityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EntityOrder{Field: &EntityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEntityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EntityWhereInput); ok {
		args.opts = append(args.opts, WithEntityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EntityTypeQuery) CollectFields(ctx context.Context, satisfies ...string) (*EntityTypeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EntityTypeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(entitytype.Columns))
		selectedFields = []string{entitytype.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[entitytype.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldOwnerID)
				fieldSeen[entitytype.FieldOwnerID] = struct{}{}
			}

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*EntityType) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"entity_type_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(entitytype.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(entitytype.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*EntityType) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(entitytype.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[entitytype.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldCreatedAt)
				fieldSeen[entitytype.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[entitytype.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldUpdatedAt)
				fieldSeen[entitytype.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[entitytype.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldCreatedBy)
				fieldSeen[entitytype.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[entitytype.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldUpdatedBy)
				fieldSeen[entitytype.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[entitytype.FieldTags]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldTags)
				fieldSeen[entitytype.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[entitytype.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldOwnerID)
				fieldSeen[entitytype.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[entitytype.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldSystemOwned)
				fieldSeen[entitytype.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[entitytype.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldInternalNotes)
				fieldSeen[entitytype.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[entitytype.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldSystemInternalID)
				fieldSeen[entitytype.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[entitytype.FieldName]; !ok {
				selectedFields = append(selectedFields, entitytype.FieldName)
				fieldSeen[entitytype.FieldName] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type entitytypePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EntityTypePaginateOption
}

func newEntityTypePaginateArgs(rv map[string]any) *entitytypePaginateArgs {
	args := &entitytypePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EntityTypeOrder:
			args.opts = append(args.opts, WithEntityTypeOrder(v))
		case []any:
			var orders []*EntityTypeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EntityTypeOrder{Field: &EntityTypeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEntityTypeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EntityTypeWhereInput); ok {
		args.opts = append(args.opts, WithEntityTypeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EventQuery) CollectFields(ctx context.Context, satisfies ...string) (*EventQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EventQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(event.Columns))
		selectedFields = []string{event.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(event.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(event.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(event.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(event.OrganizationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrganizationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrganizationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrganizationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrganizationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "invites":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InviteClient{config: _q.config}).Query()
			)
			args := newInvitePaginateArgs(fieldArgs(ctx, new(InviteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInvitePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.InvitesTable)
							s.Join(joinT).On(s.C(invite.FieldID), joinT.C(event.InvitesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.InvitesPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.InvitesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.InvitesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Invites)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, inviteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.InvitesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInvites(alias, func(wq *InviteQuery) {
				*wq = *query
			})

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: _q.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.PersonalAccessTokensTable)
							s.Join(joinT).On(s.C(personalaccesstoken.FieldID), joinT.C(event.PersonalAccessTokensPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.PersonalAccessTokensPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.PersonalAccessTokensPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.PersonalAccessTokensPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.PersonalAccessTokensPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(event.SecretsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.SecretsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.SecretsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.SecretsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.SecretsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "orgMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: _q.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrgMembershipsTable)
							s.Join(joinT).On(s.C(orgmembership.FieldID), joinT.C(event.OrgMembershipsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrgMembershipsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrgMembershipsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrgMembershipsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgMemberships)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrgMembershipsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrgMemberships(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})

		case "groupMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: _q.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.GroupMembershipsTable)
							s.Join(joinT).On(s.C(groupmembership.FieldID), joinT.C(event.GroupMembershipsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.GroupMembershipsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.GroupMembershipsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.GroupMembershipsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupMemberships)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.GroupMembershipsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroupMemberships(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})

		case "subscribers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubscriberClient{config: _q.config}).Query()
			)
			args := newSubscriberPaginateArgs(fieldArgs(ctx, new(SubscriberWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubscriberPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.SubscribersTable)
							s.Join(joinT).On(s.C(subscriber.FieldID), joinT.C(event.SubscribersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.SubscribersPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.SubscribersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.SubscribersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subscribers)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subscriberImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.SubscribersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubscribers(alias, func(wq *SubscriberQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(event.FilesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.FilesPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.FilesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.FilesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.FilesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "orgSubscriptions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgSubscriptionClient{config: _q.config}).Query()
			)
			args := newOrgSubscriptionPaginateArgs(fieldArgs(ctx, new(OrgSubscriptionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgSubscriptionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Event) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"event_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(event.OrgSubscriptionsTable)
							s.Join(joinT).On(s.C(orgsubscription.FieldID), joinT.C(event.OrgSubscriptionsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(event.OrgSubscriptionsPrimaryKey[1]), ids...))
							s.Select(joinT.C(event.OrgSubscriptionsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(event.OrgSubscriptionsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Event) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgSubscriptions)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgsubscriptionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(event.OrgSubscriptionsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrgSubscriptions(alias, func(wq *OrgSubscriptionQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[event.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, event.FieldCreatedAt)
				fieldSeen[event.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[event.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, event.FieldUpdatedAt)
				fieldSeen[event.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[event.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, event.FieldCreatedBy)
				fieldSeen[event.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[event.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, event.FieldUpdatedBy)
				fieldSeen[event.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[event.FieldTags]; !ok {
				selectedFields = append(selectedFields, event.FieldTags)
				fieldSeen[event.FieldTags] = struct{}{}
			}
		case "eventID":
			if _, ok := fieldSeen[event.FieldEventID]; !ok {
				selectedFields = append(selectedFields, event.FieldEventID)
				fieldSeen[event.FieldEventID] = struct{}{}
			}
		case "correlationID":
			if _, ok := fieldSeen[event.FieldCorrelationID]; !ok {
				selectedFields = append(selectedFields, event.FieldCorrelationID)
				fieldSeen[event.FieldCorrelationID] = struct{}{}
			}
		case "eventType":
			if _, ok := fieldSeen[event.FieldEventType]; !ok {
				selectedFields = append(selectedFields, event.FieldEventType)
				fieldSeen[event.FieldEventType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[event.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, event.FieldMetadata)
				fieldSeen[event.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type eventPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EventPaginateOption
}

func newEventPaginateArgs(rv map[string]any) *eventPaginateArgs {
	args := &eventPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EventOrder:
			args.opts = append(args.opts, WithEventOrder(v))
		case []any:
			var orders []*EventOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EventOrder{Field: &EventOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEventOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EventWhereInput); ok {
		args.opts = append(args.opts, WithEventFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *EvidenceQuery) CollectFields(ctx context.Context, satisfies ...string) (*EvidenceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *EvidenceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(evidence.Columns))
		selectedFields = []string{evidence.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[evidence.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldOwnerID)
				fieldSeen[evidence.FieldOwnerID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(evidence.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(evidence.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(evidence.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_control_implementations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(evidence.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(evidence.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(evidence.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(evidence.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(evidence.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(evidence.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(evidence.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(evidence.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(evidence.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(evidence.TasksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(evidence.TasksPrimaryKey[1]), ids...))
							s.Select(joinT.C(evidence.TasksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(evidence.TasksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.TasksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(evidence.CommentsColumn), ids...))
						})
						if err := query.GroupBy(evidence.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Evidence) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"evidence_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(evidence.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(evidence.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Evidence) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(evidence.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[evidence.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreatedAt)
				fieldSeen[evidence.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[evidence.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, evidence.FieldUpdatedAt)
				fieldSeen[evidence.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[evidence.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreatedBy)
				fieldSeen[evidence.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[evidence.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, evidence.FieldUpdatedBy)
				fieldSeen[evidence.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[evidence.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldDisplayID)
				fieldSeen[evidence.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[evidence.FieldTags]; !ok {
				selectedFields = append(selectedFields, evidence.FieldTags)
				fieldSeen[evidence.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[evidence.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, evidence.FieldOwnerID)
				fieldSeen[evidence.FieldOwnerID] = struct{}{}
			}
		case "workflowEligibleMarker":
			if _, ok := fieldSeen[evidence.FieldWorkflowEligibleMarker]; !ok {
				selectedFields = append(selectedFields, evidence.FieldWorkflowEligibleMarker)
				fieldSeen[evidence.FieldWorkflowEligibleMarker] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[evidence.FieldName]; !ok {
				selectedFields = append(selectedFields, evidence.FieldName)
				fieldSeen[evidence.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[evidence.FieldDescription]; !ok {
				selectedFields = append(selectedFields, evidence.FieldDescription)
				fieldSeen[evidence.FieldDescription] = struct{}{}
			}
		case "collectionProcedure":
			if _, ok := fieldSeen[evidence.FieldCollectionProcedure]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCollectionProcedure)
				fieldSeen[evidence.FieldCollectionProcedure] = struct{}{}
			}
		case "creationDate":
			if _, ok := fieldSeen[evidence.FieldCreationDate]; !ok {
				selectedFields = append(selectedFields, evidence.FieldCreationDate)
				fieldSeen[evidence.FieldCreationDate] = struct{}{}
			}
		case "renewalDate":
			if _, ok := fieldSeen[evidence.FieldRenewalDate]; !ok {
				selectedFields = append(selectedFields, evidence.FieldRenewalDate)
				fieldSeen[evidence.FieldRenewalDate] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[evidence.FieldSource]; !ok {
				selectedFields = append(selectedFields, evidence.FieldSource)
				fieldSeen[evidence.FieldSource] = struct{}{}
			}
		case "isAutomated":
			if _, ok := fieldSeen[evidence.FieldIsAutomated]; !ok {
				selectedFields = append(selectedFields, evidence.FieldIsAutomated)
				fieldSeen[evidence.FieldIsAutomated] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[evidence.FieldURL]; !ok {
				selectedFields = append(selectedFields, evidence.FieldURL)
				fieldSeen[evidence.FieldURL] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[evidence.FieldStatus]; !ok {
				selectedFields = append(selectedFields, evidence.FieldStatus)
				fieldSeen[evidence.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type evidencePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []EvidencePaginateOption
}

func newEvidencePaginateArgs(rv map[string]any) *evidencePaginateArgs {
	args := &evidencePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*EvidenceOrder:
			args.opts = append(args.opts, WithEvidenceOrder(v))
		case []any:
			var orders []*EvidenceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &EvidenceOrder{Field: &EvidenceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithEvidenceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*EvidenceWhereInput); ok {
		args.opts = append(args.opts, WithEvidenceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ExportQuery) CollectFields(ctx context.Context, satisfies ...string) (*ExportQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ExportQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(export.Columns))
		selectedFields = []string{export.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[export.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, export.FieldOwnerID)
				fieldSeen[export.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Export) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"export_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(export.EventsColumn), ids...))
						})
						if err := query.GroupBy(export.EventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Export) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(export.EventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Export) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"export_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(export.FilesColumn), ids...))
						})
						if err := query.GroupBy(export.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Export) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(export.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[export.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, export.FieldCreatedAt)
				fieldSeen[export.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[export.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, export.FieldUpdatedAt)
				fieldSeen[export.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[export.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, export.FieldCreatedBy)
				fieldSeen[export.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[export.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, export.FieldUpdatedBy)
				fieldSeen[export.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[export.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, export.FieldOwnerID)
				fieldSeen[export.FieldOwnerID] = struct{}{}
			}
		case "exportType":
			if _, ok := fieldSeen[export.FieldExportType]; !ok {
				selectedFields = append(selectedFields, export.FieldExportType)
				fieldSeen[export.FieldExportType] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[export.FieldFormat]; !ok {
				selectedFields = append(selectedFields, export.FieldFormat)
				fieldSeen[export.FieldFormat] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[export.FieldStatus]; !ok {
				selectedFields = append(selectedFields, export.FieldStatus)
				fieldSeen[export.FieldStatus] = struct{}{}
			}
		case "requestorID":
			if _, ok := fieldSeen[export.FieldRequestorID]; !ok {
				selectedFields = append(selectedFields, export.FieldRequestorID)
				fieldSeen[export.FieldRequestorID] = struct{}{}
			}
		case "fields":
			if _, ok := fieldSeen[export.FieldFields]; !ok {
				selectedFields = append(selectedFields, export.FieldFields)
				fieldSeen[export.FieldFields] = struct{}{}
			}
		case "filters":
			if _, ok := fieldSeen[export.FieldFilters]; !ok {
				selectedFields = append(selectedFields, export.FieldFilters)
				fieldSeen[export.FieldFilters] = struct{}{}
			}
		case "errorMessage":
			if _, ok := fieldSeen[export.FieldErrorMessage]; !ok {
				selectedFields = append(selectedFields, export.FieldErrorMessage)
				fieldSeen[export.FieldErrorMessage] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type exportPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ExportPaginateOption
}

func newExportPaginateArgs(rv map[string]any) *exportPaginateArgs {
	args := &exportPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ExportOrder:
			args.opts = append(args.opts, WithExportOrder(v))
		case []any:
			var orders []*ExportOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ExportOrder{Field: &ExportOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithExportOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ExportWhereInput); ok {
		args.opts = append(args.opts, WithExportFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FileQuery) CollectFields(ctx context.Context, satisfies ...string) (*FileQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FileQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(file.Columns))
		selectedFields = []string{file.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.WithNamedOrganization(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(file.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(file.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(file.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(file.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "contact":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
				return err
			}
			_q.WithNamedContact(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "entity":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			_q.WithNamedEntity(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "organizationSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, organizationsettingImplementors)...); err != nil {
				return err
			}
			_q.WithNamedOrganizationSetting(alias, func(wq *OrganizationSettingQuery) {
				*wq = *query
			})

		case "template":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTemplate(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "document":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
				return err
			}
			_q.WithNamedDocument(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "program":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
				return err
			}
			_q.WithNamedProgram(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
				return err
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(file.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(file.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(file.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(file.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "trustCenterSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTrustCenterSetting(alias, func(wq *TrustCenterSettingQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_integrations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(file.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(file.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(file.SecretsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(file.SecretsPrimaryKey[0]), ids...))
							s.Select(joinT.C(file.SecretsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(file.SecretsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.SecretsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "trustcenterEntities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustcenterEntityClient{config: _q.config}).Query()
			)
			args := newTrustcenterEntityPaginateArgs(fieldArgs(ctx, new(TrustcenterEntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustcenterEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"file_trustcenter_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(file.TrustcenterEntitiesColumn), ids...))
						})
						if err := query.GroupBy(file.TrustcenterEntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustcenterEntities)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterentityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.TrustcenterEntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustcenterEntities(alias, func(wq *TrustcenterEntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[file.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedAt)
				fieldSeen[file.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[file.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldUpdatedAt)
				fieldSeen[file.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[file.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedBy)
				fieldSeen[file.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[file.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, file.FieldUpdatedBy)
				fieldSeen[file.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[file.FieldTags]; !ok {
				selectedFields = append(selectedFields, file.FieldTags)
				fieldSeen[file.FieldTags] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[file.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, file.FieldSystemOwned)
				fieldSeen[file.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[file.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, file.FieldInternalNotes)
				fieldSeen[file.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[file.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, file.FieldSystemInternalID)
				fieldSeen[file.FieldSystemInternalID] = struct{}{}
			}
		case "providedFileName":
			if _, ok := fieldSeen[file.FieldProvidedFileName]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileName)
				fieldSeen[file.FieldProvidedFileName] = struct{}{}
			}
		case "providedFileExtension":
			if _, ok := fieldSeen[file.FieldProvidedFileExtension]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileExtension)
				fieldSeen[file.FieldProvidedFileExtension] = struct{}{}
			}
		case "providedFileSize":
			if _, ok := fieldSeen[file.FieldProvidedFileSize]; !ok {
				selectedFields = append(selectedFields, file.FieldProvidedFileSize)
				fieldSeen[file.FieldProvidedFileSize] = struct{}{}
			}
		case "persistedFileSize":
			if _, ok := fieldSeen[file.FieldPersistedFileSize]; !ok {
				selectedFields = append(selectedFields, file.FieldPersistedFileSize)
				fieldSeen[file.FieldPersistedFileSize] = struct{}{}
			}
		case "detectedMimeType":
			if _, ok := fieldSeen[file.FieldDetectedMimeType]; !ok {
				selectedFields = append(selectedFields, file.FieldDetectedMimeType)
				fieldSeen[file.FieldDetectedMimeType] = struct{}{}
			}
		case "md5Hash":
			if _, ok := fieldSeen[file.FieldMd5Hash]; !ok {
				selectedFields = append(selectedFields, file.FieldMd5Hash)
				fieldSeen[file.FieldMd5Hash] = struct{}{}
			}
		case "detectedContentType":
			if _, ok := fieldSeen[file.FieldDetectedContentType]; !ok {
				selectedFields = append(selectedFields, file.FieldDetectedContentType)
				fieldSeen[file.FieldDetectedContentType] = struct{}{}
			}
		case "storeKey":
			if _, ok := fieldSeen[file.FieldStoreKey]; !ok {
				selectedFields = append(selectedFields, file.FieldStoreKey)
				fieldSeen[file.FieldStoreKey] = struct{}{}
			}
		case "categoryType":
			if _, ok := fieldSeen[file.FieldCategoryType]; !ok {
				selectedFields = append(selectedFields, file.FieldCategoryType)
				fieldSeen[file.FieldCategoryType] = struct{}{}
			}
		case "uri":
			if _, ok := fieldSeen[file.FieldURI]; !ok {
				selectedFields = append(selectedFields, file.FieldURI)
				fieldSeen[file.FieldURI] = struct{}{}
			}
		case "storageScheme":
			if _, ok := fieldSeen[file.FieldStorageScheme]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageScheme)
				fieldSeen[file.FieldStorageScheme] = struct{}{}
			}
		case "storageVolume":
			if _, ok := fieldSeen[file.FieldStorageVolume]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageVolume)
				fieldSeen[file.FieldStorageVolume] = struct{}{}
			}
		case "storagePath":
			if _, ok := fieldSeen[file.FieldStoragePath]; !ok {
				selectedFields = append(selectedFields, file.FieldStoragePath)
				fieldSeen[file.FieldStoragePath] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[file.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, file.FieldMetadata)
				fieldSeen[file.FieldMetadata] = struct{}{}
			}
		case "storageRegion":
			if _, ok := fieldSeen[file.FieldStorageRegion]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageRegion)
				fieldSeen[file.FieldStorageRegion] = struct{}{}
			}
		case "storageProvider":
			if _, ok := fieldSeen[file.FieldStorageProvider]; !ok {
				selectedFields = append(selectedFields, file.FieldStorageProvider)
				fieldSeen[file.FieldStorageProvider] = struct{}{}
			}
		case "lastAccessedAt":
			if _, ok := fieldSeen[file.FieldLastAccessedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldLastAccessedAt)
				fieldSeen[file.FieldLastAccessedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type filePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FilePaginateOption
}

func newFilePaginateArgs(rv map[string]any) *filePaginateArgs {
	args := &filePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FileOrder:
			args.opts = append(args.opts, WithFileOrder(v))
		case []any:
			var orders []*FileOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FileOrder{Field: &FileOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFileOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FileWhereInput); ok {
		args.opts = append(args.opts, WithFileFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FindingQuery) CollectFields(ctx context.Context, satisfies ...string) (*FindingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FindingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(finding.Columns))
		selectedFields = []string{finding.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[finding.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, finding.FieldOwnerID)
				fieldSeen[finding.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(finding.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.EditorsColumn), ids...))
						})
						if err := query.GroupBy(finding.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ViewersColumn), ids...))
						})
						if err := query.GroupBy(finding.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(finding.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(finding.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(finding.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(finding.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(finding.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_vulnerabilities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(finding.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(finding.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(finding.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(finding.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(finding.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(finding.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(finding.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(finding.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(finding.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(finding.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(finding.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(finding.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.RisksColumn), ids...))
						})
						if err := query.GroupBy(finding.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(finding.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.AssetsColumn), ids...))
						})
						if err := query.GroupBy(finding.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(finding.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ScansColumn), ids...))
						})
						if err := query.GroupBy(finding.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.TasksColumn), ids...))
						})
						if err := query.GroupBy(finding.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_remediations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(finding.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_reviews"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(finding.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.CommentsColumn), ids...))
						})
						if err := query.GroupBy(finding.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.FilesColumn), ids...))
						})
						if err := query.GroupBy(finding.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(finding.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "controlMappings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingControlClient{config: _q.config}).Query()
			)
			args := newFindingControlPaginateArgs(fieldArgs(ctx, new(FindingControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Finding) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"finding_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(finding.ControlMappingsColumn), ids...))
						})
						if err := query.GroupBy(finding.ControlMappingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Finding) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlMappings)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(finding.ControlMappingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlMappings(alias, func(wq *FindingControlQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[finding.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldCreatedAt)
				fieldSeen[finding.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[finding.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldUpdatedAt)
				fieldSeen[finding.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[finding.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, finding.FieldCreatedBy)
				fieldSeen[finding.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[finding.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, finding.FieldUpdatedBy)
				fieldSeen[finding.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[finding.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, finding.FieldDisplayID)
				fieldSeen[finding.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[finding.FieldTags]; !ok {
				selectedFields = append(selectedFields, finding.FieldTags)
				fieldSeen[finding.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[finding.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, finding.FieldOwnerID)
				fieldSeen[finding.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[finding.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, finding.FieldSystemOwned)
				fieldSeen[finding.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[finding.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, finding.FieldInternalNotes)
				fieldSeen[finding.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[finding.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, finding.FieldSystemInternalID)
				fieldSeen[finding.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[finding.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, finding.FieldExternalID)
				fieldSeen[finding.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[finding.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, finding.FieldExternalOwnerID)
				fieldSeen[finding.FieldExternalOwnerID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[finding.FieldSource]; !ok {
				selectedFields = append(selectedFields, finding.FieldSource)
				fieldSeen[finding.FieldSource] = struct{}{}
			}
		case "resourceName":
			if _, ok := fieldSeen[finding.FieldResourceName]; !ok {
				selectedFields = append(selectedFields, finding.FieldResourceName)
				fieldSeen[finding.FieldResourceName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[finding.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, finding.FieldDisplayName)
				fieldSeen[finding.FieldDisplayName] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[finding.FieldState]; !ok {
				selectedFields = append(selectedFields, finding.FieldState)
				fieldSeen[finding.FieldState] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[finding.FieldCategory]; !ok {
				selectedFields = append(selectedFields, finding.FieldCategory)
				fieldSeen[finding.FieldCategory] = struct{}{}
			}
		case "categories":
			if _, ok := fieldSeen[finding.FieldCategories]; !ok {
				selectedFields = append(selectedFields, finding.FieldCategories)
				fieldSeen[finding.FieldCategories] = struct{}{}
			}
		case "findingClass":
			if _, ok := fieldSeen[finding.FieldFindingClass]; !ok {
				selectedFields = append(selectedFields, finding.FieldFindingClass)
				fieldSeen[finding.FieldFindingClass] = struct{}{}
			}
		case "severity":
			if _, ok := fieldSeen[finding.FieldSeverity]; !ok {
				selectedFields = append(selectedFields, finding.FieldSeverity)
				fieldSeen[finding.FieldSeverity] = struct{}{}
			}
		case "numericSeverity":
			if _, ok := fieldSeen[finding.FieldNumericSeverity]; !ok {
				selectedFields = append(selectedFields, finding.FieldNumericSeverity)
				fieldSeen[finding.FieldNumericSeverity] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[finding.FieldScore]; !ok {
				selectedFields = append(selectedFields, finding.FieldScore)
				fieldSeen[finding.FieldScore] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[finding.FieldImpact]; !ok {
				selectedFields = append(selectedFields, finding.FieldImpact)
				fieldSeen[finding.FieldImpact] = struct{}{}
			}
		case "exploitability":
			if _, ok := fieldSeen[finding.FieldExploitability]; !ok {
				selectedFields = append(selectedFields, finding.FieldExploitability)
				fieldSeen[finding.FieldExploitability] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[finding.FieldPriority]; !ok {
				selectedFields = append(selectedFields, finding.FieldPriority)
				fieldSeen[finding.FieldPriority] = struct{}{}
			}
		case "open":
			if _, ok := fieldSeen[finding.FieldOpen]; !ok {
				selectedFields = append(selectedFields, finding.FieldOpen)
				fieldSeen[finding.FieldOpen] = struct{}{}
			}
		case "blocksProduction":
			if _, ok := fieldSeen[finding.FieldBlocksProduction]; !ok {
				selectedFields = append(selectedFields, finding.FieldBlocksProduction)
				fieldSeen[finding.FieldBlocksProduction] = struct{}{}
			}
		case "production":
			if _, ok := fieldSeen[finding.FieldProduction]; !ok {
				selectedFields = append(selectedFields, finding.FieldProduction)
				fieldSeen[finding.FieldProduction] = struct{}{}
			}
		case "public":
			if _, ok := fieldSeen[finding.FieldPublic]; !ok {
				selectedFields = append(selectedFields, finding.FieldPublic)
				fieldSeen[finding.FieldPublic] = struct{}{}
			}
		case "validated":
			if _, ok := fieldSeen[finding.FieldValidated]; !ok {
				selectedFields = append(selectedFields, finding.FieldValidated)
				fieldSeen[finding.FieldValidated] = struct{}{}
			}
		case "assessmentID":
			if _, ok := fieldSeen[finding.FieldAssessmentID]; !ok {
				selectedFields = append(selectedFields, finding.FieldAssessmentID)
				fieldSeen[finding.FieldAssessmentID] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[finding.FieldDescription]; !ok {
				selectedFields = append(selectedFields, finding.FieldDescription)
				fieldSeen[finding.FieldDescription] = struct{}{}
			}
		case "recommendation":
			if _, ok := fieldSeen[finding.FieldRecommendation]; !ok {
				selectedFields = append(selectedFields, finding.FieldRecommendation)
				fieldSeen[finding.FieldRecommendation] = struct{}{}
			}
		case "recommendedActions":
			if _, ok := fieldSeen[finding.FieldRecommendedActions]; !ok {
				selectedFields = append(selectedFields, finding.FieldRecommendedActions)
				fieldSeen[finding.FieldRecommendedActions] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[finding.FieldReferences]; !ok {
				selectedFields = append(selectedFields, finding.FieldReferences)
				fieldSeen[finding.FieldReferences] = struct{}{}
			}
		case "stepsToReproduce":
			if _, ok := fieldSeen[finding.FieldStepsToReproduce]; !ok {
				selectedFields = append(selectedFields, finding.FieldStepsToReproduce)
				fieldSeen[finding.FieldStepsToReproduce] = struct{}{}
			}
		case "targets":
			if _, ok := fieldSeen[finding.FieldTargets]; !ok {
				selectedFields = append(selectedFields, finding.FieldTargets)
				fieldSeen[finding.FieldTargets] = struct{}{}
			}
		case "targetDetails":
			if _, ok := fieldSeen[finding.FieldTargetDetails]; !ok {
				selectedFields = append(selectedFields, finding.FieldTargetDetails)
				fieldSeen[finding.FieldTargetDetails] = struct{}{}
			}
		case "vector":
			if _, ok := fieldSeen[finding.FieldVector]; !ok {
				selectedFields = append(selectedFields, finding.FieldVector)
				fieldSeen[finding.FieldVector] = struct{}{}
			}
		case "remediationSLA":
			if _, ok := fieldSeen[finding.FieldRemediationSLA]; !ok {
				selectedFields = append(selectedFields, finding.FieldRemediationSLA)
				fieldSeen[finding.FieldRemediationSLA] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[finding.FieldStatus]; !ok {
				selectedFields = append(selectedFields, finding.FieldStatus)
				fieldSeen[finding.FieldStatus] = struct{}{}
			}
		case "eventTime":
			if _, ok := fieldSeen[finding.FieldEventTime]; !ok {
				selectedFields = append(selectedFields, finding.FieldEventTime)
				fieldSeen[finding.FieldEventTime] = struct{}{}
			}
		case "reportedAt":
			if _, ok := fieldSeen[finding.FieldReportedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldReportedAt)
				fieldSeen[finding.FieldReportedAt] = struct{}{}
			}
		case "sourceUpdatedAt":
			if _, ok := fieldSeen[finding.FieldSourceUpdatedAt]; !ok {
				selectedFields = append(selectedFields, finding.FieldSourceUpdatedAt)
				fieldSeen[finding.FieldSourceUpdatedAt] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[finding.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, finding.FieldExternalURI)
				fieldSeen[finding.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[finding.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, finding.FieldMetadata)
				fieldSeen[finding.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[finding.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, finding.FieldRawPayload)
				fieldSeen[finding.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type findingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FindingPaginateOption
}

func newFindingPaginateArgs(rv map[string]any) *findingPaginateArgs {
	args := &findingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FindingOrder:
			args.opts = append(args.opts, WithFindingOrder(v))
		case []any:
			var orders []*FindingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FindingOrder{Field: &FindingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFindingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FindingWhereInput); ok {
		args.opts = append(args.opts, WithFindingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *FindingControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*FindingControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *FindingControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(findingcontrol.Columns))
		selectedFields = []string{findingcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "finding":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
				return err
			}
			_q.withFinding = query
			if _, ok := fieldSeen[findingcontrol.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldFindingID)
				fieldSeen[findingcontrol.FieldFindingID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[findingcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldControlID)
				fieldSeen[findingcontrol.FieldControlID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[findingcontrol.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldStandardID)
				fieldSeen[findingcontrol.FieldStandardID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[findingcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldCreatedAt)
				fieldSeen[findingcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[findingcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldUpdatedAt)
				fieldSeen[findingcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[findingcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldCreatedBy)
				fieldSeen[findingcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[findingcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldUpdatedBy)
				fieldSeen[findingcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "findingID":
			if _, ok := fieldSeen[findingcontrol.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldFindingID)
				fieldSeen[findingcontrol.FieldFindingID] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[findingcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldControlID)
				fieldSeen[findingcontrol.FieldControlID] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[findingcontrol.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldStandardID)
				fieldSeen[findingcontrol.FieldStandardID] = struct{}{}
			}
		case "externalStandard":
			if _, ok := fieldSeen[findingcontrol.FieldExternalStandard]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldExternalStandard)
				fieldSeen[findingcontrol.FieldExternalStandard] = struct{}{}
			}
		case "externalStandardVersion":
			if _, ok := fieldSeen[findingcontrol.FieldExternalStandardVersion]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldExternalStandardVersion)
				fieldSeen[findingcontrol.FieldExternalStandardVersion] = struct{}{}
			}
		case "externalControlID":
			if _, ok := fieldSeen[findingcontrol.FieldExternalControlID]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldExternalControlID)
				fieldSeen[findingcontrol.FieldExternalControlID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[findingcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldSource)
				fieldSeen[findingcontrol.FieldSource] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[findingcontrol.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldMetadata)
				fieldSeen[findingcontrol.FieldMetadata] = struct{}{}
			}
		case "discoveredAt":
			if _, ok := fieldSeen[findingcontrol.FieldDiscoveredAt]; !ok {
				selectedFields = append(selectedFields, findingcontrol.FieldDiscoveredAt)
				fieldSeen[findingcontrol.FieldDiscoveredAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type findingcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FindingControlPaginateOption
}

func newFindingControlPaginateArgs(rv map[string]any) *findingcontrolPaginateArgs {
	args := &findingcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FindingControlOrder:
			args.opts = append(args.opts, WithFindingControlOrder(v))
		case []any:
			var orders []*FindingControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FindingControlOrder{Field: &FindingControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFindingControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FindingControlWhereInput); ok {
		args.opts = append(args.opts, WithFindingControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(group.Columns))
		selectedFields = []string{group.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[group.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, group.FieldOwnerID)
				fieldSeen[group.FieldOwnerID] = struct{}{}
			}

		case "programEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramEditorsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramEditors)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramEditors(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramBlockedGroupsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramBlockedGroups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramBlockedGroups(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProgramViewersTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(group.ProgramViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProgramViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProgramViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProgramViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramViewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProgramViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramViewers(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "riskEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskEditorsTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskEditors)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskEditors(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskBlockedGroupsTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskBlockedGroups)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskBlockedGroups(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "riskViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.RiskViewersTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(group.RiskViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.RiskViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.RiskViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.RiskViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskViewers)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.RiskViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskViewers(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlObjectiveEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveEditorsTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveEditors)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveEditors(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlObjectiveBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveBlockedGroupsTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveBlockedGroups)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveBlockedGroups(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlObjectiveViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlObjectiveViewersTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(group.ControlObjectiveViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlObjectiveViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveViewers)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlObjectiveViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveViewers(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "narrativeEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeEditorsTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeEditors)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeEditors(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "narrativeBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeBlockedGroupsTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeBlockedGroups)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeBlockedGroups(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "narrativeViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.NarrativeViewersTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(group.NarrativeViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.NarrativeViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.NarrativeViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.NarrativeViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeViewers)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.NarrativeViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeViewers(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "controlImplementationEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationEditorsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationEditors)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationEditors(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controlImplementationBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationBlockedGroupsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationBlockedGroups)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationBlockedGroups(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controlImplementationViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlImplementationViewersTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(group.ControlImplementationViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlImplementationViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlImplementationViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlImplementationViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationViewers)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlImplementationViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationViewers(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "scanEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanEditorsTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanEditors)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScanEditors(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "scanBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanBlockedGroupsTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanBlockedGroups)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScanBlockedGroups(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "scanViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ScanViewersTable)
							s.Join(joinT).On(s.C(scan.FieldID), joinT.C(group.ScanViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ScanViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ScanViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ScanViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScanViewers)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ScanViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScanViewers(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "entityEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EntityEditorsTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(group.EntityEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.EntityEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.EntityEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EntityEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityEditors)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EntityEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityEditors(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EntityBlockedGroupsTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(group.EntityBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.EntityBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.EntityBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EntityBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityBlockedGroups)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EntityBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityBlockedGroups(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EntityViewersTable)
							s.Join(joinT).On(s.C(entity.FieldID), joinT.C(group.EntityViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.EntityViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.EntityViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EntityViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityViewers)
							if nodes[i].Edges.totalCount[21] == nil {
								nodes[i].Edges.totalCount[21] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[21][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EntityViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityViewers(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "actionPlanEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ActionPlanEditorsTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(group.ActionPlanEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ActionPlanEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ActionPlanEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ActionPlanEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlanEditors)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ActionPlanEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlanEditors(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "actionPlanBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ActionPlanBlockedGroupsTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(group.ActionPlanBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ActionPlanBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ActionPlanBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ActionPlanBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlanBlockedGroups)
							if nodes[i].Edges.totalCount[23] == nil {
								nodes[i].Edges.totalCount[23] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[23][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ActionPlanBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlanBlockedGroups(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "actionPlanViewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ActionPlanViewersTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(group.ActionPlanViewersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ActionPlanViewersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ActionPlanViewersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ActionPlanViewersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlanViewers)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ActionPlanViewersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlanViewers(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedureEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProcedureEditorsTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(group.ProcedureEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProcedureEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProcedureEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProcedureEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureEditors)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProcedureEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedureEditors(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "procedureBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ProcedureBlockedGroupsTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(group.ProcedureBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ProcedureBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureBlockedGroups)
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ProcedureBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedureBlockedGroups(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicyEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.InternalPolicyEditorsTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(group.InternalPolicyEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.InternalPolicyEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyEditors)
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.InternalPolicyEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicyEditors(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "internalPolicyBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.InternalPolicyBlockedGroupsTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.InternalPolicyBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyBlockedGroups)
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.InternalPolicyBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicyBlockedGroups(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "controlEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlEditorsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(group.ControlEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlEditors)
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlEditors(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "controlBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.ControlBlockedGroupsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(group.ControlBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.ControlBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlBlockedGroups)
							if nodes[i].Edges.totalCount[30] == nil {
								nodes[i].Edges.totalCount[30] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[30][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.ControlBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlBlockedGroups(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "mappedControlEditors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: _q.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.MappedControlEditorsTable)
							s.Join(joinT).On(s.C(mappedcontrol.FieldID), joinT.C(group.MappedControlEditorsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.MappedControlEditorsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.MappedControlEditorsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.MappedControlEditorsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlEditors)
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MappedControlEditorsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControlEditors(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "mappedControlBlockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: _q.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.MappedControlBlockedGroupsTable)
							s.Join(joinT).On(s.C(mappedcontrol.FieldID), joinT.C(group.MappedControlBlockedGroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.MappedControlBlockedGroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlBlockedGroups)
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MappedControlBlockedGroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControlBlockedGroups(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupsettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(group.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(group.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(group.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(group.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(group.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[35] == nil {
								nodes[i].Edges.totalCount[35] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[35][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_integrations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(group.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(group.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(group.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(group.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(group.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(group.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(group.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(group.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: _q.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Group) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(group.MembersColumn), ids...))
						})
						if err := query.GroupBy(group.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Group) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(group.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[group.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, group.FieldCreatedAt)
				fieldSeen[group.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[group.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, group.FieldUpdatedAt)
				fieldSeen[group.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[group.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, group.FieldCreatedBy)
				fieldSeen[group.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[group.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, group.FieldUpdatedBy)
				fieldSeen[group.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[group.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, group.FieldDisplayID)
				fieldSeen[group.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[group.FieldTags]; !ok {
				selectedFields = append(selectedFields, group.FieldTags)
				fieldSeen[group.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[group.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, group.FieldOwnerID)
				fieldSeen[group.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[group.FieldName]; !ok {
				selectedFields = append(selectedFields, group.FieldName)
				fieldSeen[group.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[group.FieldDescription]; !ok {
				selectedFields = append(selectedFields, group.FieldDescription)
				fieldSeen[group.FieldDescription] = struct{}{}
			}
		case "isManaged":
			if _, ok := fieldSeen[group.FieldIsManaged]; !ok {
				selectedFields = append(selectedFields, group.FieldIsManaged)
				fieldSeen[group.FieldIsManaged] = struct{}{}
			}
		case "gravatarLogoURL":
			if _, ok := fieldSeen[group.FieldGravatarLogoURL]; !ok {
				selectedFields = append(selectedFields, group.FieldGravatarLogoURL)
				fieldSeen[group.FieldGravatarLogoURL] = struct{}{}
			}
		case "logoURL":
			if _, ok := fieldSeen[group.FieldLogoURL]; !ok {
				selectedFields = append(selectedFields, group.FieldLogoURL)
				fieldSeen[group.FieldLogoURL] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[group.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, group.FieldDisplayName)
				fieldSeen[group.FieldDisplayName] = struct{}{}
			}
		case "scimExternalID":
			if _, ok := fieldSeen[group.FieldScimExternalID]; !ok {
				selectedFields = append(selectedFields, group.FieldScimExternalID)
				fieldSeen[group.FieldScimExternalID] = struct{}{}
			}
		case "scimDisplayName":
			if _, ok := fieldSeen[group.FieldScimDisplayName]; !ok {
				selectedFields = append(selectedFields, group.FieldScimDisplayName)
				fieldSeen[group.FieldScimDisplayName] = struct{}{}
			}
		case "scimActive":
			if _, ok := fieldSeen[group.FieldScimActive]; !ok {
				selectedFields = append(selectedFields, group.FieldScimActive)
				fieldSeen[group.FieldScimActive] = struct{}{}
			}
		case "scimGroupMailing":
			if _, ok := fieldSeen[group.FieldScimGroupMailing]; !ok {
				selectedFields = append(selectedFields, group.FieldScimGroupMailing)
				fieldSeen[group.FieldScimGroupMailing] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupPaginateOption
}

func newGroupPaginateArgs(rv map[string]any) *groupPaginateArgs {
	args := &groupPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupOrder:
			args.opts = append(args.opts, WithGroupOrder(v))
		case []any:
			var orders []*GroupOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupOrder{Field: &GroupOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupWhereInput); ok {
		args.opts = append(args.opts, WithGroupFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupmembership.Columns))
		selectedFields = []string{groupmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[groupmembership.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldGroupID)
				fieldSeen[groupmembership.FieldGroupID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[groupmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUserID)
				fieldSeen[groupmembership.FieldUserID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*GroupMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"group_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(groupmembership.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(groupmembership.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(groupmembership.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(groupmembership.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(groupmembership.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*GroupMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(groupmembership.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[groupmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldCreatedAt)
				fieldSeen[groupmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUpdatedAt)
				fieldSeen[groupmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldCreatedBy)
				fieldSeen[groupmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUpdatedBy)
				fieldSeen[groupmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[groupmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldRole)
				fieldSeen[groupmembership.FieldRole] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupmembership.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldGroupID)
				fieldSeen[groupmembership.FieldGroupID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[groupmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, groupmembership.FieldUserID)
				fieldSeen[groupmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupMembershipPaginateOption
}

func newGroupMembershipPaginateArgs(rv map[string]any) *groupmembershipPaginateArgs {
	args := &groupmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupMembershipOrder:
			args.opts = append(args.opts, WithGroupMembershipOrder(v))
		case []any:
			var orders []*GroupMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupMembershipOrder{Field: &GroupMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupMembershipWhereInput); ok {
		args.opts = append(args.opts, WithGroupMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *GroupSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*GroupSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *GroupSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(groupsetting.Columns))
		selectedFields = []string{groupsetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[groupsetting.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldGroupID)
				fieldSeen[groupsetting.FieldGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[groupsetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldCreatedAt)
				fieldSeen[groupsetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[groupsetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldUpdatedAt)
				fieldSeen[groupsetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[groupsetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldCreatedBy)
				fieldSeen[groupsetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[groupsetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldUpdatedBy)
				fieldSeen[groupsetting.FieldUpdatedBy] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[groupsetting.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldVisibility)
				fieldSeen[groupsetting.FieldVisibility] = struct{}{}
			}
		case "joinPolicy":
			if _, ok := fieldSeen[groupsetting.FieldJoinPolicy]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldJoinPolicy)
				fieldSeen[groupsetting.FieldJoinPolicy] = struct{}{}
			}
		case "syncToSlack":
			if _, ok := fieldSeen[groupsetting.FieldSyncToSlack]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldSyncToSlack)
				fieldSeen[groupsetting.FieldSyncToSlack] = struct{}{}
			}
		case "syncToGithub":
			if _, ok := fieldSeen[groupsetting.FieldSyncToGithub]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldSyncToGithub)
				fieldSeen[groupsetting.FieldSyncToGithub] = struct{}{}
			}
		case "groupID":
			if _, ok := fieldSeen[groupsetting.FieldGroupID]; !ok {
				selectedFields = append(selectedFields, groupsetting.FieldGroupID)
				fieldSeen[groupsetting.FieldGroupID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type groupsettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []GroupSettingPaginateOption
}

func newGroupSettingPaginateArgs(rv map[string]any) *groupsettingPaginateArgs {
	args := &groupsettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*GroupSettingOrder:
			args.opts = append(args.opts, WithGroupSettingOrder(v))
		case []any:
			var orders []*GroupSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &GroupSettingOrder{Field: &GroupSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithGroupSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*GroupSettingWhereInput); ok {
		args.opts = append(args.opts, WithGroupSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *HushQuery) CollectFields(ctx context.Context, satisfies ...string) (*HushQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *HushQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hush.Columns))
		selectedFields = []string{hush.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[hush.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hush.FieldOwnerID)
				fieldSeen[hush.FieldOwnerID] = struct{}{}
			}

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(hush.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(hush.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(hush.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(hush.FilesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(hush.FilesPrimaryKey[1]), ids...))
							s.Select(joinT.C(hush.FilesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.FilesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.FilesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Hush) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"hush_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(hush.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(hush.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(hush.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(hush.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(hush.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Hush) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(hush.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[hush.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldCreatedAt)
				fieldSeen[hush.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[hush.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldUpdatedAt)
				fieldSeen[hush.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[hush.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, hush.FieldCreatedBy)
				fieldSeen[hush.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[hush.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, hush.FieldUpdatedBy)
				fieldSeen[hush.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[hush.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, hush.FieldOwnerID)
				fieldSeen[hush.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[hush.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, hush.FieldSystemOwned)
				fieldSeen[hush.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[hush.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, hush.FieldInternalNotes)
				fieldSeen[hush.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[hush.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, hush.FieldSystemInternalID)
				fieldSeen[hush.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[hush.FieldName]; !ok {
				selectedFields = append(selectedFields, hush.FieldName)
				fieldSeen[hush.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[hush.FieldDescription]; !ok {
				selectedFields = append(selectedFields, hush.FieldDescription)
				fieldSeen[hush.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[hush.FieldKind]; !ok {
				selectedFields = append(selectedFields, hush.FieldKind)
				fieldSeen[hush.FieldKind] = struct{}{}
			}
		case "secretName":
			if _, ok := fieldSeen[hush.FieldSecretName]; !ok {
				selectedFields = append(selectedFields, hush.FieldSecretName)
				fieldSeen[hush.FieldSecretName] = struct{}{}
			}
		case "credentialSet":
			if _, ok := fieldSeen[hush.FieldCredentialSet]; !ok {
				selectedFields = append(selectedFields, hush.FieldCredentialSet)
				fieldSeen[hush.FieldCredentialSet] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[hush.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, hush.FieldMetadata)
				fieldSeen[hush.FieldMetadata] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[hush.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldLastUsedAt)
				fieldSeen[hush.FieldLastUsedAt] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[hush.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, hush.FieldExpiresAt)
				fieldSeen[hush.FieldExpiresAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type hushPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HushPaginateOption
}

func newHushPaginateArgs(rv map[string]any) *hushPaginateArgs {
	args := &hushPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HushOrder:
			args.opts = append(args.opts, WithHushOrder(v))
		case []any:
			var orders []*HushOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HushOrder{Field: &HushOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHushOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HushWhereInput); ok {
		args.opts = append(args.opts, WithHushFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *IntegrationQuery) CollectFields(ctx context.Context, satisfies ...string) (*IntegrationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *IntegrationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(integration.Columns))
		selectedFields = []string{integration.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[integration.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integration.FieldOwnerID)
				fieldSeen[integration.FieldOwnerID] = struct{}{}
			}

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.SecretsTable)
							s.Join(joinT).On(s.C(hush.FieldID), joinT.C(integration.SecretsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.SecretsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.SecretsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.SecretsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.SecretsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.FilesColumn), ids...))
						})
						if err := query.GroupBy(integration.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(integration.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.FindingsTable)
							s.Join(joinT).On(s.C(finding.FieldID), joinT.C(integration.FindingsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.FindingsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.FindingsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.FindingsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.FindingsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.VulnerabilitiesTable)
							s.Join(joinT).On(s.C(vulnerability.FieldID), joinT.C(integration.VulnerabilitiesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.VulnerabilitiesPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.VulnerabilitiesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.VulnerabilitiesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.VulnerabilitiesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.ReviewsTable)
							s.Join(joinT).On(s.C(review.FieldID), joinT.C(integration.ReviewsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.ReviewsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.ReviewsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.ReviewsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.ReviewsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.RemediationsTable)
							s.Join(joinT).On(s.C(remediation.FieldID), joinT.C(integration.RemediationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.RemediationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.RemediationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.RemediationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.RemediationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.TasksColumn), ids...))
						})
						if err := query.GroupBy(integration.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(integration.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(integration.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(integration.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(integration.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(integration.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "directoryAccounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_accounts"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectoryAccountsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectoryAccountsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryAccounts)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectoryAccountsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "directoryGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectoryGroupsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectoryGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryGroups)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectoryGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "directoryMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_memberships"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectoryMembershipsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectoryMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryMemberships)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectoryMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})

		case "directorySyncRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			args := newDirectorySyncRunPaginateArgs(fieldArgs(ctx, new(DirectorySyncRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectorySyncRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Integration) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"integration_directory_sync_runs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(integration.DirectorySyncRunsColumn), ids...))
						})
						if err := query.GroupBy(integration.DirectorySyncRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Integration) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectorySyncRuns)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(integration.DirectorySyncRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectorySyncRuns(alias, func(wq *DirectorySyncRunQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[integration.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, integration.FieldCreatedAt)
				fieldSeen[integration.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[integration.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, integration.FieldUpdatedAt)
				fieldSeen[integration.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[integration.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, integration.FieldCreatedBy)
				fieldSeen[integration.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[integration.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, integration.FieldUpdatedBy)
				fieldSeen[integration.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[integration.FieldTags]; !ok {
				selectedFields = append(selectedFields, integration.FieldTags)
				fieldSeen[integration.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[integration.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, integration.FieldOwnerID)
				fieldSeen[integration.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[integration.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, integration.FieldSystemOwned)
				fieldSeen[integration.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[integration.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, integration.FieldInternalNotes)
				fieldSeen[integration.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[integration.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, integration.FieldSystemInternalID)
				fieldSeen[integration.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[integration.FieldName]; !ok {
				selectedFields = append(selectedFields, integration.FieldName)
				fieldSeen[integration.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[integration.FieldDescription]; !ok {
				selectedFields = append(selectedFields, integration.FieldDescription)
				fieldSeen[integration.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[integration.FieldKind]; !ok {
				selectedFields = append(selectedFields, integration.FieldKind)
				fieldSeen[integration.FieldKind] = struct{}{}
			}
		case "integrationType":
			if _, ok := fieldSeen[integration.FieldIntegrationType]; !ok {
				selectedFields = append(selectedFields, integration.FieldIntegrationType)
				fieldSeen[integration.FieldIntegrationType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[integration.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, integration.FieldMetadata)
				fieldSeen[integration.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type integrationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []IntegrationPaginateOption
}

func newIntegrationPaginateArgs(rv map[string]any) *integrationPaginateArgs {
	args := &integrationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*IntegrationOrder:
			args.opts = append(args.opts, WithIntegrationOrder(v))
		case []any:
			var orders []*IntegrationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &IntegrationOrder{Field: &IntegrationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithIntegrationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*IntegrationWhereInput); ok {
		args.opts = append(args.opts, WithIntegrationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *InternalPolicyQuery) CollectFields(ctx context.Context, satisfies ...string) (*InternalPolicyQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *InternalPolicyQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(internalpolicy.Columns))
		selectedFields = []string{internalpolicy.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[internalpolicy.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldOwnerID)
				fieldSeen[internalpolicy.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(internalpolicy.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(internalpolicy.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withApprover = query
			if _, ok := fieldSeen[internalpolicy.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApproverID)
				fieldSeen[internalpolicy.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[internalpolicy.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDelegateID)
				fieldSeen[internalpolicy.FieldDelegateID] = struct{}{}
			}

		case "internalPolicyKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicyKind = query
			if _, ok := fieldSeen[internalpolicy.FieldInternalPolicyKindID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalPolicyKindID)
				fieldSeen[internalpolicy.FieldInternalPolicyKindID] = struct{}{}
			}

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(internalpolicy.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_control_implementations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(internalpolicy.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(internalpolicy.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(internalpolicy.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(internalpolicy.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(internalpolicy.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(internalpolicy.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(internalpolicy.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(internalpolicy.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(internalpolicy.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(internalpolicy.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(internalpolicy.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(internalpolicy.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(internalpolicy.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[internalpolicy.FieldFileID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldFileID)
				fieldSeen[internalpolicy.FieldFileID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.CommentsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "discussions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			args := newDiscussionPaginateArgs(fieldArgs(ctx, new(DiscussionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDiscussionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_discussions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.DiscussionsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.DiscussionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Discussions)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.DiscussionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDiscussions(alias, func(wq *DiscussionQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*InternalPolicy) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"internal_policy_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(internalpolicy.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(internalpolicy.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*InternalPolicy) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(internalpolicy.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[internalpolicy.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldCreatedAt)
				fieldSeen[internalpolicy.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[internalpolicy.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldUpdatedAt)
				fieldSeen[internalpolicy.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[internalpolicy.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldCreatedBy)
				fieldSeen[internalpolicy.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[internalpolicy.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldUpdatedBy)
				fieldSeen[internalpolicy.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[internalpolicy.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDisplayID)
				fieldSeen[internalpolicy.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[internalpolicy.FieldTags]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldTags)
				fieldSeen[internalpolicy.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[internalpolicy.FieldRevision]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldRevision)
				fieldSeen[internalpolicy.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[internalpolicy.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldOwnerID)
				fieldSeen[internalpolicy.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[internalpolicy.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSystemOwned)
				fieldSeen[internalpolicy.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[internalpolicy.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalNotes)
				fieldSeen[internalpolicy.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[internalpolicy.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSystemInternalID)
				fieldSeen[internalpolicy.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[internalpolicy.FieldName]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldName)
				fieldSeen[internalpolicy.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[internalpolicy.FieldStatus]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldStatus)
				fieldSeen[internalpolicy.FieldStatus] = struct{}{}
			}
		case "policyType":
			if _, ok := fieldSeen[internalpolicy.FieldPolicyType]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldPolicyType)
				fieldSeen[internalpolicy.FieldPolicyType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[internalpolicy.FieldDetails]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDetails)
				fieldSeen[internalpolicy.FieldDetails] = struct{}{}
			}
		case "detailsJSON":
			if _, ok := fieldSeen[internalpolicy.FieldDetailsJSON]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDetailsJSON)
				fieldSeen[internalpolicy.FieldDetailsJSON] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[internalpolicy.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApprovalRequired)
				fieldSeen[internalpolicy.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[internalpolicy.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldReviewDue)
				fieldSeen[internalpolicy.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[internalpolicy.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldReviewFrequency)
				fieldSeen[internalpolicy.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[internalpolicy.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldApproverID)
				fieldSeen[internalpolicy.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[internalpolicy.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDelegateID)
				fieldSeen[internalpolicy.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[internalpolicy.FieldSummary]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldSummary)
				fieldSeen[internalpolicy.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldTagSuggestions)
				fieldSeen[internalpolicy.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedTagSuggestions)
				fieldSeen[internalpolicy.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldControlSuggestions)
				fieldSeen[internalpolicy.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedControlSuggestions)
				fieldSeen[internalpolicy.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldImprovementSuggestions)
				fieldSeen[internalpolicy.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[internalpolicy.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldDismissedImprovementSuggestions)
				fieldSeen[internalpolicy.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[internalpolicy.FieldURL]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldURL)
				fieldSeen[internalpolicy.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[internalpolicy.FieldFileID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldFileID)
				fieldSeen[internalpolicy.FieldFileID] = struct{}{}
			}
		case "internalPolicyKindName":
			if _, ok := fieldSeen[internalpolicy.FieldInternalPolicyKindName]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalPolicyKindName)
				fieldSeen[internalpolicy.FieldInternalPolicyKindName] = struct{}{}
			}
		case "internalPolicyKindID":
			if _, ok := fieldSeen[internalpolicy.FieldInternalPolicyKindID]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldInternalPolicyKindID)
				fieldSeen[internalpolicy.FieldInternalPolicyKindID] = struct{}{}
			}
		case "workflowEligibleMarker":
			if _, ok := fieldSeen[internalpolicy.FieldWorkflowEligibleMarker]; !ok {
				selectedFields = append(selectedFields, internalpolicy.FieldWorkflowEligibleMarker)
				fieldSeen[internalpolicy.FieldWorkflowEligibleMarker] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type internalpolicyPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InternalPolicyPaginateOption
}

func newInternalPolicyPaginateArgs(rv map[string]any) *internalpolicyPaginateArgs {
	args := &internalpolicyPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*InternalPolicyOrder:
			args.opts = append(args.opts, WithInternalPolicyOrder(v))
		case []any:
			var orders []*InternalPolicyOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &InternalPolicyOrder{Field: &InternalPolicyOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithInternalPolicyOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*InternalPolicyWhereInput); ok {
		args.opts = append(args.opts, WithInternalPolicyFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *InviteQuery) CollectFields(ctx context.Context, satisfies ...string) (*InviteQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *InviteQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(invite.Columns))
		selectedFields = []string{invite.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[invite.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnerID)
				fieldSeen[invite.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Invite) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"invite_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(invite.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(invite.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(invite.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(invite.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(invite.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Invite) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(invite.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Invite) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"invite_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(invite.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(invite.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(invite.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(invite.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(invite.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Invite) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(invite.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[invite.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, invite.FieldCreatedAt)
				fieldSeen[invite.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[invite.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, invite.FieldUpdatedAt)
				fieldSeen[invite.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[invite.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, invite.FieldCreatedBy)
				fieldSeen[invite.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[invite.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, invite.FieldUpdatedBy)
				fieldSeen[invite.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[invite.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnerID)
				fieldSeen[invite.FieldOwnerID] = struct{}{}
			}
		case "expires":
			if _, ok := fieldSeen[invite.FieldExpires]; !ok {
				selectedFields = append(selectedFields, invite.FieldExpires)
				fieldSeen[invite.FieldExpires] = struct{}{}
			}
		case "recipient":
			if _, ok := fieldSeen[invite.FieldRecipient]; !ok {
				selectedFields = append(selectedFields, invite.FieldRecipient)
				fieldSeen[invite.FieldRecipient] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[invite.FieldStatus]; !ok {
				selectedFields = append(selectedFields, invite.FieldStatus)
				fieldSeen[invite.FieldStatus] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[invite.FieldRole]; !ok {
				selectedFields = append(selectedFields, invite.FieldRole)
				fieldSeen[invite.FieldRole] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[invite.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, invite.FieldSendAttempts)
				fieldSeen[invite.FieldSendAttempts] = struct{}{}
			}
		case "requestorID":
			if _, ok := fieldSeen[invite.FieldRequestorID]; !ok {
				selectedFields = append(selectedFields, invite.FieldRequestorID)
				fieldSeen[invite.FieldRequestorID] = struct{}{}
			}
		case "ownershipTransfer":
			if _, ok := fieldSeen[invite.FieldOwnershipTransfer]; !ok {
				selectedFields = append(selectedFields, invite.FieldOwnershipTransfer)
				fieldSeen[invite.FieldOwnershipTransfer] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type invitePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []InvitePaginateOption
}

func newInvitePaginateArgs(rv map[string]any) *invitePaginateArgs {
	args := &invitePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*InviteOrder:
			args.opts = append(args.opts, WithInviteOrder(v))
		case []any:
			var orders []*InviteOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &InviteOrder{Field: &InviteOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithInviteOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*InviteWhereInput); ok {
		args.opts = append(args.opts, WithInviteFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobResultQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobResultQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobResultQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobresult.Columns))
		selectedFields = []string{jobresult.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobresult.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldOwnerID)
				fieldSeen[jobresult.FieldOwnerID] = struct{}{}
			}

		case "scheduledJob":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
				return err
			}
			_q.withScheduledJob = query
			if _, ok := fieldSeen[jobresult.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldScheduledJobID)
				fieldSeen[jobresult.FieldScheduledJobID] = struct{}{}
			}

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[jobresult.FieldFileID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFileID)
				fieldSeen[jobresult.FieldFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobresult.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldCreatedAt)
				fieldSeen[jobresult.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobresult.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldUpdatedAt)
				fieldSeen[jobresult.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobresult.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldCreatedBy)
				fieldSeen[jobresult.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobresult.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldUpdatedBy)
				fieldSeen[jobresult.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobresult.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldOwnerID)
				fieldSeen[jobresult.FieldOwnerID] = struct{}{}
			}
		case "scheduledJobID":
			if _, ok := fieldSeen[jobresult.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldScheduledJobID)
				fieldSeen[jobresult.FieldScheduledJobID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[jobresult.FieldStatus]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldStatus)
				fieldSeen[jobresult.FieldStatus] = struct{}{}
			}
		case "exitCode":
			if _, ok := fieldSeen[jobresult.FieldExitCode]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldExitCode)
				fieldSeen[jobresult.FieldExitCode] = struct{}{}
			}
		case "finishedAt":
			if _, ok := fieldSeen[jobresult.FieldFinishedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFinishedAt)
				fieldSeen[jobresult.FieldFinishedAt] = struct{}{}
			}
		case "startedAt":
			if _, ok := fieldSeen[jobresult.FieldStartedAt]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldStartedAt)
				fieldSeen[jobresult.FieldStartedAt] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[jobresult.FieldFileID]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldFileID)
				fieldSeen[jobresult.FieldFileID] = struct{}{}
			}
		case "log":
			if _, ok := fieldSeen[jobresult.FieldLog]; !ok {
				selectedFields = append(selectedFields, jobresult.FieldLog)
				fieldSeen[jobresult.FieldLog] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobresultPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobResultPaginateOption
}

func newJobResultPaginateArgs(rv map[string]any) *jobresultPaginateArgs {
	args := &jobresultPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobResultOrder:
			args.opts = append(args.opts, WithJobResultOrder(v))
		case []any:
			var orders []*JobResultOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobResultOrder{Field: &JobResultOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobResultOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobResultWhereInput); ok {
		args.opts = append(args.opts, WithJobResultFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobRunnerQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobRunnerQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunner.Columns))
		selectedFields = []string{jobrunner.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobrunner.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOwnerID)
				fieldSeen[jobrunner.FieldOwnerID] = struct{}{}
			}

		case "jobRunnerTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerTokenClient{config: _q.config}).Query()
			)
			args := newJobRunnerTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*JobRunner) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_runner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(jobrunner.JobRunnerTokensTable)
							s.Join(joinT).On(s.C(jobrunnertoken.FieldID), joinT.C(jobrunner.JobRunnerTokensPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]), ids...))
							s.Select(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(jobrunner.JobRunnerTokensPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*JobRunner) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerTokens)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnertokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobrunner.JobRunnerTokensPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunnerTokens(alias, func(wq *JobRunnerTokenQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobrunner.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldCreatedAt)
				fieldSeen[jobrunner.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunner.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldUpdatedAt)
				fieldSeen[jobrunner.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunner.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldCreatedBy)
				fieldSeen[jobrunner.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunner.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldUpdatedBy)
				fieldSeen[jobrunner.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[jobrunner.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldDisplayID)
				fieldSeen[jobrunner.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunner.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldTags)
				fieldSeen[jobrunner.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunner.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOwnerID)
				fieldSeen[jobrunner.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[jobrunner.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldSystemOwned)
				fieldSeen[jobrunner.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[jobrunner.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldInternalNotes)
				fieldSeen[jobrunner.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[jobrunner.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldSystemInternalID)
				fieldSeen[jobrunner.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[jobrunner.FieldName]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldName)
				fieldSeen[jobrunner.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[jobrunner.FieldStatus]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldStatus)
				fieldSeen[jobrunner.FieldStatus] = struct{}{}
			}
		case "ipAddress":
			if _, ok := fieldSeen[jobrunner.FieldIPAddress]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldIPAddress)
				fieldSeen[jobrunner.FieldIPAddress] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[jobrunner.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldLastSeen)
				fieldSeen[jobrunner.FieldLastSeen] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[jobrunner.FieldVersion]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldVersion)
				fieldSeen[jobrunner.FieldVersion] = struct{}{}
			}
		case "os":
			if _, ok := fieldSeen[jobrunner.FieldOs]; !ok {
				selectedFields = append(selectedFields, jobrunner.FieldOs)
				fieldSeen[jobrunner.FieldOs] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobrunnerPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerPaginateOption
}

func newJobRunnerPaginateArgs(rv map[string]any) *jobrunnerPaginateArgs {
	args := &jobrunnerPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerOrder:
			args.opts = append(args.opts, WithJobRunnerOrder(v))
		case []any:
			var orders []*JobRunnerOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerOrder{Field: &JobRunnerOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobRunnerRegistrationTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerRegistrationTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobRunnerRegistrationTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunnerregistrationtoken.Columns))
		selectedFields = []string{jobrunnerregistrationtoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldOwnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldOwnerID] = struct{}{}
			}

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			_q.withJobRunner = query
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldJobRunnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldCreatedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldUpdatedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldCreatedBy)
				fieldSeen[jobrunnerregistrationtoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldUpdatedBy)
				fieldSeen[jobrunnerregistrationtoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldTags)
				fieldSeen[jobrunnerregistrationtoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldOwnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldOwnerID] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldToken)
				fieldSeen[jobrunnerregistrationtoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldExpiresAt)
				fieldSeen[jobrunnerregistrationtoken.FieldExpiresAt] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldLastUsedAt)
				fieldSeen[jobrunnerregistrationtoken.FieldLastUsedAt] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnerregistrationtoken.FieldJobRunnerID)
				fieldSeen[jobrunnerregistrationtoken.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobrunnerregistrationtokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerRegistrationTokenPaginateOption
}

func newJobRunnerRegistrationTokenPaginateArgs(rv map[string]any) *jobrunnerregistrationtokenPaginateArgs {
	args := &jobrunnerregistrationtokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerRegistrationTokenOrder:
			args.opts = append(args.opts, WithJobRunnerRegistrationTokenOrder(v))
		case []any:
			var orders []*JobRunnerRegistrationTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerRegistrationTokenOrder{Field: &JobRunnerRegistrationTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerRegistrationTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerRegistrationTokenWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerRegistrationTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobRunnerTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobRunnerTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobRunnerTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobrunnertoken.Columns))
		selectedFields = []string{jobrunnertoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobrunnertoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldOwnerID)
				fieldSeen[jobrunnertoken.FieldOwnerID] = struct{}{}
			}

		case "jobRunners":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			args := newJobRunnerPaginateArgs(fieldArgs(ctx, new(JobRunnerWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*JobRunnerToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_runner_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(jobrunnertoken.JobRunnersTable)
							s.Join(joinT).On(s.C(jobrunner.FieldID), joinT.C(jobrunnertoken.JobRunnersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]), ids...))
							s.Select(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(jobrunnertoken.JobRunnersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*JobRunnerToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunners)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobrunnertoken.JobRunnersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunners(alias, func(wq *JobRunnerQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldCreatedAt)
				fieldSeen[jobrunnertoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldUpdatedAt)
				fieldSeen[jobrunnertoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldCreatedBy)
				fieldSeen[jobrunnertoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldUpdatedBy)
				fieldSeen[jobrunnertoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobrunnertoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldTags)
				fieldSeen[jobrunnertoken.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobrunnertoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldOwnerID)
				fieldSeen[jobrunnertoken.FieldOwnerID] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[jobrunnertoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldToken)
				fieldSeen[jobrunnertoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldExpiresAt)
				fieldSeen[jobrunnertoken.FieldExpiresAt] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldLastUsedAt)
				fieldSeen[jobrunnertoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[jobrunnertoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldIsActive)
				fieldSeen[jobrunnertoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedReason)
				fieldSeen[jobrunnertoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedBy)
				fieldSeen[jobrunnertoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[jobrunnertoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, jobrunnertoken.FieldRevokedAt)
				fieldSeen[jobrunnertoken.FieldRevokedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobrunnertokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobRunnerTokenPaginateOption
}

func newJobRunnerTokenPaginateArgs(rv map[string]any) *jobrunnertokenPaginateArgs {
	args := &jobrunnertokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobRunnerTokenOrder:
			args.opts = append(args.opts, WithJobRunnerTokenOrder(v))
		case []any:
			var orders []*JobRunnerTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobRunnerTokenOrder{Field: &JobRunnerTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobRunnerTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobRunnerTokenWhereInput); ok {
		args.opts = append(args.opts, WithJobRunnerTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *JobTemplateQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobTemplateQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *JobTemplateQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(jobtemplate.Columns))
		selectedFields = []string{jobtemplate.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[jobtemplate.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldOwnerID)
				fieldSeen[jobtemplate.FieldOwnerID] = struct{}{}
			}

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*JobTemplate) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(jobtemplate.ScheduledJobsColumn), ids...))
						})
						if err := query.GroupBy(jobtemplate.ScheduledJobsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*JobTemplate) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(jobtemplate.ScheduledJobsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[jobtemplate.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldCreatedAt)
				fieldSeen[jobtemplate.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[jobtemplate.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldUpdatedAt)
				fieldSeen[jobtemplate.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[jobtemplate.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldCreatedBy)
				fieldSeen[jobtemplate.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[jobtemplate.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldUpdatedBy)
				fieldSeen[jobtemplate.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[jobtemplate.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldDisplayID)
				fieldSeen[jobtemplate.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[jobtemplate.FieldTags]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldTags)
				fieldSeen[jobtemplate.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[jobtemplate.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldOwnerID)
				fieldSeen[jobtemplate.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[jobtemplate.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldSystemOwned)
				fieldSeen[jobtemplate.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[jobtemplate.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldInternalNotes)
				fieldSeen[jobtemplate.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[jobtemplate.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldSystemInternalID)
				fieldSeen[jobtemplate.FieldSystemInternalID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[jobtemplate.FieldTitle]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldTitle)
				fieldSeen[jobtemplate.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[jobtemplate.FieldDescription]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldDescription)
				fieldSeen[jobtemplate.FieldDescription] = struct{}{}
			}
		case "platform":
			if _, ok := fieldSeen[jobtemplate.FieldPlatform]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldPlatform)
				fieldSeen[jobtemplate.FieldPlatform] = struct{}{}
			}
		case "downloadURL":
			if _, ok := fieldSeen[jobtemplate.FieldDownloadURL]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldDownloadURL)
				fieldSeen[jobtemplate.FieldDownloadURL] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[jobtemplate.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldConfiguration)
				fieldSeen[jobtemplate.FieldConfiguration] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[jobtemplate.FieldCron]; !ok {
				selectedFields = append(selectedFields, jobtemplate.FieldCron)
				fieldSeen[jobtemplate.FieldCron] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type jobtemplatePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobTemplatePaginateOption
}

func newJobTemplatePaginateArgs(rv map[string]any) *jobtemplatePaginateArgs {
	args := &jobtemplatePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*JobTemplateOrder:
			args.opts = append(args.opts, WithJobTemplateOrder(v))
		case []any:
			var orders []*JobTemplateOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &JobTemplateOrder{Field: &JobTemplateOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithJobTemplateOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*JobTemplateWhereInput); ok {
		args.opts = append(args.opts, WithJobTemplateFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *MappableDomainQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappableDomainQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *MappableDomainQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappabledomain.Columns))
		selectedFields = []string{mappabledomain.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappableDomain) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mappable_domain_custom_domains"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(mappabledomain.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(mappabledomain.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappableDomain) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappabledomain.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[mappabledomain.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldCreatedAt)
				fieldSeen[mappabledomain.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappabledomain.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldUpdatedAt)
				fieldSeen[mappabledomain.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappabledomain.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldCreatedBy)
				fieldSeen[mappabledomain.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappabledomain.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldUpdatedBy)
				fieldSeen[mappabledomain.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappabledomain.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldTags)
				fieldSeen[mappabledomain.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[mappabledomain.FieldName]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldName)
				fieldSeen[mappabledomain.FieldName] = struct{}{}
			}
		case "zoneID":
			if _, ok := fieldSeen[mappabledomain.FieldZoneID]; !ok {
				selectedFields = append(selectedFields, mappabledomain.FieldZoneID)
				fieldSeen[mappabledomain.FieldZoneID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type mappabledomainPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappableDomainPaginateOption
}

func newMappableDomainPaginateArgs(rv map[string]any) *mappabledomainPaginateArgs {
	args := &mappabledomainPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*MappableDomainOrder:
			args.opts = append(args.opts, WithMappableDomainOrder(v))
		case []any:
			var orders []*MappableDomainOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &MappableDomainOrder{Field: &MappableDomainOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithMappableDomainOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*MappableDomainWhereInput); ok {
		args.opts = append(args.opts, WithMappableDomainFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *MappedControlQuery) CollectFields(ctx context.Context, satisfies ...string) (*MappedControlQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *MappedControlQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(mappedcontrol.Columns))
		selectedFields = []string{mappedcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[mappedcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldOwnerID)
				fieldSeen[mappedcontrol.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(mappedcontrol.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "fromControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.FromControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(mappedcontrol.FromControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.FromControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FromControls)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.FromControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFromControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "toControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.ToControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(mappedcontrol.ToControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.ToControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ToControls)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.ToControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedToControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "fromSubcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.FromSubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.FromSubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FromSubcontrols)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.FromSubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFromSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "toSubcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*MappedControl) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"mapped_control_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(mappedcontrol.ToSubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(mappedcontrol.ToSubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*MappedControl) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ToSubcontrols)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(mappedcontrol.ToSubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedToSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[mappedcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldCreatedAt)
				fieldSeen[mappedcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[mappedcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldUpdatedAt)
				fieldSeen[mappedcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[mappedcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldCreatedBy)
				fieldSeen[mappedcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[mappedcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldUpdatedBy)
				fieldSeen[mappedcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[mappedcontrol.FieldTags]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldTags)
				fieldSeen[mappedcontrol.FieldTags] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[mappedcontrol.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSystemOwned)
				fieldSeen[mappedcontrol.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[mappedcontrol.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldInternalNotes)
				fieldSeen[mappedcontrol.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[mappedcontrol.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSystemInternalID)
				fieldSeen[mappedcontrol.FieldSystemInternalID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[mappedcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldOwnerID)
				fieldSeen[mappedcontrol.FieldOwnerID] = struct{}{}
			}
		case "mappingType":
			if _, ok := fieldSeen[mappedcontrol.FieldMappingType]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldMappingType)
				fieldSeen[mappedcontrol.FieldMappingType] = struct{}{}
			}
		case "relation":
			if _, ok := fieldSeen[mappedcontrol.FieldRelation]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldRelation)
				fieldSeen[mappedcontrol.FieldRelation] = struct{}{}
			}
		case "confidence":
			if _, ok := fieldSeen[mappedcontrol.FieldConfidence]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldConfidence)
				fieldSeen[mappedcontrol.FieldConfidence] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[mappedcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, mappedcontrol.FieldSource)
				fieldSeen[mappedcontrol.FieldSource] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type mappedcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []MappedControlPaginateOption
}

func newMappedControlPaginateArgs(rv map[string]any) *mappedcontrolPaginateArgs {
	args := &mappedcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*MappedControlOrder:
			args.opts = append(args.opts, WithMappedControlOrder(v))
		case []any:
			var orders []*MappedControlOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &MappedControlOrder{Field: &MappedControlOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithMappedControlOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*MappedControlWhereInput); ok {
		args.opts = append(args.opts, WithMappedControlFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NarrativeQuery) CollectFields(ctx context.Context, satisfies ...string) (*NarrativeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NarrativeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(narrative.Columns))
		selectedFields = []string{narrative.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[narrative.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldOwnerID)
				fieldSeen[narrative.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(narrative.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(narrative.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(narrative.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "satisfies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.SatisfiesTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(narrative.SatisfiesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.SatisfiesPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.SatisfiesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.SatisfiesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Satisfies)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.SatisfiesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSatisfies(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(narrative.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(narrative.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Narrative) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"narrative_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(narrative.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(narrative.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(narrative.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(narrative.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(narrative.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Narrative) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(narrative.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[narrative.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, narrative.FieldCreatedAt)
				fieldSeen[narrative.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[narrative.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, narrative.FieldUpdatedAt)
				fieldSeen[narrative.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[narrative.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, narrative.FieldCreatedBy)
				fieldSeen[narrative.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[narrative.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, narrative.FieldUpdatedBy)
				fieldSeen[narrative.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[narrative.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDisplayID)
				fieldSeen[narrative.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[narrative.FieldTags]; !ok {
				selectedFields = append(selectedFields, narrative.FieldTags)
				fieldSeen[narrative.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[narrative.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldOwnerID)
				fieldSeen[narrative.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[narrative.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, narrative.FieldSystemOwned)
				fieldSeen[narrative.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[narrative.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, narrative.FieldInternalNotes)
				fieldSeen[narrative.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[narrative.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, narrative.FieldSystemInternalID)
				fieldSeen[narrative.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[narrative.FieldName]; !ok {
				selectedFields = append(selectedFields, narrative.FieldName)
				fieldSeen[narrative.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[narrative.FieldDescription]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDescription)
				fieldSeen[narrative.FieldDescription] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[narrative.FieldDetails]; !ok {
				selectedFields = append(selectedFields, narrative.FieldDetails)
				fieldSeen[narrative.FieldDetails] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type narrativePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NarrativePaginateOption
}

func newNarrativePaginateArgs(rv map[string]any) *narrativePaginateArgs {
	args := &narrativePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*NarrativeOrder:
			args.opts = append(args.opts, WithNarrativeOrder(v))
		case []any:
			var orders []*NarrativeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &NarrativeOrder{Field: &NarrativeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithNarrativeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*NarrativeWhereInput); ok {
		args.opts = append(args.opts, WithNarrativeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NoteQuery) CollectFields(ctx context.Context, satisfies ...string) (*NoteQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NoteQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(note.Columns))
		selectedFields = []string{note.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[note.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, note.FieldOwnerID)
				fieldSeen[note.FieldOwnerID] = struct{}{}
			}

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			_q.withTask = query

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query

		case "subcontrol":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrol = query

		case "procedure":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
				return err
			}
			_q.withProcedure = query

		case "risk":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
				return err
			}
			_q.withRisk = query

		case "internalPolicy":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicy = query

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
				return err
			}
			_q.withEvidence = query

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query

		case "discussion":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
				return err
			}
			_q.withDiscussion = query
			if _, ok := fieldSeen[note.FieldDiscussionID]; !ok {
				selectedFields = append(selectedFields, note.FieldDiscussionID)
				fieldSeen[note.FieldDiscussionID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Note) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"note_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(note.FilesColumn), ids...))
						})
						if err := query.GroupBy(note.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Note) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(note.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[note.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, note.FieldCreatedAt)
				fieldSeen[note.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[note.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, note.FieldUpdatedAt)
				fieldSeen[note.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[note.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, note.FieldCreatedBy)
				fieldSeen[note.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[note.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, note.FieldUpdatedBy)
				fieldSeen[note.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[note.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, note.FieldDisplayID)
				fieldSeen[note.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[note.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, note.FieldOwnerID)
				fieldSeen[note.FieldOwnerID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[note.FieldText]; !ok {
				selectedFields = append(selectedFields, note.FieldText)
				fieldSeen[note.FieldText] = struct{}{}
			}
		case "textJSON":
			if _, ok := fieldSeen[note.FieldTextJSON]; !ok {
				selectedFields = append(selectedFields, note.FieldTextJSON)
				fieldSeen[note.FieldTextJSON] = struct{}{}
			}
		case "noteRef":
			if _, ok := fieldSeen[note.FieldNoteRef]; !ok {
				selectedFields = append(selectedFields, note.FieldNoteRef)
				fieldSeen[note.FieldNoteRef] = struct{}{}
			}
		case "discussionID":
			if _, ok := fieldSeen[note.FieldDiscussionID]; !ok {
				selectedFields = append(selectedFields, note.FieldDiscussionID)
				fieldSeen[note.FieldDiscussionID] = struct{}{}
			}
		case "isEdited":
			if _, ok := fieldSeen[note.FieldIsEdited]; !ok {
				selectedFields = append(selectedFields, note.FieldIsEdited)
				fieldSeen[note.FieldIsEdited] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type notePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NotePaginateOption
}

func newNotePaginateArgs(rv map[string]any) *notePaginateArgs {
	args := &notePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*NoteOrder:
			args.opts = append(args.opts, WithNoteOrder(v))
		case []any:
			var orders []*NoteOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &NoteOrder{Field: &NoteOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithNoteOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*NoteWhereInput); ok {
		args.opts = append(args.opts, WithNoteFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *NotificationQuery) CollectFields(ctx context.Context, satisfies ...string) (*NotificationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *NotificationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(notification.Columns))
		selectedFields = []string{notification.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[notification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, notification.FieldOwnerID)
				fieldSeen[notification.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[notification.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, notification.FieldCreatedAt)
				fieldSeen[notification.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[notification.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, notification.FieldUpdatedAt)
				fieldSeen[notification.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[notification.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, notification.FieldCreatedBy)
				fieldSeen[notification.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[notification.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, notification.FieldUpdatedBy)
				fieldSeen[notification.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[notification.FieldTags]; !ok {
				selectedFields = append(selectedFields, notification.FieldTags)
				fieldSeen[notification.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[notification.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, notification.FieldOwnerID)
				fieldSeen[notification.FieldOwnerID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[notification.FieldUserID]; !ok {
				selectedFields = append(selectedFields, notification.FieldUserID)
				fieldSeen[notification.FieldUserID] = struct{}{}
			}
		case "notificationType":
			if _, ok := fieldSeen[notification.FieldNotificationType]; !ok {
				selectedFields = append(selectedFields, notification.FieldNotificationType)
				fieldSeen[notification.FieldNotificationType] = struct{}{}
			}
		case "objectType":
			if _, ok := fieldSeen[notification.FieldObjectType]; !ok {
				selectedFields = append(selectedFields, notification.FieldObjectType)
				fieldSeen[notification.FieldObjectType] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[notification.FieldTitle]; !ok {
				selectedFields = append(selectedFields, notification.FieldTitle)
				fieldSeen[notification.FieldTitle] = struct{}{}
			}
		case "body":
			if _, ok := fieldSeen[notification.FieldBody]; !ok {
				selectedFields = append(selectedFields, notification.FieldBody)
				fieldSeen[notification.FieldBody] = struct{}{}
			}
		case "data":
			if _, ok := fieldSeen[notification.FieldData]; !ok {
				selectedFields = append(selectedFields, notification.FieldData)
				fieldSeen[notification.FieldData] = struct{}{}
			}
		case "readAt":
			if _, ok := fieldSeen[notification.FieldReadAt]; !ok {
				selectedFields = append(selectedFields, notification.FieldReadAt)
				fieldSeen[notification.FieldReadAt] = struct{}{}
			}
		case "channels":
			if _, ok := fieldSeen[notification.FieldChannels]; !ok {
				selectedFields = append(selectedFields, notification.FieldChannels)
				fieldSeen[notification.FieldChannels] = struct{}{}
			}
		case "topic":
			if _, ok := fieldSeen[notification.FieldTopic]; !ok {
				selectedFields = append(selectedFields, notification.FieldTopic)
				fieldSeen[notification.FieldTopic] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type notificationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []NotificationPaginateOption
}

func newNotificationPaginateArgs(rv map[string]any) *notificationPaginateArgs {
	args := &notificationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &NotificationOrder{Field: &NotificationOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithNotificationOrder(order))
			}
		case *NotificationOrder:
			if v != nil {
				args.opts = append(args.opts, WithNotificationOrder(v))
			}
		}
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OnboardingQuery) CollectFields(ctx context.Context, satisfies ...string) (*OnboardingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OnboardingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(onboarding.Columns))
		selectedFields = []string{onboarding.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOrganization = query
			if _, ok := fieldSeen[onboarding.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldOrganizationID)
				fieldSeen[onboarding.FieldOrganizationID] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[onboarding.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldOrganizationID)
				fieldSeen[onboarding.FieldOrganizationID] = struct{}{}
			}
		case "companyName":
			if _, ok := fieldSeen[onboarding.FieldCompanyName]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompanyName)
				fieldSeen[onboarding.FieldCompanyName] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[onboarding.FieldDomains]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldDomains)
				fieldSeen[onboarding.FieldDomains] = struct{}{}
			}
		case "companyDetails":
			if _, ok := fieldSeen[onboarding.FieldCompanyDetails]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompanyDetails)
				fieldSeen[onboarding.FieldCompanyDetails] = struct{}{}
			}
		case "userDetails":
			if _, ok := fieldSeen[onboarding.FieldUserDetails]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldUserDetails)
				fieldSeen[onboarding.FieldUserDetails] = struct{}{}
			}
		case "compliance":
			if _, ok := fieldSeen[onboarding.FieldCompliance]; !ok {
				selectedFields = append(selectedFields, onboarding.FieldCompliance)
				fieldSeen[onboarding.FieldCompliance] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type onboardingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OnboardingPaginateOption
}

func newOnboardingPaginateArgs(rv map[string]any) *onboardingPaginateArgs {
	args := &onboardingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[whereField].(*OnboardingWhereInput); ok {
		args.opts = append(args.opts, WithOnboardingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrgMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrgMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgmembership.Columns))
		selectedFields = []string{orgmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOrganization = query
			if _, ok := fieldSeen[orgmembership.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldOrganizationID)
				fieldSeen[orgmembership.FieldOrganizationID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[orgmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUserID)
				fieldSeen[orgmembership.FieldUserID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*OrgMembership) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"org_membership_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(orgmembership.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(orgmembership.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(orgmembership.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(orgmembership.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(orgmembership.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*OrgMembership) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(orgmembership.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[orgmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldCreatedAt)
				fieldSeen[orgmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUpdatedAt)
				fieldSeen[orgmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldCreatedBy)
				fieldSeen[orgmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUpdatedBy)
				fieldSeen[orgmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[orgmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldRole)
				fieldSeen[orgmembership.FieldRole] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[orgmembership.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldOrganizationID)
				fieldSeen[orgmembership.FieldOrganizationID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[orgmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, orgmembership.FieldUserID)
				fieldSeen[orgmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type orgmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgMembershipPaginateOption
}

func newOrgMembershipPaginateArgs(rv map[string]any) *orgmembershipPaginateArgs {
	args := &orgmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrgMembershipOrder:
			args.opts = append(args.opts, WithOrgMembershipOrder(v))
		case []any:
			var orders []*OrgMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrgMembershipOrder{Field: &OrgMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrgMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrgMembershipWhereInput); ok {
		args.opts = append(args.opts, WithOrgMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrgSubscriptionQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrgSubscriptionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrgSubscriptionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(orgsubscription.Columns))
		selectedFields = []string{orgsubscription.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[orgsubscription.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldOwnerID)
				fieldSeen[orgsubscription.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*OrgSubscription) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"org_subscription_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(orgsubscription.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(orgsubscription.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(orgsubscription.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(orgsubscription.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(orgsubscription.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*OrgSubscription) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(orgsubscription.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[orgsubscription.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldCreatedAt)
				fieldSeen[orgsubscription.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[orgsubscription.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldUpdatedAt)
				fieldSeen[orgsubscription.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[orgsubscription.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldCreatedBy)
				fieldSeen[orgsubscription.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[orgsubscription.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldUpdatedBy)
				fieldSeen[orgsubscription.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[orgsubscription.FieldTags]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldTags)
				fieldSeen[orgsubscription.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[orgsubscription.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldOwnerID)
				fieldSeen[orgsubscription.FieldOwnerID] = struct{}{}
			}
		case "stripeSubscriptionID":
			if _, ok := fieldSeen[orgsubscription.FieldStripeSubscriptionID]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeSubscriptionID)
				fieldSeen[orgsubscription.FieldStripeSubscriptionID] = struct{}{}
			}
		case "stripeSubscriptionStatus":
			if _, ok := fieldSeen[orgsubscription.FieldStripeSubscriptionStatus]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldStripeSubscriptionStatus)
				fieldSeen[orgsubscription.FieldStripeSubscriptionStatus] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[orgsubscription.FieldActive]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldActive)
				fieldSeen[orgsubscription.FieldActive] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[orgsubscription.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldExpiresAt)
				fieldSeen[orgsubscription.FieldExpiresAt] = struct{}{}
			}
		case "trialExpiresAt":
			if _, ok := fieldSeen[orgsubscription.FieldTrialExpiresAt]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldTrialExpiresAt)
				fieldSeen[orgsubscription.FieldTrialExpiresAt] = struct{}{}
			}
		case "daysUntilDue":
			if _, ok := fieldSeen[orgsubscription.FieldDaysUntilDue]; !ok {
				selectedFields = append(selectedFields, orgsubscription.FieldDaysUntilDue)
				fieldSeen[orgsubscription.FieldDaysUntilDue] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type orgsubscriptionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrgSubscriptionPaginateOption
}

func newOrgSubscriptionPaginateArgs(rv map[string]any) *orgsubscriptionPaginateArgs {
	args := &orgsubscriptionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &OrgSubscriptionOrder{Field: &OrgSubscriptionOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithOrgSubscriptionOrder(order))
			}
		case *OrgSubscriptionOrder:
			if v != nil {
				args.opts = append(args.opts, WithOrgSubscriptionOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*OrgSubscriptionWhereInput); ok {
		args.opts = append(args.opts, WithOrgSubscriptionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrganizationQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrganizationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organization.Columns))
		selectedFields = []string{organization.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "controlCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlCreators)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlImplementationCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_implementation_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlImplementationCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlImplementationCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementationCreators)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlImplementationCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementationCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "controlObjectiveCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_control_objective_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlObjectiveCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlObjectiveCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectiveCreators)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlObjectiveCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectiveCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "evidenceCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_evidence_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EvidenceCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.EvidenceCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EvidenceCreators)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EvidenceCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidenceCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "assetCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_asset_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssetCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.AssetCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssetCreators)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssetCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssetCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "findingCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_finding_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.FindingCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.FindingCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.FindingCreators)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.FindingCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindingCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "vulnerabilityCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_vulnerability_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.VulnerabilityCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.VulnerabilityCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.VulnerabilityCreators)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.VulnerabilityCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilityCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "groupCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_group_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.GroupCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.GroupCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupCreators)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.GroupCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroupCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "internalPolicyCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_internal_policy_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InternalPolicyCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.InternalPolicyCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicyCreators)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InternalPolicyCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicyCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "mappedControlCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_mapped_control_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MappedControlCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.MappedControlCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControlCreators)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MappedControlCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControlCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "narrativeCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_narrative_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NarrativeCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.NarrativeCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.NarrativeCreators)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NarrativeCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarrativeCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "procedureCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_procedure_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProcedureCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProcedureCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProcedureCreators)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProcedureCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedureCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_program_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProgramCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProgramCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramCreators)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProgramCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "riskCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_risk_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RiskCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.RiskCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.RiskCreators)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RiskCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRiskCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "scheduledJobCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_scheduled_job_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobCreators)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "standardCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_standard_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.StandardCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.StandardCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.StandardCreators)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.StandardCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedStandardCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "templateCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_template_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TemplateCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TemplateCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TemplateCreators)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TemplateCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTemplateCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "subprocessorCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_subprocessor_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubprocessorCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubprocessorCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.SubprocessorCreators)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubprocessorCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubprocessorCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "trustCenterDocCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_trust_center_doc_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCenterDocCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCenterDocCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterDocCreators)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCenterDocCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterDocCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "trustCenterSubprocessorCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_trust_center_subprocessor_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCenterSubprocessorCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCenterSubprocessorCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessorCreators)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCenterSubprocessorCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterSubprocessorCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "actionPlanCreators":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_action_plan_creators"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ActionPlanCreatorsColumn), ids...))
						})
						if err := query.GroupBy(organization.ActionPlanCreatorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlanCreators)
							if nodes[i].Edges.totalCount[20] == nil {
								nodes[i].Edges.totalCount[20] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[20][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ActionPlanCreatorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlanCreators(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "parent":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withParent = query
			if _, ok := fieldSeen[organization.FieldParentOrganizationID]; !ok {
				selectedFields = append(selectedFields, organization.FieldParentOrganizationID)
				fieldSeen[organization.FieldParentOrganizationID] = struct{}{}
			}

		case "children":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"parent_organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ChildrenColumn), ids...))
						})
						if err := query.GroupBy(organization.ChildrenColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Children)
							if nodes[i].Edges.totalCount[22] == nil {
								nodes[i].Edges.totalCount[22] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[22][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ChildrenColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedChildren(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationsettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: _q.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.PersonalAccessTokensTable)
							s.Join(joinT).On(s.C(personalaccesstoken.FieldID), joinT.C(organization.PersonalAccessTokensPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.PersonalAccessTokensPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[24] == nil {
								nodes[i].Edges.totalCount[24] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[24][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.PersonalAccessTokensPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "apiTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APITokenClient{config: _q.config}).Query()
			)
			args := newAPITokenPaginateArgs(fieldArgs(ctx, new(APITokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAPITokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.APITokensColumn), ids...))
						})
						if err := query.GroupBy(organization.APITokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.APITokens)
							if nodes[i].Edges.totalCount[25] == nil {
								nodes[i].Edges.totalCount[25] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[25][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, apitokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.APITokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAPITokens(alias, func(wq *APITokenQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(organization.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(organization.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(organization.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[26] == nil {
								nodes[i].Edges.totalCount[26] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[26][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(organization.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[27] == nil {
								nodes[i].Edges.totalCount[27] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[27][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organization.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(organization.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organization.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(organization.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organization.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[28] == nil {
								nodes[i].Edges.totalCount[28] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[28][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "secrets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HushClient{config: _q.config}).Query()
			)
			args := newHushPaginateArgs(fieldArgs(ctx, new(HushWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHushPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SecretsColumn), ids...))
						})
						if err := query.GroupBy(organization.SecretsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Secrets)
							if nodes[i].Edges.totalCount[29] == nil {
								nodes[i].Edges.totalCount[29] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[29][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hushImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SecretsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSecrets(alias, func(wq *HushQuery) {
				*wq = *query
			})

		case "avatarFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withAvatarFile = query
			if _, ok := fieldSeen[organization.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarLocalFileID)
				fieldSeen[organization.FieldAvatarLocalFileID] = struct{}{}
			}

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.GroupsColumn), ids...))
						})
						if err := query.GroupBy(organization.GroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[31] == nil {
								nodes[i].Edges.totalCount[31] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[31][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.GroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "templates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			args := newTemplatePaginateArgs(fieldArgs(ctx, new(TemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TemplatesColumn), ids...))
						})
						if err := query.GroupBy(organization.TemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Templates)
							if nodes[i].Edges.totalCount[32] == nil {
								nodes[i].Edges.totalCount[32] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[32][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTemplates(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.IntegrationsColumn), ids...))
						})
						if err := query.GroupBy(organization.IntegrationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[33] == nil {
								nodes[i].Edges.totalCount[33] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[33][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.IntegrationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DocumentsColumn), ids...))
						})
						if err := query.GroupBy(organization.DocumentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[34] == nil {
								nodes[i].Edges.totalCount[34] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[34][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DocumentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "orgSubscriptions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgSubscriptionClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, orgsubscriptionImplementors)...); err != nil {
				return err
			}
			_q.WithNamedOrgSubscriptions(alias, func(wq *OrgSubscriptionQuery) {
				*wq = *query
			})

		case "invites":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InviteClient{config: _q.config}).Query()
			)
			args := newInvitePaginateArgs(fieldArgs(ctx, new(InviteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInvitePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InvitesColumn), ids...))
						})
						if err := query.GroupBy(organization.InvitesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Invites)
							if nodes[i].Edges.totalCount[36] == nil {
								nodes[i].Edges.totalCount[36] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[36][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, inviteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InvitesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInvites(alias, func(wq *InviteQuery) {
				*wq = *query
			})

		case "subscribers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubscriberClient{config: _q.config}).Query()
			)
			args := newSubscriberPaginateArgs(fieldArgs(ctx, new(SubscriberWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubscriberPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubscribersColumn), ids...))
						})
						if err := query.GroupBy(organization.SubscribersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subscribers)
							if nodes[i].Edges.totalCount[37] == nil {
								nodes[i].Edges.totalCount[37] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[37][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subscriberImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubscribersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubscribers(alias, func(wq *SubscriberQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(organization.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[38] == nil {
								nodes[i].Edges.totalCount[38] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[38][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "entityTypes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: _q.config}).Query()
			)
			args := newEntityTypePaginateArgs(fieldArgs(ctx, new(EntityTypeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityTypePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EntityTypesColumn), ids...))
						})
						if err := query.GroupBy(organization.EntityTypesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.EntityTypes)
							if nodes[i].Edges.totalCount[39] == nil {
								nodes[i].Edges.totalCount[39] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[39][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EntityTypesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntityTypes(alias, func(wq *EntityTypeQuery) {
				*wq = *query
			})

		case "contacts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ContactClient{config: _q.config}).Query()
			)
			args := newContactPaginateArgs(fieldArgs(ctx, new(ContactWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newContactPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ContactsColumn), ids...))
						})
						if err := query.GroupBy(organization.ContactsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[40] == nil {
								nodes[i].Edges.totalCount[40] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[40][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Contacts)
							if nodes[i].Edges.totalCount[40] == nil {
								nodes[i].Edges.totalCount[40] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[40][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, contactImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ContactsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedContacts(alias, func(wq *ContactQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NotesColumn), ids...))
						})
						if err := query.GroupBy(organization.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[41] == nil {
								nodes[i].Edges.totalCount[41] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[41][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[41] == nil {
								nodes[i].Edges.totalCount[41] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[41][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TasksColumn), ids...))
						})
						if err := query.GroupBy(organization.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[42] == nil {
								nodes[i].Edges.totalCount[42] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[42][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[42] == nil {
								nodes[i].Edges.totalCount[42] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[42][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(organization.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[43] == nil {
								nodes[i].Edges.totalCount[43] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[43][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[43] == nil {
								nodes[i].Edges.totalCount[43] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[43][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ProceduresColumn), ids...))
						})
						if err := query.GroupBy(organization.ProceduresColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[44] == nil {
								nodes[i].Edges.totalCount[44] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[44][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[44] == nil {
								nodes[i].Edges.totalCount[44] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[44][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ProceduresColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.InternalPoliciesColumn), ids...))
						})
						if err := query.GroupBy(organization.InternalPoliciesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[45] == nil {
								nodes[i].Edges.totalCount[45] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[45][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[45] == nil {
								nodes[i].Edges.totalCount[45] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[45][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.InternalPoliciesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RisksColumn), ids...))
						})
						if err := query.GroupBy(organization.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[46] == nil {
								nodes[i].Edges.totalCount[46] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[46][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[46] == nil {
								nodes[i].Edges.totalCount[46] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[46][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlObjectivesColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlObjectivesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[47] == nil {
								nodes[i].Edges.totalCount[47] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[47][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[47] == nil {
								nodes[i].Edges.totalCount[47] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[47][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlObjectivesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(organization.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[48] == nil {
								nodes[i].Edges.totalCount[48] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[48][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[48] == nil {
								nodes[i].Edges.totalCount[48] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[48][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[49] == nil {
								nodes[i].Edges.totalCount[49] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[49][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[49] == nil {
								nodes[i].Edges.totalCount[49] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[49][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[50] == nil {
								nodes[i].Edges.totalCount[50] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[50][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[50] == nil {
								nodes[i].Edges.totalCount[50] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[50][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ControlImplementationsColumn), ids...))
						})
						if err := query.GroupBy(organization.ControlImplementationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[51] == nil {
								nodes[i].Edges.totalCount[51] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[51][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[51] == nil {
								nodes[i].Edges.totalCount[51] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[51][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ControlImplementationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "mappedControls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&MappedControlClient{config: _q.config}).Query()
			)
			args := newMappedControlPaginateArgs(fieldArgs(ctx, new(MappedControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newMappedControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MappedControlsColumn), ids...))
						})
						if err := query.GroupBy(organization.MappedControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[52] == nil {
								nodes[i].Edges.totalCount[52] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[52][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.MappedControls)
							if nodes[i].Edges.totalCount[52] == nil {
								nodes[i].Edges.totalCount[52] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[52][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, mappedcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MappedControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMappedControls(alias, func(wq *MappedControlQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.EvidenceColumn), ids...))
						})
						if err := query.GroupBy(organization.EvidenceColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[53] == nil {
								nodes[i].Edges.totalCount[53] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[53][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[53] == nil {
								nodes[i].Edges.totalCount[53] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[53][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.EvidenceColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "standards":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			args := newStandardPaginateArgs(fieldArgs(ctx, new(StandardWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newStandardPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.StandardsColumn), ids...))
						})
						if err := query.GroupBy(organization.StandardsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[54] == nil {
								nodes[i].Edges.totalCount[54] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[54][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Standards)
							if nodes[i].Edges.totalCount[54] == nil {
								nodes[i].Edges.totalCount[54] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[54][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.StandardsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedStandards(alias, func(wq *StandardQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(organization.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[55] == nil {
								nodes[i].Edges.totalCount[55] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[55][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[55] == nil {
								nodes[i].Edges.totalCount[55] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[55][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "customDomains":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			args := newCustomDomainPaginateArgs(fieldArgs(ctx, new(CustomDomainWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomDomainPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.CustomDomainsColumn), ids...))
						})
						if err := query.GroupBy(organization.CustomDomainsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[56] == nil {
								nodes[i].Edges.totalCount[56] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[56][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomDomains)
							if nodes[i].Edges.totalCount[56] == nil {
								nodes[i].Edges.totalCount[56] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[56][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.CustomDomainsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomDomains(alias, func(wq *CustomDomainQuery) {
				*wq = *query
			})

		case "jobRunners":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			args := newJobRunnerPaginateArgs(fieldArgs(ctx, new(JobRunnerWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnersColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[57] == nil {
								nodes[i].Edges.totalCount[57] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[57][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunners)
							if nodes[i].Edges.totalCount[57] == nil {
								nodes[i].Edges.totalCount[57] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[57][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunners(alias, func(wq *JobRunnerQuery) {
				*wq = *query
			})

		case "jobRunnerTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerTokenClient{config: _q.config}).Query()
			)
			args := newJobRunnerTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnerTokensColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnerTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[58] == nil {
								nodes[i].Edges.totalCount[58] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[58][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerTokens)
							if nodes[i].Edges.totalCount[58] == nil {
								nodes[i].Edges.totalCount[58] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[58][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnertokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnerTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunnerTokens(alias, func(wq *JobRunnerTokenQuery) {
				*wq = *query
			})

		case "jobRunnerRegistrationTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerRegistrationTokenClient{config: _q.config}).Query()
			)
			args := newJobRunnerRegistrationTokenPaginateArgs(fieldArgs(ctx, new(JobRunnerRegistrationTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobRunnerRegistrationTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobRunnerRegistrationTokensColumn), ids...))
						})
						if err := query.GroupBy(organization.JobRunnerRegistrationTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[59] == nil {
								nodes[i].Edges.totalCount[59] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[59][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobRunnerRegistrationTokens)
							if nodes[i].Edges.totalCount[59] == nil {
								nodes[i].Edges.totalCount[59] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[59][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobrunnerregistrationtokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobRunnerRegistrationTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobRunnerRegistrationTokens(alias, func(wq *JobRunnerRegistrationTokenQuery) {
				*wq = *query
			})

		case "dnsVerifications":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DNSVerificationClient{config: _q.config}).Query()
			)
			args := newDNSVerificationPaginateArgs(fieldArgs(ctx, new(DNSVerificationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDNSVerificationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DNSVerificationsColumn), ids...))
						})
						if err := query.GroupBy(organization.DNSVerificationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[60] == nil {
								nodes[i].Edges.totalCount[60] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[60][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DNSVerifications)
							if nodes[i].Edges.totalCount[60] == nil {
								nodes[i].Edges.totalCount[60] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[60][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, dnsverificationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DNSVerificationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDNSVerifications(alias, func(wq *DNSVerificationQuery) {
				*wq = *query
			})

		case "jobTemplates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobTemplateClient{config: _q.config}).Query()
			)
			args := newJobTemplatePaginateArgs(fieldArgs(ctx, new(JobTemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobTemplatesColumn), ids...))
						})
						if err := query.GroupBy(organization.JobTemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[61] == nil {
								nodes[i].Edges.totalCount[61] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[61][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobTemplates)
							if nodes[i].Edges.totalCount[61] == nil {
								nodes[i].Edges.totalCount[61] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[61][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobtemplateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobTemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobTemplates(alias, func(wq *JobTemplateQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[62] == nil {
								nodes[i].Edges.totalCount[62] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[62][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[62] == nil {
								nodes[i].Edges.totalCount[62] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[62][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})

		case "jobResults":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobResultClient{config: _q.config}).Query()
			)
			args := newJobResultPaginateArgs(fieldArgs(ctx, new(JobResultWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newJobResultPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.JobResultsColumn), ids...))
						})
						if err := query.GroupBy(organization.JobResultsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[63] == nil {
								nodes[i].Edges.totalCount[63] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[63][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.JobResults)
							if nodes[i].Edges.totalCount[63] == nil {
								nodes[i].Edges.totalCount[63] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[63][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, jobresultImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.JobResultsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedJobResults(alias, func(wq *JobResultQuery) {
				*wq = *query
			})

		case "scheduledJobRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobRunClient{config: _q.config}).Query()
			)
			args := newScheduledJobRunPaginateArgs(fieldArgs(ctx, new(ScheduledJobRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScheduledJobRunsColumn), ids...))
						})
						if err := query.GroupBy(organization.ScheduledJobRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[64] == nil {
								nodes[i].Edges.totalCount[64] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[64][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobRuns)
							if nodes[i].Edges.totalCount[64] == nil {
								nodes[i].Edges.totalCount[64] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[64][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScheduledJobRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobRuns(alias, func(wq *ScheduledJobRunQuery) {
				*wq = *query
			})

		case "trustCenters":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			args := newTrustCenterPaginateArgs(fieldArgs(ctx, new(TrustCenterWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCentersColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCentersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[65] == nil {
								nodes[i].Edges.totalCount[65] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[65][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenters)
							if nodes[i].Edges.totalCount[65] == nil {
								nodes[i].Edges.totalCount[65] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[65][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCentersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenters(alias, func(wq *TrustCenterQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssetsColumn), ids...))
						})
						if err := query.GroupBy(organization.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[66] == nil {
								nodes[i].Edges.totalCount[66] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[66][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[66] == nil {
								nodes[i].Edges.totalCount[66] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[66][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ScansColumn), ids...))
						})
						if err := query.GroupBy(organization.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[67] == nil {
								nodes[i].Edges.totalCount[67] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[67][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[67] == nil {
								nodes[i].Edges.totalCount[67] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[67][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "subprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: _q.config}).Query()
			)
			args := newSubprocessorPaginateArgs(fieldArgs(ctx, new(SubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.SubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(organization.SubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[68] == nil {
								nodes[i].Edges.totalCount[68] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[68][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subprocessors)
							if nodes[i].Edges.totalCount[68] == nil {
								nodes[i].Edges.totalCount[68] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[68][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.SubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubprocessors(alias, func(wq *SubprocessorQuery) {
				*wq = *query
			})

		case "exports":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ExportClient{config: _q.config}).Query()
			)
			args := newExportPaginateArgs(fieldArgs(ctx, new(ExportWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newExportPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ExportsColumn), ids...))
						})
						if err := query.GroupBy(organization.ExportsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[69] == nil {
								nodes[i].Edges.totalCount[69] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[69][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Exports)
							if nodes[i].Edges.totalCount[69] == nil {
								nodes[i].Edges.totalCount[69] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[69][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, exportImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ExportsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedExports(alias, func(wq *ExportQuery) {
				*wq = *query
			})

		case "trustCenterWatermarkConfigs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterWatermarkConfigClient{config: _q.config}).Query()
			)
			args := newTrustCenterWatermarkConfigPaginateArgs(fieldArgs(ctx, new(TrustCenterWatermarkConfigWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterWatermarkConfigPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TrustCenterWatermarkConfigsColumn), ids...))
						})
						if err := query.GroupBy(organization.TrustCenterWatermarkConfigsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[70] == nil {
								nodes[i].Edges.totalCount[70] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[70][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterWatermarkConfigs)
							if nodes[i].Edges.totalCount[70] == nil {
								nodes[i].Edges.totalCount[70] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[70][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterwatermarkconfigImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TrustCenterWatermarkConfigsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterWatermarkConfigs(alias, func(wq *TrustCenterWatermarkConfigQuery) {
				*wq = *query
			})

		case "assessments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentClient{config: _q.config}).Query()
			)
			args := newAssessmentPaginateArgs(fieldArgs(ctx, new(AssessmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssessmentsColumn), ids...))
						})
						if err := query.GroupBy(organization.AssessmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[71] == nil {
								nodes[i].Edges.totalCount[71] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[71][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assessments)
							if nodes[i].Edges.totalCount[71] == nil {
								nodes[i].Edges.totalCount[71] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[71][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssessmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessments(alias, func(wq *AssessmentQuery) {
				*wq = *query
			})

		case "assessmentResponses":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentResponseClient{config: _q.config}).Query()
			)
			args := newAssessmentResponsePaginateArgs(fieldArgs(ctx, new(AssessmentResponseWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentResponsePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.AssessmentResponsesColumn), ids...))
						})
						if err := query.GroupBy(organization.AssessmentResponsesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[72] == nil {
								nodes[i].Edges.totalCount[72] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[72][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssessmentResponses)
							if nodes[i].Edges.totalCount[72] == nil {
								nodes[i].Edges.totalCount[72] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[72][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentresponseImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.AssessmentResponsesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessmentResponses(alias, func(wq *AssessmentResponseQuery) {
				*wq = *query
			})

		case "customTypeEnums":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			args := newCustomTypeEnumPaginateArgs(fieldArgs(ctx, new(CustomTypeEnumWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newCustomTypeEnumPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.CustomTypeEnumsColumn), ids...))
						})
						if err := query.GroupBy(organization.CustomTypeEnumsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[73] == nil {
								nodes[i].Edges.totalCount[73] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[73][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.CustomTypeEnums)
							if nodes[i].Edges.totalCount[73] == nil {
								nodes[i].Edges.totalCount[73] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[73][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.CustomTypeEnumsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedCustomTypeEnums(alias, func(wq *CustomTypeEnumQuery) {
				*wq = *query
			})

		case "tagDefinitions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TagDefinitionClient{config: _q.config}).Query()
			)
			args := newTagDefinitionPaginateArgs(fieldArgs(ctx, new(TagDefinitionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTagDefinitionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.TagDefinitionsColumn), ids...))
						})
						if err := query.GroupBy(organization.TagDefinitionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[74] == nil {
								nodes[i].Edges.totalCount[74] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[74][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TagDefinitions)
							if nodes[i].Edges.totalCount[74] == nil {
								nodes[i].Edges.totalCount[74] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[74][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tagdefinitionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.TagDefinitionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTagDefinitions(alias, func(wq *TagDefinitionQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(organization.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[75] == nil {
								nodes[i].Edges.totalCount[75] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[75][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[75] == nil {
								nodes[i].Edges.totalCount[75] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[75][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.FindingsColumn), ids...))
						})
						if err := query.GroupBy(organization.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[76] == nil {
								nodes[i].Edges.totalCount[76] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[76][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[76] == nil {
								nodes[i].Edges.totalCount[76] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[76][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(organization.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[77] == nil {
								nodes[i].Edges.totalCount[77] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[77][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[77] == nil {
								nodes[i].Edges.totalCount[77] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[77][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(organization.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[78] == nil {
								nodes[i].Edges.totalCount[78] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[78][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[78] == nil {
								nodes[i].Edges.totalCount[78] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[78][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "workflowDefinitions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowDefinitionClient{config: _q.config}).Query()
			)
			args := newWorkflowDefinitionPaginateArgs(fieldArgs(ctx, new(WorkflowDefinitionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowDefinitionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowDefinitionsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowDefinitionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[79] == nil {
								nodes[i].Edges.totalCount[79] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[79][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowDefinitions)
							if nodes[i].Edges.totalCount[79] == nil {
								nodes[i].Edges.totalCount[79] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[79][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowdefinitionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowDefinitionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowDefinitions(alias, func(wq *WorkflowDefinitionQuery) {
				*wq = *query
			})

		case "workflowInstances":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			args := newWorkflowInstancePaginateArgs(fieldArgs(ctx, new(WorkflowInstanceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowInstancePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowInstancesColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowInstancesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[80] == nil {
								nodes[i].Edges.totalCount[80] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[80][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowInstances)
							if nodes[i].Edges.totalCount[80] == nil {
								nodes[i].Edges.totalCount[80] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[80][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowInstancesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowInstances(alias, func(wq *WorkflowInstanceQuery) {
				*wq = *query
			})

		case "workflowEvents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowEventClient{config: _q.config}).Query()
			)
			args := newWorkflowEventPaginateArgs(fieldArgs(ctx, new(WorkflowEventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowEventsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowEventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[81] == nil {
								nodes[i].Edges.totalCount[81] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[81][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowEvents)
							if nodes[i].Edges.totalCount[81] == nil {
								nodes[i].Edges.totalCount[81] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[81][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workfloweventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowEventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowEvents(alias, func(wq *WorkflowEventQuery) {
				*wq = *query
			})

		case "workflowAssignments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowAssignmentsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowAssignmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[82] == nil {
								nodes[i].Edges.totalCount[82] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[82][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignments)
							if nodes[i].Edges.totalCount[82] == nil {
								nodes[i].Edges.totalCount[82] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[82][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowAssignmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignments(alias, func(wq *WorkflowAssignmentQuery) {
				*wq = *query
			})

		case "workflowAssignmentTargets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentTargetClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentTargetPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentTargetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentTargetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowAssignmentTargetsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowAssignmentTargetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[83] == nil {
								nodes[i].Edges.totalCount[83] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[83][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignmentTargets)
							if nodes[i].Edges.totalCount[83] == nil {
								nodes[i].Edges.totalCount[83] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[83][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmenttargetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowAssignmentTargetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignmentTargets(alias, func(wq *WorkflowAssignmentTargetQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(organization.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[84] == nil {
								nodes[i].Edges.totalCount[84] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[84][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[84] == nil {
								nodes[i].Edges.totalCount[84] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[84][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "directoryAccounts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			args := newDirectoryAccountPaginateArgs(fieldArgs(ctx, new(DirectoryAccountWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryAccountPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectoryAccountsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectoryAccountsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[85] == nil {
								nodes[i].Edges.totalCount[85] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[85][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryAccounts)
							if nodes[i].Edges.totalCount[85] == nil {
								nodes[i].Edges.totalCount[85] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[85][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectoryAccountsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryAccounts(alias, func(wq *DirectoryAccountQuery) {
				*wq = *query
			})

		case "directoryGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			args := newDirectoryGroupPaginateArgs(fieldArgs(ctx, new(DirectoryGroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectoryGroupsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectoryGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[86] == nil {
								nodes[i].Edges.totalCount[86] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[86][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryGroups)
							if nodes[i].Edges.totalCount[86] == nil {
								nodes[i].Edges.totalCount[86] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[86][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectoryGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryGroups(alias, func(wq *DirectoryGroupQuery) {
				*wq = *query
			})

		case "directoryMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			args := newDirectoryMembershipPaginateArgs(fieldArgs(ctx, new(DirectoryMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectoryMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectoryMembershipsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectoryMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[87] == nil {
								nodes[i].Edges.totalCount[87] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[87][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectoryMemberships)
							if nodes[i].Edges.totalCount[87] == nil {
								nodes[i].Edges.totalCount[87] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[87][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectoryMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectoryMemberships(alias, func(wq *DirectoryMembershipQuery) {
				*wq = *query
			})

		case "directorySyncRuns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectorySyncRunClient{config: _q.config}).Query()
			)
			args := newDirectorySyncRunPaginateArgs(fieldArgs(ctx, new(DirectorySyncRunWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDirectorySyncRunPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DirectorySyncRunsColumn), ids...))
						})
						if err := query.GroupBy(organization.DirectorySyncRunsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[88] == nil {
								nodes[i].Edges.totalCount[88] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[88][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.DirectorySyncRuns)
							if nodes[i].Edges.totalCount[88] == nil {
								nodes[i].Edges.totalCount[88] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[88][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, directorysyncrunImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DirectorySyncRunsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDirectorySyncRuns(alias, func(wq *DirectorySyncRunQuery) {
				*wq = *query
			})

		case "discussions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			args := newDiscussionPaginateArgs(fieldArgs(ctx, new(DiscussionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDiscussionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.DiscussionsColumn), ids...))
						})
						if err := query.GroupBy(organization.DiscussionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[89] == nil {
								nodes[i].Edges.totalCount[89] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[89][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Discussions)
							if nodes[i].Edges.totalCount[89] == nil {
								nodes[i].Edges.totalCount[89] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[89][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.DiscussionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDiscussions(alias, func(wq *DiscussionQuery) {
				*wq = *query
			})

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: _q.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Organization) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(organization.MembersColumn), ids...))
						})
						if err := query.GroupBy(organization.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[90] == nil {
								nodes[i].Edges.totalCount[90] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[90][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Organization) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[90] == nil {
								nodes[i].Edges.totalCount[90] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[90][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organization.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[organization.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldCreatedAt)
				fieldSeen[organization.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organization.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldUpdatedAt)
				fieldSeen[organization.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organization.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organization.FieldCreatedBy)
				fieldSeen[organization.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organization.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organization.FieldUpdatedBy)
				fieldSeen[organization.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organization.FieldTags]; !ok {
				selectedFields = append(selectedFields, organization.FieldTags)
				fieldSeen[organization.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[organization.FieldName]; !ok {
				selectedFields = append(selectedFields, organization.FieldName)
				fieldSeen[organization.FieldName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[organization.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, organization.FieldDisplayName)
				fieldSeen[organization.FieldDisplayName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[organization.FieldDescription]; !ok {
				selectedFields = append(selectedFields, organization.FieldDescription)
				fieldSeen[organization.FieldDescription] = struct{}{}
			}
		case "personalOrg":
			if _, ok := fieldSeen[organization.FieldPersonalOrg]; !ok {
				selectedFields = append(selectedFields, organization.FieldPersonalOrg)
				fieldSeen[organization.FieldPersonalOrg] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[organization.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarRemoteURL)
				fieldSeen[organization.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[organization.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarLocalFileID)
				fieldSeen[organization.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[organization.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organization.FieldAvatarUpdatedAt)
				fieldSeen[organization.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "dedicatedDb":
			if _, ok := fieldSeen[organization.FieldDedicatedDb]; !ok {
				selectedFields = append(selectedFields, organization.FieldDedicatedDb)
				fieldSeen[organization.FieldDedicatedDb] = struct{}{}
			}
		case "stripeCustomerID":
			if _, ok := fieldSeen[organization.FieldStripeCustomerID]; !ok {
				selectedFields = append(selectedFields, organization.FieldStripeCustomerID)
				fieldSeen[organization.FieldStripeCustomerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type organizationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationPaginateOption
}

func newOrganizationPaginateArgs(rv map[string]any) *organizationPaginateArgs {
	args := &organizationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrganizationOrder:
			args.opts = append(args.opts, WithOrganizationOrder(v))
		case []any:
			var orders []*OrganizationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrganizationOrder{Field: &OrganizationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrganizationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrganizationWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *OrganizationSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*OrganizationSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *OrganizationSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(organizationsetting.Columns))
		selectedFields = []string{organizationsetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "organization":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOrganization = query
			if _, ok := fieldSeen[organizationsetting.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOrganizationID)
				fieldSeen[organizationsetting.FieldOrganizationID] = struct{}{}
			}

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*OrganizationSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"organization_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(organizationsetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(organizationsetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(organizationsetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(organizationsetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(organizationsetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*OrganizationSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(organizationsetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[organizationsetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldCreatedAt)
				fieldSeen[organizationsetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[organizationsetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldUpdatedAt)
				fieldSeen[organizationsetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[organizationsetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldCreatedBy)
				fieldSeen[organizationsetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[organizationsetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldUpdatedBy)
				fieldSeen[organizationsetting.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[organizationsetting.FieldTags]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldTags)
				fieldSeen[organizationsetting.FieldTags] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[organizationsetting.FieldDomains]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldDomains)
				fieldSeen[organizationsetting.FieldDomains] = struct{}{}
			}
		case "billingContact":
			if _, ok := fieldSeen[organizationsetting.FieldBillingContact]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingContact)
				fieldSeen[organizationsetting.FieldBillingContact] = struct{}{}
			}
		case "billingEmail":
			if _, ok := fieldSeen[organizationsetting.FieldBillingEmail]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingEmail)
				fieldSeen[organizationsetting.FieldBillingEmail] = struct{}{}
			}
		case "billingPhone":
			if _, ok := fieldSeen[organizationsetting.FieldBillingPhone]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingPhone)
				fieldSeen[organizationsetting.FieldBillingPhone] = struct{}{}
			}
		case "billingAddress":
			if _, ok := fieldSeen[organizationsetting.FieldBillingAddress]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingAddress)
				fieldSeen[organizationsetting.FieldBillingAddress] = struct{}{}
			}
		case "taxIdentifier":
			if _, ok := fieldSeen[organizationsetting.FieldTaxIdentifier]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldTaxIdentifier)
				fieldSeen[organizationsetting.FieldTaxIdentifier] = struct{}{}
			}
		case "geoLocation":
			if _, ok := fieldSeen[organizationsetting.FieldGeoLocation]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldGeoLocation)
				fieldSeen[organizationsetting.FieldGeoLocation] = struct{}{}
			}
		case "organizationID":
			if _, ok := fieldSeen[organizationsetting.FieldOrganizationID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOrganizationID)
				fieldSeen[organizationsetting.FieldOrganizationID] = struct{}{}
			}
		case "billingNotificationsEnabled":
			if _, ok := fieldSeen[organizationsetting.FieldBillingNotificationsEnabled]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldBillingNotificationsEnabled)
				fieldSeen[organizationsetting.FieldBillingNotificationsEnabled] = struct{}{}
			}
		case "allowedEmailDomains":
			if _, ok := fieldSeen[organizationsetting.FieldAllowedEmailDomains]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldAllowedEmailDomains)
				fieldSeen[organizationsetting.FieldAllowedEmailDomains] = struct{}{}
			}
		case "allowMatchingDomainsAutojoin":
			if _, ok := fieldSeen[organizationsetting.FieldAllowMatchingDomainsAutojoin]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldAllowMatchingDomainsAutojoin)
				fieldSeen[organizationsetting.FieldAllowMatchingDomainsAutojoin] = struct{}{}
			}
		case "identityProvider":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProvider]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProvider)
				fieldSeen[organizationsetting.FieldIdentityProvider] = struct{}{}
			}
		case "identityProviderClientID":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderClientID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderClientID)
				fieldSeen[organizationsetting.FieldIdentityProviderClientID] = struct{}{}
			}
		case "identityProviderClientSecret":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderClientSecret]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderClientSecret)
				fieldSeen[organizationsetting.FieldIdentityProviderClientSecret] = struct{}{}
			}
		case "identityProviderMetadataEndpoint":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderMetadataEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderMetadataEndpoint)
				fieldSeen[organizationsetting.FieldIdentityProviderMetadataEndpoint] = struct{}{}
			}
		case "identityProviderAuthTested":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderAuthTested]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderAuthTested)
				fieldSeen[organizationsetting.FieldIdentityProviderAuthTested] = struct{}{}
			}
		case "identityProviderEntityID":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderEntityID]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderEntityID)
				fieldSeen[organizationsetting.FieldIdentityProviderEntityID] = struct{}{}
			}
		case "oidcDiscoveryEndpoint":
			if _, ok := fieldSeen[organizationsetting.FieldOidcDiscoveryEndpoint]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldOidcDiscoveryEndpoint)
				fieldSeen[organizationsetting.FieldOidcDiscoveryEndpoint] = struct{}{}
			}
		case "samlSigninURL":
			if _, ok := fieldSeen[organizationsetting.FieldSamlSigninURL]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldSamlSigninURL)
				fieldSeen[organizationsetting.FieldSamlSigninURL] = struct{}{}
			}
		case "samlIssuer":
			if _, ok := fieldSeen[organizationsetting.FieldSamlIssuer]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldSamlIssuer)
				fieldSeen[organizationsetting.FieldSamlIssuer] = struct{}{}
			}
		case "samlCert":
			if _, ok := fieldSeen[organizationsetting.FieldSamlCert]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldSamlCert)
				fieldSeen[organizationsetting.FieldSamlCert] = struct{}{}
			}
		case "identityProviderLoginEnforced":
			if _, ok := fieldSeen[organizationsetting.FieldIdentityProviderLoginEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldIdentityProviderLoginEnforced)
				fieldSeen[organizationsetting.FieldIdentityProviderLoginEnforced] = struct{}{}
			}
		case "multifactorAuthEnforced":
			if _, ok := fieldSeen[organizationsetting.FieldMultifactorAuthEnforced]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldMultifactorAuthEnforced)
				fieldSeen[organizationsetting.FieldMultifactorAuthEnforced] = struct{}{}
			}
		case "complianceWebhookToken":
			if _, ok := fieldSeen[organizationsetting.FieldComplianceWebhookToken]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldComplianceWebhookToken)
				fieldSeen[organizationsetting.FieldComplianceWebhookToken] = struct{}{}
			}
		case "paymentMethodAdded":
			if _, ok := fieldSeen[organizationsetting.FieldPaymentMethodAdded]; !ok {
				selectedFields = append(selectedFields, organizationsetting.FieldPaymentMethodAdded)
				fieldSeen[organizationsetting.FieldPaymentMethodAdded] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type organizationsettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []OrganizationSettingPaginateOption
}

func newOrganizationSettingPaginateArgs(rv map[string]any) *organizationsettingPaginateArgs {
	args := &organizationsettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*OrganizationSettingOrder:
			args.opts = append(args.opts, WithOrganizationSettingOrder(v))
		case []any:
			var orders []*OrganizationSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &OrganizationSettingOrder{Field: &OrganizationSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithOrganizationSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*OrganizationSettingWhereInput); ok {
		args.opts = append(args.opts, WithOrganizationSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *PersonalAccessTokenQuery) CollectFields(ctx context.Context, satisfies ...string) (*PersonalAccessTokenQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *PersonalAccessTokenQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(personalaccesstoken.Columns))
		selectedFields = []string{personalaccesstoken.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[personalaccesstoken.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldOwnerID)
				fieldSeen[personalaccesstoken.FieldOwnerID] = struct{}{}
			}

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*PersonalAccessToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"personal_access_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(personalaccesstoken.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(personalaccesstoken.OrganizationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(personalaccesstoken.OrganizationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*PersonalAccessToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(personalaccesstoken.OrganizationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*PersonalAccessToken) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"personal_access_token_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(personalaccesstoken.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(personalaccesstoken.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(personalaccesstoken.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(personalaccesstoken.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(personalaccesstoken.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*PersonalAccessToken) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(personalaccesstoken.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldCreatedAt)
				fieldSeen[personalaccesstoken.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldUpdatedAt)
				fieldSeen[personalaccesstoken.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldCreatedBy)
				fieldSeen[personalaccesstoken.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldUpdatedBy)
				fieldSeen[personalaccesstoken.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[personalaccesstoken.FieldTags]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldTags)
				fieldSeen[personalaccesstoken.FieldTags] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[personalaccesstoken.FieldName]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldName)
				fieldSeen[personalaccesstoken.FieldName] = struct{}{}
			}
		case "token":
			if _, ok := fieldSeen[personalaccesstoken.FieldToken]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldToken)
				fieldSeen[personalaccesstoken.FieldToken] = struct{}{}
			}
		case "expiresAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldExpiresAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldExpiresAt)
				fieldSeen[personalaccesstoken.FieldExpiresAt] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[personalaccesstoken.FieldDescription]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldDescription)
				fieldSeen[personalaccesstoken.FieldDescription] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[personalaccesstoken.FieldScopes]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldScopes)
				fieldSeen[personalaccesstoken.FieldScopes] = struct{}{}
			}
		case "ssoAuthorizations":
			if _, ok := fieldSeen[personalaccesstoken.FieldSSOAuthorizations]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldSSOAuthorizations)
				fieldSeen[personalaccesstoken.FieldSSOAuthorizations] = struct{}{}
			}
		case "lastUsedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldLastUsedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldLastUsedAt)
				fieldSeen[personalaccesstoken.FieldLastUsedAt] = struct{}{}
			}
		case "isActive":
			if _, ok := fieldSeen[personalaccesstoken.FieldIsActive]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldIsActive)
				fieldSeen[personalaccesstoken.FieldIsActive] = struct{}{}
			}
		case "revokedReason":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedReason]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedReason)
				fieldSeen[personalaccesstoken.FieldRevokedReason] = struct{}{}
			}
		case "revokedBy":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedBy]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedBy)
				fieldSeen[personalaccesstoken.FieldRevokedBy] = struct{}{}
			}
		case "revokedAt":
			if _, ok := fieldSeen[personalaccesstoken.FieldRevokedAt]; !ok {
				selectedFields = append(selectedFields, personalaccesstoken.FieldRevokedAt)
				fieldSeen[personalaccesstoken.FieldRevokedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type personalaccesstokenPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []PersonalAccessTokenPaginateOption
}

func newPersonalAccessTokenPaginateArgs(rv map[string]any) *personalaccesstokenPaginateArgs {
	args := &personalaccesstokenPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*PersonalAccessTokenOrder:
			args.opts = append(args.opts, WithPersonalAccessTokenOrder(v))
		case []any:
			var orders []*PersonalAccessTokenOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &PersonalAccessTokenOrder{Field: &PersonalAccessTokenOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithPersonalAccessTokenOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*PersonalAccessTokenWhereInput); ok {
		args.opts = append(args.opts, WithPersonalAccessTokenFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProcedureQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProcedureQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProcedureQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(procedure.Columns))
		selectedFields = []string{procedure.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[procedure.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldOwnerID)
				fieldSeen[procedure.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(procedure.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(procedure.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "approver":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withApprover = query
			if _, ok := fieldSeen[procedure.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApproverID)
				fieldSeen[procedure.FieldApproverID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[procedure.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDelegateID)
				fieldSeen[procedure.FieldDelegateID] = struct{}{}
			}

		case "procedureKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withProcedureKind = query
			if _, ok := fieldSeen[procedure.FieldProcedureKindID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureKindID)
				fieldSeen[procedure.FieldProcedureKindID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(procedure.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(procedure.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(procedure.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(procedure.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(procedure.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(procedure.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(procedure.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(procedure.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(procedure.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(procedure.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(procedure.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(procedure.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(procedure.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(procedure.CommentsColumn), ids...))
						})
						if err := query.GroupBy(procedure.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "discussions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			args := newDiscussionPaginateArgs(fieldArgs(ctx, new(DiscussionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDiscussionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_discussions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(procedure.DiscussionsColumn), ids...))
						})
						if err := query.GroupBy(procedure.DiscussionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Discussions)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.DiscussionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDiscussions(alias, func(wq *DiscussionQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[procedure.FieldFileID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldFileID)
				fieldSeen[procedure.FieldFileID] = struct{}{}
			}

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Procedure) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"procedure_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(procedure.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(procedure.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Procedure) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(procedure.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[procedure.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, procedure.FieldCreatedAt)
				fieldSeen[procedure.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[procedure.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, procedure.FieldUpdatedAt)
				fieldSeen[procedure.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[procedure.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, procedure.FieldCreatedBy)
				fieldSeen[procedure.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[procedure.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, procedure.FieldUpdatedBy)
				fieldSeen[procedure.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[procedure.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDisplayID)
				fieldSeen[procedure.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[procedure.FieldTags]; !ok {
				selectedFields = append(selectedFields, procedure.FieldTags)
				fieldSeen[procedure.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[procedure.FieldRevision]; !ok {
				selectedFields = append(selectedFields, procedure.FieldRevision)
				fieldSeen[procedure.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[procedure.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldOwnerID)
				fieldSeen[procedure.FieldOwnerID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[procedure.FieldName]; !ok {
				selectedFields = append(selectedFields, procedure.FieldName)
				fieldSeen[procedure.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[procedure.FieldStatus]; !ok {
				selectedFields = append(selectedFields, procedure.FieldStatus)
				fieldSeen[procedure.FieldStatus] = struct{}{}
			}
		case "procedureType":
			if _, ok := fieldSeen[procedure.FieldProcedureType]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureType)
				fieldSeen[procedure.FieldProcedureType] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[procedure.FieldDetails]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDetails)
				fieldSeen[procedure.FieldDetails] = struct{}{}
			}
		case "detailsJSON":
			if _, ok := fieldSeen[procedure.FieldDetailsJSON]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDetailsJSON)
				fieldSeen[procedure.FieldDetailsJSON] = struct{}{}
			}
		case "approvalRequired":
			if _, ok := fieldSeen[procedure.FieldApprovalRequired]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApprovalRequired)
				fieldSeen[procedure.FieldApprovalRequired] = struct{}{}
			}
		case "reviewDue":
			if _, ok := fieldSeen[procedure.FieldReviewDue]; !ok {
				selectedFields = append(selectedFields, procedure.FieldReviewDue)
				fieldSeen[procedure.FieldReviewDue] = struct{}{}
			}
		case "reviewFrequency":
			if _, ok := fieldSeen[procedure.FieldReviewFrequency]; !ok {
				selectedFields = append(selectedFields, procedure.FieldReviewFrequency)
				fieldSeen[procedure.FieldReviewFrequency] = struct{}{}
			}
		case "approverID":
			if _, ok := fieldSeen[procedure.FieldApproverID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldApproverID)
				fieldSeen[procedure.FieldApproverID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[procedure.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDelegateID)
				fieldSeen[procedure.FieldDelegateID] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[procedure.FieldSummary]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSummary)
				fieldSeen[procedure.FieldSummary] = struct{}{}
			}
		case "tagSuggestions":
			if _, ok := fieldSeen[procedure.FieldTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldTagSuggestions)
				fieldSeen[procedure.FieldTagSuggestions] = struct{}{}
			}
		case "dismissedTagSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedTagSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedTagSuggestions)
				fieldSeen[procedure.FieldDismissedTagSuggestions] = struct{}{}
			}
		case "controlSuggestions":
			if _, ok := fieldSeen[procedure.FieldControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldControlSuggestions)
				fieldSeen[procedure.FieldControlSuggestions] = struct{}{}
			}
		case "dismissedControlSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedControlSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedControlSuggestions)
				fieldSeen[procedure.FieldDismissedControlSuggestions] = struct{}{}
			}
		case "improvementSuggestions":
			if _, ok := fieldSeen[procedure.FieldImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldImprovementSuggestions)
				fieldSeen[procedure.FieldImprovementSuggestions] = struct{}{}
			}
		case "dismissedImprovementSuggestions":
			if _, ok := fieldSeen[procedure.FieldDismissedImprovementSuggestions]; !ok {
				selectedFields = append(selectedFields, procedure.FieldDismissedImprovementSuggestions)
				fieldSeen[procedure.FieldDismissedImprovementSuggestions] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[procedure.FieldURL]; !ok {
				selectedFields = append(selectedFields, procedure.FieldURL)
				fieldSeen[procedure.FieldURL] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[procedure.FieldFileID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldFileID)
				fieldSeen[procedure.FieldFileID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[procedure.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSystemOwned)
				fieldSeen[procedure.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[procedure.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, procedure.FieldInternalNotes)
				fieldSeen[procedure.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[procedure.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldSystemInternalID)
				fieldSeen[procedure.FieldSystemInternalID] = struct{}{}
			}
		case "procedureKindName":
			if _, ok := fieldSeen[procedure.FieldProcedureKindName]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureKindName)
				fieldSeen[procedure.FieldProcedureKindName] = struct{}{}
			}
		case "procedureKindID":
			if _, ok := fieldSeen[procedure.FieldProcedureKindID]; !ok {
				selectedFields = append(selectedFields, procedure.FieldProcedureKindID)
				fieldSeen[procedure.FieldProcedureKindID] = struct{}{}
			}
		case "workflowEligibleMarker":
			if _, ok := fieldSeen[procedure.FieldWorkflowEligibleMarker]; !ok {
				selectedFields = append(selectedFields, procedure.FieldWorkflowEligibleMarker)
				fieldSeen[procedure.FieldWorkflowEligibleMarker] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type procedurePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProcedurePaginateOption
}

func newProcedurePaginateArgs(rv map[string]any) *procedurePaginateArgs {
	args := &procedurePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProcedureOrder:
			args.opts = append(args.opts, WithProcedureOrder(v))
		case []any:
			var orders []*ProcedureOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProcedureOrder{Field: &ProcedureOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProcedureOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProcedureWhereInput); ok {
		args.opts = append(args.opts, WithProcedureFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProgramQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProgramQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(program.Columns))
		selectedFields = []string{program.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[program.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldOwnerID)
				fieldSeen[program.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(program.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "programKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withProgramKind = query
			if _, ok := fieldSeen[program.FieldProgramKindID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramKindID)
				fieldSeen[program.FieldProgramKindID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(program.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(program.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(program.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(program.InternalPoliciesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.InternalPoliciesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.InternalPoliciesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.InternalPoliciesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.InternalPoliciesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(program.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(program.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(program.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "notes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_notes"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.NotesColumn), ids...))
						})
						if err := query.GroupBy(program.NotesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Notes)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.NotesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNotes(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(program.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(program.EvidencePrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.EvidencePrimaryKey[0]), ids...))
							s.Select(joinT.C(program.EvidencePrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.EvidencePrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.EvidencePrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.NarrativesTable)
							s.Join(joinT).On(s.C(narrative.FieldID), joinT.C(program.NarrativesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.NarrativesPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.NarrativesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.NarrativesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.NarrativesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(program.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(program.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(program.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(program.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(program.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(program.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(program.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(program.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(program.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "programOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withProgramOwner = query
			if _, ok := fieldSeen[program.FieldProgramOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramOwnerID)
				fieldSeen[program.FieldProgramOwnerID] = struct{}{}
			}

		case "members":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramMembershipClient{config: _q.config}).Query()
			)
			args := newProgramMembershipPaginateArgs(fieldArgs(ctx, new(ProgramMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Program) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(program.MembersColumn), ids...))
						})
						if err := query.GroupBy(program.MembersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Program) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Members)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(program.MembersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedMembers(alias, func(wq *ProgramMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[program.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, program.FieldCreatedAt)
				fieldSeen[program.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[program.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, program.FieldUpdatedAt)
				fieldSeen[program.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[program.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, program.FieldCreatedBy)
				fieldSeen[program.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[program.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, program.FieldUpdatedBy)
				fieldSeen[program.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[program.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, program.FieldDisplayID)
				fieldSeen[program.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[program.FieldTags]; !ok {
				selectedFields = append(selectedFields, program.FieldTags)
				fieldSeen[program.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[program.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldOwnerID)
				fieldSeen[program.FieldOwnerID] = struct{}{}
			}
		case "programKindName":
			if _, ok := fieldSeen[program.FieldProgramKindName]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramKindName)
				fieldSeen[program.FieldProgramKindName] = struct{}{}
			}
		case "programKindID":
			if _, ok := fieldSeen[program.FieldProgramKindID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramKindID)
				fieldSeen[program.FieldProgramKindID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[program.FieldName]; !ok {
				selectedFields = append(selectedFields, program.FieldName)
				fieldSeen[program.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[program.FieldDescription]; !ok {
				selectedFields = append(selectedFields, program.FieldDescription)
				fieldSeen[program.FieldDescription] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[program.FieldStatus]; !ok {
				selectedFields = append(selectedFields, program.FieldStatus)
				fieldSeen[program.FieldStatus] = struct{}{}
			}
		case "programType":
			if _, ok := fieldSeen[program.FieldProgramType]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramType)
				fieldSeen[program.FieldProgramType] = struct{}{}
			}
		case "frameworkName":
			if _, ok := fieldSeen[program.FieldFrameworkName]; !ok {
				selectedFields = append(selectedFields, program.FieldFrameworkName)
				fieldSeen[program.FieldFrameworkName] = struct{}{}
			}
		case "startDate":
			if _, ok := fieldSeen[program.FieldStartDate]; !ok {
				selectedFields = append(selectedFields, program.FieldStartDate)
				fieldSeen[program.FieldStartDate] = struct{}{}
			}
		case "endDate":
			if _, ok := fieldSeen[program.FieldEndDate]; !ok {
				selectedFields = append(selectedFields, program.FieldEndDate)
				fieldSeen[program.FieldEndDate] = struct{}{}
			}
		case "auditorReady":
			if _, ok := fieldSeen[program.FieldAuditorReady]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorReady)
				fieldSeen[program.FieldAuditorReady] = struct{}{}
			}
		case "auditorWriteComments":
			if _, ok := fieldSeen[program.FieldAuditorWriteComments]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorWriteComments)
				fieldSeen[program.FieldAuditorWriteComments] = struct{}{}
			}
		case "auditorReadComments":
			if _, ok := fieldSeen[program.FieldAuditorReadComments]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorReadComments)
				fieldSeen[program.FieldAuditorReadComments] = struct{}{}
			}
		case "auditFirm":
			if _, ok := fieldSeen[program.FieldAuditFirm]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditFirm)
				fieldSeen[program.FieldAuditFirm] = struct{}{}
			}
		case "auditor":
			if _, ok := fieldSeen[program.FieldAuditor]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditor)
				fieldSeen[program.FieldAuditor] = struct{}{}
			}
		case "auditorEmail":
			if _, ok := fieldSeen[program.FieldAuditorEmail]; !ok {
				selectedFields = append(selectedFields, program.FieldAuditorEmail)
				fieldSeen[program.FieldAuditorEmail] = struct{}{}
			}
		case "programOwnerID":
			if _, ok := fieldSeen[program.FieldProgramOwnerID]; !ok {
				selectedFields = append(selectedFields, program.FieldProgramOwnerID)
				fieldSeen[program.FieldProgramOwnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type programPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramPaginateOption
}

func newProgramPaginateArgs(rv map[string]any) *programPaginateArgs {
	args := &programPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProgramOrder:
			args.opts = append(args.opts, WithProgramOrder(v))
		case []any:
			var orders []*ProgramOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProgramOrder{Field: &ProgramOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProgramOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProgramWhereInput); ok {
		args.opts = append(args.opts, WithProgramFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProgramMembershipQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProgramMembershipQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProgramMembershipQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(programmembership.Columns))
		selectedFields = []string{programmembership.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "program":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
				return err
			}
			_q.withProgram = query
			if _, ok := fieldSeen[programmembership.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldProgramID)
				fieldSeen[programmembership.FieldProgramID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[programmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUserID)
				fieldSeen[programmembership.FieldUserID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[programmembership.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldCreatedAt)
				fieldSeen[programmembership.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[programmembership.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUpdatedAt)
				fieldSeen[programmembership.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[programmembership.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldCreatedBy)
				fieldSeen[programmembership.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[programmembership.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUpdatedBy)
				fieldSeen[programmembership.FieldUpdatedBy] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[programmembership.FieldRole]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldRole)
				fieldSeen[programmembership.FieldRole] = struct{}{}
			}
		case "programID":
			if _, ok := fieldSeen[programmembership.FieldProgramID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldProgramID)
				fieldSeen[programmembership.FieldProgramID] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[programmembership.FieldUserID]; !ok {
				selectedFields = append(selectedFields, programmembership.FieldUserID)
				fieldSeen[programmembership.FieldUserID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type programmembershipPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProgramMembershipPaginateOption
}

func newProgramMembershipPaginateArgs(rv map[string]any) *programmembershipPaginateArgs {
	args := &programmembershipPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ProgramMembershipOrder:
			args.opts = append(args.opts, WithProgramMembershipOrder(v))
		case []any:
			var orders []*ProgramMembershipOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ProgramMembershipOrder{Field: &ProgramMembershipOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithProgramMembershipOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ProgramMembershipWhereInput); ok {
		args.opts = append(args.opts, WithProgramMembershipFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RemediationQuery) CollectFields(ctx context.Context, satisfies ...string) (*RemediationQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RemediationQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(remediation.Columns))
		selectedFields = []string{remediation.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[remediation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldOwnerID)
				fieldSeen[remediation.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(remediation.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.EditorsColumn), ids...))
						})
						if err := query.GroupBy(remediation.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ViewersColumn), ids...))
						})
						if err := query.GroupBy(remediation.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(remediation.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(remediation.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(remediation.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(remediation.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(remediation.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_findings"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.FindingsColumn), ids...))
						})
						if err := query.GroupBy(remediation.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_vulnerabilities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(remediation.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(remediation.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(remediation.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(remediation.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(remediation.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(remediation.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.TasksColumn), ids...))
						})
						if err := query.GroupBy(remediation.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ControlsColumn), ids...))
						})
						if err := query.GroupBy(remediation.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(remediation.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.RisksColumn), ids...))
						})
						if err := query.GroupBy(remediation.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(remediation.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.AssetsColumn), ids...))
						})
						if err := query.GroupBy(remediation.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(remediation.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_reviews"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(remediation.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.CommentsColumn), ids...))
						})
						if err := query.GroupBy(remediation.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Remediation) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"remediation_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(remediation.FilesColumn), ids...))
						})
						if err := query.GroupBy(remediation.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Remediation) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(remediation.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[remediation.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldCreatedAt)
				fieldSeen[remediation.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[remediation.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldUpdatedAt)
				fieldSeen[remediation.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[remediation.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, remediation.FieldCreatedBy)
				fieldSeen[remediation.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[remediation.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, remediation.FieldUpdatedBy)
				fieldSeen[remediation.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[remediation.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldDisplayID)
				fieldSeen[remediation.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[remediation.FieldTags]; !ok {
				selectedFields = append(selectedFields, remediation.FieldTags)
				fieldSeen[remediation.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[remediation.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldOwnerID)
				fieldSeen[remediation.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[remediation.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSystemOwned)
				fieldSeen[remediation.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[remediation.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, remediation.FieldInternalNotes)
				fieldSeen[remediation.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[remediation.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSystemInternalID)
				fieldSeen[remediation.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[remediation.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExternalID)
				fieldSeen[remediation.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[remediation.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExternalOwnerID)
				fieldSeen[remediation.FieldExternalOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[remediation.FieldTitle]; !ok {
				selectedFields = append(selectedFields, remediation.FieldTitle)
				fieldSeen[remediation.FieldTitle] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[remediation.FieldState]; !ok {
				selectedFields = append(selectedFields, remediation.FieldState)
				fieldSeen[remediation.FieldState] = struct{}{}
			}
		case "intent":
			if _, ok := fieldSeen[remediation.FieldIntent]; !ok {
				selectedFields = append(selectedFields, remediation.FieldIntent)
				fieldSeen[remediation.FieldIntent] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[remediation.FieldSummary]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSummary)
				fieldSeen[remediation.FieldSummary] = struct{}{}
			}
		case "explanation":
			if _, ok := fieldSeen[remediation.FieldExplanation]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExplanation)
				fieldSeen[remediation.FieldExplanation] = struct{}{}
			}
		case "instructions":
			if _, ok := fieldSeen[remediation.FieldInstructions]; !ok {
				selectedFields = append(selectedFields, remediation.FieldInstructions)
				fieldSeen[remediation.FieldInstructions] = struct{}{}
			}
		case "ownerReference":
			if _, ok := fieldSeen[remediation.FieldOwnerReference]; !ok {
				selectedFields = append(selectedFields, remediation.FieldOwnerReference)
				fieldSeen[remediation.FieldOwnerReference] = struct{}{}
			}
		case "repositoryURI":
			if _, ok := fieldSeen[remediation.FieldRepositoryURI]; !ok {
				selectedFields = append(selectedFields, remediation.FieldRepositoryURI)
				fieldSeen[remediation.FieldRepositoryURI] = struct{}{}
			}
		case "pullRequestURI":
			if _, ok := fieldSeen[remediation.FieldPullRequestURI]; !ok {
				selectedFields = append(selectedFields, remediation.FieldPullRequestURI)
				fieldSeen[remediation.FieldPullRequestURI] = struct{}{}
			}
		case "ticketReference":
			if _, ok := fieldSeen[remediation.FieldTicketReference]; !ok {
				selectedFields = append(selectedFields, remediation.FieldTicketReference)
				fieldSeen[remediation.FieldTicketReference] = struct{}{}
			}
		case "dueAt":
			if _, ok := fieldSeen[remediation.FieldDueAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldDueAt)
				fieldSeen[remediation.FieldDueAt] = struct{}{}
			}
		case "completedAt":
			if _, ok := fieldSeen[remediation.FieldCompletedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldCompletedAt)
				fieldSeen[remediation.FieldCompletedAt] = struct{}{}
			}
		case "prGeneratedAt":
			if _, ok := fieldSeen[remediation.FieldPrGeneratedAt]; !ok {
				selectedFields = append(selectedFields, remediation.FieldPrGeneratedAt)
				fieldSeen[remediation.FieldPrGeneratedAt] = struct{}{}
			}
		case "error":
			if _, ok := fieldSeen[remediation.FieldError]; !ok {
				selectedFields = append(selectedFields, remediation.FieldError)
				fieldSeen[remediation.FieldError] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[remediation.FieldSource]; !ok {
				selectedFields = append(selectedFields, remediation.FieldSource)
				fieldSeen[remediation.FieldSource] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[remediation.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, remediation.FieldExternalURI)
				fieldSeen[remediation.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[remediation.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, remediation.FieldMetadata)
				fieldSeen[remediation.FieldMetadata] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type remediationPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RemediationPaginateOption
}

func newRemediationPaginateArgs(rv map[string]any) *remediationPaginateArgs {
	args := &remediationPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*RemediationOrder:
			args.opts = append(args.opts, WithRemediationOrder(v))
		case []any:
			var orders []*RemediationOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &RemediationOrder{Field: &RemediationOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithRemediationOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*RemediationWhereInput); ok {
		args.opts = append(args.opts, WithRemediationFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ReviewQuery) CollectFields(ctx context.Context, satisfies ...string) (*ReviewQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ReviewQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(review.Columns))
		selectedFields = []string{review.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[review.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, review.FieldOwnerID)
				fieldSeen[review.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(review.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.EditorsColumn), ids...))
						})
						if err := query.GroupBy(review.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.ViewersColumn), ids...))
						})
						if err := query.GroupBy(review.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(review.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(review.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(review.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(review.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(review.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_findings"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.FindingsColumn), ids...))
						})
						if err := query.GroupBy(review.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "vulnerabilities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&VulnerabilityClient{config: _q.config}).Query()
			)
			args := newVulnerabilityPaginateArgs(fieldArgs(ctx, new(VulnerabilityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newVulnerabilityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_vulnerabilities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.VulnerabilitiesColumn), ids...))
						})
						if err := query.GroupBy(review.VulnerabilitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Vulnerabilities)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, vulnerabilityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.VulnerabilitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedVulnerabilities(alias, func(wq *VulnerabilityQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(review.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(review.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(review.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(review.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(review.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_remediations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(review.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.ControlsColumn), ids...))
						})
						if err := query.GroupBy(review.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(review.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.RisksColumn), ids...))
						})
						if err := query.GroupBy(review.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(review.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.AssetsColumn), ids...))
						})
						if err := query.GroupBy(review.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(review.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.TasksColumn), ids...))
						})
						if err := query.GroupBy(review.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "reviewer":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withReviewer = query
			if _, ok := fieldSeen[review.FieldReviewerID]; !ok {
				selectedFields = append(selectedFields, review.FieldReviewerID)
				fieldSeen[review.FieldReviewerID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.CommentsColumn), ids...))
						})
						if err := query.GroupBy(review.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Review) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"review_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(review.FilesColumn), ids...))
						})
						if err := query.GroupBy(review.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Review) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(review.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[review.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldCreatedAt)
				fieldSeen[review.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[review.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldUpdatedAt)
				fieldSeen[review.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[review.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, review.FieldCreatedBy)
				fieldSeen[review.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[review.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, review.FieldUpdatedBy)
				fieldSeen[review.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[review.FieldTags]; !ok {
				selectedFields = append(selectedFields, review.FieldTags)
				fieldSeen[review.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[review.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, review.FieldOwnerID)
				fieldSeen[review.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[review.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, review.FieldSystemOwned)
				fieldSeen[review.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[review.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, review.FieldInternalNotes)
				fieldSeen[review.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[review.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, review.FieldSystemInternalID)
				fieldSeen[review.FieldSystemInternalID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[review.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, review.FieldExternalID)
				fieldSeen[review.FieldExternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[review.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, review.FieldExternalOwnerID)
				fieldSeen[review.FieldExternalOwnerID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[review.FieldTitle]; !ok {
				selectedFields = append(selectedFields, review.FieldTitle)
				fieldSeen[review.FieldTitle] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[review.FieldState]; !ok {
				selectedFields = append(selectedFields, review.FieldState)
				fieldSeen[review.FieldState] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[review.FieldCategory]; !ok {
				selectedFields = append(selectedFields, review.FieldCategory)
				fieldSeen[review.FieldCategory] = struct{}{}
			}
		case "classification":
			if _, ok := fieldSeen[review.FieldClassification]; !ok {
				selectedFields = append(selectedFields, review.FieldClassification)
				fieldSeen[review.FieldClassification] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[review.FieldSummary]; !ok {
				selectedFields = append(selectedFields, review.FieldSummary)
				fieldSeen[review.FieldSummary] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[review.FieldDetails]; !ok {
				selectedFields = append(selectedFields, review.FieldDetails)
				fieldSeen[review.FieldDetails] = struct{}{}
			}
		case "reporter":
			if _, ok := fieldSeen[review.FieldReporter]; !ok {
				selectedFields = append(selectedFields, review.FieldReporter)
				fieldSeen[review.FieldReporter] = struct{}{}
			}
		case "approved":
			if _, ok := fieldSeen[review.FieldApproved]; !ok {
				selectedFields = append(selectedFields, review.FieldApproved)
				fieldSeen[review.FieldApproved] = struct{}{}
			}
		case "reviewedAt":
			if _, ok := fieldSeen[review.FieldReviewedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldReviewedAt)
				fieldSeen[review.FieldReviewedAt] = struct{}{}
			}
		case "reportedAt":
			if _, ok := fieldSeen[review.FieldReportedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldReportedAt)
				fieldSeen[review.FieldReportedAt] = struct{}{}
			}
		case "approvedAt":
			if _, ok := fieldSeen[review.FieldApprovedAt]; !ok {
				selectedFields = append(selectedFields, review.FieldApprovedAt)
				fieldSeen[review.FieldApprovedAt] = struct{}{}
			}
		case "reviewerID":
			if _, ok := fieldSeen[review.FieldReviewerID]; !ok {
				selectedFields = append(selectedFields, review.FieldReviewerID)
				fieldSeen[review.FieldReviewerID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[review.FieldSource]; !ok {
				selectedFields = append(selectedFields, review.FieldSource)
				fieldSeen[review.FieldSource] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[review.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, review.FieldExternalURI)
				fieldSeen[review.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[review.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, review.FieldMetadata)
				fieldSeen[review.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[review.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, review.FieldRawPayload)
				fieldSeen[review.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type reviewPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ReviewPaginateOption
}

func newReviewPaginateArgs(rv map[string]any) *reviewPaginateArgs {
	args := &reviewPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ReviewOrder:
			args.opts = append(args.opts, WithReviewOrder(v))
		case []any:
			var orders []*ReviewOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ReviewOrder{Field: &ReviewOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithReviewOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ReviewWhereInput); ok {
		args.opts = append(args.opts, WithReviewFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RiskQuery) CollectFields(ctx context.Context, satisfies ...string) (*RiskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RiskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(risk.Columns))
		selectedFields = []string{risk.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[risk.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, risk.FieldOwnerID)
				fieldSeen[risk.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(risk.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "riskKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withRiskKind = query
			if _, ok := fieldSeen[risk.FieldRiskKindID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskKindID)
				fieldSeen[risk.FieldRiskKindID] = struct{}{}
			}

		case "riskCategory":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withRiskCategory = query
			if _, ok := fieldSeen[risk.FieldRiskCategoryID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskCategoryID)
				fieldSeen[risk.FieldRiskCategoryID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(risk.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(risk.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(risk.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(risk.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(risk.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(risk.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(risk.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(risk.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(risk.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(risk.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(risk.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(risk.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(risk.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.AssetsColumn), ids...))
						})
						if err := query.GroupBy(risk.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(risk.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.ScansColumn), ids...))
						})
						if err := query.GroupBy(risk.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "stakeholder":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withStakeholder = query
			if _, ok := fieldSeen[risk.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, risk.FieldStakeholderID)
				fieldSeen[risk.FieldStakeholderID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[risk.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDelegateID)
				fieldSeen[risk.FieldDelegateID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.CommentsColumn), ids...))
						})
						if err := query.GroupBy(risk.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "discussions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			args := newDiscussionPaginateArgs(fieldArgs(ctx, new(DiscussionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDiscussionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Risk) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"risk_discussions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(risk.DiscussionsColumn), ids...))
						})
						if err := query.GroupBy(risk.DiscussionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Risk) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Discussions)
							if nodes[i].Edges.totalCount[19] == nil {
								nodes[i].Edges.totalCount[19] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[19][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(risk.DiscussionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDiscussions(alias, func(wq *DiscussionQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[risk.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, risk.FieldCreatedAt)
				fieldSeen[risk.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[risk.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, risk.FieldUpdatedAt)
				fieldSeen[risk.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[risk.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, risk.FieldCreatedBy)
				fieldSeen[risk.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[risk.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, risk.FieldUpdatedBy)
				fieldSeen[risk.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[risk.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDisplayID)
				fieldSeen[risk.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[risk.FieldTags]; !ok {
				selectedFields = append(selectedFields, risk.FieldTags)
				fieldSeen[risk.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[risk.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, risk.FieldOwnerID)
				fieldSeen[risk.FieldOwnerID] = struct{}{}
			}
		case "riskKindName":
			if _, ok := fieldSeen[risk.FieldRiskKindName]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskKindName)
				fieldSeen[risk.FieldRiskKindName] = struct{}{}
			}
		case "riskKindID":
			if _, ok := fieldSeen[risk.FieldRiskKindID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskKindID)
				fieldSeen[risk.FieldRiskKindID] = struct{}{}
			}
		case "riskCategoryName":
			if _, ok := fieldSeen[risk.FieldRiskCategoryName]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskCategoryName)
				fieldSeen[risk.FieldRiskCategoryName] = struct{}{}
			}
		case "riskCategoryID":
			if _, ok := fieldSeen[risk.FieldRiskCategoryID]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskCategoryID)
				fieldSeen[risk.FieldRiskCategoryID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[risk.FieldName]; !ok {
				selectedFields = append(selectedFields, risk.FieldName)
				fieldSeen[risk.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[risk.FieldStatus]; !ok {
				selectedFields = append(selectedFields, risk.FieldStatus)
				fieldSeen[risk.FieldStatus] = struct{}{}
			}
		case "riskType":
			if _, ok := fieldSeen[risk.FieldRiskType]; !ok {
				selectedFields = append(selectedFields, risk.FieldRiskType)
				fieldSeen[risk.FieldRiskType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[risk.FieldCategory]; !ok {
				selectedFields = append(selectedFields, risk.FieldCategory)
				fieldSeen[risk.FieldCategory] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[risk.FieldImpact]; !ok {
				selectedFields = append(selectedFields, risk.FieldImpact)
				fieldSeen[risk.FieldImpact] = struct{}{}
			}
		case "likelihood":
			if _, ok := fieldSeen[risk.FieldLikelihood]; !ok {
				selectedFields = append(selectedFields, risk.FieldLikelihood)
				fieldSeen[risk.FieldLikelihood] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[risk.FieldScore]; !ok {
				selectedFields = append(selectedFields, risk.FieldScore)
				fieldSeen[risk.FieldScore] = struct{}{}
			}
		case "mitigation":
			if _, ok := fieldSeen[risk.FieldMitigation]; !ok {
				selectedFields = append(selectedFields, risk.FieldMitigation)
				fieldSeen[risk.FieldMitigation] = struct{}{}
			}
		case "mitigationJSON":
			if _, ok := fieldSeen[risk.FieldMitigationJSON]; !ok {
				selectedFields = append(selectedFields, risk.FieldMitigationJSON)
				fieldSeen[risk.FieldMitigationJSON] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[risk.FieldDetails]; !ok {
				selectedFields = append(selectedFields, risk.FieldDetails)
				fieldSeen[risk.FieldDetails] = struct{}{}
			}
		case "detailsJSON":
			if _, ok := fieldSeen[risk.FieldDetailsJSON]; !ok {
				selectedFields = append(selectedFields, risk.FieldDetailsJSON)
				fieldSeen[risk.FieldDetailsJSON] = struct{}{}
			}
		case "businessCosts":
			if _, ok := fieldSeen[risk.FieldBusinessCosts]; !ok {
				selectedFields = append(selectedFields, risk.FieldBusinessCosts)
				fieldSeen[risk.FieldBusinessCosts] = struct{}{}
			}
		case "businessCostsJSON":
			if _, ok := fieldSeen[risk.FieldBusinessCostsJSON]; !ok {
				selectedFields = append(selectedFields, risk.FieldBusinessCostsJSON)
				fieldSeen[risk.FieldBusinessCostsJSON] = struct{}{}
			}
		case "stakeholderID":
			if _, ok := fieldSeen[risk.FieldStakeholderID]; !ok {
				selectedFields = append(selectedFields, risk.FieldStakeholderID)
				fieldSeen[risk.FieldStakeholderID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[risk.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, risk.FieldDelegateID)
				fieldSeen[risk.FieldDelegateID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type riskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RiskPaginateOption
}

func newRiskPaginateArgs(rv map[string]any) *riskPaginateArgs {
	args := &riskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*RiskOrder:
			args.opts = append(args.opts, WithRiskOrder(v))
		case []any:
			var orders []*RiskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &RiskOrder{Field: &RiskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithRiskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*RiskWhereInput); ok {
		args.opts = append(args.opts, WithRiskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScanQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScanQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScanQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scan.Columns))
		selectedFields = []string{scan.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[scan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scan.FieldOwnerID)
				fieldSeen[scan.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.BlockedGroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.BlockedGroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.BlockedGroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.BlockedGroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.BlockedGroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.BlockedGroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.EditorsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.EditorsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.EditorsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.EditorsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.EditorsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.EditorsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.ViewersTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(scan.ViewersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.ViewersPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.ViewersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.ViewersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.ViewersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scan.AssetsTable)
							s.Join(joinT).On(s.C(asset.FieldID), joinT.C(scan.AssetsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scan.AssetsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scan.AssetsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scan.AssetsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.AssetsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Scan) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scan_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(scan.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(scan.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Scan) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scan.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[scan.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scan.FieldCreatedAt)
				fieldSeen[scan.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scan.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scan.FieldUpdatedAt)
				fieldSeen[scan.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scan.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scan.FieldCreatedBy)
				fieldSeen[scan.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scan.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scan.FieldUpdatedBy)
				fieldSeen[scan.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[scan.FieldTags]; !ok {
				selectedFields = append(selectedFields, scan.FieldTags)
				fieldSeen[scan.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scan.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scan.FieldOwnerID)
				fieldSeen[scan.FieldOwnerID] = struct{}{}
			}
		case "target":
			if _, ok := fieldSeen[scan.FieldTarget]; !ok {
				selectedFields = append(selectedFields, scan.FieldTarget)
				fieldSeen[scan.FieldTarget] = struct{}{}
			}
		case "scanType":
			if _, ok := fieldSeen[scan.FieldScanType]; !ok {
				selectedFields = append(selectedFields, scan.FieldScanType)
				fieldSeen[scan.FieldScanType] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[scan.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, scan.FieldMetadata)
				fieldSeen[scan.FieldMetadata] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scan.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scan.FieldStatus)
				fieldSeen[scan.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scanPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScanPaginateOption
}

func newScanPaginateArgs(rv map[string]any) *scanPaginateArgs {
	args := &scanPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScanOrder:
			args.opts = append(args.opts, WithScanOrder(v))
		case []any:
			var orders []*ScanOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScanOrder{Field: &ScanOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScanOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScanWhereInput); ok {
		args.opts = append(args.opts, WithScanFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScheduledJobQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScheduledJobQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjob.Columns))
		selectedFields = []string{scheduledjob.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[scheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldOwnerID)
				fieldSeen[scheduledjob.FieldOwnerID] = struct{}{}
			}

		case "jobTemplate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobTemplateClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobtemplateImplementors)...); err != nil {
				return err
			}
			_q.withJobTemplate = query
			if _, ok := fieldSeen[scheduledjob.FieldJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobID)
				fieldSeen[scheduledjob.FieldJobID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ScheduledJob) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scheduled_job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scheduledjob.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(scheduledjob.ControlsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scheduledjob.ControlsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scheduledjob.ControlsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scheduledjob.ControlsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ScheduledJob) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scheduledjob.ControlsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*ScheduledJob) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"scheduled_job_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(scheduledjob.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(scheduledjob.SubcontrolsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(scheduledjob.SubcontrolsPrimaryKey[0]), ids...))
							s.Select(joinT.C(scheduledjob.SubcontrolsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(scheduledjob.SubcontrolsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*ScheduledJob) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(scheduledjob.SubcontrolsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			_q.withJobRunner = query
			if _, ok := fieldSeen[scheduledjob.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobRunnerID)
				fieldSeen[scheduledjob.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjob.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCreatedAt)
				fieldSeen[scheduledjob.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjob.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldUpdatedAt)
				fieldSeen[scheduledjob.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjob.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCreatedBy)
				fieldSeen[scheduledjob.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjob.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldUpdatedBy)
				fieldSeen[scheduledjob.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[scheduledjob.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldDisplayID)
				fieldSeen[scheduledjob.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjob.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldOwnerID)
				fieldSeen[scheduledjob.FieldOwnerID] = struct{}{}
			}
		case "jobID":
			if _, ok := fieldSeen[scheduledjob.FieldJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobID)
				fieldSeen[scheduledjob.FieldJobID] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[scheduledjob.FieldActive]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldActive)
				fieldSeen[scheduledjob.FieldActive] = struct{}{}
			}
		case "configuration":
			if _, ok := fieldSeen[scheduledjob.FieldConfiguration]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldConfiguration)
				fieldSeen[scheduledjob.FieldConfiguration] = struct{}{}
			}
		case "cron":
			if _, ok := fieldSeen[scheduledjob.FieldCron]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldCron)
				fieldSeen[scheduledjob.FieldCron] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[scheduledjob.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjob.FieldJobRunnerID)
				fieldSeen[scheduledjob.FieldJobRunnerID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scheduledjobPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobPaginateOption
}

func newScheduledJobPaginateArgs(rv map[string]any) *scheduledjobPaginateArgs {
	args := &scheduledjobPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScheduledJobOrder:
			args.opts = append(args.opts, WithScheduledJobOrder(v))
		case []any:
			var orders []*ScheduledJobOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScheduledJobOrder{Field: &ScheduledJobOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScheduledJobOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ScheduledJobRunQuery) CollectFields(ctx context.Context, satisfies ...string) (*ScheduledJobRunQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ScheduledJobRunQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(scheduledjobrun.Columns))
		selectedFields = []string{scheduledjobrun.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[scheduledjobrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldOwnerID)
				fieldSeen[scheduledjobrun.FieldOwnerID] = struct{}{}
			}

		case "scheduledJob":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
				return err
			}
			_q.withScheduledJob = query
			if _, ok := fieldSeen[scheduledjobrun.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScheduledJobID)
				fieldSeen[scheduledjobrun.FieldScheduledJobID] = struct{}{}
			}

		case "jobRunner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&JobRunnerClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, jobrunnerImplementors)...); err != nil {
				return err
			}
			_q.withJobRunner = query
			if _, ok := fieldSeen[scheduledjobrun.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldJobRunnerID)
				fieldSeen[scheduledjobrun.FieldJobRunnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[scheduledjobrun.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldCreatedAt)
				fieldSeen[scheduledjobrun.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[scheduledjobrun.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldUpdatedAt)
				fieldSeen[scheduledjobrun.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[scheduledjobrun.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldCreatedBy)
				fieldSeen[scheduledjobrun.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[scheduledjobrun.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldUpdatedBy)
				fieldSeen[scheduledjobrun.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[scheduledjobrun.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldOwnerID)
				fieldSeen[scheduledjobrun.FieldOwnerID] = struct{}{}
			}
		case "jobRunnerID":
			if _, ok := fieldSeen[scheduledjobrun.FieldJobRunnerID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldJobRunnerID)
				fieldSeen[scheduledjobrun.FieldJobRunnerID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[scheduledjobrun.FieldStatus]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldStatus)
				fieldSeen[scheduledjobrun.FieldStatus] = struct{}{}
			}
		case "scheduledJobID":
			if _, ok := fieldSeen[scheduledjobrun.FieldScheduledJobID]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScheduledJobID)
				fieldSeen[scheduledjobrun.FieldScheduledJobID] = struct{}{}
			}
		case "expectedExecutionTime":
			if _, ok := fieldSeen[scheduledjobrun.FieldExpectedExecutionTime]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldExpectedExecutionTime)
				fieldSeen[scheduledjobrun.FieldExpectedExecutionTime] = struct{}{}
			}
		case "script":
			if _, ok := fieldSeen[scheduledjobrun.FieldScript]; !ok {
				selectedFields = append(selectedFields, scheduledjobrun.FieldScript)
				fieldSeen[scheduledjobrun.FieldScript] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type scheduledjobrunPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ScheduledJobRunPaginateOption
}

func newScheduledJobRunPaginateArgs(rv map[string]any) *scheduledjobrunPaginateArgs {
	args := &scheduledjobrunPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ScheduledJobRunOrder:
			args.opts = append(args.opts, WithScheduledJobRunOrder(v))
		case []any:
			var orders []*ScheduledJobRunOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ScheduledJobRunOrder{Field: &ScheduledJobRunOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithScheduledJobRunOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ScheduledJobRunWhereInput); ok {
		args.opts = append(args.opts, WithScheduledJobRunFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *StandardQuery) CollectFields(ctx context.Context, satisfies ...string) (*StandardQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *StandardQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(standard.Columns))
		selectedFields = []string{standard.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[standard.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standard.FieldOwnerID)
				fieldSeen[standard.FieldOwnerID] = struct{}{}
			}

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Standard) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"standard_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(standard.ControlsColumn), ids...))
						})
						if err := query.GroupBy(standard.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Standard) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(standard.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "trustCenterCompliances":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterComplianceClient{config: _q.config}).Query()
			)
			args := newTrustCenterCompliancePaginateArgs(fieldArgs(ctx, new(TrustCenterComplianceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterCompliancePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Standard) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"standard_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(standard.TrustCenterCompliancesColumn), ids...))
						})
						if err := query.GroupBy(standard.TrustCenterCompliancesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Standard) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterCompliances)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentercomplianceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(standard.TrustCenterCompliancesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterCompliances(alias, func(wq *TrustCenterComplianceQuery) {
				*wq = *query
			})

		case "trustCenterDocs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterDocClient{config: _q.config}).Query()
			)
			args := newTrustCenterDocPaginateArgs(fieldArgs(ctx, new(TrustCenterDocWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterDocPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Standard) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"standard_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(standard.TrustCenterDocsColumn), ids...))
						})
						if err := query.GroupBy(standard.TrustCenterDocsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Standard) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterDocs)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterdocImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(standard.TrustCenterDocsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterDocs(alias, func(wq *TrustCenterDocQuery) {
				*wq = *query
			})

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[standard.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, standard.FieldLogoFileID)
				fieldSeen[standard.FieldLogoFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[standard.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, standard.FieldCreatedAt)
				fieldSeen[standard.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[standard.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, standard.FieldUpdatedAt)
				fieldSeen[standard.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[standard.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, standard.FieldCreatedBy)
				fieldSeen[standard.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[standard.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, standard.FieldUpdatedBy)
				fieldSeen[standard.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[standard.FieldTags]; !ok {
				selectedFields = append(selectedFields, standard.FieldTags)
				fieldSeen[standard.FieldTags] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[standard.FieldRevision]; !ok {
				selectedFields = append(selectedFields, standard.FieldRevision)
				fieldSeen[standard.FieldRevision] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[standard.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, standard.FieldOwnerID)
				fieldSeen[standard.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[standard.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, standard.FieldSystemOwned)
				fieldSeen[standard.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[standard.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, standard.FieldInternalNotes)
				fieldSeen[standard.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[standard.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, standard.FieldSystemInternalID)
				fieldSeen[standard.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[standard.FieldName]; !ok {
				selectedFields = append(selectedFields, standard.FieldName)
				fieldSeen[standard.FieldName] = struct{}{}
			}
		case "shortName":
			if _, ok := fieldSeen[standard.FieldShortName]; !ok {
				selectedFields = append(selectedFields, standard.FieldShortName)
				fieldSeen[standard.FieldShortName] = struct{}{}
			}
		case "framework":
			if _, ok := fieldSeen[standard.FieldFramework]; !ok {
				selectedFields = append(selectedFields, standard.FieldFramework)
				fieldSeen[standard.FieldFramework] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[standard.FieldDescription]; !ok {
				selectedFields = append(selectedFields, standard.FieldDescription)
				fieldSeen[standard.FieldDescription] = struct{}{}
			}
		case "governingBodyLogoURL":
			if _, ok := fieldSeen[standard.FieldGoverningBodyLogoURL]; !ok {
				selectedFields = append(selectedFields, standard.FieldGoverningBodyLogoURL)
				fieldSeen[standard.FieldGoverningBodyLogoURL] = struct{}{}
			}
		case "governingBody":
			if _, ok := fieldSeen[standard.FieldGoverningBody]; !ok {
				selectedFields = append(selectedFields, standard.FieldGoverningBody)
				fieldSeen[standard.FieldGoverningBody] = struct{}{}
			}
		case "domains":
			if _, ok := fieldSeen[standard.FieldDomains]; !ok {
				selectedFields = append(selectedFields, standard.FieldDomains)
				fieldSeen[standard.FieldDomains] = struct{}{}
			}
		case "link":
			if _, ok := fieldSeen[standard.FieldLink]; !ok {
				selectedFields = append(selectedFields, standard.FieldLink)
				fieldSeen[standard.FieldLink] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[standard.FieldStatus]; !ok {
				selectedFields = append(selectedFields, standard.FieldStatus)
				fieldSeen[standard.FieldStatus] = struct{}{}
			}
		case "isPublic":
			if _, ok := fieldSeen[standard.FieldIsPublic]; !ok {
				selectedFields = append(selectedFields, standard.FieldIsPublic)
				fieldSeen[standard.FieldIsPublic] = struct{}{}
			}
		case "freeToUse":
			if _, ok := fieldSeen[standard.FieldFreeToUse]; !ok {
				selectedFields = append(selectedFields, standard.FieldFreeToUse)
				fieldSeen[standard.FieldFreeToUse] = struct{}{}
			}
		case "standardType":
			if _, ok := fieldSeen[standard.FieldStandardType]; !ok {
				selectedFields = append(selectedFields, standard.FieldStandardType)
				fieldSeen[standard.FieldStandardType] = struct{}{}
			}
		case "version":
			if _, ok := fieldSeen[standard.FieldVersion]; !ok {
				selectedFields = append(selectedFields, standard.FieldVersion)
				fieldSeen[standard.FieldVersion] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[standard.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, standard.FieldLogoFileID)
				fieldSeen[standard.FieldLogoFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type standardPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []StandardPaginateOption
}

func newStandardPaginateArgs(rv map[string]any) *standardPaginateArgs {
	args := &standardPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*StandardOrder:
			args.opts = append(args.opts, WithStandardOrder(v))
		case []any:
			var orders []*StandardOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &StandardOrder{Field: &StandardOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithStandardOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*StandardWhereInput); ok {
		args.opts = append(args.opts, WithStandardFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubcontrolQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubcontrolQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubcontrolQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subcontrol.Columns))
		selectedFields = []string{subcontrol.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(subcontrol.EvidencePrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.EvidencePrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.EvidencePrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.EvidencePrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.EvidencePrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(subcontrol.ControlObjectivesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ControlObjectivesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ControlObjectivesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.TasksTable)
							s.Join(joinT).On(s.C(task.FieldID), joinT.C(subcontrol.TasksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.TasksPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.TasksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.TasksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.TasksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "narratives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NarrativeClient{config: _q.config}).Query()
			)
			args := newNarrativePaginateArgs(fieldArgs(ctx, new(NarrativeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNarrativePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_narratives"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.NarrativesColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.NarrativesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Narratives)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, narrativeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.NarrativesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedNarratives(alias, func(wq *NarrativeQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(subcontrol.RisksPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.RisksPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.RisksPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.RisksPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.RisksPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(subcontrol.ProceduresPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ProceduresPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ProceduresPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ProceduresPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ProceduresPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(subcontrol.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.CommentsColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "discussions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DiscussionClient{config: _q.config}).Query()
			)
			args := newDiscussionPaginateArgs(fieldArgs(ctx, new(DiscussionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDiscussionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_discussions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.DiscussionsColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.DiscussionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Discussions)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, discussionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.DiscussionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDiscussions(alias, func(wq *DiscussionQuery) {
				*wq = *query
			})

		case "controlOwner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withControlOwner = query
			if _, ok := fieldSeen[subcontrol.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlOwnerID)
				fieldSeen[subcontrol.FieldControlOwnerID] = struct{}{}
			}

		case "delegate":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withDelegate = query
			if _, ok := fieldSeen[subcontrol.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDelegateID)
				fieldSeen[subcontrol.FieldDelegateID] = struct{}{}
			}

		case "responsibleParty":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
				return err
			}
			_q.withResponsibleParty = query
			if _, ok := fieldSeen[subcontrol.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldResponsiblePartyID)
				fieldSeen[subcontrol.FieldResponsiblePartyID] = struct{}{}
			}

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[subcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldOwnerID)
				fieldSeen[subcontrol.FieldOwnerID] = struct{}{}
			}

		case "subcontrolKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrolKind = query
			if _, ok := fieldSeen[subcontrol.FieldSubcontrolKindID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcontrolKindID)
				fieldSeen[subcontrol.FieldSubcontrolKindID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[subcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlID)
				fieldSeen[subcontrol.FieldControlID] = struct{}{}
			}

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(subcontrol.ControlImplementationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ControlImplementationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ControlImplementationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "scheduledJobs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScheduledJobClient{config: _q.config}).Query()
			)
			args := newScheduledJobPaginateArgs(fieldArgs(ctx, new(ScheduledJobWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScheduledJobPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subcontrol.ScheduledJobsTable)
							s.Join(joinT).On(s.C(scheduledjob.FieldID), joinT.C(subcontrol.ScheduledJobsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]), ids...))
							s.Select(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(subcontrol.ScheduledJobsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ScheduledJobs)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scheduledjobImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.ScheduledJobsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScheduledJobs(alias, func(wq *ScheduledJobQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subcontrol) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subcontrol_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subcontrol.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(subcontrol.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subcontrol) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subcontrol.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subcontrol.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCreatedAt)
				fieldSeen[subcontrol.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subcontrol.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldUpdatedAt)
				fieldSeen[subcontrol.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subcontrol.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCreatedBy)
				fieldSeen[subcontrol.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subcontrol.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldUpdatedBy)
				fieldSeen[subcontrol.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[subcontrol.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDisplayID)
				fieldSeen[subcontrol.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subcontrol.FieldTags]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldTags)
				fieldSeen[subcontrol.FieldTags] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[subcontrol.FieldTitle]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldTitle)
				fieldSeen[subcontrol.FieldTitle] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subcontrol.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDescription)
				fieldSeen[subcontrol.FieldDescription] = struct{}{}
			}
		case "descriptionJSON":
			if _, ok := fieldSeen[subcontrol.FieldDescriptionJSON]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDescriptionJSON)
				fieldSeen[subcontrol.FieldDescriptionJSON] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[subcontrol.FieldAliases]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAliases)
				fieldSeen[subcontrol.FieldAliases] = struct{}{}
			}
		case "referenceID":
			if _, ok := fieldSeen[subcontrol.FieldReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceID)
				fieldSeen[subcontrol.FieldReferenceID] = struct{}{}
			}
		case "auditorReferenceID":
			if _, ok := fieldSeen[subcontrol.FieldAuditorReferenceID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAuditorReferenceID)
				fieldSeen[subcontrol.FieldAuditorReferenceID] = struct{}{}
			}
		case "responsiblePartyID":
			if _, ok := fieldSeen[subcontrol.FieldResponsiblePartyID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldResponsiblePartyID)
				fieldSeen[subcontrol.FieldResponsiblePartyID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[subcontrol.FieldStatus]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldStatus)
				fieldSeen[subcontrol.FieldStatus] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[subcontrol.FieldSource]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSource)
				fieldSeen[subcontrol.FieldSource] = struct{}{}
			}
		case "referenceFramework":
			if _, ok := fieldSeen[subcontrol.FieldReferenceFramework]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceFramework)
				fieldSeen[subcontrol.FieldReferenceFramework] = struct{}{}
			}
		case "referenceFrameworkRevision":
			if _, ok := fieldSeen[subcontrol.FieldReferenceFrameworkRevision]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferenceFrameworkRevision)
				fieldSeen[subcontrol.FieldReferenceFrameworkRevision] = struct{}{}
			}
		case "controlType":
			if _, ok := fieldSeen[subcontrol.FieldControlType]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlType)
				fieldSeen[subcontrol.FieldControlType] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[subcontrol.FieldCategory]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCategory)
				fieldSeen[subcontrol.FieldCategory] = struct{}{}
			}
		case "categoryID":
			if _, ok := fieldSeen[subcontrol.FieldCategoryID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldCategoryID)
				fieldSeen[subcontrol.FieldCategoryID] = struct{}{}
			}
		case "subcategory":
			if _, ok := fieldSeen[subcontrol.FieldSubcategory]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcategory)
				fieldSeen[subcontrol.FieldSubcategory] = struct{}{}
			}
		case "mappedCategories":
			if _, ok := fieldSeen[subcontrol.FieldMappedCategories]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldMappedCategories)
				fieldSeen[subcontrol.FieldMappedCategories] = struct{}{}
			}
		case "assessmentObjectives":
			if _, ok := fieldSeen[subcontrol.FieldAssessmentObjectives]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAssessmentObjectives)
				fieldSeen[subcontrol.FieldAssessmentObjectives] = struct{}{}
			}
		case "assessmentMethods":
			if _, ok := fieldSeen[subcontrol.FieldAssessmentMethods]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldAssessmentMethods)
				fieldSeen[subcontrol.FieldAssessmentMethods] = struct{}{}
			}
		case "controlQuestions":
			if _, ok := fieldSeen[subcontrol.FieldControlQuestions]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlQuestions)
				fieldSeen[subcontrol.FieldControlQuestions] = struct{}{}
			}
		case "implementationGuidance":
			if _, ok := fieldSeen[subcontrol.FieldImplementationGuidance]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldImplementationGuidance)
				fieldSeen[subcontrol.FieldImplementationGuidance] = struct{}{}
			}
		case "exampleEvidence":
			if _, ok := fieldSeen[subcontrol.FieldExampleEvidence]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldExampleEvidence)
				fieldSeen[subcontrol.FieldExampleEvidence] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[subcontrol.FieldReferences]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldReferences)
				fieldSeen[subcontrol.FieldReferences] = struct{}{}
			}
		case "testingProcedures":
			if _, ok := fieldSeen[subcontrol.FieldTestingProcedures]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldTestingProcedures)
				fieldSeen[subcontrol.FieldTestingProcedures] = struct{}{}
			}
		case "evidenceRequests":
			if _, ok := fieldSeen[subcontrol.FieldEvidenceRequests]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldEvidenceRequests)
				fieldSeen[subcontrol.FieldEvidenceRequests] = struct{}{}
			}
		case "controlOwnerID":
			if _, ok := fieldSeen[subcontrol.FieldControlOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlOwnerID)
				fieldSeen[subcontrol.FieldControlOwnerID] = struct{}{}
			}
		case "delegateID":
			if _, ok := fieldSeen[subcontrol.FieldDelegateID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldDelegateID)
				fieldSeen[subcontrol.FieldDelegateID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subcontrol.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldOwnerID)
				fieldSeen[subcontrol.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subcontrol.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSystemOwned)
				fieldSeen[subcontrol.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[subcontrol.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldInternalNotes)
				fieldSeen[subcontrol.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[subcontrol.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSystemInternalID)
				fieldSeen[subcontrol.FieldSystemInternalID] = struct{}{}
			}
		case "subcontrolKindName":
			if _, ok := fieldSeen[subcontrol.FieldSubcontrolKindName]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcontrolKindName)
				fieldSeen[subcontrol.FieldSubcontrolKindName] = struct{}{}
			}
		case "subcontrolKindID":
			if _, ok := fieldSeen[subcontrol.FieldSubcontrolKindID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldSubcontrolKindID)
				fieldSeen[subcontrol.FieldSubcontrolKindID] = struct{}{}
			}
		case "workflowEligibleMarker":
			if _, ok := fieldSeen[subcontrol.FieldWorkflowEligibleMarker]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldWorkflowEligibleMarker)
				fieldSeen[subcontrol.FieldWorkflowEligibleMarker] = struct{}{}
			}
		case "refCode":
			if _, ok := fieldSeen[subcontrol.FieldRefCode]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldRefCode)
				fieldSeen[subcontrol.FieldRefCode] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[subcontrol.FieldControlID]; !ok {
				selectedFields = append(selectedFields, subcontrol.FieldControlID)
				fieldSeen[subcontrol.FieldControlID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subcontrolPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubcontrolPaginateOption
}

func newSubcontrolPaginateArgs(rv map[string]any) *subcontrolPaginateArgs {
	args := &subcontrolPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubcontrolOrder:
			args.opts = append(args.opts, WithSubcontrolOrder(v))
		case []any:
			var orders []*SubcontrolOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubcontrolOrder{Field: &SubcontrolOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubcontrolOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubcontrolWhereInput); ok {
		args.opts = append(args.opts, WithSubcontrolFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubprocessorQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubprocessorQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubprocessorQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subprocessor.Columns))
		selectedFields = []string{subprocessor.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[subprocessor.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldOwnerID)
				fieldSeen[subprocessor.FieldOwnerID] = struct{}{}
			}

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[subprocessor.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoFileID)
				fieldSeen[subprocessor.FieldLogoFileID] = struct{}{}
			}

		case "trustCenterSubprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSubprocessorClient{config: _q.config}).Query()
			)
			args := newTrustCenterSubprocessorPaginateArgs(fieldArgs(ctx, new(TrustCenterSubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subprocessor) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subprocessor_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(subprocessor.TrustCenterSubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(subprocessor.TrustCenterSubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subprocessor) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentersubprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subprocessor.TrustCenterSubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterSubprocessors(alias, func(wq *TrustCenterSubprocessorQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subprocessor.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldCreatedAt)
				fieldSeen[subprocessor.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subprocessor.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldUpdatedAt)
				fieldSeen[subprocessor.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subprocessor.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldCreatedBy)
				fieldSeen[subprocessor.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subprocessor.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldUpdatedBy)
				fieldSeen[subprocessor.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subprocessor.FieldTags]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldTags)
				fieldSeen[subprocessor.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subprocessor.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldOwnerID)
				fieldSeen[subprocessor.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[subprocessor.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldSystemOwned)
				fieldSeen[subprocessor.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[subprocessor.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldInternalNotes)
				fieldSeen[subprocessor.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[subprocessor.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldSystemInternalID)
				fieldSeen[subprocessor.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[subprocessor.FieldName]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldName)
				fieldSeen[subprocessor.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[subprocessor.FieldDescription]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldDescription)
				fieldSeen[subprocessor.FieldDescription] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[subprocessor.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoRemoteURL)
				fieldSeen[subprocessor.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[subprocessor.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, subprocessor.FieldLogoFileID)
				fieldSeen[subprocessor.FieldLogoFileID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subprocessorPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubprocessorPaginateOption
}

func newSubprocessorPaginateArgs(rv map[string]any) *subprocessorPaginateArgs {
	args := &subprocessorPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubprocessorOrder:
			args.opts = append(args.opts, WithSubprocessorOrder(v))
		case []any:
			var orders []*SubprocessorOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubprocessorOrder{Field: &SubprocessorOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubprocessorOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubprocessorWhereInput); ok {
		args.opts = append(args.opts, WithSubprocessorFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SubscriberQuery) CollectFields(ctx context.Context, satisfies ...string) (*SubscriberQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SubscriberQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(subscriber.Columns))
		selectedFields = []string{subscriber.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[subscriber.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldOwnerID)
				fieldSeen[subscriber.FieldOwnerID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Subscriber) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"subscriber_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(subscriber.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(subscriber.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(subscriber.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(subscriber.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(subscriber.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Subscriber) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(subscriber.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[subscriber.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldCreatedAt)
				fieldSeen[subscriber.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[subscriber.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUpdatedAt)
				fieldSeen[subscriber.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[subscriber.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldCreatedBy)
				fieldSeen[subscriber.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[subscriber.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUpdatedBy)
				fieldSeen[subscriber.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[subscriber.FieldTags]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldTags)
				fieldSeen[subscriber.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[subscriber.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldOwnerID)
				fieldSeen[subscriber.FieldOwnerID] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[subscriber.FieldEmail]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldEmail)
				fieldSeen[subscriber.FieldEmail] = struct{}{}
			}
		case "phoneNumber":
			if _, ok := fieldSeen[subscriber.FieldPhoneNumber]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldPhoneNumber)
				fieldSeen[subscriber.FieldPhoneNumber] = struct{}{}
			}
		case "verifiedEmail":
			if _, ok := fieldSeen[subscriber.FieldVerifiedEmail]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldVerifiedEmail)
				fieldSeen[subscriber.FieldVerifiedEmail] = struct{}{}
			}
		case "verifiedPhone":
			if _, ok := fieldSeen[subscriber.FieldVerifiedPhone]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldVerifiedPhone)
				fieldSeen[subscriber.FieldVerifiedPhone] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[subscriber.FieldActive]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldActive)
				fieldSeen[subscriber.FieldActive] = struct{}{}
			}
		case "unsubscribed":
			if _, ok := fieldSeen[subscriber.FieldUnsubscribed]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldUnsubscribed)
				fieldSeen[subscriber.FieldUnsubscribed] = struct{}{}
			}
		case "sendAttempts":
			if _, ok := fieldSeen[subscriber.FieldSendAttempts]; !ok {
				selectedFields = append(selectedFields, subscriber.FieldSendAttempts)
				fieldSeen[subscriber.FieldSendAttempts] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type subscriberPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SubscriberPaginateOption
}

func newSubscriberPaginateArgs(rv map[string]any) *subscriberPaginateArgs {
	args := &subscriberPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*SubscriberOrder:
			args.opts = append(args.opts, WithSubscriberOrder(v))
		case []any:
			var orders []*SubscriberOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &SubscriberOrder{Field: &SubscriberOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithSubscriberOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*SubscriberWhereInput); ok {
		args.opts = append(args.opts, WithSubscriberFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TFASettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*TFASettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TFASettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tfasetting.Columns))
		selectedFields = []string{tfasetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[tfasetting.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldOwnerID)
				fieldSeen[tfasetting.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[tfasetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldCreatedAt)
				fieldSeen[tfasetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[tfasetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldUpdatedAt)
				fieldSeen[tfasetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[tfasetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldCreatedBy)
				fieldSeen[tfasetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[tfasetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldUpdatedBy)
				fieldSeen[tfasetting.FieldUpdatedBy] = struct{}{}
			}
		case "verified":
			if _, ok := fieldSeen[tfasetting.FieldVerified]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldVerified)
				fieldSeen[tfasetting.FieldVerified] = struct{}{}
			}
		case "totpAllowed":
			if _, ok := fieldSeen[tfasetting.FieldTotpAllowed]; !ok {
				selectedFields = append(selectedFields, tfasetting.FieldTotpAllowed)
				fieldSeen[tfasetting.FieldTotpAllowed] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type tfasettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TFASettingPaginateOption
}

func newTFASettingPaginateArgs(rv map[string]any) *tfasettingPaginateArgs {
	args := &tfasettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TFASettingOrder:
			args.opts = append(args.opts, WithTFASettingOrder(v))
		case []any:
			var orders []*TFASettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TFASettingOrder{Field: &TFASettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTFASettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TFASettingWhereInput); ok {
		args.opts = append(args.opts, WithTFASettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TagDefinitionQuery) CollectFields(ctx context.Context, satisfies ...string) (*TagDefinitionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TagDefinitionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tagdefinition.Columns))
		selectedFields = []string{tagdefinition.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[tagdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldOwnerID)
				fieldSeen[tagdefinition.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[tagdefinition.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldCreatedAt)
				fieldSeen[tagdefinition.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[tagdefinition.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldUpdatedAt)
				fieldSeen[tagdefinition.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[tagdefinition.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldCreatedBy)
				fieldSeen[tagdefinition.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[tagdefinition.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldUpdatedBy)
				fieldSeen[tagdefinition.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[tagdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldOwnerID)
				fieldSeen[tagdefinition.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[tagdefinition.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldSystemOwned)
				fieldSeen[tagdefinition.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[tagdefinition.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldInternalNotes)
				fieldSeen[tagdefinition.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[tagdefinition.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldSystemInternalID)
				fieldSeen[tagdefinition.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[tagdefinition.FieldName]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldName)
				fieldSeen[tagdefinition.FieldName] = struct{}{}
			}
		case "aliases":
			if _, ok := fieldSeen[tagdefinition.FieldAliases]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldAliases)
				fieldSeen[tagdefinition.FieldAliases] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[tagdefinition.FieldSlug]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldSlug)
				fieldSeen[tagdefinition.FieldSlug] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[tagdefinition.FieldDescription]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldDescription)
				fieldSeen[tagdefinition.FieldDescription] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[tagdefinition.FieldColor]; !ok {
				selectedFields = append(selectedFields, tagdefinition.FieldColor)
				fieldSeen[tagdefinition.FieldColor] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type tagdefinitionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TagDefinitionPaginateOption
}

func newTagDefinitionPaginateArgs(rv map[string]any) *tagdefinitionPaginateArgs {
	args := &tagdefinitionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TagDefinitionOrder:
			args.opts = append(args.opts, WithTagDefinitionOrder(v))
		case []any:
			var orders []*TagDefinitionOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TagDefinitionOrder{Field: &TagDefinitionOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTagDefinitionOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TagDefinitionWhereInput); ok {
		args.opts = append(args.opts, WithTagDefinitionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TaskQuery) CollectFields(ctx context.Context, satisfies ...string) (*TaskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TaskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(task.Columns))
		selectedFields = []string{task.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[task.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, task.FieldOwnerID)
				fieldSeen[task.FieldOwnerID] = struct{}{}
			}

		case "taskKind":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomTypeEnumClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customtypeenumImplementors)...); err != nil {
				return err
			}
			_q.withTaskKind = query
			if _, ok := fieldSeen[task.FieldTaskKindID]; !ok {
				selectedFields = append(selectedFields, task.FieldTaskKindID)
				fieldSeen[task.FieldTaskKindID] = struct{}{}
			}

		case "assigner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withAssigner = query
			if _, ok := fieldSeen[task.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssignerID)
				fieldSeen[task.FieldAssignerID] = struct{}{}
			}

		case "assignee":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withAssignee = query
			if _, ok := fieldSeen[task.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssigneeID)
				fieldSeen[task.FieldAssigneeID] = struct{}{}
			}

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.CommentsColumn), ids...))
						})
						if err := query.GroupBy(task.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(task.GroupsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.GroupsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.GroupsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.GroupsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.GroupsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "internalPolicies":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			args := newInternalPolicyPaginateArgs(fieldArgs(ctx, new(InternalPolicyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newInternalPolicyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.InternalPoliciesTable)
							s.Join(joinT).On(s.C(internalpolicy.FieldID), joinT.C(task.InternalPoliciesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.InternalPoliciesPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.InternalPoliciesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.InternalPoliciesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.InternalPolicies)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.InternalPoliciesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedInternalPolicies(alias, func(wq *InternalPolicyQuery) {
				*wq = *query
			})

		case "procedures":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			args := newProcedurePaginateArgs(fieldArgs(ctx, new(ProcedureWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProcedurePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ProceduresTable)
							s.Join(joinT).On(s.C(procedure.FieldID), joinT.C(task.ProceduresPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ProceduresPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ProceduresPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ProceduresPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Procedures)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ProceduresPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProcedures(alias, func(wq *ProcedureQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlsTable)
							s.Join(joinT).On(s.C(control.FieldID), joinT.C(task.ControlsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.SubcontrolsTable)
							s.Join(joinT).On(s.C(subcontrol.FieldID), joinT.C(task.SubcontrolsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.SubcontrolsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.SubcontrolsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.SubcontrolsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.SubcontrolsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "controlObjectives":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlObjectiveClient{config: _q.config}).Query()
			)
			args := newControlObjectivePaginateArgs(fieldArgs(ctx, new(ControlObjectiveWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlObjectivePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlObjectivesTable)
							s.Join(joinT).On(s.C(controlobjective.FieldID), joinT.C(task.ControlObjectivesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlObjectivesPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlObjectivesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlObjectivesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlObjectives)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlobjectiveImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlObjectivesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlObjectives(alias, func(wq *ControlObjectiveQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(task.ProgramsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ProgramsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ProgramsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ProgramsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ProgramsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.RisksTable)
							s.Join(joinT).On(s.C(risk.FieldID), joinT.C(task.RisksPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.RisksPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.RisksPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.RisksPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.RisksPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "controlImplementations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlImplementationClient{config: _q.config}).Query()
			)
			args := newControlImplementationPaginateArgs(fieldArgs(ctx, new(ControlImplementationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlImplementationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ControlImplementationsTable)
							s.Join(joinT).On(s.C(controlimplementation.FieldID), joinT.C(task.ControlImplementationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ControlImplementationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ControlImplementationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ControlImplementationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ControlImplementations)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlimplementationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ControlImplementationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControlImplementations(alias, func(wq *ControlImplementationQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(task.ActionPlansPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(task.ActionPlansPrimaryKey[1]), ids...))
							s.Select(joinT.C(task.ActionPlansPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(task.ActionPlansPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ActionPlansPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			args := newEvidencePaginateArgs(fieldArgs(ctx, new(EvidenceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEvidencePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(task.EvidenceTable)
							s.Join(joinT).On(s.C(evidence.FieldID), joinT.C(task.EvidencePrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(task.EvidencePrimaryKey[0]), ids...))
							s.Select(joinT.C(task.EvidencePrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(task.EvidencePrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Evidence)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.EvidencePrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvidence(alias, func(wq *EvidenceQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"task_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(task.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})

		case "parent":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			_q.withParent = query
			if _, ok := fieldSeen[task.FieldParentTaskID]; !ok {
				selectedFields = append(selectedFields, task.FieldParentTaskID)
				fieldSeen[task.FieldParentTaskID] = struct{}{}
			}

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[task.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedAt)
				fieldSeen[task.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[task.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldUpdatedAt)
				fieldSeen[task.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[task.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedBy)
				fieldSeen[task.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[task.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, task.FieldUpdatedBy)
				fieldSeen[task.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[task.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, task.FieldDisplayID)
				fieldSeen[task.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[task.FieldTags]; !ok {
				selectedFields = append(selectedFields, task.FieldTags)
				fieldSeen[task.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[task.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, task.FieldOwnerID)
				fieldSeen[task.FieldOwnerID] = struct{}{}
			}
		case "taskKindName":
			if _, ok := fieldSeen[task.FieldTaskKindName]; !ok {
				selectedFields = append(selectedFields, task.FieldTaskKindName)
				fieldSeen[task.FieldTaskKindName] = struct{}{}
			}
		case "taskKindID":
			if _, ok := fieldSeen[task.FieldTaskKindID]; !ok {
				selectedFields = append(selectedFields, task.FieldTaskKindID)
				fieldSeen[task.FieldTaskKindID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[task.FieldTitle]; !ok {
				selectedFields = append(selectedFields, task.FieldTitle)
				fieldSeen[task.FieldTitle] = struct{}{}
			}
		case "details":
			if _, ok := fieldSeen[task.FieldDetails]; !ok {
				selectedFields = append(selectedFields, task.FieldDetails)
				fieldSeen[task.FieldDetails] = struct{}{}
			}
		case "detailsJSON":
			if _, ok := fieldSeen[task.FieldDetailsJSON]; !ok {
				selectedFields = append(selectedFields, task.FieldDetailsJSON)
				fieldSeen[task.FieldDetailsJSON] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[task.FieldStatus]; !ok {
				selectedFields = append(selectedFields, task.FieldStatus)
				fieldSeen[task.FieldStatus] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[task.FieldCategory]; !ok {
				selectedFields = append(selectedFields, task.FieldCategory)
				fieldSeen[task.FieldCategory] = struct{}{}
			}
		case "due":
			if _, ok := fieldSeen[task.FieldDue]; !ok {
				selectedFields = append(selectedFields, task.FieldDue)
				fieldSeen[task.FieldDue] = struct{}{}
			}
		case "completed":
			if _, ok := fieldSeen[task.FieldCompleted]; !ok {
				selectedFields = append(selectedFields, task.FieldCompleted)
				fieldSeen[task.FieldCompleted] = struct{}{}
			}
		case "assigneeID":
			if _, ok := fieldSeen[task.FieldAssigneeID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssigneeID)
				fieldSeen[task.FieldAssigneeID] = struct{}{}
			}
		case "assignerID":
			if _, ok := fieldSeen[task.FieldAssignerID]; !ok {
				selectedFields = append(selectedFields, task.FieldAssignerID)
				fieldSeen[task.FieldAssignerID] = struct{}{}
			}
		case "systemGenerated":
			if _, ok := fieldSeen[task.FieldSystemGenerated]; !ok {
				selectedFields = append(selectedFields, task.FieldSystemGenerated)
				fieldSeen[task.FieldSystemGenerated] = struct{}{}
			}
		case "idempotencyKey":
			if _, ok := fieldSeen[task.FieldIdempotencyKey]; !ok {
				selectedFields = append(selectedFields, task.FieldIdempotencyKey)
				fieldSeen[task.FieldIdempotencyKey] = struct{}{}
			}
		case "externalReferenceURL":
			if _, ok := fieldSeen[task.FieldExternalReferenceURL]; !ok {
				selectedFields = append(selectedFields, task.FieldExternalReferenceURL)
				fieldSeen[task.FieldExternalReferenceURL] = struct{}{}
			}
		case "parentTaskID":
			if _, ok := fieldSeen[task.FieldParentTaskID]; !ok {
				selectedFields = append(selectedFields, task.FieldParentTaskID)
				fieldSeen[task.FieldParentTaskID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type taskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TaskPaginateOption
}

func newTaskPaginateArgs(rv map[string]any) *taskPaginateArgs {
	args := &taskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TaskOrder:
			args.opts = append(args.opts, WithTaskOrder(v))
		case []any:
			var orders []*TaskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TaskOrder{Field: &TaskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTaskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TaskWhereInput); ok {
		args.opts = append(args.opts, WithTaskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TemplateQuery) CollectFields(ctx context.Context, satisfies ...string) (*TemplateQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TemplateQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(template.Columns))
		selectedFields = []string{template.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[template.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, template.FieldOwnerID)
				fieldSeen[template.FieldOwnerID] = struct{}{}
			}

		case "documents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DocumentDataClient{config: _q.config}).Query()
			)
			args := newDocumentDataPaginateArgs(fieldArgs(ctx, new(DocumentDataWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newDocumentDataPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(template.DocumentsColumn), ids...))
						})
						if err := query.GroupBy(template.DocumentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Documents)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, documentdataImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.DocumentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedDocuments(alias, func(wq *DocumentDataQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(template.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(template.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(template.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(template.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(template.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[template.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, template.FieldTrustCenterID)
				fieldSeen[template.FieldTrustCenterID] = struct{}{}
			}

		case "assessments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssessmentClient{config: _q.config}).Query()
			)
			args := newAssessmentPaginateArgs(fieldArgs(ctx, new(AssessmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssessmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Template) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"template_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(template.AssessmentsColumn), ids...))
						})
						if err := query.GroupBy(template.AssessmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Template) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assessments)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assessmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(template.AssessmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssessments(alias, func(wq *AssessmentQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[template.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, template.FieldCreatedAt)
				fieldSeen[template.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[template.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, template.FieldUpdatedAt)
				fieldSeen[template.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[template.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, template.FieldCreatedBy)
				fieldSeen[template.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[template.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, template.FieldUpdatedBy)
				fieldSeen[template.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[template.FieldTags]; !ok {
				selectedFields = append(selectedFields, template.FieldTags)
				fieldSeen[template.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[template.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, template.FieldOwnerID)
				fieldSeen[template.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[template.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, template.FieldSystemOwned)
				fieldSeen[template.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[template.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, template.FieldInternalNotes)
				fieldSeen[template.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[template.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, template.FieldSystemInternalID)
				fieldSeen[template.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[template.FieldName]; !ok {
				selectedFields = append(selectedFields, template.FieldName)
				fieldSeen[template.FieldName] = struct{}{}
			}
		case "templateType":
			if _, ok := fieldSeen[template.FieldTemplateType]; !ok {
				selectedFields = append(selectedFields, template.FieldTemplateType)
				fieldSeen[template.FieldTemplateType] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[template.FieldDescription]; !ok {
				selectedFields = append(selectedFields, template.FieldDescription)
				fieldSeen[template.FieldDescription] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[template.FieldKind]; !ok {
				selectedFields = append(selectedFields, template.FieldKind)
				fieldSeen[template.FieldKind] = struct{}{}
			}
		case "jsonconfig":
			if _, ok := fieldSeen[template.FieldJsonconfig]; !ok {
				selectedFields = append(selectedFields, template.FieldJsonconfig)
				fieldSeen[template.FieldJsonconfig] = struct{}{}
			}
		case "uischema":
			if _, ok := fieldSeen[template.FieldUischema]; !ok {
				selectedFields = append(selectedFields, template.FieldUischema)
				fieldSeen[template.FieldUischema] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[template.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, template.FieldTrustCenterID)
				fieldSeen[template.FieldTrustCenterID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type templatePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TemplatePaginateOption
}

func newTemplatePaginateArgs(rv map[string]any) *templatePaginateArgs {
	args := &templatePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TemplateOrder:
			args.opts = append(args.opts, WithTemplateOrder(v))
		case []any:
			var orders []*TemplateOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TemplateOrder{Field: &TemplateOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTemplateOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TemplateWhereInput); ok {
		args.opts = append(args.opts, WithTemplateFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenter.Columns))
		selectedFields = []string{trustcenter.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[trustcenter.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldOwnerID)
				fieldSeen[trustcenter.FieldOwnerID] = struct{}{}
			}

		case "customDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
				return err
			}
			_q.withCustomDomain = query
			if _, ok := fieldSeen[trustcenter.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCustomDomainID)
				fieldSeen[trustcenter.FieldCustomDomainID] = struct{}{}
			}

		case "previewDomain":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&CustomDomainClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, customdomainImplementors)...); err != nil {
				return err
			}
			_q.withPreviewDomain = query
			if _, ok := fieldSeen[trustcenter.FieldPreviewDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPreviewDomainID)
				fieldSeen[trustcenter.FieldPreviewDomainID] = struct{}{}
			}

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "previewSetting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcentersettingImplementors)...); err != nil {
				return err
			}
			_q.withPreviewSetting = query

		case "watermarkConfig":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterWatermarkConfigClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterwatermarkconfigImplementors)...); err != nil {
				return err
			}
			_q.withWatermarkConfig = query

		case "trustCenterSubprocessors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterSubprocessorClient{config: _q.config}).Query()
			)
			args := newTrustCenterSubprocessorPaginateArgs(fieldArgs(ctx, new(TrustCenterSubprocessorWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterSubprocessorPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterSubprocessorsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterSubprocessorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterSubprocessors)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentersubprocessorImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterSubprocessorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterSubprocessors(alias, func(wq *TrustCenterSubprocessorQuery) {
				*wq = *query
			})

		case "trustCenterDocs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterDocClient{config: _q.config}).Query()
			)
			args := newTrustCenterDocPaginateArgs(fieldArgs(ctx, new(TrustCenterDocWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterDocPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterDocsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterDocsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterDocs)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterdocImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterDocsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterDocs(alias, func(wq *TrustCenterDocQuery) {
				*wq = *query
			})

		case "trustCenterCompliances":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterComplianceClient{config: _q.config}).Query()
			)
			args := newTrustCenterCompliancePaginateArgs(fieldArgs(ctx, new(TrustCenterComplianceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustCenterCompliancePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustCenterCompliancesColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustCenterCompliancesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustCenterCompliances)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcentercomplianceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustCenterCompliancesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustCenterCompliances(alias, func(wq *TrustCenterComplianceQuery) {
				*wq = *query
			})

		case "templates":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TemplateClient{config: _q.config}).Query()
			)
			args := newTemplatePaginateArgs(fieldArgs(ctx, new(TemplateWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTemplatePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TemplatesColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TemplatesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Templates)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, templateImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TemplatesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTemplates(alias, func(wq *TemplateQuery) {
				*wq = *query
			})

		case "posts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_posts"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.PostsColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.PostsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Posts)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.PostsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPosts(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "trustcenterEntities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustcenterEntityClient{config: _q.config}).Query()
			)
			args := newTrustcenterEntityPaginateArgs(fieldArgs(ctx, new(TrustcenterEntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTrustcenterEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenter) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_trustcenter_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trustcenter.TrustcenterEntitiesColumn), ids...))
						})
						if err := query.GroupBy(trustcenter.TrustcenterEntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenter) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TrustcenterEntities)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, trustcenterentityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcenter.TrustcenterEntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTrustcenterEntities(alias, func(wq *TrustcenterEntityQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[trustcenter.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCreatedAt)
				fieldSeen[trustcenter.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenter.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldUpdatedAt)
				fieldSeen[trustcenter.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenter.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCreatedBy)
				fieldSeen[trustcenter.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenter.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldUpdatedBy)
				fieldSeen[trustcenter.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenter.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldTags)
				fieldSeen[trustcenter.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenter.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldOwnerID)
				fieldSeen[trustcenter.FieldOwnerID] = struct{}{}
			}
		case "slug":
			if _, ok := fieldSeen[trustcenter.FieldSlug]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldSlug)
				fieldSeen[trustcenter.FieldSlug] = struct{}{}
			}
		case "customDomainID":
			if _, ok := fieldSeen[trustcenter.FieldCustomDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldCustomDomainID)
				fieldSeen[trustcenter.FieldCustomDomainID] = struct{}{}
			}
		case "previewDomainID":
			if _, ok := fieldSeen[trustcenter.FieldPreviewDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPreviewDomainID)
				fieldSeen[trustcenter.FieldPreviewDomainID] = struct{}{}
			}
		case "pirschDomainID":
			if _, ok := fieldSeen[trustcenter.FieldPirschDomainID]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPirschDomainID)
				fieldSeen[trustcenter.FieldPirschDomainID] = struct{}{}
			}
		case "pirschIdentificationCode":
			if _, ok := fieldSeen[trustcenter.FieldPirschIdentificationCode]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPirschIdentificationCode)
				fieldSeen[trustcenter.FieldPirschIdentificationCode] = struct{}{}
			}
		case "previewStatus":
			if _, ok := fieldSeen[trustcenter.FieldPreviewStatus]; !ok {
				selectedFields = append(selectedFields, trustcenter.FieldPreviewStatus)
				fieldSeen[trustcenter.FieldPreviewStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterPaginateOption
}

func newTrustCenterPaginateArgs(rv map[string]any) *trustcenterPaginateArgs {
	args := &trustcenterPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterOrder:
			args.opts = append(args.opts, WithTrustCenterOrder(v))
		case []any:
			var orders []*TrustCenterOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterOrder{Field: &TrustCenterOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterComplianceQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterComplianceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterComplianceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentercompliance.Columns))
		selectedFields = []string{trustcentercompliance.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcentercompliance.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTrustCenterID)
				fieldSeen[trustcentercompliance.FieldTrustCenterID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[trustcentercompliance.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldStandardID)
				fieldSeen[trustcentercompliance.FieldStandardID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentercompliance.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldCreatedAt)
				fieldSeen[trustcentercompliance.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentercompliance.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldUpdatedAt)
				fieldSeen[trustcentercompliance.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentercompliance.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldCreatedBy)
				fieldSeen[trustcentercompliance.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentercompliance.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldUpdatedBy)
				fieldSeen[trustcentercompliance.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcentercompliance.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTags)
				fieldSeen[trustcentercompliance.FieldTags] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[trustcentercompliance.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldStandardID)
				fieldSeen[trustcentercompliance.FieldStandardID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentercompliance.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentercompliance.FieldTrustCenterID)
				fieldSeen[trustcentercompliance.FieldTrustCenterID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentercompliancePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterCompliancePaginateOption
}

func newTrustCenterCompliancePaginateArgs(rv map[string]any) *trustcentercompliancePaginateArgs {
	args := &trustcentercompliancePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterComplianceOrder:
			args.opts = append(args.opts, WithTrustCenterComplianceOrder(v))
		case []any:
			var orders []*TrustCenterComplianceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterComplianceOrder{Field: &TrustCenterComplianceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterComplianceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterComplianceWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterComplianceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterDocQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterDocQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterDocQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterdoc.Columns))
		selectedFields = []string{trustcenterdoc.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcenterdoc.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTrustCenterID)
				fieldSeen[trustcenterdoc.FieldTrustCenterID] = struct{}{}
			}

		case "standard":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&StandardClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, standardImplementors)...); err != nil {
				return err
			}
			_q.withStandard = query
			if _, ok := fieldSeen[trustcenterdoc.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldStandardID)
				fieldSeen[trustcenterdoc.FieldStandardID] = struct{}{}
			}

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[trustcenterdoc.FieldFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldFileID)
				fieldSeen[trustcenterdoc.FieldFileID] = struct{}{}
			}

		case "originalFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withOriginalFile = query
			if _, ok := fieldSeen[trustcenterdoc.FieldOriginalFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldOriginalFileID)
				fieldSeen[trustcenterdoc.FieldOriginalFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterdoc.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldCreatedAt)
				fieldSeen[trustcenterdoc.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterdoc.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldUpdatedAt)
				fieldSeen[trustcenterdoc.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterdoc.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldCreatedBy)
				fieldSeen[trustcenterdoc.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterdoc.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldUpdatedBy)
				fieldSeen[trustcenterdoc.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[trustcenterdoc.FieldTags]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTags)
				fieldSeen[trustcenterdoc.FieldTags] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterdoc.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTrustCenterID)
				fieldSeen[trustcenterdoc.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcenterdoc.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldTitle)
				fieldSeen[trustcenterdoc.FieldTitle] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcenterdoc.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldCategory)
				fieldSeen[trustcenterdoc.FieldCategory] = struct{}{}
			}
		case "fileID":
			if _, ok := fieldSeen[trustcenterdoc.FieldFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldFileID)
				fieldSeen[trustcenterdoc.FieldFileID] = struct{}{}
			}
		case "originalFileID":
			if _, ok := fieldSeen[trustcenterdoc.FieldOriginalFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldOriginalFileID)
				fieldSeen[trustcenterdoc.FieldOriginalFileID] = struct{}{}
			}
		case "watermarkingEnabled":
			if _, ok := fieldSeen[trustcenterdoc.FieldWatermarkingEnabled]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldWatermarkingEnabled)
				fieldSeen[trustcenterdoc.FieldWatermarkingEnabled] = struct{}{}
			}
		case "watermarkStatus":
			if _, ok := fieldSeen[trustcenterdoc.FieldWatermarkStatus]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldWatermarkStatus)
				fieldSeen[trustcenterdoc.FieldWatermarkStatus] = struct{}{}
			}
		case "visibility":
			if _, ok := fieldSeen[trustcenterdoc.FieldVisibility]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldVisibility)
				fieldSeen[trustcenterdoc.FieldVisibility] = struct{}{}
			}
		case "standardID":
			if _, ok := fieldSeen[trustcenterdoc.FieldStandardID]; !ok {
				selectedFields = append(selectedFields, trustcenterdoc.FieldStandardID)
				fieldSeen[trustcenterdoc.FieldStandardID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterdocPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterDocPaginateOption
}

func newTrustCenterDocPaginateArgs(rv map[string]any) *trustcenterdocPaginateArgs {
	args := &trustcenterdocPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterDocOrder:
			args.opts = append(args.opts, WithTrustCenterDocOrder(v))
		case []any:
			var orders []*TrustCenterDocOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterDocOrder{Field: &TrustCenterDocOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterDocOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterDocWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterDocFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersetting.Columns))
		selectedFields = []string{trustcentersetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*TrustCenterSetting) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"trust_center_setting_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(trustcentersetting.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(trustcentersetting.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(trustcentersetting.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(trustcentersetting.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(trustcentersetting.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*TrustCenterSetting) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trustcentersetting.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[trustcentersetting.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoLocalFileID)
				fieldSeen[trustcentersetting.FieldLogoLocalFileID] = struct{}{}
			}

		case "faviconFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFaviconFile = query
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconLocalFileID)
				fieldSeen[trustcentersetting.FieldFaviconLocalFileID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldCreatedAt)
				fieldSeen[trustcentersetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldUpdatedAt)
				fieldSeen[trustcentersetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldCreatedBy)
				fieldSeen[trustcentersetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldUpdatedBy)
				fieldSeen[trustcentersetting.FieldUpdatedBy] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersetting.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTrustCenterID)
				fieldSeen[trustcentersetting.FieldTrustCenterID] = struct{}{}
			}
		case "title":
			if _, ok := fieldSeen[trustcentersetting.FieldTitle]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldTitle)
				fieldSeen[trustcentersetting.FieldTitle] = struct{}{}
			}
		case "overview":
			if _, ok := fieldSeen[trustcentersetting.FieldOverview]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldOverview)
				fieldSeen[trustcentersetting.FieldOverview] = struct{}{}
			}
		case "logoRemoteURL":
			if _, ok := fieldSeen[trustcentersetting.FieldLogoRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoRemoteURL)
				fieldSeen[trustcentersetting.FieldLogoRemoteURL] = struct{}{}
			}
		case "logoLocalFileID":
			if _, ok := fieldSeen[trustcentersetting.FieldLogoLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldLogoLocalFileID)
				fieldSeen[trustcentersetting.FieldLogoLocalFileID] = struct{}{}
			}
		case "faviconRemoteURL":
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconRemoteURL]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconRemoteURL)
				fieldSeen[trustcentersetting.FieldFaviconRemoteURL] = struct{}{}
			}
		case "faviconLocalFileID":
			if _, ok := fieldSeen[trustcentersetting.FieldFaviconLocalFileID]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFaviconLocalFileID)
				fieldSeen[trustcentersetting.FieldFaviconLocalFileID] = struct{}{}
			}
		case "themeMode":
			if _, ok := fieldSeen[trustcentersetting.FieldThemeMode]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldThemeMode)
				fieldSeen[trustcentersetting.FieldThemeMode] = struct{}{}
			}
		case "primaryColor":
			if _, ok := fieldSeen[trustcentersetting.FieldPrimaryColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldPrimaryColor)
				fieldSeen[trustcentersetting.FieldPrimaryColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcentersetting.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldFont)
				fieldSeen[trustcentersetting.FieldFont] = struct{}{}
			}
		case "foregroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldForegroundColor)
				fieldSeen[trustcentersetting.FieldForegroundColor] = struct{}{}
			}
		case "backgroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldBackgroundColor)
				fieldSeen[trustcentersetting.FieldBackgroundColor] = struct{}{}
			}
		case "accentColor":
			if _, ok := fieldSeen[trustcentersetting.FieldAccentColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldAccentColor)
				fieldSeen[trustcentersetting.FieldAccentColor] = struct{}{}
			}
		case "secondaryBackgroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldSecondaryBackgroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldSecondaryBackgroundColor)
				fieldSeen[trustcentersetting.FieldSecondaryBackgroundColor] = struct{}{}
			}
		case "secondaryForegroundColor":
			if _, ok := fieldSeen[trustcentersetting.FieldSecondaryForegroundColor]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldSecondaryForegroundColor)
				fieldSeen[trustcentersetting.FieldSecondaryForegroundColor] = struct{}{}
			}
		case "environment":
			if _, ok := fieldSeen[trustcentersetting.FieldEnvironment]; !ok {
				selectedFields = append(selectedFields, trustcentersetting.FieldEnvironment)
				fieldSeen[trustcentersetting.FieldEnvironment] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentersettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSettingPaginateOption
}

func newTrustCenterSettingPaginateArgs(rv map[string]any) *trustcentersettingPaginateArgs {
	args := &trustcentersettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterSettingOrder:
			args.opts = append(args.opts, WithTrustCenterSettingOrder(v))
		case []any:
			var orders []*TrustCenterSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterSettingOrder{Field: &TrustCenterSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSettingWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterSubprocessorQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterSubprocessorQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterSubprocessorQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcentersubprocessor.Columns))
		selectedFields = []string{trustcentersubprocessor.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcentersubprocessor.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessor.FieldTrustCenterID] = struct{}{}
			}

		case "subprocessor":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubprocessorClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subprocessorImplementors)...); err != nil {
				return err
			}
			_q.withSubprocessor = query
			if _, ok := fieldSeen[trustcentersubprocessor.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessor.FieldSubprocessorID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCreatedAt)
				fieldSeen[trustcentersubprocessor.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldUpdatedAt)
				fieldSeen[trustcentersubprocessor.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCreatedBy)
				fieldSeen[trustcentersubprocessor.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldUpdatedBy)
				fieldSeen[trustcentersubprocessor.FieldUpdatedBy] = struct{}{}
			}
		case "subprocessorID":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldSubprocessorID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldSubprocessorID)
				fieldSeen[trustcentersubprocessor.FieldSubprocessorID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldTrustCenterID)
				fieldSeen[trustcentersubprocessor.FieldTrustCenterID] = struct{}{}
			}
		case "countries":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCountries]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCountries)
				fieldSeen[trustcentersubprocessor.FieldCountries] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[trustcentersubprocessor.FieldCategory]; !ok {
				selectedFields = append(selectedFields, trustcentersubprocessor.FieldCategory)
				fieldSeen[trustcentersubprocessor.FieldCategory] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcentersubprocessorPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterSubprocessorPaginateOption
}

func newTrustCenterSubprocessorPaginateArgs(rv map[string]any) *trustcentersubprocessorPaginateArgs {
	args := &trustcentersubprocessorPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterSubprocessorOrder:
			args.opts = append(args.opts, WithTrustCenterSubprocessorOrder(v))
		case []any:
			var orders []*TrustCenterSubprocessorOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterSubprocessorOrder{Field: &TrustCenterSubprocessorOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterSubprocessorOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterSubprocessorWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterSubprocessorFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustCenterWatermarkConfigQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustCenterWatermarkConfigQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustCenterWatermarkConfigQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterwatermarkconfig.Columns))
		selectedFields = []string{trustcenterwatermarkconfig.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldOwnerID)
				fieldSeen[trustcenterwatermarkconfig.FieldOwnerID] = struct{}{}
			}

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, false, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.WithNamedTrustCenter(alias, func(wq *TrustCenterQuery) {
				*wq = *query
			})

		case "file":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withFile = query
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldLogoID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldLogoID)
				fieldSeen[trustcenterwatermarkconfig.FieldLogoID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldCreatedAt)
				fieldSeen[trustcenterwatermarkconfig.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldUpdatedAt)
				fieldSeen[trustcenterwatermarkconfig.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldCreatedBy)
				fieldSeen[trustcenterwatermarkconfig.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldUpdatedBy)
				fieldSeen[trustcenterwatermarkconfig.FieldUpdatedBy] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldOwnerID)
				fieldSeen[trustcenterwatermarkconfig.FieldOwnerID] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldTrustCenterID)
				fieldSeen[trustcenterwatermarkconfig.FieldTrustCenterID] = struct{}{}
			}
		case "isEnabled":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldIsEnabled]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldIsEnabled)
				fieldSeen[trustcenterwatermarkconfig.FieldIsEnabled] = struct{}{}
			}
		case "logoID":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldLogoID]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldLogoID)
				fieldSeen[trustcenterwatermarkconfig.FieldLogoID] = struct{}{}
			}
		case "text":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldText]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldText)
				fieldSeen[trustcenterwatermarkconfig.FieldText] = struct{}{}
			}
		case "fontSize":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldFontSize]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldFontSize)
				fieldSeen[trustcenterwatermarkconfig.FieldFontSize] = struct{}{}
			}
		case "opacity":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldOpacity]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldOpacity)
				fieldSeen[trustcenterwatermarkconfig.FieldOpacity] = struct{}{}
			}
		case "rotation":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldRotation]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldRotation)
				fieldSeen[trustcenterwatermarkconfig.FieldRotation] = struct{}{}
			}
		case "color":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldColor]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldColor)
				fieldSeen[trustcenterwatermarkconfig.FieldColor] = struct{}{}
			}
		case "font":
			if _, ok := fieldSeen[trustcenterwatermarkconfig.FieldFont]; !ok {
				selectedFields = append(selectedFields, trustcenterwatermarkconfig.FieldFont)
				fieldSeen[trustcenterwatermarkconfig.FieldFont] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterwatermarkconfigPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustCenterWatermarkConfigPaginateOption
}

func newTrustCenterWatermarkConfigPaginateArgs(rv map[string]any) *trustcenterwatermarkconfigPaginateArgs {
	args := &trustcenterwatermarkconfigPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustCenterWatermarkConfigOrder:
			args.opts = append(args.opts, WithTrustCenterWatermarkConfigOrder(v))
		case []any:
			var orders []*TrustCenterWatermarkConfigOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustCenterWatermarkConfigOrder{Field: &TrustCenterWatermarkConfigOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustCenterWatermarkConfigOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustCenterWatermarkConfigWhereInput); ok {
		args.opts = append(args.opts, WithTrustCenterWatermarkConfigFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TrustcenterEntityQuery) CollectFields(ctx context.Context, satisfies ...string) (*TrustcenterEntityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TrustcenterEntityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trustcenterentity.Columns))
		selectedFields = []string{trustcenterentity.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "logoFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withLogoFile = query
			if _, ok := fieldSeen[trustcenterentity.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldLogoFileID)
				fieldSeen[trustcenterentity.FieldLogoFileID] = struct{}{}
			}

		case "trustCenter":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TrustCenterClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, trustcenterImplementors)...); err != nil {
				return err
			}
			_q.withTrustCenter = query
			if _, ok := fieldSeen[trustcenterentity.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldTrustCenterID)
				fieldSeen[trustcenterentity.FieldTrustCenterID] = struct{}{}
			}

		case "entityType":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityTypeClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, entitytypeImplementors)...); err != nil {
				return err
			}
			_q.withEntityType = query
			if _, ok := fieldSeen[trustcenterentity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldEntityTypeID)
				fieldSeen[trustcenterentity.FieldEntityTypeID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[trustcenterentity.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldCreatedAt)
				fieldSeen[trustcenterentity.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trustcenterentity.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldUpdatedAt)
				fieldSeen[trustcenterentity.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[trustcenterentity.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldCreatedBy)
				fieldSeen[trustcenterentity.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[trustcenterentity.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldUpdatedBy)
				fieldSeen[trustcenterentity.FieldUpdatedBy] = struct{}{}
			}
		case "logoFileID":
			if _, ok := fieldSeen[trustcenterentity.FieldLogoFileID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldLogoFileID)
				fieldSeen[trustcenterentity.FieldLogoFileID] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[trustcenterentity.FieldURL]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldURL)
				fieldSeen[trustcenterentity.FieldURL] = struct{}{}
			}
		case "trustCenterID":
			if _, ok := fieldSeen[trustcenterentity.FieldTrustCenterID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldTrustCenterID)
				fieldSeen[trustcenterentity.FieldTrustCenterID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[trustcenterentity.FieldName]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldName)
				fieldSeen[trustcenterentity.FieldName] = struct{}{}
			}
		case "entityTypeID":
			if _, ok := fieldSeen[trustcenterentity.FieldEntityTypeID]; !ok {
				selectedFields = append(selectedFields, trustcenterentity.FieldEntityTypeID)
				fieldSeen[trustcenterentity.FieldEntityTypeID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type trustcenterentityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TrustcenterEntityPaginateOption
}

func newTrustcenterEntityPaginateArgs(rv map[string]any) *trustcenterentityPaginateArgs {
	args := &trustcenterentityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TrustcenterEntityOrder:
			args.opts = append(args.opts, WithTrustcenterEntityOrder(v))
		case []any:
			var orders []*TrustcenterEntityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TrustcenterEntityOrder{Field: &TrustcenterEntityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTrustcenterEntityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TrustcenterEntityWhereInput); ok {
		args.opts = append(args.opts, WithTrustcenterEntityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(user.Columns))
		selectedFields = []string{user.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "personalAccessTokens":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&PersonalAccessTokenClient{config: _q.config}).Query()
			)
			args := newPersonalAccessTokenPaginateArgs(fieldArgs(ctx, new(PersonalAccessTokenWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newPersonalAccessTokenPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.PersonalAccessTokensColumn), ids...))
						})
						if err := query.GroupBy(user.PersonalAccessTokensColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.PersonalAccessTokens)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, personalaccesstokenImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.PersonalAccessTokensColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPersonalAccessTokens(alias, func(wq *PersonalAccessTokenQuery) {
				*wq = *query
			})

		case "tfaSettings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TFASettingClient{config: _q.config}).Query()
			)
			args := newTFASettingPaginateArgs(fieldArgs(ctx, new(TFASettingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTFASettingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.TfaSettingsColumn), ids...))
						})
						if err := query.GroupBy(user.TfaSettingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TfaSettings)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tfasettingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.TfaSettingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTfaSettings(alias, func(wq *TFASettingQuery) {
				*wq = *query
			})

		case "setting":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserSettingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, usersettingImplementors)...); err != nil {
				return err
			}
			_q.withSetting = query

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.GroupsTable)
							s.Join(joinT).On(s.C(group.FieldID), joinT.C(user.GroupsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.GroupsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.GroupsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.GroupsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.GroupsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "organizations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			args := newOrganizationPaginateArgs(fieldArgs(ctx, new(OrganizationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrganizationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.OrganizationsTable)
							s.Join(joinT).On(s.C(organization.FieldID), joinT.C(user.OrganizationsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.OrganizationsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.OrganizationsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.OrganizationsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Organizations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.OrganizationsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrganizations(alias, func(wq *OrganizationQuery) {
				*wq = *query
			})

		case "webauthns":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WebauthnClient{config: _q.config}).Query()
			)
			args := newWebauthnPaginateArgs(fieldArgs(ctx, new(WebauthnWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWebauthnPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.WebauthnsColumn), ids...))
						})
						if err := query.GroupBy(user.WebauthnsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Webauthns)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, webauthnImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.WebauthnsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWebauthns(alias, func(wq *WebauthnQuery) {
				*wq = *query
			})

		case "avatarFile":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			_q.withAvatarFile = query
			if _, ok := fieldSeen[user.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarLocalFileID)
				fieldSeen[user.FieldAvatarLocalFileID] = struct{}{}
			}

		case "events":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EventClient{config: _q.config}).Query()
			)
			args := newEventPaginateArgs(fieldArgs(ctx, new(EventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.EventsTable)
							s.Join(joinT).On(s.C(event.FieldID), joinT.C(user.EventsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.EventsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.EventsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.EventsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Events)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, eventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.EventsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEvents(alias, func(wq *EventQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_action_plans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ActionPlansColumn), ids...))
						})
						if err := query.GroupBy(user.ActionPlansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ActionPlansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(user.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "assignerTasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assigner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.AssignerTasksColumn), ids...))
						})
						if err := query.GroupBy(user.AssignerTasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssignerTasks)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.AssignerTasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssignerTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "assigneeTasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"assignee_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.AssigneeTasksColumn), ids...))
						})
						if err := query.GroupBy(user.AssigneeTasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.AssigneeTasks)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.AssigneeTasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssigneeTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.ProgramsTable)
							s.Join(joinT).On(s.C(program.FieldID), joinT.C(user.ProgramsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.ProgramsPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.ProgramsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.ProgramsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "programsOwned":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"program_owner_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ProgramsOwnedColumn), ids...))
						})
						if err := query.GroupBy(user.ProgramsOwnedColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramsOwned)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramsOwnedColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramsOwned(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "groupMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupMembershipClient{config: _q.config}).Query()
			)
			args := newGroupMembershipPaginateArgs(fieldArgs(ctx, new(GroupMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.GroupMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.GroupMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.GroupMemberships)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.GroupMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroupMemberships(alias, func(wq *GroupMembershipQuery) {
				*wq = *query
			})

		case "orgMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrgMembershipClient{config: _q.config}).Query()
			)
			args := newOrgMembershipPaginateArgs(fieldArgs(ctx, new(OrgMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newOrgMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.OrgMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.OrgMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.OrgMemberships)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, orgmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.OrgMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedOrgMemberships(alias, func(wq *OrgMembershipQuery) {
				*wq = *query
			})

		case "programMemberships":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramMembershipClient{config: _q.config}).Query()
			)
			args := newProgramMembershipPaginateArgs(fieldArgs(ctx, new(ProgramMembershipWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramMembershipPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"user_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ProgramMembershipsColumn), ids...))
						})
						if err := query.GroupBy(user.ProgramMembershipsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProgramMemberships)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programmembershipImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProgramMembershipsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProgramMemberships(alias, func(wq *ProgramMembershipQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[user.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedAt)
				fieldSeen[user.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[user.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedAt)
				fieldSeen[user.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[user.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedBy)
				fieldSeen[user.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[user.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedBy)
				fieldSeen[user.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[user.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, user.FieldDisplayID)
				fieldSeen[user.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[user.FieldTags]; !ok {
				selectedFields = append(selectedFields, user.FieldTags)
				fieldSeen[user.FieldTags] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[user.FieldEmail]; !ok {
				selectedFields = append(selectedFields, user.FieldEmail)
				fieldSeen[user.FieldEmail] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[user.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, user.FieldFirstName)
				fieldSeen[user.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[user.FieldLastName]; !ok {
				selectedFields = append(selectedFields, user.FieldLastName)
				fieldSeen[user.FieldLastName] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[user.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, user.FieldDisplayName)
				fieldSeen[user.FieldDisplayName] = struct{}{}
			}
		case "avatarRemoteURL":
			if _, ok := fieldSeen[user.FieldAvatarRemoteURL]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarRemoteURL)
				fieldSeen[user.FieldAvatarRemoteURL] = struct{}{}
			}
		case "avatarLocalFileID":
			if _, ok := fieldSeen[user.FieldAvatarLocalFileID]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarLocalFileID)
				fieldSeen[user.FieldAvatarLocalFileID] = struct{}{}
			}
		case "avatarUpdatedAt":
			if _, ok := fieldSeen[user.FieldAvatarUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatarUpdatedAt)
				fieldSeen[user.FieldAvatarUpdatedAt] = struct{}{}
			}
		case "lastSeen":
			if _, ok := fieldSeen[user.FieldLastSeen]; !ok {
				selectedFields = append(selectedFields, user.FieldLastSeen)
				fieldSeen[user.FieldLastSeen] = struct{}{}
			}
		case "lastLoginProvider":
			if _, ok := fieldSeen[user.FieldLastLoginProvider]; !ok {
				selectedFields = append(selectedFields, user.FieldLastLoginProvider)
				fieldSeen[user.FieldLastLoginProvider] = struct{}{}
			}
		case "sub":
			if _, ok := fieldSeen[user.FieldSub]; !ok {
				selectedFields = append(selectedFields, user.FieldSub)
				fieldSeen[user.FieldSub] = struct{}{}
			}
		case "authProvider":
			if _, ok := fieldSeen[user.FieldAuthProvider]; !ok {
				selectedFields = append(selectedFields, user.FieldAuthProvider)
				fieldSeen[user.FieldAuthProvider] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[user.FieldRole]; !ok {
				selectedFields = append(selectedFields, user.FieldRole)
				fieldSeen[user.FieldRole] = struct{}{}
			}
		case "scimExternalID":
			if _, ok := fieldSeen[user.FieldScimExternalID]; !ok {
				selectedFields = append(selectedFields, user.FieldScimExternalID)
				fieldSeen[user.FieldScimExternalID] = struct{}{}
			}
		case "scimUsername":
			if _, ok := fieldSeen[user.FieldScimUsername]; !ok {
				selectedFields = append(selectedFields, user.FieldScimUsername)
				fieldSeen[user.FieldScimUsername] = struct{}{}
			}
		case "scimActive":
			if _, ok := fieldSeen[user.FieldScimActive]; !ok {
				selectedFields = append(selectedFields, user.FieldScimActive)
				fieldSeen[user.FieldScimActive] = struct{}{}
			}
		case "scimPreferredLanguage":
			if _, ok := fieldSeen[user.FieldScimPreferredLanguage]; !ok {
				selectedFields = append(selectedFields, user.FieldScimPreferredLanguage)
				fieldSeen[user.FieldScimPreferredLanguage] = struct{}{}
			}
		case "scimLocale":
			if _, ok := fieldSeen[user.FieldScimLocale]; !ok {
				selectedFields = append(selectedFields, user.FieldScimLocale)
				fieldSeen[user.FieldScimLocale] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type userPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserPaginateOption
}

func newUserPaginateArgs(rv map[string]any) *userPaginateArgs {
	args := &userPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserOrder:
			args.opts = append(args.opts, WithUserOrder(v))
		case []any:
			var orders []*UserOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserOrder{Field: &UserOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserWhereInput); ok {
		args.opts = append(args.opts, WithUserFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserSettingQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserSettingQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserSettingQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usersetting.Columns))
		selectedFields = []string{usersetting.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[usersetting.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUserID)
				fieldSeen[usersetting.FieldUserID] = struct{}{}
			}

		case "defaultOrg":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withDefaultOrg = query
		case "createdAt":
			if _, ok := fieldSeen[usersetting.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldCreatedAt)
				fieldSeen[usersetting.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usersetting.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUpdatedAt)
				fieldSeen[usersetting.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[usersetting.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldCreatedBy)
				fieldSeen[usersetting.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[usersetting.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUpdatedBy)
				fieldSeen[usersetting.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[usersetting.FieldTags]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldTags)
				fieldSeen[usersetting.FieldTags] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[usersetting.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldUserID)
				fieldSeen[usersetting.FieldUserID] = struct{}{}
			}
		case "locked":
			if _, ok := fieldSeen[usersetting.FieldLocked]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldLocked)
				fieldSeen[usersetting.FieldLocked] = struct{}{}
			}
		case "silencedAt":
			if _, ok := fieldSeen[usersetting.FieldSilencedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldSilencedAt)
				fieldSeen[usersetting.FieldSilencedAt] = struct{}{}
			}
		case "suspendedAt":
			if _, ok := fieldSeen[usersetting.FieldSuspendedAt]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldSuspendedAt)
				fieldSeen[usersetting.FieldSuspendedAt] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[usersetting.FieldStatus]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldStatus)
				fieldSeen[usersetting.FieldStatus] = struct{}{}
			}
		case "emailConfirmed":
			if _, ok := fieldSeen[usersetting.FieldEmailConfirmed]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldEmailConfirmed)
				fieldSeen[usersetting.FieldEmailConfirmed] = struct{}{}
			}
		case "isWebauthnAllowed":
			if _, ok := fieldSeen[usersetting.FieldIsWebauthnAllowed]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldIsWebauthnAllowed)
				fieldSeen[usersetting.FieldIsWebauthnAllowed] = struct{}{}
			}
		case "isTfaEnabled":
			if _, ok := fieldSeen[usersetting.FieldIsTfaEnabled]; !ok {
				selectedFields = append(selectedFields, usersetting.FieldIsTfaEnabled)
				fieldSeen[usersetting.FieldIsTfaEnabled] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type usersettingPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserSettingPaginateOption
}

func newUserSettingPaginateArgs(rv map[string]any) *usersettingPaginateArgs {
	args := &usersettingPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserSettingOrder:
			args.opts = append(args.opts, WithUserSettingOrder(v))
		case []any:
			var orders []*UserSettingOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserSettingOrder{Field: &UserSettingOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserSettingOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserSettingWhereInput); ok {
		args.opts = append(args.opts, WithUserSettingFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *VulnerabilityQuery) CollectFields(ctx context.Context, satisfies ...string) (*VulnerabilityQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *VulnerabilityQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(vulnerability.Columns))
		selectedFields = []string{vulnerability.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[vulnerability.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldOwnerID)
				fieldSeen[vulnerability.FieldOwnerID] = struct{}{}
			}

		case "blockedGroups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_blocked_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.BlockedGroupsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.BlockedGroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.BlockedGroups)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.BlockedGroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedBlockedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "editors":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_editors"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.EditorsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.EditorsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Editors)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.EditorsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEditors(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "viewers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_viewers"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ViewersColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ViewersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Viewers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ViewersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedViewers(alias, func(wq *GroupQuery) {
				*wq = *query
			})

		case "integrations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&IntegrationClient{config: _q.config}).Query()
			)
			args := newIntegrationPaginateArgs(fieldArgs(ctx, new(IntegrationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newIntegrationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(vulnerability.IntegrationsTable)
							s.Join(joinT).On(s.C(integration.FieldID), joinT.C(vulnerability.IntegrationsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(vulnerability.IntegrationsPrimaryKey[1]), ids...))
							s.Select(joinT.C(vulnerability.IntegrationsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(vulnerability.IntegrationsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Integrations)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, integrationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.IntegrationsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedIntegrations(alias, func(wq *IntegrationQuery) {
				*wq = *query
			})

		case "findings":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			args := newFindingPaginateArgs(fieldArgs(ctx, new(FindingWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFindingPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_findings"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.FindingsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.FindingsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Findings)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.FindingsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFindings(alias, func(wq *FindingQuery) {
				*wq = *query
			})

		case "actionPlans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			args := newActionPlanPaginateArgs(fieldArgs(ctx, new(ActionPlanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newActionPlanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_id"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(vulnerability.ActionPlansTable)
							s.Join(joinT).On(s.C(actionplan.FieldID), joinT.C(vulnerability.ActionPlansPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(vulnerability.ActionPlansPrimaryKey[0]), ids...))
							s.Select(joinT.C(vulnerability.ActionPlansPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(vulnerability.ActionPlansPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActionPlans)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ActionPlansPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedActionPlans(alias, func(wq *ActionPlanQuery) {
				*wq = *query
			})

		case "controls":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			args := newControlPaginateArgs(fieldArgs(ctx, new(ControlWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newControlPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_controls"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ControlsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ControlsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Controls)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ControlsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedControls(alias, func(wq *ControlQuery) {
				*wq = *query
			})

		case "subcontrols":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			args := newSubcontrolPaginateArgs(fieldArgs(ctx, new(SubcontrolWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newSubcontrolPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_subcontrols"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.SubcontrolsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.SubcontrolsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Subcontrols)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.SubcontrolsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedSubcontrols(alias, func(wq *SubcontrolQuery) {
				*wq = *query
			})

		case "risks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RiskClient{config: _q.config}).Query()
			)
			args := newRiskPaginateArgs(fieldArgs(ctx, new(RiskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRiskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_risks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.RisksColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.RisksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Risks)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, riskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.RisksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRisks(alias, func(wq *RiskQuery) {
				*wq = *query
			})

		case "programs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProgramClient{config: _q.config}).Query()
			)
			args := newProgramPaginateArgs(fieldArgs(ctx, new(ProgramWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProgramPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_programs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ProgramsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ProgramsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Programs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, programImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ProgramsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedPrograms(alias, func(wq *ProgramQuery) {
				*wq = *query
			})

		case "assets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&AssetClient{config: _q.config}).Query()
			)
			args := newAssetPaginateArgs(fieldArgs(ctx, new(AssetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAssetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_assets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.AssetsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.AssetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Assets)
							if nodes[i].Edges.totalCount[11] == nil {
								nodes[i].Edges.totalCount[11] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[11][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, assetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.AssetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAssets(alias, func(wq *AssetQuery) {
				*wq = *query
			})

		case "entities":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EntityClient{config: _q.config}).Query()
			)
			args := newEntityPaginateArgs(fieldArgs(ctx, new(EntityWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newEntityPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_entities"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.EntitiesColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.EntitiesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Entities)
							if nodes[i].Edges.totalCount[12] == nil {
								nodes[i].Edges.totalCount[12] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[12][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, entityImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.EntitiesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedEntities(alias, func(wq *EntityQuery) {
				*wq = *query
			})

		case "scans":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ScanClient{config: _q.config}).Query()
			)
			args := newScanPaginateArgs(fieldArgs(ctx, new(ScanWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newScanPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_scans"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ScansColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ScansColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Scans)
							if nodes[i].Edges.totalCount[13] == nil {
								nodes[i].Edges.totalCount[13] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[13][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, scanImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ScansColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedScans(alias, func(wq *ScanQuery) {
				*wq = *query
			})

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_tasks"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.TasksColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[14] == nil {
								nodes[i].Edges.totalCount[14] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[14][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "remediations":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RemediationClient{config: _q.config}).Query()
			)
			args := newRemediationPaginateArgs(fieldArgs(ctx, new(RemediationWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRemediationPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_remediations"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.RemediationsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.RemediationsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Remediations)
							if nodes[i].Edges.totalCount[15] == nil {
								nodes[i].Edges.totalCount[15] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[15][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, remediationImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.RemediationsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRemediations(alias, func(wq *RemediationQuery) {
				*wq = *query
			})

		case "reviews":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ReviewClient{config: _q.config}).Query()
			)
			args := newReviewPaginateArgs(fieldArgs(ctx, new(ReviewWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newReviewPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_reviews"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.ReviewsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.ReviewsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Reviews)
							if nodes[i].Edges.totalCount[16] == nil {
								nodes[i].Edges.totalCount[16] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[16][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, reviewImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.ReviewsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedReviews(alias, func(wq *ReviewQuery) {
				*wq = *query
			})

		case "comments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&NoteClient{config: _q.config}).Query()
			)
			args := newNotePaginateArgs(fieldArgs(ctx, new(NoteWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newNotePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_comments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.CommentsColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.CommentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Comments)
							if nodes[i].Edges.totalCount[17] == nil {
								nodes[i].Edges.totalCount[17] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[17][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, noteImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.CommentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedComments(alias, func(wq *NoteQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: _q.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Vulnerability) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"vulnerability_files"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(vulnerability.FilesColumn), ids...))
						})
						if err := query.GroupBy(vulnerability.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Vulnerability) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[18] == nil {
								nodes[i].Edges.totalCount[18] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[18][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(vulnerability.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[vulnerability.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCreatedAt)
				fieldSeen[vulnerability.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[vulnerability.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldUpdatedAt)
				fieldSeen[vulnerability.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[vulnerability.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCreatedBy)
				fieldSeen[vulnerability.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[vulnerability.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldUpdatedBy)
				fieldSeen[vulnerability.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[vulnerability.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDisplayID)
				fieldSeen[vulnerability.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[vulnerability.FieldTags]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldTags)
				fieldSeen[vulnerability.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[vulnerability.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldOwnerID)
				fieldSeen[vulnerability.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[vulnerability.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSystemOwned)
				fieldSeen[vulnerability.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[vulnerability.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldInternalNotes)
				fieldSeen[vulnerability.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[vulnerability.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSystemInternalID)
				fieldSeen[vulnerability.FieldSystemInternalID] = struct{}{}
			}
		case "externalOwnerID":
			if _, ok := fieldSeen[vulnerability.FieldExternalOwnerID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExternalOwnerID)
				fieldSeen[vulnerability.FieldExternalOwnerID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[vulnerability.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExternalID)
				fieldSeen[vulnerability.FieldExternalID] = struct{}{}
			}
		case "cveID":
			if _, ok := fieldSeen[vulnerability.FieldCveID]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCveID)
				fieldSeen[vulnerability.FieldCveID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[vulnerability.FieldSource]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSource)
				fieldSeen[vulnerability.FieldSource] = struct{}{}
			}
		case "displayName":
			if _, ok := fieldSeen[vulnerability.FieldDisplayName]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDisplayName)
				fieldSeen[vulnerability.FieldDisplayName] = struct{}{}
			}
		case "category":
			if _, ok := fieldSeen[vulnerability.FieldCategory]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldCategory)
				fieldSeen[vulnerability.FieldCategory] = struct{}{}
			}
		case "severity":
			if _, ok := fieldSeen[vulnerability.FieldSeverity]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSeverity)
				fieldSeen[vulnerability.FieldSeverity] = struct{}{}
			}
		case "score":
			if _, ok := fieldSeen[vulnerability.FieldScore]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldScore)
				fieldSeen[vulnerability.FieldScore] = struct{}{}
			}
		case "impact":
			if _, ok := fieldSeen[vulnerability.FieldImpact]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldImpact)
				fieldSeen[vulnerability.FieldImpact] = struct{}{}
			}
		case "exploitability":
			if _, ok := fieldSeen[vulnerability.FieldExploitability]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExploitability)
				fieldSeen[vulnerability.FieldExploitability] = struct{}{}
			}
		case "priority":
			if _, ok := fieldSeen[vulnerability.FieldPriority]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldPriority)
				fieldSeen[vulnerability.FieldPriority] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[vulnerability.FieldStatus]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldStatus)
				fieldSeen[vulnerability.FieldStatus] = struct{}{}
			}
		case "summary":
			if _, ok := fieldSeen[vulnerability.FieldSummary]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSummary)
				fieldSeen[vulnerability.FieldSummary] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[vulnerability.FieldDescription]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDescription)
				fieldSeen[vulnerability.FieldDescription] = struct{}{}
			}
		case "vector":
			if _, ok := fieldSeen[vulnerability.FieldVector]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldVector)
				fieldSeen[vulnerability.FieldVector] = struct{}{}
			}
		case "remediationSLA":
			if _, ok := fieldSeen[vulnerability.FieldRemediationSLA]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldRemediationSLA)
				fieldSeen[vulnerability.FieldRemediationSLA] = struct{}{}
			}
		case "open":
			if _, ok := fieldSeen[vulnerability.FieldOpen]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldOpen)
				fieldSeen[vulnerability.FieldOpen] = struct{}{}
			}
		case "blocking":
			if _, ok := fieldSeen[vulnerability.FieldBlocking]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldBlocking)
				fieldSeen[vulnerability.FieldBlocking] = struct{}{}
			}
		case "production":
			if _, ok := fieldSeen[vulnerability.FieldProduction]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldProduction)
				fieldSeen[vulnerability.FieldProduction] = struct{}{}
			}
		case "public":
			if _, ok := fieldSeen[vulnerability.FieldPublic]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldPublic)
				fieldSeen[vulnerability.FieldPublic] = struct{}{}
			}
		case "validated":
			if _, ok := fieldSeen[vulnerability.FieldValidated]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldValidated)
				fieldSeen[vulnerability.FieldValidated] = struct{}{}
			}
		case "references":
			if _, ok := fieldSeen[vulnerability.FieldReferences]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldReferences)
				fieldSeen[vulnerability.FieldReferences] = struct{}{}
			}
		case "impacts":
			if _, ok := fieldSeen[vulnerability.FieldImpacts]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldImpacts)
				fieldSeen[vulnerability.FieldImpacts] = struct{}{}
			}
		case "publishedAt":
			if _, ok := fieldSeen[vulnerability.FieldPublishedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldPublishedAt)
				fieldSeen[vulnerability.FieldPublishedAt] = struct{}{}
			}
		case "discoveredAt":
			if _, ok := fieldSeen[vulnerability.FieldDiscoveredAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldDiscoveredAt)
				fieldSeen[vulnerability.FieldDiscoveredAt] = struct{}{}
			}
		case "sourceUpdatedAt":
			if _, ok := fieldSeen[vulnerability.FieldSourceUpdatedAt]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldSourceUpdatedAt)
				fieldSeen[vulnerability.FieldSourceUpdatedAt] = struct{}{}
			}
		case "externalURI":
			if _, ok := fieldSeen[vulnerability.FieldExternalURI]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldExternalURI)
				fieldSeen[vulnerability.FieldExternalURI] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[vulnerability.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldMetadata)
				fieldSeen[vulnerability.FieldMetadata] = struct{}{}
			}
		case "rawPayload":
			if _, ok := fieldSeen[vulnerability.FieldRawPayload]; !ok {
				selectedFields = append(selectedFields, vulnerability.FieldRawPayload)
				fieldSeen[vulnerability.FieldRawPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type vulnerabilityPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []VulnerabilityPaginateOption
}

func newVulnerabilityPaginateArgs(rv map[string]any) *vulnerabilityPaginateArgs {
	args := &vulnerabilityPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*VulnerabilityOrder:
			args.opts = append(args.opts, WithVulnerabilityOrder(v))
		case []any:
			var orders []*VulnerabilityOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &VulnerabilityOrder{Field: &VulnerabilityOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithVulnerabilityOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*VulnerabilityWhereInput); ok {
		args.opts = append(args.opts, WithVulnerabilityFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WebauthnQuery) CollectFields(ctx context.Context, satisfies ...string) (*WebauthnQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WebauthnQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(webauthn.Columns))
		selectedFields = []string{webauthn.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[webauthn.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldOwnerID)
				fieldSeen[webauthn.FieldOwnerID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[webauthn.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldCreatedAt)
				fieldSeen[webauthn.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[webauthn.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldUpdatedAt)
				fieldSeen[webauthn.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[webauthn.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldCreatedBy)
				fieldSeen[webauthn.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[webauthn.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldUpdatedBy)
				fieldSeen[webauthn.FieldUpdatedBy] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[webauthn.FieldTags]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldTags)
				fieldSeen[webauthn.FieldTags] = struct{}{}
			}
		case "aaguid":
			if _, ok := fieldSeen[webauthn.FieldAaguid]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldAaguid)
				fieldSeen[webauthn.FieldAaguid] = struct{}{}
			}
		case "backupEligible":
			if _, ok := fieldSeen[webauthn.FieldBackupEligible]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldBackupEligible)
				fieldSeen[webauthn.FieldBackupEligible] = struct{}{}
			}
		case "backupState":
			if _, ok := fieldSeen[webauthn.FieldBackupState]; !ok {
				selectedFields = append(selectedFields, webauthn.FieldBackupState)
				fieldSeen[webauthn.FieldBackupState] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type webauthnPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WebauthnPaginateOption
}

func newWebauthnPaginateArgs(rv map[string]any) *webauthnPaginateArgs {
	args := &webauthnPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &WebauthnOrder{Field: &WebauthnOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithWebauthnOrder(order))
			}
		case *WebauthnOrder:
			if v != nil {
				args.opts = append(args.opts, WithWebauthnOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*WebauthnWhereInput); ok {
		args.opts = append(args.opts, WithWebauthnFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowAssignmentQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowAssignmentQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowAssignmentQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowassignment.Columns))
		selectedFields = []string{workflowassignment.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowassignment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldOwnerID)
				fieldSeen[workflowassignment.FieldOwnerID] = struct{}{}
			}

		case "workflowInstance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowInstance = query
			if _, ok := fieldSeen[workflowassignment.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldWorkflowInstanceID)
				fieldSeen[workflowassignment.FieldWorkflowInstanceID] = struct{}{}
			}

		case "workflowAssignmentTargets":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentTargetClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentTargetPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentTargetWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentTargetPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowAssignment) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_assignment_workflow_assignment_targets"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowassignment.WorkflowAssignmentTargetsColumn), ids...))
						})
						if err := query.GroupBy(workflowassignment.WorkflowAssignmentTargetsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowAssignment) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignmentTargets)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmenttargetImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowassignment.WorkflowAssignmentTargetsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignmentTargets(alias, func(wq *WorkflowAssignmentTargetQuery) {
				*wq = *query
			})

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[workflowassignment.FieldActorUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorUserID)
				fieldSeen[workflowassignment.FieldActorUserID] = struct{}{}
			}

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[workflowassignment.FieldActorGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorGroupID)
				fieldSeen[workflowassignment.FieldActorGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowassignment.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldCreatedAt)
				fieldSeen[workflowassignment.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowassignment.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldUpdatedAt)
				fieldSeen[workflowassignment.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowassignment.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldCreatedBy)
				fieldSeen[workflowassignment.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowassignment.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldUpdatedBy)
				fieldSeen[workflowassignment.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowassignment.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldDisplayID)
				fieldSeen[workflowassignment.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowassignment.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldTags)
				fieldSeen[workflowassignment.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowassignment.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldOwnerID)
				fieldSeen[workflowassignment.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowassignment.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldWorkflowInstanceID)
				fieldSeen[workflowassignment.FieldWorkflowInstanceID] = struct{}{}
			}
		case "assignmentKey":
			if _, ok := fieldSeen[workflowassignment.FieldAssignmentKey]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldAssignmentKey)
				fieldSeen[workflowassignment.FieldAssignmentKey] = struct{}{}
			}
		case "role":
			if _, ok := fieldSeen[workflowassignment.FieldRole]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldRole)
				fieldSeen[workflowassignment.FieldRole] = struct{}{}
			}
		case "label":
			if _, ok := fieldSeen[workflowassignment.FieldLabel]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldLabel)
				fieldSeen[workflowassignment.FieldLabel] = struct{}{}
			}
		case "required":
			if _, ok := fieldSeen[workflowassignment.FieldRequired]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldRequired)
				fieldSeen[workflowassignment.FieldRequired] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[workflowassignment.FieldStatus]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldStatus)
				fieldSeen[workflowassignment.FieldStatus] = struct{}{}
			}
		case "metadata":
			if _, ok := fieldSeen[workflowassignment.FieldMetadata]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldMetadata)
				fieldSeen[workflowassignment.FieldMetadata] = struct{}{}
			}
		case "decidedAt":
			if _, ok := fieldSeen[workflowassignment.FieldDecidedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldDecidedAt)
				fieldSeen[workflowassignment.FieldDecidedAt] = struct{}{}
			}
		case "actorUserID":
			if _, ok := fieldSeen[workflowassignment.FieldActorUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorUserID)
				fieldSeen[workflowassignment.FieldActorUserID] = struct{}{}
			}
		case "actorGroupID":
			if _, ok := fieldSeen[workflowassignment.FieldActorGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldActorGroupID)
				fieldSeen[workflowassignment.FieldActorGroupID] = struct{}{}
			}
		case "notes":
			if _, ok := fieldSeen[workflowassignment.FieldNotes]; !ok {
				selectedFields = append(selectedFields, workflowassignment.FieldNotes)
				fieldSeen[workflowassignment.FieldNotes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowassignmentPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowAssignmentPaginateOption
}

func newWorkflowAssignmentPaginateArgs(rv map[string]any) *workflowassignmentPaginateArgs {
	args := &workflowassignmentPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowAssignmentOrder:
			args.opts = append(args.opts, WithWorkflowAssignmentOrder(v))
		case []any:
			var orders []*WorkflowAssignmentOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowAssignmentOrder{Field: &WorkflowAssignmentOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowAssignmentOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowAssignmentWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowAssignmentFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowAssignmentTargetQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowAssignmentTargetQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowAssignmentTargetQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowassignmenttarget.Columns))
		selectedFields = []string{workflowassignmenttarget.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldOwnerID)
				fieldSeen[workflowassignmenttarget.FieldOwnerID] = struct{}{}
			}

		case "workflowAssignment":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowassignmentImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowAssignment = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldWorkflowAssignmentID)
				fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID] = struct{}{}
			}

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetUserID)
				fieldSeen[workflowassignmenttarget.FieldTargetUserID] = struct{}{}
			}

		case "group":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
				return err
			}
			_q.withGroup = query
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetGroupID)
				fieldSeen[workflowassignmenttarget.FieldTargetGroupID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldCreatedAt)
				fieldSeen[workflowassignmenttarget.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldUpdatedAt)
				fieldSeen[workflowassignmenttarget.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldCreatedBy)
				fieldSeen[workflowassignmenttarget.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldUpdatedBy)
				fieldSeen[workflowassignmenttarget.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldDisplayID)
				fieldSeen[workflowassignmenttarget.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTags)
				fieldSeen[workflowassignmenttarget.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldOwnerID)
				fieldSeen[workflowassignmenttarget.FieldOwnerID] = struct{}{}
			}
		case "workflowAssignmentID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldWorkflowAssignmentID)
				fieldSeen[workflowassignmenttarget.FieldWorkflowAssignmentID] = struct{}{}
			}
		case "targetType":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetType]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetType)
				fieldSeen[workflowassignmenttarget.FieldTargetType] = struct{}{}
			}
		case "targetUserID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetUserID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetUserID)
				fieldSeen[workflowassignmenttarget.FieldTargetUserID] = struct{}{}
			}
		case "targetGroupID":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldTargetGroupID]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldTargetGroupID)
				fieldSeen[workflowassignmenttarget.FieldTargetGroupID] = struct{}{}
			}
		case "resolverKey":
			if _, ok := fieldSeen[workflowassignmenttarget.FieldResolverKey]; !ok {
				selectedFields = append(selectedFields, workflowassignmenttarget.FieldResolverKey)
				fieldSeen[workflowassignmenttarget.FieldResolverKey] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowassignmenttargetPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowAssignmentTargetPaginateOption
}

func newWorkflowAssignmentTargetPaginateArgs(rv map[string]any) *workflowassignmenttargetPaginateArgs {
	args := &workflowassignmenttargetPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowAssignmentTargetOrder:
			args.opts = append(args.opts, WithWorkflowAssignmentTargetOrder(v))
		case []any:
			var orders []*WorkflowAssignmentTargetOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowAssignmentTargetOrder{Field: &WorkflowAssignmentTargetOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowAssignmentTargetOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowAssignmentTargetWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowAssignmentTargetFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowDefinitionQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowDefinitionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowDefinitionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowdefinition.Columns))
		selectedFields = []string{workflowdefinition.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldOwnerID)
				fieldSeen[workflowdefinition.FieldOwnerID] = struct{}{}
			}

		case "tagDefinitions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TagDefinitionClient{config: _q.config}).Query()
			)
			args := newTagDefinitionPaginateArgs(fieldArgs(ctx, new(TagDefinitionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTagDefinitionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowDefinition) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_definition_tag_definitions"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowdefinition.TagDefinitionsColumn), ids...))
						})
						if err := query.GroupBy(workflowdefinition.TagDefinitionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowDefinition) error {
						for i := range nodes {
							n := len(nodes[i].Edges.TagDefinitions)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tagdefinitionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowdefinition.TagDefinitionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTagDefinitions(alias, func(wq *TagDefinitionQuery) {
				*wq = *query
			})

		case "groups":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&GroupClient{config: _q.config}).Query()
			)
			args := newGroupPaginateArgs(fieldArgs(ctx, new(GroupWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newGroupPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowDefinition) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_definition_groups"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowdefinition.GroupsColumn), ids...))
						})
						if err := query.GroupBy(workflowdefinition.GroupsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowDefinition) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Groups)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, groupImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowdefinition.GroupsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedGroups(alias, func(wq *GroupQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[workflowdefinition.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldCreatedAt)
				fieldSeen[workflowdefinition.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowdefinition.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldUpdatedAt)
				fieldSeen[workflowdefinition.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowdefinition.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldCreatedBy)
				fieldSeen[workflowdefinition.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowdefinition.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldUpdatedBy)
				fieldSeen[workflowdefinition.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowdefinition.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDisplayID)
				fieldSeen[workflowdefinition.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowdefinition.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldTags)
				fieldSeen[workflowdefinition.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowdefinition.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldOwnerID)
				fieldSeen[workflowdefinition.FieldOwnerID] = struct{}{}
			}
		case "systemOwned":
			if _, ok := fieldSeen[workflowdefinition.FieldSystemOwned]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldSystemOwned)
				fieldSeen[workflowdefinition.FieldSystemOwned] = struct{}{}
			}
		case "internalNotes":
			if _, ok := fieldSeen[workflowdefinition.FieldInternalNotes]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldInternalNotes)
				fieldSeen[workflowdefinition.FieldInternalNotes] = struct{}{}
			}
		case "systemInternalID":
			if _, ok := fieldSeen[workflowdefinition.FieldSystemInternalID]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldSystemInternalID)
				fieldSeen[workflowdefinition.FieldSystemInternalID] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[workflowdefinition.FieldName]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldName)
				fieldSeen[workflowdefinition.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[workflowdefinition.FieldDescription]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDescription)
				fieldSeen[workflowdefinition.FieldDescription] = struct{}{}
			}
		case "workflowKind":
			if _, ok := fieldSeen[workflowdefinition.FieldWorkflowKind]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldWorkflowKind)
				fieldSeen[workflowdefinition.FieldWorkflowKind] = struct{}{}
			}
		case "schemaType":
			if _, ok := fieldSeen[workflowdefinition.FieldSchemaType]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldSchemaType)
				fieldSeen[workflowdefinition.FieldSchemaType] = struct{}{}
			}
		case "revision":
			if _, ok := fieldSeen[workflowdefinition.FieldRevision]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldRevision)
				fieldSeen[workflowdefinition.FieldRevision] = struct{}{}
			}
		case "draft":
			if _, ok := fieldSeen[workflowdefinition.FieldDraft]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDraft)
				fieldSeen[workflowdefinition.FieldDraft] = struct{}{}
			}
		case "publishedAt":
			if _, ok := fieldSeen[workflowdefinition.FieldPublishedAt]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldPublishedAt)
				fieldSeen[workflowdefinition.FieldPublishedAt] = struct{}{}
			}
		case "cooldownSeconds":
			if _, ok := fieldSeen[workflowdefinition.FieldCooldownSeconds]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldCooldownSeconds)
				fieldSeen[workflowdefinition.FieldCooldownSeconds] = struct{}{}
			}
		case "isDefault":
			if _, ok := fieldSeen[workflowdefinition.FieldIsDefault]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldIsDefault)
				fieldSeen[workflowdefinition.FieldIsDefault] = struct{}{}
			}
		case "active":
			if _, ok := fieldSeen[workflowdefinition.FieldActive]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldActive)
				fieldSeen[workflowdefinition.FieldActive] = struct{}{}
			}
		case "definitionJSON":
			if _, ok := fieldSeen[workflowdefinition.FieldDefinitionJSON]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldDefinitionJSON)
				fieldSeen[workflowdefinition.FieldDefinitionJSON] = struct{}{}
			}
		case "trackedFields":
			if _, ok := fieldSeen[workflowdefinition.FieldTrackedFields]; !ok {
				selectedFields = append(selectedFields, workflowdefinition.FieldTrackedFields)
				fieldSeen[workflowdefinition.FieldTrackedFields] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowdefinitionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowDefinitionPaginateOption
}

func newWorkflowDefinitionPaginateArgs(rv map[string]any) *workflowdefinitionPaginateArgs {
	args := &workflowdefinitionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowDefinitionOrder:
			args.opts = append(args.opts, WithWorkflowDefinitionOrder(v))
		case []any:
			var orders []*WorkflowDefinitionOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowDefinitionOrder{Field: &WorkflowDefinitionOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowDefinitionOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowDefinitionWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowDefinitionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowEventQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowEventQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowEventQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowevent.Columns))
		selectedFields = []string{workflowevent.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowevent.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldOwnerID)
				fieldSeen[workflowevent.FieldOwnerID] = struct{}{}
			}

		case "workflowInstance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowInstance = query
			if _, ok := fieldSeen[workflowevent.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldWorkflowInstanceID)
				fieldSeen[workflowevent.FieldWorkflowInstanceID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowevent.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldCreatedAt)
				fieldSeen[workflowevent.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowevent.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldUpdatedAt)
				fieldSeen[workflowevent.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowevent.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldCreatedBy)
				fieldSeen[workflowevent.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowevent.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldUpdatedBy)
				fieldSeen[workflowevent.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowevent.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldDisplayID)
				fieldSeen[workflowevent.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowevent.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldTags)
				fieldSeen[workflowevent.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowevent.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldOwnerID)
				fieldSeen[workflowevent.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowevent.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldWorkflowInstanceID)
				fieldSeen[workflowevent.FieldWorkflowInstanceID] = struct{}{}
			}
		case "eventType":
			if _, ok := fieldSeen[workflowevent.FieldEventType]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldEventType)
				fieldSeen[workflowevent.FieldEventType] = struct{}{}
			}
		case "payload":
			if _, ok := fieldSeen[workflowevent.FieldPayload]; !ok {
				selectedFields = append(selectedFields, workflowevent.FieldPayload)
				fieldSeen[workflowevent.FieldPayload] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workfloweventPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowEventPaginateOption
}

func newWorkflowEventPaginateArgs(rv map[string]any) *workfloweventPaginateArgs {
	args := &workfloweventPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowEventOrder:
			args.opts = append(args.opts, WithWorkflowEventOrder(v))
		case []any:
			var orders []*WorkflowEventOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowEventOrder{Field: &WorkflowEventOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowEventOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowEventWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowEventFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowInstanceQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowInstanceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowInstanceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowinstance.Columns))
		selectedFields = []string{workflowinstance.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowinstance.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldOwnerID)
				fieldSeen[workflowinstance.FieldOwnerID] = struct{}{}
			}

		case "workflowDefinition":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowDefinitionClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowdefinitionImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowDefinition = query
			if _, ok := fieldSeen[workflowinstance.FieldWorkflowDefinitionID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldWorkflowDefinitionID)
				fieldSeen[workflowinstance.FieldWorkflowDefinitionID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[workflowinstance.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldControlID)
				fieldSeen[workflowinstance.FieldControlID] = struct{}{}
			}

		case "internalPolicy":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicy = query
			if _, ok := fieldSeen[workflowinstance.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldInternalPolicyID)
				fieldSeen[workflowinstance.FieldInternalPolicyID] = struct{}{}
			}

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
				return err
			}
			_q.withEvidence = query
			if _, ok := fieldSeen[workflowinstance.FieldEvidenceID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldEvidenceID)
				fieldSeen[workflowinstance.FieldEvidenceID] = struct{}{}
			}

		case "subcontrol":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrol = query
			if _, ok := fieldSeen[workflowinstance.FieldSubcontrolID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldSubcontrolID)
				fieldSeen[workflowinstance.FieldSubcontrolID] = struct{}{}
			}

		case "actionPlan":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
				return err
			}
			_q.withActionPlan = query
			if _, ok := fieldSeen[workflowinstance.FieldActionPlanID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldActionPlanID)
				fieldSeen[workflowinstance.FieldActionPlanID] = struct{}{}
			}

		case "procedure":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
				return err
			}
			_q.withProcedure = query
			if _, ok := fieldSeen[workflowinstance.FieldProcedureID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldProcedureID)
				fieldSeen[workflowinstance.FieldProcedureID] = struct{}{}
			}

		case "workflowAssignments":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowAssignmentClient{config: _q.config}).Query()
			)
			args := newWorkflowAssignmentPaginateArgs(fieldArgs(ctx, new(WorkflowAssignmentWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowAssignmentPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowInstance) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_instance_workflow_assignments"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowinstance.WorkflowAssignmentsColumn), ids...))
						})
						if err := query.GroupBy(workflowinstance.WorkflowAssignmentsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowInstance) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowAssignments)
							if nodes[i].Edges.totalCount[8] == nil {
								nodes[i].Edges.totalCount[8] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[8][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowassignmentImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowinstance.WorkflowAssignmentsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowAssignments(alias, func(wq *WorkflowAssignmentQuery) {
				*wq = *query
			})

		case "workflowEvents":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowEventClient{config: _q.config}).Query()
			)
			args := newWorkflowEventPaginateArgs(fieldArgs(ctx, new(WorkflowEventWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowEventPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowInstance) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_instance_workflow_events"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowinstance.WorkflowEventsColumn), ids...))
						})
						if err := query.GroupBy(workflowinstance.WorkflowEventsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowInstance) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowEvents)
							if nodes[i].Edges.totalCount[9] == nil {
								nodes[i].Edges.totalCount[9] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[9][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workfloweventImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowinstance.WorkflowEventsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowEvents(alias, func(wq *WorkflowEventQuery) {
				*wq = *query
			})

		case "workflowObjectRefs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowObjectRefClient{config: _q.config}).Query()
			)
			args := newWorkflowObjectRefPaginateArgs(fieldArgs(ctx, new(WorkflowObjectRefWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newWorkflowObjectRefPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*WorkflowInstance) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID string `sql:"workflow_instance_workflow_object_refs"`
							Count  int    `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(workflowinstance.WorkflowObjectRefsColumn), ids...))
						})
						if err := query.GroupBy(workflowinstance.WorkflowObjectRefsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[string]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*WorkflowInstance) error {
						for i := range nodes {
							n := len(nodes[i].Edges.WorkflowObjectRefs)
							if nodes[i].Edges.totalCount[10] == nil {
								nodes[i].Edges.totalCount[10] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[10][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, workflowobjectrefImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(workflowinstance.WorkflowObjectRefsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedWorkflowObjectRefs(alias, func(wq *WorkflowObjectRefQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[workflowinstance.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldCreatedAt)
				fieldSeen[workflowinstance.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowinstance.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldUpdatedAt)
				fieldSeen[workflowinstance.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowinstance.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldCreatedBy)
				fieldSeen[workflowinstance.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowinstance.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldUpdatedBy)
				fieldSeen[workflowinstance.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowinstance.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldDisplayID)
				fieldSeen[workflowinstance.FieldDisplayID] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[workflowinstance.FieldTags]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldTags)
				fieldSeen[workflowinstance.FieldTags] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowinstance.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldOwnerID)
				fieldSeen[workflowinstance.FieldOwnerID] = struct{}{}
			}
		case "workflowDefinitionID":
			if _, ok := fieldSeen[workflowinstance.FieldWorkflowDefinitionID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldWorkflowDefinitionID)
				fieldSeen[workflowinstance.FieldWorkflowDefinitionID] = struct{}{}
			}
		case "workflowProposalID":
			if _, ok := fieldSeen[workflowinstance.FieldWorkflowProposalID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldWorkflowProposalID)
				fieldSeen[workflowinstance.FieldWorkflowProposalID] = struct{}{}
			}
		case "state":
			if _, ok := fieldSeen[workflowinstance.FieldState]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldState)
				fieldSeen[workflowinstance.FieldState] = struct{}{}
			}
		case "context":
			if _, ok := fieldSeen[workflowinstance.FieldContext]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldContext)
				fieldSeen[workflowinstance.FieldContext] = struct{}{}
			}
		case "lastEvaluatedAt":
			if _, ok := fieldSeen[workflowinstance.FieldLastEvaluatedAt]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldLastEvaluatedAt)
				fieldSeen[workflowinstance.FieldLastEvaluatedAt] = struct{}{}
			}
		case "definitionSnapshot":
			if _, ok := fieldSeen[workflowinstance.FieldDefinitionSnapshot]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldDefinitionSnapshot)
				fieldSeen[workflowinstance.FieldDefinitionSnapshot] = struct{}{}
			}
		case "currentActionIndex":
			if _, ok := fieldSeen[workflowinstance.FieldCurrentActionIndex]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldCurrentActionIndex)
				fieldSeen[workflowinstance.FieldCurrentActionIndex] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[workflowinstance.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldControlID)
				fieldSeen[workflowinstance.FieldControlID] = struct{}{}
			}
		case "internalPolicyID":
			if _, ok := fieldSeen[workflowinstance.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldInternalPolicyID)
				fieldSeen[workflowinstance.FieldInternalPolicyID] = struct{}{}
			}
		case "evidenceID":
			if _, ok := fieldSeen[workflowinstance.FieldEvidenceID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldEvidenceID)
				fieldSeen[workflowinstance.FieldEvidenceID] = struct{}{}
			}
		case "subcontrolID":
			if _, ok := fieldSeen[workflowinstance.FieldSubcontrolID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldSubcontrolID)
				fieldSeen[workflowinstance.FieldSubcontrolID] = struct{}{}
			}
		case "actionPlanID":
			if _, ok := fieldSeen[workflowinstance.FieldActionPlanID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldActionPlanID)
				fieldSeen[workflowinstance.FieldActionPlanID] = struct{}{}
			}
		case "procedureID":
			if _, ok := fieldSeen[workflowinstance.FieldProcedureID]; !ok {
				selectedFields = append(selectedFields, workflowinstance.FieldProcedureID)
				fieldSeen[workflowinstance.FieldProcedureID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowinstancePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowInstancePaginateOption
}

func newWorkflowInstancePaginateArgs(rv map[string]any) *workflowinstancePaginateArgs {
	args := &workflowinstancePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowInstanceOrder:
			args.opts = append(args.opts, WithWorkflowInstanceOrder(v))
		case []any:
			var orders []*WorkflowInstanceOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowInstanceOrder{Field: &WorkflowInstanceOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowInstanceOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowInstanceWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowInstanceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *WorkflowObjectRefQuery) CollectFields(ctx context.Context, satisfies ...string) (*WorkflowObjectRefQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *WorkflowObjectRefQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(workflowobjectref.Columns))
		selectedFields = []string{workflowobjectref.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&OrganizationClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, organizationImplementors)...); err != nil {
				return err
			}
			_q.withOwner = query
			if _, ok := fieldSeen[workflowobjectref.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldOwnerID)
				fieldSeen[workflowobjectref.FieldOwnerID] = struct{}{}
			}

		case "workflowInstance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&WorkflowInstanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, workflowinstanceImplementors)...); err != nil {
				return err
			}
			_q.withWorkflowInstance = query
			if _, ok := fieldSeen[workflowobjectref.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldWorkflowInstanceID)
				fieldSeen[workflowobjectref.FieldWorkflowInstanceID] = struct{}{}
			}

		case "control":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ControlClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, controlImplementors)...); err != nil {
				return err
			}
			_q.withControl = query
			if _, ok := fieldSeen[workflowobjectref.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldControlID)
				fieldSeen[workflowobjectref.FieldControlID] = struct{}{}
			}

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			_q.withTask = query
			if _, ok := fieldSeen[workflowobjectref.FieldTaskID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldTaskID)
				fieldSeen[workflowobjectref.FieldTaskID] = struct{}{}
			}

		case "internalPolicy":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&InternalPolicyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, internalpolicyImplementors)...); err != nil {
				return err
			}
			_q.withInternalPolicy = query
			if _, ok := fieldSeen[workflowobjectref.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldInternalPolicyID)
				fieldSeen[workflowobjectref.FieldInternalPolicyID] = struct{}{}
			}

		case "finding":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FindingClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, findingImplementors)...); err != nil {
				return err
			}
			_q.withFinding = query
			if _, ok := fieldSeen[workflowobjectref.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldFindingID)
				fieldSeen[workflowobjectref.FieldFindingID] = struct{}{}
			}

		case "directoryAccount":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryAccountClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directoryaccountImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryAccount = query
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryAccountID)
				fieldSeen[workflowobjectref.FieldDirectoryAccountID] = struct{}{}
			}

		case "directoryGroup":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryGroupClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorygroupImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryGroup = query
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryGroupID)
				fieldSeen[workflowobjectref.FieldDirectoryGroupID] = struct{}{}
			}

		case "directoryMembership":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DirectoryMembershipClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, directorymembershipImplementors)...); err != nil {
				return err
			}
			_q.withDirectoryMembership = query
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryMembershipID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryMembershipID)
				fieldSeen[workflowobjectref.FieldDirectoryMembershipID] = struct{}{}
			}

		case "evidence":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&EvidenceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, evidenceImplementors)...); err != nil {
				return err
			}
			_q.withEvidence = query
			if _, ok := fieldSeen[workflowobjectref.FieldEvidenceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldEvidenceID)
				fieldSeen[workflowobjectref.FieldEvidenceID] = struct{}{}
			}

		case "subcontrol":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&SubcontrolClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, subcontrolImplementors)...); err != nil {
				return err
			}
			_q.withSubcontrol = query
			if _, ok := fieldSeen[workflowobjectref.FieldSubcontrolID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldSubcontrolID)
				fieldSeen[workflowobjectref.FieldSubcontrolID] = struct{}{}
			}

		case "actionPlan":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ActionPlanClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, actionplanImplementors)...); err != nil {
				return err
			}
			_q.withActionPlan = query
			if _, ok := fieldSeen[workflowobjectref.FieldActionPlanID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldActionPlanID)
				fieldSeen[workflowobjectref.FieldActionPlanID] = struct{}{}
			}

		case "procedure":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProcedureClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, procedureImplementors)...); err != nil {
				return err
			}
			_q.withProcedure = query
			if _, ok := fieldSeen[workflowobjectref.FieldProcedureID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldProcedureID)
				fieldSeen[workflowobjectref.FieldProcedureID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[workflowobjectref.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldCreatedAt)
				fieldSeen[workflowobjectref.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[workflowobjectref.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldUpdatedAt)
				fieldSeen[workflowobjectref.FieldUpdatedAt] = struct{}{}
			}
		case "createdBy":
			if _, ok := fieldSeen[workflowobjectref.FieldCreatedBy]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldCreatedBy)
				fieldSeen[workflowobjectref.FieldCreatedBy] = struct{}{}
			}
		case "updatedBy":
			if _, ok := fieldSeen[workflowobjectref.FieldUpdatedBy]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldUpdatedBy)
				fieldSeen[workflowobjectref.FieldUpdatedBy] = struct{}{}
			}
		case "displayID":
			if _, ok := fieldSeen[workflowobjectref.FieldDisplayID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDisplayID)
				fieldSeen[workflowobjectref.FieldDisplayID] = struct{}{}
			}
		case "ownerID":
			if _, ok := fieldSeen[workflowobjectref.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldOwnerID)
				fieldSeen[workflowobjectref.FieldOwnerID] = struct{}{}
			}
		case "workflowInstanceID":
			if _, ok := fieldSeen[workflowobjectref.FieldWorkflowInstanceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldWorkflowInstanceID)
				fieldSeen[workflowobjectref.FieldWorkflowInstanceID] = struct{}{}
			}
		case "controlID":
			if _, ok := fieldSeen[workflowobjectref.FieldControlID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldControlID)
				fieldSeen[workflowobjectref.FieldControlID] = struct{}{}
			}
		case "taskID":
			if _, ok := fieldSeen[workflowobjectref.FieldTaskID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldTaskID)
				fieldSeen[workflowobjectref.FieldTaskID] = struct{}{}
			}
		case "internalPolicyID":
			if _, ok := fieldSeen[workflowobjectref.FieldInternalPolicyID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldInternalPolicyID)
				fieldSeen[workflowobjectref.FieldInternalPolicyID] = struct{}{}
			}
		case "findingID":
			if _, ok := fieldSeen[workflowobjectref.FieldFindingID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldFindingID)
				fieldSeen[workflowobjectref.FieldFindingID] = struct{}{}
			}
		case "directoryAccountID":
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryAccountID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryAccountID)
				fieldSeen[workflowobjectref.FieldDirectoryAccountID] = struct{}{}
			}
		case "directoryGroupID":
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryGroupID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryGroupID)
				fieldSeen[workflowobjectref.FieldDirectoryGroupID] = struct{}{}
			}
		case "directoryMembershipID":
			if _, ok := fieldSeen[workflowobjectref.FieldDirectoryMembershipID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldDirectoryMembershipID)
				fieldSeen[workflowobjectref.FieldDirectoryMembershipID] = struct{}{}
			}
		case "evidenceID":
			if _, ok := fieldSeen[workflowobjectref.FieldEvidenceID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldEvidenceID)
				fieldSeen[workflowobjectref.FieldEvidenceID] = struct{}{}
			}
		case "subcontrolID":
			if _, ok := fieldSeen[workflowobjectref.FieldSubcontrolID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldSubcontrolID)
				fieldSeen[workflowobjectref.FieldSubcontrolID] = struct{}{}
			}
		case "actionPlanID":
			if _, ok := fieldSeen[workflowobjectref.FieldActionPlanID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldActionPlanID)
				fieldSeen[workflowobjectref.FieldActionPlanID] = struct{}{}
			}
		case "procedureID":
			if _, ok := fieldSeen[workflowobjectref.FieldProcedureID]; !ok {
				selectedFields = append(selectedFields, workflowobjectref.FieldProcedureID)
				fieldSeen[workflowobjectref.FieldProcedureID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type workflowobjectrefPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []WorkflowObjectRefPaginateOption
}

func newWorkflowObjectRefPaginateArgs(rv map[string]any) *workflowobjectrefPaginateArgs {
	args := &workflowobjectrefPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*WorkflowObjectRefOrder:
			args.opts = append(args.opts, WithWorkflowObjectRefOrder(v))
		case []any:
			var orders []*WorkflowObjectRefOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &WorkflowObjectRefOrder{Field: &WorkflowObjectRefOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithWorkflowObjectRefOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*WorkflowObjectRefWhereInput); ok {
		args.opts = append(args.opts, WithWorkflowObjectRefFilter(v.Filter))
	}
	return args
}

const (
	afterField     = "after"
	firstField     = "first"
	beforeField    = "before"
	lastField      = "last"
	orderByField   = "orderBy"
	directionField = "direction"
	fieldField     = "field"
	whereField     = "where"
)

func fieldArgs(ctx context.Context, whereInput any, path ...string) map[string]any {
	field := collectedField(ctx, path...)
	if field == nil || field.Arguments == nil {
		return nil
	}
	oc := graphql.GetOperationContext(ctx)
	args := field.ArgumentMap(oc.Variables)
	return unmarshalArgs(ctx, whereInput, args)
}

// unmarshalArgs allows extracting the field arguments from their raw representation.
func unmarshalArgs(ctx context.Context, whereInput any, args map[string]any) map[string]any {
	for _, k := range []string{firstField, lastField} {
		v, ok := args[k]
		if !ok || v == nil {
			continue
		}
		i, err := graphql.UnmarshalInt(v)
		if err == nil {
			args[k] = &i
		}
	}
	for _, k := range []string{beforeField, afterField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		c := &Cursor{}
		if c.UnmarshalGQL(v) == nil {
			args[k] = c
		}
	}
	if v, ok := args[whereField]; ok && whereInput != nil {
		if err := graphql.UnmarshalInputFromContext(ctx, v, whereInput); err == nil {
			args[whereField] = whereInput
		}
	}

	return args
}

// mayAddCondition appends another type condition to the satisfies list
// if it does not exist in the list.
func mayAddCondition(satisfies []string, typeCond []string) []string {
Cond:
	for _, c := range typeCond {
		for _, s := range satisfies {
			if c == s {
				continue Cond
			}
		}
		satisfies = append(satisfies, c)
	}
	return satisfies
}
